{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. 预测全家桶与机器学习四大神器"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attrition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Catboost"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train=pd.read_csv('~/data/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('~/data/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import catboost as cb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model = cb.CatBoostClassifier(iterations=1000, \n",
    "                              depth=7, \n",
    "                              learning_rate=0.01, \n",
    "                              loss_function='Logloss', \n",
    "                              eval_metric='AUC',\n",
    "                              logging_level='Verbose', \n",
    "                              metric_period=50\n",
    "                             )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# 得到分类特征的列号\n",
    "categorical_features_indices = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    if X_train.columns.values[i] in attr:\n",
    "        categorical_features_indices.append(i)\n",
    "print(categorical_features_indices)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 3, 5, 6, 9, 13, 15, 19, 20]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=categorical_features_indices)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\ttest: 0.6390374\tbest: 0.6390374 (0)\ttotal: 65.8ms\tremaining: 1m 5s\n",
      "50:\ttest: 0.7893703\tbest: 0.7893703 (50)\ttotal: 216ms\tremaining: 4.01s\n",
      "100:\ttest: 0.7950453\tbest: 0.7950453 (100)\ttotal: 386ms\tremaining: 3.44s\n",
      "150:\ttest: 0.8011568\tbest: 0.8011568 (150)\ttotal: 560ms\tremaining: 3.15s\n",
      "200:\ttest: 0.7958092\tbest: 0.8011568 (150)\ttotal: 752ms\tremaining: 2.99s\n",
      "250:\ttest: 0.8023573\tbest: 0.8023573 (250)\ttotal: 947ms\tremaining: 2.82s\n",
      "300:\ttest: 0.8034487\tbest: 0.8034487 (300)\ttotal: 1.12s\tremaining: 2.6s\n",
      "350:\ttest: 0.8046491\tbest: 0.8046491 (350)\ttotal: 1.3s\tremaining: 2.4s\n",
      "400:\ttest: 0.8030121\tbest: 0.8046491 (350)\ttotal: 1.53s\tremaining: 2.29s\n",
      "450:\ttest: 0.8054131\tbest: 0.8054131 (450)\ttotal: 1.73s\tremaining: 2.11s\n",
      "500:\ttest: 0.8067227\tbest: 0.8067227 (500)\ttotal: 1.93s\tremaining: 1.92s\n",
      "550:\ttest: 0.8062862\tbest: 0.8067227 (500)\ttotal: 2.1s\tremaining: 1.72s\n",
      "600:\ttest: 0.8056313\tbest: 0.8067227 (500)\ttotal: 2.29s\tremaining: 1.52s\n",
      "650:\ttest: 0.8053039\tbest: 0.8067227 (500)\ttotal: 2.47s\tremaining: 1.32s\n",
      "700:\ttest: 0.8061770\tbest: 0.8067227 (500)\ttotal: 2.67s\tremaining: 1.14s\n",
      "750:\ttest: 0.8082506\tbest: 0.8082506 (750)\ttotal: 2.84s\tremaining: 941ms\n",
      "800:\ttest: 0.8072684\tbest: 0.8082506 (750)\ttotal: 3.04s\tremaining: 755ms\n",
      "850:\ttest: 0.8073775\tbest: 0.8082506 (750)\ttotal: 3.23s\tremaining: 566ms\n",
      "900:\ttest: 0.8084688\tbest: 0.8084688 (900)\ttotal: 3.43s\tremaining: 377ms\n",
      "950:\ttest: 0.8092328\tbest: 0.8092328 (950)\ttotal: 3.62s\tremaining: 187ms\n",
      "999:\ttest: 0.8105424\tbest: 0.8105424 (999)\ttotal: 3.83s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8105423988\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fe2a0788a10>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#model = cb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test)\n",
    "#predict = model.predict_proba(test)\n",
    "#print(predict)\n",
    "test['Attrition']=predict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "## 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['Attrition']].to_csv('~/data/course_data/submit_cb.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### GBDT"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train=pd.read_csv('~/data/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('~/data/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# 采用回归算法，可以得到更好的AUC结果\n",
    "model = GradientBoostingRegressor(random_state=10)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(test)\n",
    "print(predict)\n",
    "test['Attrition']=predict\n",
    "#print(predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1.01678366e-01  4.47445681e-02  1.42121556e-01  7.57204880e-02\n",
      "  7.03200210e-01  3.70055651e-01  3.74376235e-01  4.37242139e-02\n",
      " -1.15634448e-01  2.97987772e-01  1.20779518e-01  1.09366950e-01\n",
      "  1.07679394e-01  7.66600582e-01  7.51844882e-02 -4.76111832e-02\n",
      "  4.28285053e-02 -1.09673242e-02  1.59486732e-01  9.62417811e-02\n",
      "  6.47325348e-01  1.10040397e-01 -9.94554567e-03 -4.55439809e-02\n",
      "  2.68815031e-01  3.37430996e-01  7.35105859e-02  1.06048931e-01\n",
      "  5.50770434e-01  4.15464265e-02  1.79826162e-01  1.01207422e-03\n",
      "  1.58722155e-01  1.58671176e-01  8.62998751e-02  2.67636183e-02\n",
      "  1.24005756e-01  9.94003577e-02  8.73177129e-02  1.59141438e-03\n",
      "  3.02853331e-02 -5.02317582e-03 -2.69498786e-03  8.75329962e-03\n",
      "  3.69313030e-02  5.03418977e-01  2.62794122e-01 -1.16559089e-02\n",
      "  8.28838190e-01  4.78927949e-01  2.30745577e-01  3.61855221e-01\n",
      "  1.97193403e-01  2.08480315e-01  4.27257886e-01  7.31510619e-02\n",
      " -4.10414290e-02  1.41280282e-01 -5.16541193e-02  4.63709471e-01\n",
      "  8.91047041e-03  1.57167715e-01  1.84855334e-01  1.13116428e-01\n",
      "  4.46265354e-01  1.00820826e-01  7.08375330e-02  6.37916953e-02\n",
      "  7.90271693e-02  3.50858142e-01  8.43984002e-02  2.85213179e-01\n",
      "  1.04485698e-01  1.20758657e-02  3.51095480e-02  8.00985610e-02\n",
      "  6.84449166e-02  1.13112977e-01  1.77433366e-01 -2.05739435e-02\n",
      " -4.76577275e-02  1.29302613e-02  3.32325238e-02  1.18673501e-01\n",
      "  5.91157913e-02  7.93768217e-02  6.01967826e-02  1.57592456e-01\n",
      "  6.66959752e-02  6.90960977e-02  4.96217528e-01  3.57899272e-02\n",
      "  1.39515858e-01  2.40791672e-01 -7.51708010e-02  6.94081026e-02\n",
      "  9.39873785e-02  3.21196083e-01 -4.76763552e-02  1.34821474e-02\n",
      "  2.19062667e-01  3.66039069e-01  3.44431854e-01  3.26254249e-02\n",
      " -1.90729947e-02  2.26095477e-02  1.04759230e-01  3.21919749e-01\n",
      "  5.20608898e-01  5.92291999e-02  2.76918434e-01  1.50335871e-01\n",
      " -2.32225872e-02  1.37745337e-01  7.02121029e-02  2.40504156e-02\n",
      " -1.83350362e-02  1.10830730e-01  4.37648859e-02 -6.21781805e-02\n",
      "  3.02702114e-02 -4.43218432e-03  1.99606416e-02  7.92852082e-01\n",
      "  3.00599518e-01  1.11339129e-01  6.41440161e-02  7.71254026e-02\n",
      "  8.88823641e-02  4.38784724e-02  7.20951064e-02  6.81299346e-01\n",
      "  4.45871282e-01  2.86304938e-01  3.35873763e-01  2.66461924e-01\n",
      "  3.68630236e-01  1.15704982e-01  8.92148111e-02  2.77847112e-01\n",
      "  2.01300768e-02  1.14969206e-01  1.57500157e-01  6.80522005e-02\n",
      "  2.32527064e-01  1.00925834e-02  6.68175914e-02  1.01203833e-01\n",
      "  1.53286650e-01 -4.04768746e-02 -1.66495630e-02  1.67942188e-01\n",
      "  6.05068896e-02  1.47024077e-01  4.82134726e-02  1.82307956e-02\n",
      "  2.78127362e-01  1.95225871e-01  8.52037177e-02 -4.86623546e-02\n",
      "  2.53996999e-01 -4.15455092e-02  3.25779791e-01  5.73075378e-01\n",
      "  2.07987130e-02  1.49099988e-01  3.15818350e-01 -2.40181674e-05\n",
      " -3.90114920e-02  9.46526743e-03  7.89657435e-02  8.87631693e-02\n",
      "  3.21649488e-02  1.93424518e-01  1.95749300e-01  3.31933538e-01\n",
      "  6.92359788e-02  3.06183063e-01  3.14928530e-01  1.55234252e-01\n",
      " -1.51408728e-02  1.88543423e-03  1.98220305e-02  6.86230677e-01\n",
      " -1.13091623e-02  1.57242051e-02  1.97955143e-01  2.36289404e-02\n",
      "  2.60205033e-01  1.32609768e-01  2.51464113e-01  7.41649588e-01\n",
      "  6.43095075e-02 -5.44132338e-02  1.32196173e-01  2.02623984e-01\n",
      "  8.47459908e-02  4.08807947e-02  5.58523111e-01  2.46524114e-02\n",
      "  2.43820956e-01  1.24861506e-01  1.58939457e-01  7.54770988e-03\n",
      "  7.92706304e-02  1.81286089e-01  4.30835527e-01 -3.80002905e-02\n",
      "  8.28918966e-02  1.47852343e-02  9.80401111e-02  1.94043180e-02\n",
      "  1.76909921e-02  9.43626951e-02  5.23583141e-02 -1.54912709e-02\n",
      "  4.83923119e-02  2.76540997e-01  5.03204846e-02  9.20246367e-01\n",
      "  8.07185777e-02  4.12035468e-01  5.09187992e-01  1.68638791e-01\n",
      "  2.80326779e-01 -1.08722422e-02  5.28288273e-02  3.70142537e-01\n",
      "  7.63654128e-01  2.13252369e-01 -7.84403781e-03  4.43898956e-01\n",
      " -1.39441774e-02  2.56857775e-02  7.14615543e-03  2.85003120e-01\n",
      "  4.64692435e-01 -9.25899031e-02  9.78737627e-02  8.90592044e-02\n",
      "  1.11027278e-01  1.05783790e-01  1.43637917e-02  9.55080031e-02\n",
      "  7.20672477e-02  4.54912103e-02  3.96397638e-02  4.13056135e-01\n",
      "  1.83594979e-02  1.28774900e-01  1.99024506e-01  1.38500037e-01\n",
      "  2.21309385e-01  1.65110705e-01  2.83837078e-01  2.80273587e-02\n",
      " -4.59208213e-02  6.94518598e-01  2.93032445e-01  3.64194473e-01\n",
      "  2.71657966e-01  7.24382244e-02  2.14046525e-01  1.35579809e-02\n",
      "  1.88356257e-01  2.93602451e-01 -5.80784811e-04  2.04865374e-01\n",
      "  1.28818792e-01  8.59591941e-02  1.00198600e-01 -2.14552034e-02\n",
      "  8.08882224e-02  4.95489702e-02  3.51382579e-03  3.90933827e-02\n",
      "  1.94128900e-01  3.30237759e-01  1.40952972e-01  1.91272969e-01\n",
      "  2.12574509e-01  1.84276049e-01  9.16673787e-02 -3.22161443e-02\n",
      "  1.19657691e-01  2.07738446e-01 -1.47083162e-01  9.64869527e-02\n",
      "  6.49368915e-02  3.51400437e-02  5.75395894e-02  5.23520231e-01\n",
      "  1.88642571e-02  1.34401530e-01]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['Attrition']].to_csv('~/data/course_data/submit_gbdt.csv')\n",
    "print('submit_gbdt.csv saved')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "submit_gbdt.csv saved\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LGB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train=pd.read_csv('~/data/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('~/data/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('../../resource/course_data_BI/temp.csv')\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# param = {\n",
    "#     'num_leaves':41,\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective':'binary',\n",
    "#     'max_depth':15,\n",
    "#     'learning_rate':0.001,\n",
    "#     'metric':'binary_logloss'}\n",
    "param = {'boosting_type':'gbdt',\n",
    "                        'objective' : 'binary', #\n",
    "                        # 'metric' : 'binary_logloss',\n",
    "                        'metric' : 'auc',\n",
    "                        # 'metric' : 'self_metric',\n",
    "                        'learning_rate' : 0.01,\n",
    "                        'max_depth' : 15,\n",
    "                        'feature_fraction':0.8,\n",
    "                        'bagging_fraction': 0.9,\n",
    "                        'bagging_freq': 8,\n",
    "                        'lambda_l1': 0.6,\n",
    "                        'lambda_l2': 0,\n",
    "                        # 'scale_pos_weight':k,\n",
    "                        # 'is_unbalance':True\n",
    "        }\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "\n",
    "model = lgb.train(param,train_data,valid_sets=[train_data,valid_data],num_boost_round = 10000 ,early_stopping_rounds=200,verbose_eval=25, categorical_feature=attr)\n",
    "predict=model.predict(test)\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "#test['Attrition']=predict\n",
    "test[['Attrition']].to_csv('~/data/course_data/submit_lgb.csv')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/lilithgames/miniforge3/envs/tf/lib/python3.9/site-packages/lightgbm/basic.py:1705: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['Age', 'BusinessTravel', 'Department', 'Education', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 139, number of negative: 801\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1138\n",
      "[LightGBM] [Info] Number of data points in the train set: 940, number of used features: 30\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147872 -> initscore=-1.751387\n",
      "[LightGBM] [Info] Start training from score -1.751387\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/lilithgames/miniforge3/envs/tf/lib/python3.9/site-packages/lightgbm/basic.py:1433: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/lilithgames/miniforge3/envs/tf/lib/python3.9/site-packages/lightgbm/basic.py:1245: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\ttraining's auc: 0.932315\tvalid_1's auc: 0.769071\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\ttraining's auc: 0.945976\tvalid_1's auc: 0.782058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\ttraining's auc: 0.96058\tvalid_1's auc: 0.791226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\ttraining's auc: 0.970145\tvalid_1's auc: 0.800502\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[125]\ttraining's auc: 0.977025\tvalid_1's auc: 0.795482\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[150]\ttraining's auc: 0.98298\tvalid_1's auc: 0.801812\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _log_callback at 0x2826b3280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lilithgames/miniforge3/envs/tf/lib/python3.9/site-packages/lightgbm/basic.py\", line 76, in _log_callback\n",
      "    def _log_callback(msg):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[175]\ttraining's auc: 0.987453\tvalid_1's auc: 0.800393\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Test xgboost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import warnings\n",
    "%pylab inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# load data from url\n",
    "df = pd.read_csv('~/data/Titanic.txt', sep=',', quotechar='\"', encoding='ISO 8859-15')\n",
    "df.info()\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   row.names  1313 non-null   int64  \n",
      " 1   pclass     1313 non-null   object \n",
      " 2   survived   1313 non-null   int64  \n",
      " 3   name       1313 non-null   object \n",
      " 4   age        633 non-null    float64\n",
      " 5   embarked   821 non-null    object \n",
      " 6   home.dest  754 non-null    object \n",
      " 7   room       77 non-null     object \n",
      " 8   ticket     69 non-null     object \n",
      " 9   boat       347 non-null    object \n",
      " 10  sex        1313 non-null   object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 113.0+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>embarked</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>room</th>\n",
       "      <th>ticket</th>\n",
       "      <th>boat</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>St Louis, MO</td>\n",
       "      <td>B-5</td>\n",
       "      <td>24160 L221</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(135)</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1st</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1st</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "      <td>C22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names pclass  survived  \\\n",
       "0          1    1st         1   \n",
       "1          2    1st         0   \n",
       "2          3    1st         0   \n",
       "3          4    1st         0   \n",
       "4          5    1st         1   \n",
       "\n",
       "                                              name      age     embarked  \\\n",
       "0                     Allen, Miss Elisabeth Walton  29.0000  Southampton   \n",
       "1                      Allison, Miss Helen Loraine   2.0000  Southampton   \n",
       "2              Allison, Mr Hudson Joshua Creighton  30.0000  Southampton   \n",
       "3  Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)  25.0000  Southampton   \n",
       "4                    Allison, Master Hudson Trevor   0.9167  Southampton   \n",
       "\n",
       "                         home.dest room      ticket   boat     sex  \n",
       "0                     St Louis, MO  B-5  24160 L221      2  female  \n",
       "1  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "2  Montreal, PQ / Chesterville, ON  C26         NaN  (135)    male  \n",
       "3  Montreal, PQ / Chesterville, ON  C26         NaN    NaN  female  \n",
       "4  Montreal, PQ / Chesterville, ON  C22         NaN     11    male  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Filter some features\n",
    "features = df[['pclass', 'age', 'sex']]\n",
    "# Label\n",
    "label = df['survived']\n",
    "features.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  1313 non-null   object \n",
      " 1   age     633 non-null    float64\n",
      " 2   sex     1313 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Missing values ​​are filled with mean\n",
    "features['age'].fillna(df['age'].mean(), inplace=True)\n",
    "features.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  1313 non-null   object \n",
      " 1   age     1313 non-null   float64\n",
      " 2   sex     1313 non-null   object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 30.9+ KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Divide the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, label, test_size = 0.25, random_state=33)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Feature vectorization\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer(sparse = False)\n",
    "train_x = vec.fit_transform(train_x.to_dict(orient='record'))\n",
    "test_x = vec.transform(test_x.to_dict(orient='record'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Random forest training and prediction\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_x, train_y)\n",
    "print('The accuracy of random Forest Classifier on testing set:', rfc.score(test_x, test_y))\n",
    "\n",
    "\"\"\"\n",
    "The accuracy of random Forest Classifier on testing set: 0.7781155015197568\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The accuracy of random Forest Classifier on testing set: 0.7811550151975684\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nThe accuracy of random Forest Classifier on testing set: 0.7781155015197568\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# xgboost training and prediction\n",
    "from xgboost import XGBClassifier\n",
    "xb = XGBClassifier()\n",
    "print(xb)\n",
    "xb.fit(train_x, train_y)\n",
    "# print(f'The accuracy:', xb.score(test_x, test_y))\n",
    "# \"\"\"\n",
    "# The accuracy: 0.7750759878419453\n",
    "# \"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "print(f'accuracy:', xb.score(test_x, test_y))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'xb' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jd/jhbp58m554l8fyt81nfks5jm0000gn/T/ipykernel_50833/1358690550.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xb' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "5cf53de3813216cb4783f6412eb339fef4fdabd54508af35145546354c08cf85"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}