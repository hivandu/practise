{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 2 挖掘数据中的关联规则"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "## Apriori"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "from efficient_apriori import apriori\n",
    "# 设置数据集\n",
    "transactions = [('牛奶','面包','尿布'),\n",
    "\t\t('可乐','面包', '尿布', '啤酒'),\n",
    "\t\t('牛奶','尿布', '啤酒', '鸡蛋'),\n",
    "\t\t('面包', '牛奶', '尿布', '啤酒'),\n",
    "\t\t('面包', '牛奶', '尿布', '可乐')]\n",
    "# 挖掘频繁项集和频繁规则\n",
    "itemsets, rules = apriori(transactions, min_support=0.5,  min_confidence=1)\n",
    "print(\"频繁项集：\", itemsets)\n",
    "print(\"关联规则：\", rules)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "频繁项集： {1: {('面包',): 4, ('牛奶',): 4, ('尿布',): 5, ('啤酒',): 3}, 2: {('尿布', '牛奶'): 4, ('尿布', '面包'): 4, ('牛奶', '面包'): 3, ('啤酒', '尿布'): 3}, 3: {('尿布', '牛奶', '面包'): 3}}\n",
      "关联规则： [{牛奶} -> {尿布}, {面包} -> {尿布}, {啤酒} -> {尿布}, {牛奶, 面包} -> {尿布}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "## Regression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "### Pearson"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute(x):\n",
    "    return 2*x*x+1\n",
    "x=[i for i in range(100)]\n",
    "y=[compute(i) for i in x]\n",
    "data = pd.DataFrame({'x':x,'y':y})\n",
    "# 查看pearson系数\n",
    "print(data.corr())\n",
    "print(data.corr(method='spearman'))\n",
    "print(data.corr(method='kendall'))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          x         y\n",
      "x  1.000000  0.967644\n",
      "y  0.967644  1.000000\n",
      "     x    y\n",
      "x  1.0  1.0\n",
      "y  1.0  1.0\n",
      "     x    y\n",
      "x  1.0  1.0\n",
      "y  1.0  1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "### 回归分析\n",
    "import random\n",
    "from sklearn import linear_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "reg = linear_model.LinearRegression()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "def generate(x):\n",
    "\ty = 2*x+10+random.random()\n",
    "\treturn y\n",
    "\n",
    "train_x = []\n",
    "train_y = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "for x in range(1000):\n",
    "\ttrain_x.append([x])\n",
    "\ty = generate(x)\n",
    "\ttrain_y.append([y])\n",
    "\n",
    "reg.fit (train_x, train_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# coef_ 保存线性模型的系数w\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.99996812]]\n",
      "[10.50946744]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 使用sklearn自带的糖尿病数据集，进行回归分析\n",
    "\n",
    "Diabetes：包含442个患者的10个生理特征（年龄，性别、体重、血压）和一年以后疾病级数指标"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# 加载数据\n",
    "diabetes = datasets.load_diabetes()\n",
    "data = diabetes.data\n",
    "#import numpy as np\n",
    "#print(np.max(data))\n",
    "#data.to_csv('diabetes.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# 数据探索\n",
    "print(data.shape)\n",
    "print(data[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(442, 10)\n",
      "[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
      " -0.04340085 -0.00259226  0.01990842 -0.01764613]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# 训练集 70%，测试集30%\n",
    "train_x, test_x, train_y, test_y = train_test_split(diabetes.data, diabetes.target, test_size=0.3, random_state=14)\n",
    "print(len(train_x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "309\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "#回归训练及预测\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(train_x, train_y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "print(clf.coef_)\n",
    "#print(train_x.shape)\n",
    "#print(clf.score(test_x, test_y))\n",
    "pred_y = clf.predict(test_x)\n",
    "print(mean_squared_error(test_y, pred_y))\n",
    "r_sq = clf.score(train_x, train_y) #确定系数\n",
    "print('r_sq:', r_sq)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  32.03000032 -228.38626681  492.80665731  313.61844116 -991.31389923\n",
      "  551.99413533  190.16297006  278.51146815  781.03825662   72.08348977]\n",
      "3180.3670319563707\n",
      "r_sq: 0.5194074106259234\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## BreadBasket"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 数据加载\n",
    "data = pd.read_csv('~/data/Issue_004/BreadBasket_DMS.csv')\n",
    "# 统一小写\n",
    "data['Item'] = data['Item'].str.lower()\n",
    "# 去掉none项\n",
    "data = data.drop(data[data.Item == 'none'].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 采用efficient_apriori工具包\n",
    "def rule1():\n",
    "\tfrom efficient_apriori import apriori\n",
    "\tstart = time.time()\n",
    "\t# 得到一维数组orders_series，并且将Transaction作为index, value为Item取值\n",
    "\torders_series = data.set_index('Transaction')['Item']\n",
    "\t# 将数据集进行格式转换\n",
    "\ttransactions = []\n",
    "\ttemp_index = 0\n",
    "\tfor i, v in orders_series.items():\n",
    "\t\tif i != temp_index:\n",
    "\t\t\ttemp_set = set()\n",
    "\t\t\ttemp_index = i\n",
    "\t\t\ttemp_set.add(v)\n",
    "\t\t\ttransactions.append(temp_set)\n",
    "\t\telse:\n",
    "\t\t\ttemp_set.add(v)\n",
    "\t\n",
    "\t# 挖掘频繁项集和频繁规则\n",
    "\titemsets, rules = apriori(transactions, min_support=0.02,  min_confidence=0.5)\n",
    "\tprint('频繁项集：', itemsets)\n",
    "\tprint('关联规则：', rules)\n",
    "\tend = time.time()\n",
    "\tprint(\"用时：\", end-start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# 采用mlxtend.frequent_patterns工具包\n",
    "def rule2():\n",
    "\tfrom mlxtend.frequent_patterns import apriori\n",
    "\tfrom mlxtend.frequent_patterns import association_rules\n",
    "\tpd.options.display.max_columns=100\n",
    "\tstart = time.time()\n",
    "\thot_encoded_df=data.groupby(['Transaction','Item'])['Item'].count().unstack().reset_index().fillna(0).set_index('Transaction')\n",
    "\thot_encoded_df = hot_encoded_df.applymap(encode_units)\n",
    "\tfrequent_itemsets = apriori(hot_encoded_df, min_support=0.02, use_colnames=True)\n",
    "\trules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.5)\n",
    "\tprint(\"频繁项集：\", frequent_itemsets)\n",
    "\tprint(\"关联规则：\", rules[ (rules['lift'] >= 1) & (rules['confidence'] >= 0.5) ])\n",
    "\t#print(rules['confidence'])\n",
    "\tend = time.time()\n",
    "\tprint(\"用时：\", end-start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "rule1()\n",
    "print('-'*100)\n",
    "rule2()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "频繁项集： {1: {('scandinavian',): 275, ('hot chocolate',): 552, ('cookies',): 515, ('muffin',): 364, ('pastry',): 815, ('coffee',): 4528, ('bread',): 3096, ('medialuna',): 585, ('tea',): 1350, ('farm house',): 371, ('juice',): 365, ('soup',): 326, ('cake',): 983, ('sandwich',): 680, ('alfajores',): 344, ('brownie',): 379, ('truffles',): 192, ('toast',): 318, ('scone',): 327}, 2: {('bread', 'coffee'): 852, ('bread', 'pastry'): 276, ('coffee', 'pastry'): 450, ('coffee', 'medialuna'): 333, ('coffee', 'tea'): 472, ('bread', 'tea'): 266, ('coffee', 'juice'): 195, ('coffee', 'hot chocolate'): 280, ('coffee', 'cookies'): 267, ('cake', 'coffee'): 518, ('cake', 'tea'): 225, ('bread', 'cake'): 221, ('coffee', 'sandwich'): 362, ('coffee', 'toast'): 224}}\n",
      "关联规则： [{pastry} -> {coffee}, {medialuna} -> {coffee}, {juice} -> {coffee}, {hot chocolate} -> {coffee}, {cookies} -> {coffee}, {cake} -> {coffee}, {sandwich} -> {coffee}, {toast} -> {coffee}]\n",
      "用时： 0.09279513359069824\n",
      "----------------------------------------------------------------------------------------------------\n",
      "频繁项集：      support                 itemsets\n",
      "0   0.036348              (alfajores)\n",
      "1   0.327134                  (bread)\n",
      "2   0.040046                (brownie)\n",
      "3   0.103867                   (cake)\n",
      "4   0.478445                 (coffee)\n",
      "5   0.054417                (cookies)\n",
      "6   0.039201             (farm house)\n",
      "7   0.058326          (hot chocolate)\n",
      "8   0.038567                  (juice)\n",
      "9   0.061813              (medialuna)\n",
      "10  0.038462                 (muffin)\n",
      "11  0.086116                 (pastry)\n",
      "12  0.071851               (sandwich)\n",
      "13  0.029057           (scandinavian)\n",
      "14  0.034552                  (scone)\n",
      "15  0.034446                   (soup)\n",
      "16  0.142646                    (tea)\n",
      "17  0.033601                  (toast)\n",
      "18  0.020287               (truffles)\n",
      "19  0.023352            (bread, cake)\n",
      "20  0.090025          (bread, coffee)\n",
      "21  0.029163          (pastry, bread)\n",
      "22  0.028107             (bread, tea)\n",
      "23  0.054734           (cake, coffee)\n",
      "24  0.023774              (cake, tea)\n",
      "25  0.028212        (coffee, cookies)\n",
      "26  0.029586  (hot chocolate, coffee)\n",
      "27  0.020604          (juice, coffee)\n",
      "28  0.035186      (coffee, medialuna)\n",
      "29  0.047549         (pastry, coffee)\n",
      "30  0.038250       (coffee, sandwich)\n",
      "31  0.049873            (coffee, tea)\n",
      "32  0.023669          (coffee, toast)\n",
      "关联规则：         antecedents consequents  antecedent support  consequent support  \\\n",
      "8            (cake)    (coffee)            0.103867            0.478445   \n",
      "13        (cookies)    (coffee)            0.054417            0.478445   \n",
      "14  (hot chocolate)    (coffee)            0.058326            0.478445   \n",
      "16          (juice)    (coffee)            0.038567            0.478445   \n",
      "19      (medialuna)    (coffee)            0.061813            0.478445   \n",
      "20         (pastry)    (coffee)            0.086116            0.478445   \n",
      "23       (sandwich)    (coffee)            0.071851            0.478445   \n",
      "27          (toast)    (coffee)            0.033601            0.478445   \n",
      "\n",
      "     support  confidence      lift  leverage  conviction  \n",
      "8   0.054734    0.526958  1.101399  0.005039    1.102557  \n",
      "13  0.028212    0.518447  1.083608  0.002177    1.083069  \n",
      "14  0.029586    0.507246  1.060199  0.001680    1.058451  \n",
      "16  0.020604    0.534247  1.116632  0.002152    1.119810  \n",
      "19  0.035186    0.569231  1.189753  0.005612    1.210754  \n",
      "20  0.047549    0.552147  1.154046  0.006347    1.164569  \n",
      "23  0.038250    0.532353  1.112674  0.003873    1.115276  \n",
      "27  0.023669    0.704403  1.472276  0.007592    1.764411  \n",
      "用时： 0.2136378288269043\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "## MovieActors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## 下载某个演员/导演的电影数据集"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "from lxml import etree\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from efficient_apriori import apriori\n",
    "import csv"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里我们需要使用ChromeDrvier来做模拟\n",
    "\n",
    "Step1，打开谷歌浏览器， 在地址栏输入 chrome://version/  查看版本信息\n",
    "\n",
    "Step2，ChromeDriver版本下载地址：http://chromedriver.storage.googleapis.com/index.html\n",
    "\n",
    "Step3，放到Python\\Lib\\site-packages相应路径"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "driver = webdriver.Chrome('/Applications/chromedriver')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# 设置想要下载的导演 数据集\n",
    "director = u'徐峥'\n",
    "base_url = 'https://movie.douban.com/subject_search?search_text='+director+'&cat=1002&start='\n",
    "\n",
    "movie_actors = {}\n",
    "# 下载指定页面的数据\n",
    "def download(request_url):\n",
    "\tdriver.get(request_url)\n",
    "\ttime.sleep(1)\n",
    "\thtml = driver.find_element_by_xpath(\"//*\").get_attribute(\"outerHTML\")\n",
    "\thtml = etree.HTML(html)\n",
    "\t# 设置电影名称，导演演员 的XPATH\n",
    "\tmovie_lists = html.xpath(\"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='title']/a[@class='title-text']\")\n",
    "\tname_lists = html.xpath(\"/html/body/div[@id='wrapper']/div[@id='root']/div[1]//div[@class='item-root']/div[@class='detail']/div[@class='meta abstract_2']\")\n",
    "\t# 获取返回的数据个数\n",
    "\tnum = len(movie_lists)\n",
    "\t\n",
    "\tif num > 15: #第一页会有16条数据\n",
    "\t\t# 默认第一个不是，所以需要去掉\n",
    "\t\tmovie_lists = movie_lists[1:]\n",
    "\t\tname_lists = name_lists[1:]\n",
    "\tfor (movie, name_list) in zip(movie_lists, name_lists):\n",
    "\t\t# 会存在数据为空的情况\n",
    "\t\tif name_list.text is None: \n",
    "\t\t\tcontinue\n",
    "\t\t# 显示下演员名称\n",
    "\t\tnames = name_list.text.split('/')\n",
    "\t\tmovie_actors[movie.text] = name_list.text.replace(\" \", \"\")\n",
    "\t\tprint(name_list.text.replace(\" \", \"\"))\n",
    "\tprint('OK') # 代表这页数据下载成功\n",
    "\tif num >= 15:\n",
    "\t\t# 继续下一页\n",
    "\t\treturn True\n",
    "\telse:\n",
    "\t\t# 没有下一页\n",
    "\t\treturn False\n",
    "\n",
    "# 开始的ID为0，每页增加15\n",
    "start = 0\n",
    "while start<10000: #最多抽取1万部电影\n",
    "\trequest_url = base_url + str(start)\n",
    "\t# 下载数据，并返回是否有下一页\n",
    "\tflag = download(request_url)\n",
    "\tif flag:\n",
    "\t\tstart = start + 15\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "# 将字典类型转化为DataFrame\n",
    "movie_actors = pd.DataFrame(movie_actors, index=[0])\n",
    "#print(movie_actors)\n",
    "# DataFrame 行列转换\n",
    "movie_actors = pd.DataFrame(movie_actors.values.T, index=movie_actors.columns, columns=movie_actors.index)\n",
    "movie_actors.index.name = 'title'\n",
    "movie_actors.set_axis(['actors'], axis='columns', inplace=True)\n",
    "movie_actors.to_csv('~/data/Issue_004/movie_actors.csv')\n",
    "print('finished')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "文牧野/徐峥/王传君/周一围/谭卓/章宇/杨新鸣/王佳佳/王砚辉\n",
      "宁浩/徐峥/陈思诚/闫非/彭大魔/邓超/俞白眉/葛优/黄渤/范伟/沈腾/张占义/王宝强\n",
      "陈凯歌/张一白/管虎/薛晓路/徐峥/宁浩/文牧野/黄渤/张译/韩昊霖/杜江/葛优/刘昊然/宋佳/王千源\n",
      "宁浩/郭涛/刘桦/连晋/黄渤/徐峥/优恵/罗兰/王迅\n",
      "黄渤/舒淇/王宝强/张艺兴/于和伟/王迅/李勤勤/李又麟\n",
      "贾樟柯/赵涛/廖凡/徐峥/梁嘉艳/刁亦男/张一白/丁嘉丽/张译\n",
      "吴京/章子怡/徐峥/沈腾/韩昊霖/黄轩/宋佳/欧豪\n",
      "宁浩/黄渤/沈腾/汤姆·派福瑞/马修·莫里森/徐峥/于和伟/雷佳音/刘桦\n",
      "宁浩/徐峥/黄渤/余男/多布杰/王双宝/巴多/杨新鸣/郭虹\n",
      "宁浩/黄渤/徐峥/袁泉/周冬雨/陶慧/岳小军/沈腾/张俪\n",
      "徐峥/王宝强/黄渤/陶虹/谢楠/范冰冰\n",
      "宁浩/黄渤/戎祥/九孔/徐峥/王双宝/巴多/董立范/高捷\n",
      "徐峥/黄梅莹/袁泉/郭京飞/黄景瑜/贾冰/高以翔/沈腾\n",
      "任静/严敏/黄渤/孙红雷/黄磊/罗志祥/张艺兴/王迅/陈乔恩/郭涛\n",
      "徐峥/包贝尔/杜鹃/葛民辉/李灿森/潘虹/赵有亮/朱媛媛\n",
      "OK\n",
      "苏伦/雷佳音/佟丽娅/张衣/于和伟/王正佳/陶虹/李念/李光洁\n",
      "陈正道/徐峥/莫文蔚/胡静/吕中/王耀庆/杨凯迪\n",
      "叶伟民/徐峥/王宝强/李曼/李小璐/左小青/张歆艺/黄小蕾/马健\n",
      "谭晓虹/李诞/王思文/王建国/张雨绮/罗永浩/庞博/呼兰/杨蒙恩\n",
      "谭晓虹/于谦/李诞/吴昕/池子/马东/王建国/程璐/庞博\n",
      "彭浩翔/杨千嬅/余文乐/杨幂/徐峥/陈逸宁/林兆霞/谷德昭/詹瑞文\n",
      "任鹏远/徐峥/王丽坤/王砚辉/段博文/任达华/于和伟/朱珠/赵达\n",
      "张建亚/徐峥/刘仪伟/宁静/白冰/伊能静/车永莉/沈星/宋佳\n",
      "韩三平/黄建新/刘烨/冯远征/张嘉益/陈坤/马少骅/李沁/周润发/赵本山\n",
      "嵇天毅/于和伟/张丹峰/侯梦莎/傅浤鸣/徐洪浩/吴秀波/徐峥/侯勇\n",
      "杨庆/徐峥/李小璐/乔任梁/杨青/张嘉益/赵英俊\n",
      "金依萌/范冰冰/李治廷/吴佩慈/蒋劲夫/丹尼尔·海尼/刘维/倪虹洁/黎明\n",
      "张建亚/林嘉欣/邓超/黄渤/范伟/古巨基/黄磊/苏有朋/佟大为\n",
      "黄渤/邓超/姚晨/陈凯歌/成龙/胡歌/王宝强/王源\n",
      "刘仪伟/黄磊/谢娜/孙天宇/关悦/王晶/徐峥/佟大为\n",
      "OK\n",
      "范小天/叶崇铭/梦继/徐峥/陶虹/孙兴/李立群/陈红/翁虹/屈中恒/钮承泽\n",
      "郑军/徐峥/陈好/唐国强/王辉/李小燕/杨昊飞/焦晃/李倩\n",
      "霍建起/黄晓明/徐峥/蒲巴甲/罗晋/汤镇业/锦荣/谭凯/姜超\n",
      "吴彤/章子怡/徐峥/吴秀波/张国立/伊一/刘天池/陈凯歌/许鞍华\n",
      "孙太泉/杨军/张庭/徐峥/万弘杰/刘莉莉/孙宝光/史可/李倩/杨俊毅\n",
      "邵晓黎/徐峥/张子枫/王宣予/张颂文/王太利/肖央/岳小军/杜家毅\n",
      "李海蜀/徐峥/许绍雄/林鹏/李凤绪/仁龙/郭明翔/朱琳/冯瓅\n",
      "孙皓/徐峥/宋佳/梅婷/张歆艺/马苏/车晓/隋兰/王茂蕾\n",
      "谭晓虹/袁咏仪/吴昕/张绍刚/卡姆/庞博/宝石Gem/梁龙/李佳琦\n",
      "钟少雄/徐峥/谢娜/黄奕/邱胜翊/应采儿/何炅/孙兴/杜海涛\n",
      "刘仪伟/张坚庭/孙周/林锦和/葛优/范冰冰/闫妮/邱心志/姚晨/徐峥/徐帆\n",
      "果靖霖/郭采洁/刘雪华/徐峥/王芯宜\n",
      "徐峥/孙菲菲/唐国强/舒畅/王绘春/苗皓钧/杜志国/宗峰岩\n",
      "黄渤/舒淇/王宝强/张艺兴/于和伟/王迅/李勤勤/李又麟\n",
      "程耳/徐峥/黄奕/肖博\n",
      "OK\n",
      "严典雅/陈智雄/宁静/万茜/孟佳/李斯丹妮/张雨绮/郁可唯/黄龄/徐峥\n",
      "叶烽/王自健/中孝介/宁浩/李东学/黄龄/宋丹丹/王雷/范明\n",
      "吴彤/沈涛/王源/沈腾/贾玲/欧阳娜娜/刘芸/凌潇肃/周一围\n",
      "孙立军/范伟/闫妮/张丰毅/濮存昕/张一山/林永健/黄宏/冯远征\n",
      "陶晶莹/李安/巩俐/谢盈萱/周迅/赵涛/曾美慧孜/孙俪\n",
      "程耳/高圆圆/徐峥/陶虹/鄢钷\n",
      "高一功/徐峥/伊春德/王虎城/公磊\n",
      "刘烨/易小星/董子健/徐峥/张一山/佟丽娅/克里斯·帕拉特/小沈阳\n",
      "王伟廷/徐峥/赵丽颖/于波/杨俊毅/雷恪生\n",
      "丁黑/张可颐/谢君豪/陈丽娜/吴兴国/徐峥/黄奕\n",
      "邵艺辉/徐峥/马伊琍/吴越/倪虹洁/周野芒/黄明昊/王影璐/宁理\n",
      "李翰韬/徐峥/张铁林/张庭/刘希媛/陈继铭/董志华/张曦文/李琦\n",
      "黄蜀芹/巍子/严晓频/王琳/佟瑞欣/吴越/马晓伟/江珊/华明伟\n",
      "曹晓震/俞杭英/陈坤/徐峥/韩庚/吴磊/大鹏/尹正\n",
      "张韵华/冯广泉/史久峰/袁岳/徐峥/余彬/黄达亮/曹秋根/姚安濂\n",
      "OK\n",
      "刘志/欧阳震华/李铭顺/张世/徐峥/寇振海/保剑锋/宁静/范文芳\n",
      "徐峥\n",
      "黄建新/王志文/江珊/王琳/阮丹宁/徐峥/吴越\n",
      "徐峥/宋小宝/尹正/伊一/郭麒麟/赵英俊\n",
      "徐峥\n",
      "张健伟/张敏/童安格/唐国强/秦风/田岷/白雪云/柯蓝/刘瑞琪\n",
      "张继科/李现/朱一龙/肖战/张艺兴/罗志祥/迪丽热巴/曹可凡\n",
      "曹郁/程工/冯唐/路妍/文林/徐峥\n",
      "黄渤/王迅/一纳\n",
      "徐峥/雷佳音/陶虹/袁泉\n",
      "朱传光/于荣光/倪虹洁/刘蓓/徐峥/高宝宝/王奎荣\n",
      "陈正道/刘烨/徐峥/佟大为/黄轩/马苏/袁泉/李易峰/祖峰\n",
      "陈家林/徐峥/朱媛媛/李又麟/林熙越/夏力薪/林家川\n",
      "邓洁/陈磊/殳俏/赵子琪/赵胤胤/徐峥/金世佳\n",
      "范秀明/陈家霏/徐峥/王刚/曾宝仪/祁艳/娄宇健/宋茹惠/魏宗万/王征宇\n",
      "OK\n",
      "苏有朋/林心如/古巨基/高鑫/寇振海/王琳/徐幸/赵雅芝\n",
      "田华/刘嘉玲/徐峥/赵又廷/马思纯/明道/杨子姗\n",
      "陶白莉/邹集城/杨若兮/徐峥/聂远/刘威/傅艺伟/戴春荣/张璐/谢宁\n",
      "徐峥/王传君/周一围/谭卓/章宇/杨新鸣/王佳佳/王砚辉\n",
      "宁浩/黄渤/徐峥\n",
      "汪遵熹/刘劲/王允/马晓伟/徐风/史鑫/谢钢/夏正兴/尹铸胜\n",
      "张番番/陶虹/李小冉/郭涛/解晓东/徐峥/廖凡\n",
      "赵丽颖/易烊千玺/徐峥/周冬雨/刘昊然/陈凯歌/朱丹/华少\n",
      "凯文·格劳特/徐峥/关晓彤\n",
      "苏菲·玛索/黑泽清/伊莎贝尔·于佩尔/阿斯哈·法哈蒂/蒋雯丽/阿贝尔·费拉拉/关锦鹏StanleyKwan/雷蒙德·雷德\n",
      "武越/徐峥\n",
      "溥一隽/徐峥/张延/白庆琳/牛萌萌\n",
      "鞠觉亮/徐峥/徐锦江/邢岷山/商蓉/罗海琼/沈晓海/王灵/姜黎黎\n",
      "贾樟柯/姜文/张艺谋/文牧野/毕赣/黄渤/徐峥/章宇\n",
      "艾朗·德罗榭/马特·弗里沃/托德·芬内尔/安柏·戈德法布/GangZhao/浦蒲/YuanFang/LukeZhiGangLiu/PengZhenZhong\n",
      "OK\n",
      "徐峥/王传君/周一围/谭卓/章宇/杨新鸣/文牧野/王砚辉\n",
      "徐峥\n",
      "沈腾/马丽/常远/葛优/黄渤/范伟/徐峥/贾玲\n",
      "成龙/朱丽叶·比诺什/阿米尔·汗/徐峥/姚晨/麦斯·米科尔森/约翰尼·德普/伊莎贝尔·于佩尔\n",
      "汪峰/徐峥/刘震云/白百何/马东/苏芒/贾乃亮/梁文道\n",
      "谭智桐/牛振华/吕丽萍/徐峥/付连智/周莉/贾兆冀/秦焰/吴樾\n",
      "徐峥/李诞\n",
      "文牧野/徐峥/姚晨/章宇/佟丽娅/霍建起/苏伦/黄尧\n",
      "江海洋/傅东育/刘小锋/范冰冰/徐峥/廖学秋/薛佳凝/许承先\n",
      "吴兵/郝蕾/丁志诚/何琳/徐峥/鲍国安/傅彪\n",
      "章子怡/王家卫/陈可辛/李雪健/张晋/徐峥/杨子姗/佟大为\n",
      "何念/徐峥\n",
      "贾樟柯/刘震云/张杨/陈凯歌/唐大年/吴楠/颜丙燕/冯小刚\n",
      "成浩/徐峥/李冰冰\n",
      "徐小朋/张海宇/马书良/贺坪/刘炫锐/卫莱/梁文慧/倪萍/沙溢\n",
      "OK\n",
      "薛晓路/徐峥/汤唯/陈可辛/李睿珺/崔健/滕文骥/郑洞天\n",
      "吴兵/徐峥/何琳/王劲松/常蓝天/吕中\n",
      "徐峥/陈飞宇/梁永棋/李嘉鑫/金遥源\n",
      "曹红梅/李琦/徐峥/刘园园/薛佳凝/刘栋/艾东/钉铛/宁理\n",
      "陈晓雷/丁志城/傅彪/赵子琪\n",
      "韩东君\n",
      "张晓颖/李红陶\n",
      "张菁/徐铮/牛莉/魏积安\n",
      "OK\n",
      "finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# 分析MovieLens 电影分类中的频繁项集和关联规则"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "# 数据加载\n",
    "movies = pd.read_csv('~/data/Issue_004/movie_actors.csv')\n",
    "#print(movies.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# 将genres进行one-hot编码（离散特征有多少取值，就用多少维来表示这个特征）\n",
    "movies_hot_encoded = movies.drop('actors',1).join(movies.actors.str.get_dummies('/'))\n",
    "pd.options.display.max_columns=100\n",
    "print(movies_hot_encoded.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            title  GangZhao  LukeZhiGangLiu  PengZhenZhong  YuanFang  一纳  丁嘉丽  \\\n",
      "0   我不是药神‎ (2018)         0               0              0         0   0    0   \n",
      "1  我和我的家乡‎ (2020)         0               0              0         0   0    0   \n",
      "2  我和我的祖国‎ (2019)         0               0              0         0   0    0   \n",
      "3   疯狂的石头‎ (2006)         0               0              0         0   0    0   \n",
      "4    一出好戏‎ (2018)         0               0              0         0   0    0   \n",
      "\n",
      "   丁志城  丁志诚  丁黑  万弘杰  万茜  严典雅  严敏  严晓频  中孝介  丹尼尔·海尼  乔任梁  九孔  于和伟  于波  于荣光  \\\n",
      "0    0    0   0    0   0    0   0    0    0       0    0   0    0   0    0   \n",
      "1    0    0   0    0   0    0   0    0    0       0    0   0    0   0    0   \n",
      "2    0    0   0    0   0    0   0    0    0       0    0   0    0   0    0   \n",
      "3    0    0   0    0   0    0   0    0    0       0    0   0    0   0    0   \n",
      "4    0    0   0    0   0    0   0    0    0       0    0   0    1   0    0   \n",
      "\n",
      "   于谦  仁龙  付连智  任达华  任静  任鹏远  伊一  伊春德  伊能静  伊莎贝尔·于佩尔  优恵  何念  何炅  何琳  余彬  余文乐  \\\n",
      "0   0   0    0    0   0    0   0    0    0         0   0   0   0   0   0    0   \n",
      "1   0   0    0    0   0    0   0    0    0         0   0   0   0   0   0    0   \n",
      "2   0   0    0    0   0    0   0    0    0         0   0   0   0   0   0    0   \n",
      "3   0   0    0    0   0    0   0    0    0         0   1   0   0   0   0    0   \n",
      "4   0   0    0    0   0    0   0    0    0         0   0   0   0   0   0    0   \n",
      "\n",
      "   余男  佟丽娅  佟大为  佟瑞欣  侯勇  侯梦莎  保剑锋  俞杭英  俞白眉  倪萍  倪虹洁  傅东育  ...  陶虹  隋兰  雷佳音  \\\n",
      "0   0    0    0    0   0    0    0    0    0   0    0    0  ...   0   0    0   \n",
      "1   0    0    0    0   0    0    0    0    1   0    0    0  ...   0   0    0   \n",
      "2   0    0    0    0   0    0    0    0    0   0    0    0  ...   0   0    0   \n",
      "3   0    0    0    0   0    0    0    0    0   0    0    0  ...   0   0    0   \n",
      "4   0    0    0    0   0    0    0    0    0   0    0    0  ...   0   0    0   \n",
      "\n",
      "   雷恪生  雷蒙德·雷德  霍建起  鞠觉亮  韩三平  韩东君  韩庚  韩昊霖  颜丙燕  马东  马丽  马书良  马伊琍  马修·莫里森  \\\n",
      "0    0       0    0    0    0    0   0    0    0   0   0    0    0       0   \n",
      "1    0       0    0    0    0    0   0    0    0   0   0    0    0       0   \n",
      "2    0       0    0    0    0    0   0    1    0   0   0    0    0       0   \n",
      "3    0       0    0    0    0    0   0    0    0   0   0    0    0       0   \n",
      "4    0       0    0    0    0    0   0    0    0   0   0    0    0       0   \n",
      "\n",
      "   马健  马少骅  马思纯  马晓伟  马特·弗里沃  马苏  高一功  高以翔  高圆圆  高宝宝  高捷  高鑫  魏宗万  魏积安  鲍国安  \\\n",
      "0   0    0    0    0       0   0    0    0    0    0   0   0    0    0    0   \n",
      "1   0    0    0    0       0   0    0    0    0    0   0   0    0    0    0   \n",
      "2   0    0    0    0       0   0    0    0    0    0   0   0    0    0    0   \n",
      "3   0    0    0    0       0   0    0    0    0    0   0   0    0    0    0   \n",
      "4   0    0    0    0       0   0    0    0    0    0   0   0    0    0    0   \n",
      "\n",
      "   麦斯·米科尔森  黄奕  黄宏  黄小蕾  黄尧  黄建新  黄明昊  黄晓明  黄景瑜  黄梅莹  黄渤  黄磊  黄蜀芹  黄轩  黄达亮  \\\n",
      "0        0   0   0    0   0    0    0    0    0    0   0   0    0   0    0   \n",
      "1        0   0   0    0   0    0    0    0    0    0   1   0    0   0    0   \n",
      "2        0   0   0    0   0    0    0    0    0    0   1   0    0   0    0   \n",
      "3        0   0   0    0   0    0    0    0    0    0   1   0    0   0    0   \n",
      "4        0   0   0    0   0    0    0    0    0    0   1   0    0   0    0   \n",
      "\n",
      "   黄龄  黎明  黑泽清  \n",
      "0   0   0    0  \n",
      "1   0   0    0  \n",
      "2   0   0    0  \n",
      "3   0   0    0  \n",
      "4   0   0    0  \n",
      "\n",
      "[5 rows x 566 columns]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_90586/549538654.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  movies_hot_encoded = movies.drop('actors',1).join(movies.actors.str.get_dummies('/'))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "# 将movieId, title设置为index\n",
    "movies_hot_encoded.set_index(['title'],inplace=True)\n",
    "#print(movies_hot_encoded.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# 挖掘频繁项集，最小支持度为0.02\n",
    "itemsets = apriori(movies_hot_encoded,use_colnames=True, min_support=0.05)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "# 按照支持度从大到小进行时候粗\n",
    "itemsets = itemsets.sort_values(by=\"support\" , ascending=False) \n",
    "print('-'*20, '频繁项集', '-'*20)\n",
    "print(itemsets)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 频繁项集 --------------------\n",
      "     support      itemsets\n",
      "2   0.743363          (徐峥)\n",
      "6   0.150442          (黄渤)\n",
      "10  0.097345      (黄渤, 徐峥)\n",
      "1   0.079646          (宁浩)\n",
      "7   0.070796      (宁浩, 徐峥)\n",
      "8   0.070796      (黄渤, 宁浩)\n",
      "11  0.070796  (黄渤, 宁浩, 徐峥)\n",
      "3   0.061947          (沈腾)\n",
      "0   0.053097         (于和伟)\n",
      "4   0.053097         (王宝强)\n",
      "5   0.053097          (陶虹)\n",
      "9   0.053097      (沈腾, 徐峥)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# 根据频繁项集计算关联规则，设置最小提升度为2\n",
    "rules =  association_rules(itemsets, metric='lift', min_threshold=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# 按照提升度从大到小进行排序\n",
    "rules = rules.sort_values(by=\"lift\" , ascending=False) \n",
    "#rules.to_csv('./rules.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "print('-'*20, '关联规则', '-'*20)\n",
    "print(rules)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 关联规则 --------------------\n",
      "  antecedents consequents  antecedent support  consequent support   support  \\\n",
      "2    (黄渤, 徐峥)        (宁浩)            0.097345            0.079646  0.070796   \n",
      "5        (宁浩)    (黄渤, 徐峥)            0.079646            0.097345  0.070796   \n",
      "3    (宁浩, 徐峥)        (黄渤)            0.070796            0.150442  0.070796   \n",
      "4        (黄渤)    (宁浩, 徐峥)            0.150442            0.070796  0.070796   \n",
      "0        (黄渤)        (宁浩)            0.150442            0.079646  0.070796   \n",
      "1        (宁浩)        (黄渤)            0.079646            0.150442  0.070796   \n",
      "\n",
      "   confidence      lift  leverage  conviction  \n",
      "2    0.727273  9.131313  0.063043    3.374631  \n",
      "5    0.888889  9.131313  0.063043    8.123894  \n",
      "3    1.000000  6.647059  0.060146         inf  \n",
      "4    0.470588  6.647059  0.060146    1.755162  \n",
      "0    0.470588  5.908497  0.058814    1.738446  \n",
      "1    0.888889  5.908497  0.058814    7.646018  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "### 分析MovieLens 电影分类中的频繁项集和关联规则"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# 数据加载\n",
    "movies = pd.read_csv('~/data/issue_004/movies.csv')\n",
    "#print(movies.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# 将genres进行one-hot编码（离散特征有多少取值，就用多少维来表示这个特征）\n",
    "print(movies['genres'])\n",
    "movies_hot_encoded = movies.drop('genres',1).join(movies.genres.str.get_dummies(sep='|'))\n",
    "print(movies_hot_encoded)\n",
    "\n",
    "pd.options.display.max_columns=100\n",
    "print(movies_hot_encoded.head())\n",
    "\n",
    "# 将movieId, title设置为index\n",
    "movies_hot_encoded.set_index(['movieId','title'],inplace=True)\n",
    "#print(movies_hot_encoded.head())\n",
    "# 挖掘频繁项集，最小支持度为0.02\n",
    "itemsets = apriori(movies_hot_encoded,use_colnames=True, min_support=0.02)\n",
    "# 按照支持度从大到小进行时候粗\n",
    "itemsets = itemsets.sort_values(by=\"support\" , ascending=False) \n",
    "print('-'*20, '频繁项集', '-'*20)\n",
    "print(itemsets)\n",
    "# 根据频繁项集计算关联规则，设置最小提升度为2\n",
    "rules =  association_rules(itemsets, metric='lift', min_threshold=2)\n",
    "# 按照提升度从大到小进行排序\n",
    "rules = rules.sort_values(by=\"lift\" , ascending=False) \n",
    "#rules.to_csv('./rules.csv')\n",
    "print('-'*20, '关联规则', '-'*20)\n",
    "print(rules)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        Adventure|Animation|Children|Comedy|Fantasy\n",
      "1                         Adventure|Children|Fantasy\n",
      "2                                     Comedy|Romance\n",
      "3                               Comedy|Drama|Romance\n",
      "4                                             Comedy\n",
      "                            ...                     \n",
      "27273                                         Comedy\n",
      "27274                                         Comedy\n",
      "27275                                      Adventure\n",
      "27276                             (no genres listed)\n",
      "27277                       Adventure|Fantasy|Horror\n",
      "Name: genres, Length: 27278, dtype: object\n",
      "       movieId                               title  (no genres listed)  \\\n",
      "0            1                    Toy Story (1995)                   0   \n",
      "1            2                      Jumanji (1995)                   0   \n",
      "2            3             Grumpier Old Men (1995)                   0   \n",
      "3            4            Waiting to Exhale (1995)                   0   \n",
      "4            5  Father of the Bride Part II (1995)                   0   \n",
      "...        ...                                 ...                 ...   \n",
      "27273   131254        Kein Bund für's Leben (2007)                   0   \n",
      "27274   131256       Feuer, Eis & Dosenbier (2002)                   0   \n",
      "27275   131258                  The Pirates (2014)                   0   \n",
      "27276   131260                 Rentun Ruusu (2001)                   1   \n",
      "27277   131262                    Innocence (2014)                   0   \n",
      "\n",
      "       Action  Adventure  Animation  Children  Comedy  Crime  Documentary  \\\n",
      "0           0          1          1         1       1      0            0   \n",
      "1           0          1          0         1       0      0            0   \n",
      "2           0          0          0         0       1      0            0   \n",
      "3           0          0          0         0       1      0            0   \n",
      "4           0          0          0         0       1      0            0   \n",
      "...       ...        ...        ...       ...     ...    ...          ...   \n",
      "27273       0          0          0         0       1      0            0   \n",
      "27274       0          0          0         0       1      0            0   \n",
      "27275       0          1          0         0       0      0            0   \n",
      "27276       0          0          0         0       0      0            0   \n",
      "27277       0          1          0         0       0      0            0   \n",
      "\n",
      "       Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  Romance  \\\n",
      "0          0        1          0       0     0        0        0        0   \n",
      "1          0        1          0       0     0        0        0        0   \n",
      "2          0        0          0       0     0        0        0        1   \n",
      "3          1        0          0       0     0        0        0        1   \n",
      "4          0        0          0       0     0        0        0        0   \n",
      "...      ...      ...        ...     ...   ...      ...      ...      ...   \n",
      "27273      0        0          0       0     0        0        0        0   \n",
      "27274      0        0          0       0     0        0        0        0   \n",
      "27275      0        0          0       0     0        0        0        0   \n",
      "27276      0        0          0       0     0        0        0        0   \n",
      "27277      0        1          0       1     0        0        0        0   \n",
      "\n",
      "       Sci-Fi  Thriller  War  Western  \n",
      "0           0         0    0        0  \n",
      "1           0         0    0        0  \n",
      "2           0         0    0        0  \n",
      "3           0         0    0        0  \n",
      "4           0         0    0        0  \n",
      "...       ...       ...  ...      ...  \n",
      "27273       0         0    0        0  \n",
      "27274       0         0    0        0  \n",
      "27275       0         0    0        0  \n",
      "27276       0         0    0        0  \n",
      "27277       0         0    0        0  \n",
      "\n",
      "[27278 rows x 22 columns]\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  Drama  Fantasy  \\\n",
      "0          1          1         1       1      0            0      0        1   \n",
      "1          1          0         1       0      0            0      0        1   \n",
      "2          0          0         0       1      0            0      0        0   \n",
      "3          0          0         0       1      0            0      1        0   \n",
      "4          0          0         0       1      0            0      0        0   \n",
      "\n",
      "   Film-Noir  Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n",
      "0          0       0     0        0        0        0       0         0    0   \n",
      "1          0       0     0        0        0        0       0         0    0   \n",
      "2          0       0     0        0        0        1       0         0    0   \n",
      "3          0       0     0        0        0        1       0         0    0   \n",
      "4          0       0     0        0        0        0       0         0    0   \n",
      "\n",
      "   Western  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_90586/931687501.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  movies_hot_encoded = movies.drop('genres',1).join(movies.genres.str.get_dummies(sep='|'))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 频繁项集 --------------------\n",
      "     support                  itemsets\n",
      "7   0.489185                   (Drama)\n",
      "4   0.306987                  (Comedy)\n",
      "14  0.153164                (Thriller)\n",
      "12  0.151294                 (Romance)\n",
      "0   0.129042                  (Action)\n",
      "5   0.107743                   (Crime)\n",
      "9   0.095718                  (Horror)\n",
      "31  0.094325          (Romance, Drama)\n",
      "26  0.093335           (Drama, Comedy)\n",
      "6   0.090586             (Documentary)\n",
      "1   0.085380               (Adventure)\n",
      "27  0.069470         (Romance, Comedy)\n",
      "32  0.068480         (Thriller, Drama)\n",
      "13  0.063898                  (Sci-Fi)\n",
      "28  0.062761            (Drama, Crime)\n",
      "11  0.055503                 (Mystery)\n",
      "8   0.051763                 (Fantasy)\n",
      "29  0.045165         (Thriller, Crime)\n",
      "20  0.044101           (Drama, Action)\n",
      "15  0.043772                     (War)\n",
      "3   0.041755                (Children)\n",
      "22  0.040655        (Thriller, Action)\n",
      "34  0.039336        (Thriller, Horror)\n",
      "10  0.037979                 (Musical)\n",
      "2   0.037649               (Animation)\n",
      "17  0.035633       (Adventure, Action)\n",
      "33  0.032774              (War, Drama)\n",
      "35  0.029144       (Thriller, Mystery)\n",
      "19  0.028118           (Action, Crime)\n",
      "36  0.027458  (Romance, Drama, Comedy)\n",
      "30  0.026432          (Mystery, Drama)\n",
      "18  0.026358          (Action, Comedy)\n",
      "25  0.025368           (Crime, Comedy)\n",
      "24  0.025295        (Adventure, Drama)\n",
      "37  0.024965  (Thriller, Drama, Crime)\n",
      "16  0.024782                 (Western)\n",
      "21  0.023499          (Action, Sci-Fi)\n",
      "23  0.022032       (Adventure, Comedy)\n",
      "-------------------- 关联规则 --------------------\n",
      "          antecedents        consequents  antecedent support  \\\n",
      "9           (Mystery)         (Thriller)            0.055503   \n",
      "8          (Thriller)          (Mystery)            0.153164   \n",
      "15            (Crime)  (Thriller, Drama)            0.107743   \n",
      "12  (Thriller, Drama)            (Crime)            0.068480   \n",
      "7            (Action)        (Adventure)            0.129042   \n",
      "6         (Adventure)           (Action)            0.085380   \n",
      "16           (Action)           (Sci-Fi)            0.129042   \n",
      "17           (Sci-Fi)           (Action)            0.063898   \n",
      "0          (Thriller)            (Crime)            0.153164   \n",
      "1             (Crime)         (Thriller)            0.107743   \n",
      "5            (Horror)         (Thriller)            0.095718   \n",
      "4          (Thriller)           (Horror)            0.153164   \n",
      "13     (Drama, Crime)         (Thriller)            0.062761   \n",
      "14         (Thriller)     (Drama, Crime)            0.153164   \n",
      "3            (Action)         (Thriller)            0.129042   \n",
      "2          (Thriller)           (Action)            0.153164   \n",
      "10           (Action)            (Crime)            0.129042   \n",
      "11            (Crime)           (Action)            0.107743   \n",
      "\n",
      "    consequent support   support  confidence      lift  leverage  conviction  \n",
      "9             0.153164  0.029144    0.525099  3.428352  0.020643    1.783185  \n",
      "8             0.055503  0.029144    0.190282  3.428352  0.020643    1.166453  \n",
      "15            0.068480  0.024965    0.231711  3.383632  0.017587    1.212461  \n",
      "12            0.107743  0.024965    0.364561  3.383632  0.017587    1.404159  \n",
      "7             0.085380  0.035633    0.276136  3.234198  0.024616    1.263525  \n",
      "6             0.129042  0.035633    0.417347  3.234198  0.024616    1.494813  \n",
      "16            0.063898  0.023499    0.182102  2.849906  0.015253    1.144523  \n",
      "17            0.129042  0.023499    0.367757  2.849906  0.015253    1.377568  \n",
      "0             0.107743  0.045165    0.294878  2.736877  0.028662    1.265394  \n",
      "1             0.153164  0.045165    0.419190  2.736877  0.028662    1.458027  \n",
      "5             0.153164  0.039336    0.410954  2.683100  0.024675    1.437639  \n",
      "4             0.095718  0.039336    0.256821  2.683100  0.024675    1.216776  \n",
      "13            0.153164  0.024965    0.397780  2.597093  0.015352    1.406192  \n",
      "14            0.062761  0.024965    0.162997  2.597093  0.015352    1.119755  \n",
      "3             0.153164  0.040655    0.315057  2.056994  0.020891    1.236360  \n",
      "2             0.129042  0.040655    0.265438  2.056994  0.020891    1.185684  \n",
      "10            0.107743  0.028118    0.217898  2.022393  0.014215    1.140845  \n",
      "11            0.129042  0.028118    0.260973  2.022393  0.014215    1.178520  \n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "35f69483aa8b7b2bb12f1e6f2ffb8fe1120cf837ca5a80070d69961a5682f06d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}