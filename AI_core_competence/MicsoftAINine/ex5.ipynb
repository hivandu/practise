{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 5 Seq2Sequence，机器自动翻译， Image Caption, Attention机制"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequence to sequence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def create_model(n_input, n_output, n_units):\n",
    "    # encoder\n",
    "    encoder_input = Input(shape=(None, n_input))\n",
    "    encoder = LSTM(n_units, return_state=True)\n",
    "    _,encoder_h, encoder_c = encoder(encoder_input)\n",
    "    encoder_state = [encoder_h, encoder_c]\n",
    "    \n",
    "    \n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_input = Input(shape=(None, n_output))\n",
    "    decoder = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_output, _, _ = decoder(decoder_input,\n",
    "                                   initial_state=encoder_state)\n",
    "    decoder_dense = Dense(n_output, activation='softmax')\n",
    "    decoder_output = decoder_dense(decoder_output)\n",
    "    \n",
    "    # Define the model \n",
    "    model = Model([encoder_input, decoder_input], decoder_output)\n",
    "    \n",
    "    # inference setup\n",
    "    # encoder\n",
    "    encoder_infer = Model(encoder_input, encoder_state)\n",
    "    \n",
    "    # decoder\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))    \n",
    "    decoder_state_input = [decoder_state_input_h, decoder_state_input_c] \n",
    "    \n",
    "    decoder_infer_output, decoder_infer_state_h, decoder_infer_state_c = decoder(decoder_input,\n",
    "                                                                                 initial_state=decoder_state_input)\n",
    "    decoder_infer_state = [decoder_infer_state_h, decoder_infer_state_c]\n",
    "    decoder_infer_output = decoder_dense(decoder_infer_output)\n",
    "    \n",
    "    decoder_infer = Model([decoder_input] + decoder_state_input,\n",
    "                          [decoder_infer_output] + decoder_infer_state)\n",
    "    \n",
    "    return model, encoder_infer, decoder_infer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "N_UNITS = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 50\n",
    "NUM_SAMPLES = 10000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据下载\n",
    "[下载地址](http://www.manythings.org/anki/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据读取"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_path = '../resource/cmn.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:NUM_SAMPLES,:,]\n",
    "df.columns=['inputs', 'targets', 'others']\n",
    "\n",
    "df['targets'] = df['targets'].apply(lambda x: '\\t'+x+'\\n')\n",
    "\n",
    "input_texts = df.inputs.values.tolist()\n",
    "target_texts = df.targets.values.tolist()\n",
    "\n",
    "input_characters = sorted(list(set(df.inputs.unique().sum())))\n",
    "target_characters = sorted(list(set(df.targets.unique().sum())))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "INUPT_LENGTH = max([len(i) for i in input_texts])\n",
    "OUTPUT_LENGTH = max([len(i) for i in target_texts])\n",
    "INPUT_FEATURE_LENGTH = len(input_characters)\n",
    "OUTPUT_FEATURE_LENGTH = len(target_characters)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 向量化"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "encoder_input = np.zeros((NUM_SAMPLES, INUPT_LENGTH, INPUT_FEATURE_LENGTH))\n",
    "decoder_input = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))\n",
    "decoder_output = np.zeros((NUM_SAMPLES, OUTPUT_LENGTH, OUTPUT_FEATURE_LENGTH))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "input_dict = {char:index for index,char in enumerate(input_characters)}\n",
    "input_dict_reverse = {index:char for index,char in enumerate(input_characters)}\n",
    "target_dict = {char:index for index,char in enumerate(target_characters)}\n",
    "target_dict_reverse = {index:char for index,char in enumerate(target_characters)}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for seq_index,seq in enumerate(input_texts):\n",
    "    for char_index, char in enumerate(seq):\n",
    "        encoder_input[seq_index, char_index, input_dict[char]] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "for seq_index,seq in enumerate(target_texts):\n",
    "    for char_index,char in enumerate(seq):\n",
    "        decoder_input[seq_index,char_index, target_dict[char]] = 1.0\n",
    "        if char_index > 0:\n",
    "            decoder_output[seq_index,char_index-1, target_dict[char]] = 1.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 观察向量化的数据"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "''.join([input_dict_reverse[np.argmax(i)] for i in encoder_input[0] if max(i) !=0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "''.join([target_dict_reverse[np.argmax(i)] for i in decoder_output[0] if max(i) !=0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'嗨。\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 创建模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model_train, encoder_infer, decoder_infer = create_model(INPUT_FEATURE_LENGTH,\n",
    "                                                         OUTPUT_FEATURE_LENGTH,\n",
    "                                                         N_UNITS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Compile & run training\n",
    "model_train.compile(optimizer='rmsprop',\n",
    "                    loss='categorical_crossentropy')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model_train.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 72)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 2561)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 336896      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  2885632     input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2561)   658177      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,880,705\n",
      "Trainable params: 3,880,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "encoder_infer.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 72)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 256), (None, 256) 336896    \n",
      "=================================================================\n",
      "Total params: 336,896\n",
      "Trainable params: 336,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "decoder_infer.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 2561)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  2885632     input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2561)   658177      lstm_2[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,543,809\n",
      "Trainable params: 3,543,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "validation_split = 0.2\n",
    "model_train.fit([encoder_input,decoder_input],\n",
    "                decoder_output,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCH,\n",
    "                validation_split=validation_split)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "8000/8000 [==============================] - 115s 14ms/step - loss: 1.9547 - val_loss: 2.4884\n",
      "Epoch 2/50\n",
      "8000/8000 [==============================] - 111s 14ms/step - loss: 1.8150 - val_loss: 2.3762\n",
      "Epoch 3/50\n",
      "8000/8000 [==============================] - 111s 14ms/step - loss: 1.7301 - val_loss: 2.2877\n",
      "Epoch 4/50\n",
      "8000/8000 [==============================] - 111s 14ms/step - loss: 1.6244 - val_loss: 2.2138\n",
      "Epoch 5/50\n",
      "8000/8000 [==============================] - 111s 14ms/step - loss: 1.5545 - val_loss: 2.1385\n",
      "Epoch 6/50\n",
      "2752/8000 [=========>....................] - ETA: 1:08 - loss: 1.4965"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8648856ef8fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 validation_split=validation_split)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 预测序列"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def predict_chinese(source,encoder_inference, decoder_inference, n_steps, features):\n",
    "    state = encoder_inference.predict(source)\n",
    "    predict_seq = np.zeros((1,1,features))\n",
    "    predict_seq[0,0,target_dict['\\t']] = 1\n",
    "\n",
    "    output = ''\n",
    "\n",
    "    for i in range(n_steps): # n_steps为句子最大长度\n",
    "        yhat,h,c = decoder_inference.predict([predict_seq]+state)\n",
    "        char_index = np.argmax(yhat[0,-1,:])\n",
    "        char = target_dict_reverse[char_index]\n",
    "        output += char\n",
    "        state = [h,c]\n",
    "        predict_seq = np.zeros((1,1,features))\n",
    "        predict_seq[0,0,char_index] = 1\n",
    "        if char == '\\n':\n",
    "            break\n",
    "    return output"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for i in range(1000,1100):\n",
    "    test = encoder_input[i:i+1,:,:] \n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    print(input_texts[i])\n",
    "    print(out)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stop grumbling.\n",
      "你的是我的。\n",
      "\n",
      "Stop resisting!\n",
      "你的在我的。\n",
      "\n",
      "Summer is over.\n",
      "我不是我的。\n",
      "\n",
      "Take your time.\n",
      "你是什麼？\n",
      "\n",
      "Take your time.\n",
      "你是什麼？\n",
      "\n",
      "That was wrong.\n",
      "你是我的。\n",
      "\n",
      "That's a shame.\n",
      "你是我的。\n",
      "\n",
      "That's logical.\n",
      "你是我的。\n",
      "\n",
      "That's my coat.\n",
      "你是我的。\n",
      "\n",
      "That's perfect.\n",
      "你是我的。\n",
      "\n",
      "That's too bad.\n",
      "你是我的。\n",
      "\n",
      "That's too bad.\n",
      "你是我的。\n",
      "\n",
      "That's too bad.\n",
      "你是我的。\n",
      "\n",
      "The birds sang.\n",
      "你是我的。\n",
      "\n",
      "The flag is up.\n",
      "你是我的。\n",
      "\n",
      "The phone rang.\n",
      "你是我的。\n",
      "\n",
      "Their eyes met.\n",
      "那是我的。\n",
      "\n",
      "These are pens.\n",
      "你是我的。\n",
      "\n",
      "They hated Tom.\n",
      "你是我的。\n",
      "\n",
      "They have jobs.\n",
      "你是我的。\n",
      "\n",
      "They let me go.\n",
      "你是我的。\n",
      "\n",
      "They love that.\n",
      "你是我的。\n",
      "\n",
      "They trust Tom.\n",
      "你是我的。\n",
      "\n",
      "They want more.\n",
      "那是我的。\n",
      "\n",
      "They want this.\n",
      "那是我的。\n",
      "\n",
      "They were good.\n",
      "你是我的。\n",
      "\n",
      "This is a book.\n",
      "那是我的。\n",
      "\n",
      "This is my bag.\n",
      "那是我的。\n",
      "\n",
      "Tom can change.\n",
      "那是我的。\n",
      "\n",
      "Tom can't swim.\n",
      "那是我的。\n",
      "\n",
      "Tom has a plan.\n",
      "那是我的。\n",
      "\n",
      "Tom is a rabbi.\n",
      "那是我的。\n",
      "\n",
      "Tom is no fool.\n",
      "那是我的。\n",
      "\n",
      "Tom isn't dumb.\n",
      "那是我的。\n",
      "\n",
      "Tom looks pale.\n",
      "那是我的。\n",
      "\n",
      "Tom loves dogs.\n",
      "那是我的。\n",
      "\n",
      "Tom turned red.\n",
      "那是我的。\n",
      "\n",
      "Tom walked out.\n",
      "他是我的。\n",
      "\n",
      "Tom was crying.\n",
      "他是我的。\n",
      "\n",
      "Tom won't stop.\n",
      "那是我的。\n",
      "\n",
      "Tom's fearless.\n",
      "那是我的。\n",
      "\n",
      "Tom's laughing.\n",
      "那是我的。\n",
      "\n",
      "Tom's thrilled.\n",
      "那是我的。\n",
      "\n",
      "Turn on the TV.\n",
      "你是什麼？\n",
      "\n",
      "Turn up the TV.\n",
      "你是什麼？\n",
      "\n",
      "Was Tom asleep?\n",
      "你不是我的。\n",
      "\n",
      "Wash your feet.\n",
      "你不是我的。\n",
      "\n",
      "Wash your feet.\n",
      "你不是我的。\n",
      "\n",
      "Watch yourself.\n",
      "你不是我的。\n",
      "\n",
      "We forgive you.\n",
      "他們是我的。\n",
      "\n",
      "We knew no one.\n",
      "他們是我的。\n",
      "\n",
      "We need a hero.\n",
      "他們是我的。\n",
      "\n",
      "We study music.\n",
      "他們是我的。\n",
      "\n",
      "We were robbed.\n",
      "他們是我的。\n",
      "\n",
      "We'll continue.\n",
      "他們是我的。\n",
      "\n",
      "We're a family.\n",
      "他是我的。\n",
      "\n",
      "We're not late.\n",
      "他是我的。\n",
      "\n",
      "Well, let's go.\n",
      "你是我的。\n",
      "\n",
      "Were you right?\n",
      "你不是我的。\n",
      "\n",
      "What about you?\n",
      "你不是我的。\n",
      "\n",
      "What about you?\n",
      "你不是我的。\n",
      "\n",
      "What do you do?\n",
      "你不是我的。\n",
      "\n",
      "What's her job?\n",
      "你不是我的。\n",
      "\n",
      "Where do we go?\n",
      "你不是我的。\n",
      "\n",
      "Where were you?\n",
      "我不是我的。\n",
      "\n",
      "Who's that guy?\n",
      "我不是你的。\n",
      "\n",
      "Who's that man?\n",
      "我不是你的。\n",
      "\n",
      "Why do you ask?\n",
      "我不是你的。\n",
      "\n",
      "Why is he here?\n",
      "你不是我的。\n",
      "\n",
      "Wipe your eyes.\n",
      "你不是我的。\n",
      "\n",
      "Yes, I know it.\n",
      "我不是你的。\n",
      "\n",
      "Yes, of course.\n",
      "我不是我的。\n",
      "\n",
      "You look bored.\n",
      "我不是我的。\n",
      "\n",
      "You look tense.\n",
      "我不是我的。\n",
      "\n",
      "You look tired.\n",
      "我不是我的。\n",
      "\n",
      "You look tired.\n",
      "我不是我的。\n",
      "\n",
      "You must do it.\n",
      "我不是我的。\n",
      "\n",
      "You'll love it.\n",
      "我不是你的。\n",
      "\n",
      "You're kidding!\n",
      "我不是你的。\n",
      "\n",
      "You're welcome.\n",
      "我不是你的。\n",
      "\n",
      "A man must work.\n",
      "他們是我的。\n",
      "\n",
      "Are you friends?\n",
      "我不是你的。\n",
      "\n",
      "Are you kidding?\n",
      "我不是你的。\n",
      "\n",
      "Are you over 18?\n",
      "我不是你的。\n",
      "\n",
      "Are you serious?\n",
      "我不是你的。\n",
      "\n",
      "Are you thirsty?\n",
      "我不是你的。\n",
      "\n",
      "Balls are round.\n",
      "你是我的。\n",
      "\n",
      "Be happy for me.\n",
      "你不是我的。\n",
      "\n",
      "Behave yourself.\n",
      "你是什麼？\n",
      "\n",
      "Black suits you.\n",
      "你是我的。\n",
      "\n",
      "Boil some water.\n",
      "你是我的。\n",
      "\n",
      "Call the police!\n",
      "你不是我的。\n",
      "\n",
      "Call the police!\n",
      "你不是我的。\n",
      "\n",
      "Call the police.\n",
      "你不是我的。\n",
      "\n",
      "Can you find it?\n",
      "我不是你的。\n",
      "\n",
      "Can you help me?\n",
      "我不是你的。\n",
      "\n",
      "Can you help me?\n",
      "我不是你的。\n",
      "\n",
      "Can you help us?\n",
      "我不是你的。\n",
      "\n",
      "Clean your room.\n",
      "你不是我的。\n",
      "\n",
      "Clean your room.\n",
      "你不是我的。\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "e149da774136999aaf00d4dc0a73ad671f5415143dd98642849dddd1d0bac9b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}