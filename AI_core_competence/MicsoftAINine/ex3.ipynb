{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3 深度卷积网络与计算机图像"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Alexnet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, 11, 4), # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2), # kernel_size, stride\n",
    "        # 减小卷积窗⼝口，使用填充为2来使得输入与输出的高和宽一致，且增⼤输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "        # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步 增⼤了输出通道数。\n",
    "        # 前两个卷积层后不使用池化层来减小输入的⾼和宽 \n",
    "            nn.Conv2d(256, 384, 3, 1, 1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    ")\n",
    "        # 这里全连接层的输出个数⽐ALexNet中的⼤数倍。使⽤dropout来缓解过拟合。\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "        # 输出层，论⽂1000 \n",
    "            nn.Linear(4096, 1000),\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def forward(self, img):\n",
    "    feature = self.conv(img)\n",
    "    output = self.fc(feature.view(img.shape[0], -1))\n",
    "    return output\n",
    "\n",
    "net = AlexNet()\n",
    "print(net)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import torch\n",
    "import torchvision.models as models # 导入网络框架\n",
    "import ptflops # 导入计算FLOPs的包"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "ptflops.get_model_complexity_info(models.vgg16(), (3,224,224))\n",
    "# ('15.5 GMac', '138.36 M')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/du/miniforge3/envs/tf/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-gqmopi53/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VGG(\n",
      "  138.358 M, 100.000% Params, 15.504 GMac, 100.000% MACs, \n",
      "  (features): Sequential(\n",
      "    14.715 M, 10.635% Params, 15.38 GMac, 99.202% MACs, \n",
      "    (0): Conv2d(0.002 M, 0.001% Params, 0.09 GMac, 0.580% MACs, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.003 GMac, 0.021% MACs, inplace=True)\n",
      "    (2): Conv2d(0.037 M, 0.027% Params, 1.853 GMac, 11.951% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0.0 M, 0.000% Params, 0.003 GMac, 0.021% MACs, inplace=True)\n",
      "    (4): MaxPool2d(0.0 M, 0.000% Params, 0.003 GMac, 0.021% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(0.074 M, 0.053% Params, 0.926 GMac, 5.976% MACs, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.010% MACs, inplace=True)\n",
      "    (7): Conv2d(0.148 M, 0.107% Params, 1.851 GMac, 11.941% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(0.0 M, 0.000% Params, 0.002 GMac, 0.010% MACs, inplace=True)\n",
      "    (9): MaxPool2d(0.0 M, 0.000% Params, 0.002 GMac, 0.010% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(0.295 M, 0.213% Params, 0.926 GMac, 5.971% MACs, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "    (12): Conv2d(0.59 M, 0.426% Params, 1.85 GMac, 11.936% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "    (14): Conv2d(0.59 M, 0.426% Params, 1.85 GMac, 11.936% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, inplace=True)\n",
      "    (16): MaxPool2d(0.0 M, 0.000% Params, 0.001 GMac, 0.005% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(1.18 M, 0.853% Params, 0.925 GMac, 5.968% MACs, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "    (19): Conv2d(2.36 M, 1.706% Params, 1.85 GMac, 11.933% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "    (21): Conv2d(2.36 M, 1.706% Params, 1.85 GMac, 11.933% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, inplace=True)\n",
      "    (23): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.003% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(2.36 M, 1.706% Params, 0.463 GMac, 2.983% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "    (26): Conv2d(2.36 M, 1.706% Params, 0.463 GMac, 2.983% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "    (28): Conv2d(2.36 M, 1.706% Params, 0.463 GMac, 2.983% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, inplace=True)\n",
      "    (30): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.001% MACs, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    123.643 M, 89.365% Params, 0.124 GMac, 0.798% MACs, \n",
      "    (0): Linear(102.765 M, 74.275% Params, 0.103 GMac, 0.663% MACs, in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (3): Linear(16.781 M, 12.129% Params, 0.017 GMac, 0.108% MACs, in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, inplace=True)\n",
      "    (5): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (6): Linear(4.097 M, 2.961% Params, 0.004 GMac, 0.026% MACs, in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('15.5 GMac', '138.36 M')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.9.0.post2\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "## Assignment"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 超参数定义\n",
    "EPOCH = 10               # 训练epoch次数\n",
    "BATCH_SIZE = 64         # 批训练的数量\n",
    "LR = 0.001              # 学习率\n",
    "DOWNLOAD_MNIST = False  # 设置True 可以自动下载数据"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import os\n",
    "path = os.path.expanduser('~/data/MS/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# MNIST数据集下载\n",
    "train_data = datasets.CIFAR10(root=path,\n",
    "                         train=True,                         # 这里是训练集\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True\n",
    "                        )\n",
    "\n",
    "test_data = datasets.CIFAR10(root=path,\n",
    "                        train=False,                         # 测试集\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True\n",
    "                        )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /Users/du/data/MS/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "170499072it [00:31, 5348209.39it/s]                                \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting /Users/du/data/MS/cifar-10-python.tar.gz to /Users/du/data/MS/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Cifar-10的标签\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# 输出图像\n",
    "temp = train_data[1][0].numpy()\n",
    "#print(temp)\n",
    "#print(temp.shape)\n",
    "temp = temp.transpose(1, 2, 0)\n",
    "print(temp.shape)\n",
    "#print(temp)\n",
    "plt.imshow(temp)\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 使用DataLoader进行分批\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# ResNet Model\n",
    "#model = ResNet34()\n",
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "#model = torchvision.models.densenet161(pretrained=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#损失函数:这里用交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#优化器 这里用SGD\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#device : GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import time\n",
    "# 训练\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 清空上一轮梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "    print('epoch{} loss:{:.4f} time:{:.4f}'.format(epoch+1, loss.item(), time.time()-start_time))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#保存训练模型\n",
    "file_name = 'cifar10_resnet.pt'\n",
    "torch.save(model, file_name)\n",
    "print(file_name+' saved')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 测试\n",
    "model = torch.load('cifar10_resnet.pt')\n",
    "model.eval()\n",
    "print(model)\n",
    "correct = 0\n",
    "total = 0"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cifar10_resnet.pt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_85027/3282167305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 测试\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10_resnet.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cifar10_resnet.pt'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    # 前向传播\n",
    "    out = model(images)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'total' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/ipykernel_85027/1261415423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'total' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#输出识别准确率\n",
    "print('10000测试图像 准确率:{:.4f}%'.format(100 * correct / total)) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Cifar10 Resnet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 超参数定义\n",
    "EPOCH = 10               # 训练epoch次数\n",
    "BATCH_SIZE = 64         # 批训练的数量\n",
    "LR = 0.001              # 学习率\n",
    "DOWNLOAD_MNIST = False  # 设置True 可以自动下载数据"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MNIST数据集下载\n",
    "train_data = datasets.CIFAR10(root=path,\n",
    "                         train=True,                         # 这里是训练集\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True\n",
    "                        )\n",
    "\n",
    "test_data = datasets.CIFAR10(root=path,\n",
    "                        train=False,                         # 测试集\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True\n",
    "                        )\n",
    "# Cifar-10的标签\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# 输出图像\n",
    "temp = train_data[1][0].numpy()\n",
    "#print(temp)\n",
    "#print(temp.shape)\n",
    "temp = temp.transpose(1, 2, 0)\n",
    "print(temp.shape)\n",
    "#print(temp)\n",
    "plt.imshow(temp)\n",
    "plt.show()\n",
    "\n",
    "# 使用DataLoader进行分批\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ResNet Model\n",
    "#model = ResNet34()\n",
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "#model = torchvision.models.densenet161(pretrained=False)\n",
    "\n",
    "\n",
    "#损失函数:这里用交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#优化器 这里用SGD\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#device : GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 训练\n",
    "for epoch in range(EPOCH):\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失函数\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 清空上一轮梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "    print('epoch{} loss:{:.4f} time:{:.4f}'.format(epoch+1, loss.item(), time.time()-start_time))\n",
    "\n",
    "#保存训练模型\n",
    "file_name = 'cifar10_resnet.pt'\n",
    "torch.save(model, file_name)\n",
    "print(file_name+' saved')\n",
    "\n",
    "\n",
    "# 测试\n",
    "model = torch.load('cifar10_resnet.pt')\n",
    "model.eval()\n",
    "print(model)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    # 前向传播\n",
    "    out = model(images)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "#输出识别准确率\n",
    "print('10000测试图像 准确率:{:.4f}%'.format(100 * correct / total)) \n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "35f69483aa8b7b2bb12f1e6f2ffb8fe1120cf837ca5a80070d69961a5682f06d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}