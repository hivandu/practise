{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 机器学习一"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression Example\n",
    "\n",
    "Implement Linear Regression for Beijing House Price Problem"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Part-01: Linear Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "\n",
    "housing_price = load_boston()\n",
    "dataframe = pd.DataFrame(housing_price['data'])\n",
    "dataframe.columns = housing_price['feature_names']\n",
    "dataframe['price'] = housing_price['target']\n",
    "\n",
    "# sns.heatmap(dataframe.corr(), annot=True, fmt='.1f')\n",
    "# plt.show()\n",
    "\n",
    "print(dataframe.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "rm = dataframe['RM']\n",
    "lst = dataframe['LSTAT']\n",
    "target = dataframe['price']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def model(x, w, b):\n",
    "    return np.dot(x, w.T) + b\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return np.mean( (yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def partial_w(x1, x2, y, yhat):\n",
    "    return np.array([2 *np.mean((yhat - y) * x1), 2 * np.mean((yhat - y)  * x2)])\n",
    "\n",
    "\n",
    "def partial_b(x1, x2, y, yhat):\n",
    "    return 2 * np.mean((yhat - y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "w = np.random.random_sample((1, 2))\n",
    "print(w)\n",
    "b = 0\n",
    "alpha = 1e-5\n",
    "\n",
    "epoch = 200\n",
    "history = []\n",
    "\n",
    "history_k_b_loss = []"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.28069036 0.31921797]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for e in range(epoch):\n",
    "    losses = []\n",
    "    for batch in range(len(rm)):\n",
    "        random_index = random.choice(range(len(rm)))\n",
    "\n",
    "        x1, x2 = rm[random_index], lst[random_index]\n",
    "        y = target[random_index]\n",
    "\n",
    "        yhat = model(np.array([x1, x2]), w, b)\n",
    "        loss_v = loss(yhat, y)\n",
    "\n",
    "        w = w - partial_w(x1, x2, y, yhat) * alpha\n",
    "        b = b - partial_b(x1, x2, y, yhat) * alpha\n",
    "\n",
    "        losses.append(loss_v)\n",
    "\n",
    "        history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, loss: {}'.format(e, batch, np.mean(losses)))\n",
    "\n",
    "    history.append(np.mean(losses))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Batch: 0, loss: 151.86271856102778\n",
      "Epoch: 0, Batch: 100, loss: 263.5872813250959\n",
      "Epoch: 0, Batch: 200, loss: 251.738169143727\n",
      "Epoch: 0, Batch: 300, loss: 265.0873434683313\n",
      "Epoch: 0, Batch: 400, loss: 246.81922554270534\n",
      "Epoch: 0, Batch: 500, loss: 235.3032255992267\n",
      "Epoch: 1, Batch: 0, loss: 19.57790198635195\n",
      "Epoch: 1, Batch: 100, loss: 159.31380412508983\n",
      "Epoch: 1, Batch: 200, loss: 149.39271607684955\n",
      "Epoch: 1, Batch: 300, loss: 166.24008703389129\n",
      "Epoch: 1, Batch: 400, loss: 160.65535981907715\n",
      "Epoch: 1, Batch: 500, loss: 159.46308073670542\n",
      "Epoch: 2, Batch: 0, loss: 218.59722447423346\n",
      "Epoch: 2, Batch: 100, loss: 136.07201691576378\n",
      "Epoch: 2, Batch: 200, loss: 161.51368122041697\n",
      "Epoch: 2, Batch: 300, loss: 159.4969141796809\n",
      "Epoch: 2, Batch: 400, loss: 146.21689426224953\n",
      "Epoch: 2, Batch: 500, loss: 138.22587212292893\n",
      "Epoch: 3, Batch: 0, loss: 69.70191445306189\n",
      "Epoch: 3, Batch: 100, loss: 116.16786760488094\n",
      "Epoch: 3, Batch: 200, loss: 119.71565030867042\n",
      "Epoch: 3, Batch: 300, loss: 119.72495468428124\n",
      "Epoch: 3, Batch: 400, loss: 116.70865835408661\n",
      "Epoch: 3, Batch: 500, loss: 111.52662518854393\n",
      "Epoch: 4, Batch: 0, loss: 301.1079696325349\n",
      "Epoch: 4, Batch: 100, loss: 101.1909070945794\n",
      "Epoch: 4, Batch: 200, loss: 100.01416445487479\n",
      "Epoch: 4, Batch: 300, loss: 90.97206766070506\n",
      "Epoch: 4, Batch: 400, loss: 86.95881766845801\n",
      "Epoch: 4, Batch: 500, loss: 88.33357502745008\n",
      "Epoch: 5, Batch: 0, loss: 687.0273172938508\n",
      "Epoch: 5, Batch: 100, loss: 87.36807188405818\n",
      "Epoch: 5, Batch: 200, loss: 74.37797938908042\n",
      "Epoch: 5, Batch: 300, loss: 75.59216012531017\n",
      "Epoch: 5, Batch: 400, loss: 78.77199270772117\n",
      "Epoch: 5, Batch: 500, loss: 77.72356050510173\n",
      "Epoch: 6, Batch: 0, loss: 142.03235346639255\n",
      "Epoch: 6, Batch: 100, loss: 82.12889078928916\n",
      "Epoch: 6, Batch: 200, loss: 80.40001132271382\n",
      "Epoch: 6, Batch: 300, loss: 79.73214799065559\n",
      "Epoch: 6, Batch: 400, loss: 78.41625605450311\n",
      "Epoch: 6, Batch: 500, loss: 73.61440886769903\n",
      "Epoch: 7, Batch: 0, loss: 2.999704782203545\n",
      "Epoch: 7, Batch: 100, loss: 53.73487423242271\n",
      "Epoch: 7, Batch: 200, loss: 69.25139129372873\n",
      "Epoch: 7, Batch: 300, loss: 71.43868136744443\n",
      "Epoch: 7, Batch: 400, loss: 74.62067875620376\n",
      "Epoch: 7, Batch: 500, loss: 71.88724308147587\n",
      "Epoch: 8, Batch: 0, loss: 36.896851330025626\n",
      "Epoch: 8, Batch: 100, loss: 69.68140462796016\n",
      "Epoch: 8, Batch: 200, loss: 69.0446454834692\n",
      "Epoch: 8, Batch: 300, loss: 66.61806321337968\n",
      "Epoch: 8, Batch: 400, loss: 64.1019048076429\n",
      "Epoch: 8, Batch: 500, loss: 64.57199748726141\n",
      "Epoch: 9, Batch: 0, loss: 1.5620537354076756\n",
      "Epoch: 9, Batch: 100, loss: 62.479252095999044\n",
      "Epoch: 9, Batch: 200, loss: 56.29570175037498\n",
      "Epoch: 9, Batch: 300, loss: 63.127310419096595\n",
      "Epoch: 9, Batch: 400, loss: 66.26081494988455\n",
      "Epoch: 9, Batch: 500, loss: 62.1994102965722\n",
      "Epoch: 10, Batch: 0, loss: 22.030416485290065\n",
      "Epoch: 10, Batch: 100, loss: 62.62437714937045\n",
      "Epoch: 10, Batch: 200, loss: 59.05630710317881\n",
      "Epoch: 10, Batch: 300, loss: 54.5041687174911\n",
      "Epoch: 10, Batch: 400, loss: 55.32999280381202\n",
      "Epoch: 10, Batch: 500, loss: 54.87343559518623\n",
      "Epoch: 11, Batch: 0, loss: 29.361104848422762\n",
      "Epoch: 11, Batch: 100, loss: 42.547683806003\n",
      "Epoch: 11, Batch: 200, loss: 35.99141361624825\n",
      "Epoch: 11, Batch: 300, loss: 34.940465018782014\n",
      "Epoch: 11, Batch: 400, loss: 40.66636646214102\n",
      "Epoch: 11, Batch: 500, loss: 38.28134421927383\n",
      "Epoch: 12, Batch: 0, loss: 59.49993038102367\n",
      "Epoch: 12, Batch: 100, loss: 39.89516680768858\n",
      "Epoch: 12, Batch: 200, loss: 34.19837436038725\n",
      "Epoch: 12, Batch: 300, loss: 33.48473431165181\n",
      "Epoch: 12, Batch: 400, loss: 34.69317741078055\n",
      "Epoch: 12, Batch: 500, loss: 33.12654176831267\n",
      "Epoch: 13, Batch: 0, loss: 25.271972178731048\n",
      "Epoch: 13, Batch: 100, loss: 31.612711881588854\n",
      "Epoch: 13, Batch: 200, loss: 39.35781727181857\n",
      "Epoch: 13, Batch: 300, loss: 36.8155649469042\n",
      "Epoch: 13, Batch: 400, loss: 38.3033897993873\n",
      "Epoch: 13, Batch: 500, loss: 36.61344656354103\n",
      "Epoch: 14, Batch: 0, loss: 7.084891138776679\n",
      "Epoch: 14, Batch: 100, loss: 40.910490317411615\n",
      "Epoch: 14, Batch: 200, loss: 44.152767526044386\n",
      "Epoch: 14, Batch: 300, loss: 43.27885404471312\n",
      "Epoch: 14, Batch: 400, loss: 46.88395620164672\n",
      "Epoch: 14, Batch: 500, loss: 44.38927904791927\n",
      "Epoch: 15, Batch: 0, loss: 20.45614877389572\n",
      "Epoch: 15, Batch: 100, loss: 32.40748144288569\n",
      "Epoch: 15, Batch: 200, loss: 37.07707762580113\n",
      "Epoch: 15, Batch: 300, loss: 37.09109419926531\n",
      "Epoch: 15, Batch: 400, loss: 39.30329538619549\n",
      "Epoch: 15, Batch: 500, loss: 36.578203328669986\n",
      "Epoch: 16, Batch: 0, loss: 92.38577100309116\n",
      "Epoch: 16, Batch: 100, loss: 38.66016206695904\n",
      "Epoch: 16, Batch: 200, loss: 31.916286313138308\n",
      "Epoch: 16, Batch: 300, loss: 34.41960011323012\n",
      "Epoch: 16, Batch: 400, loss: 33.85825821505797\n",
      "Epoch: 16, Batch: 500, loss: 34.78532404516187\n",
      "Epoch: 17, Batch: 0, loss: 6.889806565934152\n",
      "Epoch: 17, Batch: 100, loss: 21.95791331495036\n",
      "Epoch: 17, Batch: 200, loss: 27.29413704953488\n",
      "Epoch: 17, Batch: 300, loss: 28.412592296096975\n",
      "Epoch: 17, Batch: 400, loss: 28.729023867738768\n",
      "Epoch: 17, Batch: 500, loss: 29.226775199267674\n",
      "Epoch: 18, Batch: 0, loss: 198.27259611730167\n",
      "Epoch: 18, Batch: 100, loss: 42.10293942614401\n",
      "Epoch: 18, Batch: 200, loss: 39.8124791105493\n",
      "Epoch: 18, Batch: 300, loss: 34.54985922784335\n",
      "Epoch: 18, Batch: 400, loss: 33.20359934905601\n",
      "Epoch: 18, Batch: 500, loss: 34.0249912901313\n",
      "Epoch: 19, Batch: 0, loss: 17.98815619986454\n",
      "Epoch: 19, Batch: 100, loss: 26.076312723388213\n",
      "Epoch: 19, Batch: 200, loss: 29.222649772026145\n",
      "Epoch: 19, Batch: 300, loss: 30.624361129199805\n",
      "Epoch: 19, Batch: 400, loss: 30.218575917281\n",
      "Epoch: 19, Batch: 500, loss: 30.00436544578612\n",
      "Epoch: 20, Batch: 0, loss: 0.0015859058859536035\n",
      "Epoch: 20, Batch: 100, loss: 24.623892928988273\n",
      "Epoch: 20, Batch: 200, loss: 35.26859813481474\n",
      "Epoch: 20, Batch: 300, loss: 34.69751343874608\n",
      "Epoch: 20, Batch: 400, loss: 34.12203376947327\n",
      "Epoch: 20, Batch: 500, loss: 34.46291319407624\n",
      "Epoch: 21, Batch: 0, loss: 161.14912550890529\n",
      "Epoch: 21, Batch: 100, loss: 43.69241143537513\n",
      "Epoch: 21, Batch: 200, loss: 34.354055564250764\n",
      "Epoch: 21, Batch: 300, loss: 33.4141543870957\n",
      "Epoch: 21, Batch: 400, loss: 29.67776980159644\n",
      "Epoch: 21, Batch: 500, loss: 31.359651906740048\n",
      "Epoch: 22, Batch: 0, loss: 4.694933397995705\n",
      "Epoch: 22, Batch: 100, loss: 27.317556158556176\n",
      "Epoch: 22, Batch: 200, loss: 28.053522442427383\n",
      "Epoch: 22, Batch: 300, loss: 31.531247469511346\n",
      "Epoch: 22, Batch: 400, loss: 31.89224710598725\n",
      "Epoch: 22, Batch: 500, loss: 31.942578678990216\n",
      "Epoch: 23, Batch: 0, loss: 60.49088020425111\n",
      "Epoch: 23, Batch: 100, loss: 24.336701308769136\n",
      "Epoch: 23, Batch: 200, loss: 31.7638544445267\n",
      "Epoch: 23, Batch: 300, loss: 32.897238300733655\n",
      "Epoch: 23, Batch: 400, loss: 34.370256622575575\n",
      "Epoch: 23, Batch: 500, loss: 34.20967828301992\n",
      "Epoch: 24, Batch: 0, loss: 12.227703694585443\n",
      "Epoch: 24, Batch: 100, loss: 40.038148660323756\n",
      "Epoch: 24, Batch: 200, loss: 37.685625987092166\n",
      "Epoch: 24, Batch: 300, loss: 35.586942453758894\n",
      "Epoch: 24, Batch: 400, loss: 33.269859003856475\n",
      "Epoch: 24, Batch: 500, loss: 32.85228694694926\n",
      "Epoch: 25, Batch: 0, loss: 3.926836992766063\n",
      "Epoch: 25, Batch: 100, loss: 33.15925241452309\n",
      "Epoch: 25, Batch: 200, loss: 34.356903394375564\n",
      "Epoch: 25, Batch: 300, loss: 33.58234853599115\n",
      "Epoch: 25, Batch: 400, loss: 35.02741156475758\n",
      "Epoch: 25, Batch: 500, loss: 33.499646226388\n",
      "Epoch: 26, Batch: 0, loss: 0.8578349713062072\n",
      "Epoch: 26, Batch: 100, loss: 32.596236380035656\n",
      "Epoch: 26, Batch: 200, loss: 32.489380350880275\n",
      "Epoch: 26, Batch: 300, loss: 31.1861640307448\n",
      "Epoch: 26, Batch: 400, loss: 32.26211836114462\n",
      "Epoch: 26, Batch: 500, loss: 31.369599042609938\n",
      "Epoch: 27, Batch: 0, loss: 22.104615036401647\n",
      "Epoch: 27, Batch: 100, loss: 28.481794856334727\n",
      "Epoch: 27, Batch: 200, loss: 27.45479438330033\n",
      "Epoch: 27, Batch: 300, loss: 28.926492481023608\n",
      "Epoch: 27, Batch: 400, loss: 29.11832225082311\n",
      "Epoch: 27, Batch: 500, loss: 30.083655866017732\n",
      "Epoch: 28, Batch: 0, loss: 243.9054676188883\n",
      "Epoch: 28, Batch: 100, loss: 31.258928854990803\n",
      "Epoch: 28, Batch: 200, loss: 27.1684138839439\n",
      "Epoch: 28, Batch: 300, loss: 27.30249422801341\n",
      "Epoch: 28, Batch: 400, loss: 29.928183857148284\n",
      "Epoch: 28, Batch: 500, loss: 33.041488562238925\n",
      "Epoch: 29, Batch: 0, loss: 0.7775333426504427\n",
      "Epoch: 29, Batch: 100, loss: 38.46476642429085\n",
      "Epoch: 29, Batch: 200, loss: 35.68328200190081\n",
      "Epoch: 29, Batch: 300, loss: 34.00318422649962\n",
      "Epoch: 29, Batch: 400, loss: 30.707524154260668\n",
      "Epoch: 29, Batch: 500, loss: 32.190528443319\n",
      "Epoch: 30, Batch: 0, loss: 48.637841165298916\n",
      "Epoch: 30, Batch: 100, loss: 22.94695814802364\n",
      "Epoch: 30, Batch: 200, loss: 25.67216308285661\n",
      "Epoch: 30, Batch: 300, loss: 27.455337516276327\n",
      "Epoch: 30, Batch: 400, loss: 27.849067951681878\n",
      "Epoch: 30, Batch: 500, loss: 26.887034347906557\n",
      "Epoch: 31, Batch: 0, loss: 20.304078356280304\n",
      "Epoch: 31, Batch: 100, loss: 38.522726074437244\n",
      "Epoch: 31, Batch: 200, loss: 34.9724137530051\n",
      "Epoch: 31, Batch: 300, loss: 33.27969556826092\n",
      "Epoch: 31, Batch: 400, loss: 30.907077573856046\n",
      "Epoch: 31, Batch: 500, loss: 32.38314340701879\n",
      "Epoch: 32, Batch: 0, loss: 10.015481515053919\n",
      "Epoch: 32, Batch: 100, loss: 26.563299662973957\n",
      "Epoch: 32, Batch: 200, loss: 30.724156498987995\n",
      "Epoch: 32, Batch: 300, loss: 33.743815007070964\n",
      "Epoch: 32, Batch: 400, loss: 30.268636963866264\n",
      "Epoch: 32, Batch: 500, loss: 32.402676391411525\n",
      "Epoch: 33, Batch: 0, loss: 0.5254683355011355\n",
      "Epoch: 33, Batch: 100, loss: 35.25841782970075\n",
      "Epoch: 33, Batch: 200, loss: 28.401137696364298\n",
      "Epoch: 33, Batch: 300, loss: 29.49186240006472\n",
      "Epoch: 33, Batch: 400, loss: 29.96508705300463\n",
      "Epoch: 33, Batch: 500, loss: 30.55342166100101\n",
      "Epoch: 34, Batch: 0, loss: 2.2955256387773195\n",
      "Epoch: 34, Batch: 100, loss: 18.128325369461805\n",
      "Epoch: 34, Batch: 200, loss: 29.533707550641537\n",
      "Epoch: 34, Batch: 300, loss: 28.960121574071206\n",
      "Epoch: 34, Batch: 400, loss: 32.216607843548445\n",
      "Epoch: 34, Batch: 500, loss: 32.88118393543442\n",
      "Epoch: 35, Batch: 0, loss: 12.865802606499042\n",
      "Epoch: 35, Batch: 100, loss: 33.53305044875567\n",
      "Epoch: 35, Batch: 200, loss: 33.54673711401922\n",
      "Epoch: 35, Batch: 300, loss: 33.26120705217852\n",
      "Epoch: 35, Batch: 400, loss: 32.79340425299953\n",
      "Epoch: 35, Batch: 500, loss: 38.07164670136746\n",
      "Epoch: 36, Batch: 0, loss: 398.62390400862836\n",
      "Epoch: 36, Batch: 100, loss: 36.13101239787231\n",
      "Epoch: 36, Batch: 200, loss: 28.618909581039627\n",
      "Epoch: 36, Batch: 300, loss: 23.982691265199144\n",
      "Epoch: 36, Batch: 400, loss: 24.09533228701084\n",
      "Epoch: 36, Batch: 500, loss: 22.935853351816746\n",
      "Epoch: 37, Batch: 0, loss: 214.23728368033275\n",
      "Epoch: 37, Batch: 100, loss: 28.16159535058307\n",
      "Epoch: 37, Batch: 200, loss: 26.38081711486729\n",
      "Epoch: 37, Batch: 300, loss: 29.88253928859922\n",
      "Epoch: 37, Batch: 400, loss: 30.83522442151158\n",
      "Epoch: 37, Batch: 500, loss: 32.04091003910562\n",
      "Epoch: 38, Batch: 0, loss: 13.842287234347062\n",
      "Epoch: 38, Batch: 100, loss: 26.384582946521476\n",
      "Epoch: 38, Batch: 200, loss: 29.959006237792153\n",
      "Epoch: 38, Batch: 300, loss: 27.625150184565015\n",
      "Epoch: 38, Batch: 400, loss: 30.622622549620512\n",
      "Epoch: 38, Batch: 500, loss: 30.861543594594178\n",
      "Epoch: 39, Batch: 0, loss: 0.7557671680993573\n",
      "Epoch: 39, Batch: 100, loss: 25.466551089412796\n",
      "Epoch: 39, Batch: 200, loss: 27.4856789415227\n",
      "Epoch: 39, Batch: 300, loss: 26.573142058853207\n",
      "Epoch: 39, Batch: 400, loss: 25.7361860954227\n",
      "Epoch: 39, Batch: 500, loss: 26.634017651720708\n",
      "Epoch: 40, Batch: 0, loss: 15.012149720727257\n",
      "Epoch: 40, Batch: 100, loss: 28.193843288443166\n",
      "Epoch: 40, Batch: 200, loss: 27.82214169101274\n",
      "Epoch: 40, Batch: 300, loss: 32.42203834921894\n",
      "Epoch: 40, Batch: 400, loss: 30.136698269864144\n",
      "Epoch: 40, Batch: 500, loss: 32.43330453679556\n",
      "Epoch: 41, Batch: 0, loss: 118.78843345902989\n",
      "Epoch: 41, Batch: 100, loss: 41.41042775080013\n",
      "Epoch: 41, Batch: 200, loss: 40.429680544209646\n",
      "Epoch: 41, Batch: 300, loss: 38.929380287067985\n",
      "Epoch: 41, Batch: 400, loss: 37.49354141848373\n",
      "Epoch: 41, Batch: 500, loss: 41.268319843346205\n",
      "Epoch: 42, Batch: 0, loss: 4.068897454001062\n",
      "Epoch: 42, Batch: 100, loss: 27.55957524542181\n",
      "Epoch: 42, Batch: 200, loss: 30.590362682751405\n",
      "Epoch: 42, Batch: 300, loss: 33.07731074722544\n",
      "Epoch: 42, Batch: 400, loss: 35.42535231962564\n",
      "Epoch: 42, Batch: 500, loss: 35.3182428807358\n",
      "Epoch: 43, Batch: 0, loss: 2.173626151743135\n",
      "Epoch: 43, Batch: 100, loss: 25.62597591429642\n",
      "Epoch: 43, Batch: 200, loss: 24.344820769540966\n",
      "Epoch: 43, Batch: 300, loss: 27.08379379696445\n",
      "Epoch: 43, Batch: 400, loss: 26.182313632491283\n",
      "Epoch: 43, Batch: 500, loss: 25.76147547706503\n",
      "Epoch: 44, Batch: 0, loss: 1.0543236506099445\n",
      "Epoch: 44, Batch: 100, loss: 28.005291809908496\n",
      "Epoch: 44, Batch: 200, loss: 28.634022140881505\n",
      "Epoch: 44, Batch: 300, loss: 30.631171859496327\n",
      "Epoch: 44, Batch: 400, loss: 31.760867575697592\n",
      "Epoch: 44, Batch: 500, loss: 33.82733294838247\n",
      "Epoch: 45, Batch: 0, loss: 13.510566037436215\n",
      "Epoch: 45, Batch: 100, loss: 24.961139764541144\n",
      "Epoch: 45, Batch: 200, loss: 20.821521378900584\n",
      "Epoch: 45, Batch: 300, loss: 21.99949545190694\n",
      "Epoch: 45, Batch: 400, loss: 24.24693057579323\n",
      "Epoch: 45, Batch: 500, loss: 25.753938696000034\n",
      "Epoch: 46, Batch: 0, loss: 14.72202806931071\n",
      "Epoch: 46, Batch: 100, loss: 42.101117360517314\n",
      "Epoch: 46, Batch: 200, loss: 34.93242262987167\n",
      "Epoch: 46, Batch: 300, loss: 34.944104686674144\n",
      "Epoch: 46, Batch: 400, loss: 32.787950991621734\n",
      "Epoch: 46, Batch: 500, loss: 30.598427838384552\n",
      "Epoch: 47, Batch: 0, loss: 0.0905165483219156\n",
      "Epoch: 47, Batch: 100, loss: 52.73033108727144\n",
      "Epoch: 47, Batch: 200, loss: 40.812239471941275\n",
      "Epoch: 47, Batch: 300, loss: 35.88203310840532\n",
      "Epoch: 47, Batch: 400, loss: 35.39601954379696\n",
      "Epoch: 47, Batch: 500, loss: 35.06192472755305\n",
      "Epoch: 48, Batch: 0, loss: 0.41331500332857307\n",
      "Epoch: 48, Batch: 100, loss: 39.53511605875581\n",
      "Epoch: 48, Batch: 200, loss: 32.17648913102445\n",
      "Epoch: 48, Batch: 300, loss: 31.274276059266406\n",
      "Epoch: 48, Batch: 400, loss: 31.06141590727584\n",
      "Epoch: 48, Batch: 500, loss: 29.91555958655462\n",
      "Epoch: 49, Batch: 0, loss: 36.1340883209245\n",
      "Epoch: 49, Batch: 100, loss: 26.02133862371226\n",
      "Epoch: 49, Batch: 200, loss: 25.698756375721548\n",
      "Epoch: 49, Batch: 300, loss: 27.08756977066256\n",
      "Epoch: 49, Batch: 400, loss: 27.983550898940393\n",
      "Epoch: 49, Batch: 500, loss: 28.734677793158482\n",
      "Epoch: 50, Batch: 0, loss: 8.915098622499553\n",
      "Epoch: 50, Batch: 100, loss: 27.674222998815512\n",
      "Epoch: 50, Batch: 200, loss: 30.189970372797045\n",
      "Epoch: 50, Batch: 300, loss: 33.876596258314585\n",
      "Epoch: 50, Batch: 400, loss: 33.004765867596944\n",
      "Epoch: 50, Batch: 500, loss: 33.47469335826658\n",
      "Epoch: 51, Batch: 0, loss: 159.50930520520754\n",
      "Epoch: 51, Batch: 100, loss: 32.17631675999327\n",
      "Epoch: 51, Batch: 200, loss: 31.285823960705997\n",
      "Epoch: 51, Batch: 300, loss: 31.04698431646898\n",
      "Epoch: 51, Batch: 400, loss: 29.70239326193607\n",
      "Epoch: 51, Batch: 500, loss: 29.517623990371238\n",
      "Epoch: 52, Batch: 0, loss: 0.3379845675212036\n",
      "Epoch: 52, Batch: 100, loss: 33.76613611574095\n",
      "Epoch: 52, Batch: 200, loss: 36.54785494531031\n",
      "Epoch: 52, Batch: 300, loss: 32.1693767288305\n",
      "Epoch: 52, Batch: 400, loss: 31.59731384422743\n",
      "Epoch: 52, Batch: 500, loss: 33.86558850121941\n",
      "Epoch: 53, Batch: 0, loss: 30.710940584755257\n",
      "Epoch: 53, Batch: 100, loss: 24.26515757648127\n",
      "Epoch: 53, Batch: 200, loss: 25.462565026445503\n",
      "Epoch: 53, Batch: 300, loss: 28.071322710968257\n",
      "Epoch: 53, Batch: 400, loss: 26.806666357250666\n",
      "Epoch: 53, Batch: 500, loss: 29.86906534788889\n",
      "Epoch: 54, Batch: 0, loss: 3.251208118468873\n",
      "Epoch: 54, Batch: 100, loss: 26.72640565860997\n",
      "Epoch: 54, Batch: 200, loss: 24.540073163896103\n",
      "Epoch: 54, Batch: 300, loss: 28.65492119910187\n",
      "Epoch: 54, Batch: 400, loss: 25.617123134842277\n",
      "Epoch: 54, Batch: 500, loss: 27.05855648092723\n",
      "Epoch: 55, Batch: 0, loss: 0.3823770900253979\n",
      "Epoch: 55, Batch: 100, loss: 57.98255198154399\n",
      "Epoch: 55, Batch: 200, loss: 39.7185978832313\n",
      "Epoch: 55, Batch: 300, loss: 36.39462736082935\n",
      "Epoch: 55, Batch: 400, loss: 32.7077147214083\n",
      "Epoch: 55, Batch: 500, loss: 32.268753246925776\n",
      "Epoch: 56, Batch: 0, loss: 9.50190681155597\n",
      "Epoch: 56, Batch: 100, loss: 34.334716751575236\n",
      "Epoch: 56, Batch: 200, loss: 31.56608556109674\n",
      "Epoch: 56, Batch: 300, loss: 32.33175019994608\n",
      "Epoch: 56, Batch: 400, loss: 30.842374454947386\n",
      "Epoch: 56, Batch: 500, loss: 29.9872919135674\n",
      "Epoch: 57, Batch: 0, loss: 21.212535089908908\n",
      "Epoch: 57, Batch: 100, loss: 31.504120170261437\n",
      "Epoch: 57, Batch: 200, loss: 30.17816414808487\n",
      "Epoch: 57, Batch: 300, loss: 30.58278826299807\n",
      "Epoch: 57, Batch: 400, loss: 29.504009395186625\n",
      "Epoch: 57, Batch: 500, loss: 30.116778687315172\n",
      "Epoch: 58, Batch: 0, loss: 0.5823375144454358\n",
      "Epoch: 58, Batch: 100, loss: 30.421549366229605\n",
      "Epoch: 58, Batch: 200, loss: 34.147710802142676\n",
      "Epoch: 58, Batch: 300, loss: 35.742212194576744\n",
      "Epoch: 58, Batch: 400, loss: 34.03083636922469\n",
      "Epoch: 58, Batch: 500, loss: 31.912926444769067\n",
      "Epoch: 59, Batch: 0, loss: 1.498364506794748\n",
      "Epoch: 59, Batch: 100, loss: 25.113171115935934\n",
      "Epoch: 59, Batch: 200, loss: 31.742653993990764\n",
      "Epoch: 59, Batch: 300, loss: 32.88018362261261\n",
      "Epoch: 59, Batch: 400, loss: 34.73348567380645\n",
      "Epoch: 59, Batch: 500, loss: 35.166402543350614\n",
      "Epoch: 60, Batch: 0, loss: 58.89771516501617\n",
      "Epoch: 60, Batch: 100, loss: 44.31483073246654\n",
      "Epoch: 60, Batch: 200, loss: 38.18930108240712\n",
      "Epoch: 60, Batch: 300, loss: 37.03711120444295\n",
      "Epoch: 60, Batch: 400, loss: 35.96569891616204\n",
      "Epoch: 60, Batch: 500, loss: 34.49047978851318\n",
      "Epoch: 61, Batch: 0, loss: 15.653458266171622\n",
      "Epoch: 61, Batch: 100, loss: 30.61358978654125\n",
      "Epoch: 61, Batch: 200, loss: 27.611073648637383\n",
      "Epoch: 61, Batch: 300, loss: 33.31015695441362\n",
      "Epoch: 61, Batch: 400, loss: 33.61562964343377\n",
      "Epoch: 61, Batch: 500, loss: 32.7392434534786\n",
      "Epoch: 62, Batch: 0, loss: 3.5374909102434016\n",
      "Epoch: 62, Batch: 100, loss: 25.223080017817196\n",
      "Epoch: 62, Batch: 200, loss: 25.318297856061022\n",
      "Epoch: 62, Batch: 300, loss: 29.980016180151615\n",
      "Epoch: 62, Batch: 400, loss: 28.20780327570491\n",
      "Epoch: 62, Batch: 500, loss: 28.65620686100714\n",
      "Epoch: 63, Batch: 0, loss: 8.782388031812198\n",
      "Epoch: 63, Batch: 100, loss: 41.760476803492274\n",
      "Epoch: 63, Batch: 200, loss: 37.239657883258836\n",
      "Epoch: 63, Batch: 300, loss: 33.96675312269565\n",
      "Epoch: 63, Batch: 400, loss: 36.91796511949727\n",
      "Epoch: 63, Batch: 500, loss: 36.541487628569264\n",
      "Epoch: 64, Batch: 0, loss: 7.282500385317131\n",
      "Epoch: 64, Batch: 100, loss: 33.36578910746297\n",
      "Epoch: 64, Batch: 200, loss: 37.12876354216032\n",
      "Epoch: 64, Batch: 300, loss: 36.52640170187666\n",
      "Epoch: 64, Batch: 400, loss: 35.699576711298874\n",
      "Epoch: 64, Batch: 500, loss: 32.692721973581776\n",
      "Epoch: 65, Batch: 0, loss: 22.52103754388937\n",
      "Epoch: 65, Batch: 100, loss: 47.02809516423788\n",
      "Epoch: 65, Batch: 200, loss: 38.61208101673671\n",
      "Epoch: 65, Batch: 300, loss: 36.22418451234597\n",
      "Epoch: 65, Batch: 400, loss: 35.252876316772834\n",
      "Epoch: 65, Batch: 500, loss: 35.35232626560442\n",
      "Epoch: 66, Batch: 0, loss: 64.75033103490945\n",
      "Epoch: 66, Batch: 100, loss: 40.507250472795256\n",
      "Epoch: 66, Batch: 200, loss: 39.32120015028534\n",
      "Epoch: 66, Batch: 300, loss: 35.993703138579164\n",
      "Epoch: 66, Batch: 400, loss: 34.43458353290945\n",
      "Epoch: 66, Batch: 500, loss: 34.59135179617969\n",
      "Epoch: 67, Batch: 0, loss: 6.434877106434207\n",
      "Epoch: 67, Batch: 100, loss: 26.434394046578145\n",
      "Epoch: 67, Batch: 200, loss: 27.268025049974003\n",
      "Epoch: 67, Batch: 300, loss: 24.327803006276493\n",
      "Epoch: 67, Batch: 400, loss: 28.495852273366207\n",
      "Epoch: 67, Batch: 500, loss: 28.84909726676323\n",
      "Epoch: 68, Batch: 0, loss: 4.863210598704809\n",
      "Epoch: 68, Batch: 100, loss: 32.59408453038587\n",
      "Epoch: 68, Batch: 200, loss: 35.29543664640058\n",
      "Epoch: 68, Batch: 300, loss: 32.13697429878962\n",
      "Epoch: 68, Batch: 400, loss: 32.0188567965559\n",
      "Epoch: 68, Batch: 500, loss: 34.475404533261084\n",
      "Epoch: 69, Batch: 0, loss: 3.5129181248062027\n",
      "Epoch: 69, Batch: 100, loss: 38.81002575770595\n",
      "Epoch: 69, Batch: 200, loss: 32.65944937289356\n",
      "Epoch: 69, Batch: 300, loss: 36.25344493416537\n",
      "Epoch: 69, Batch: 400, loss: 35.301358161566384\n",
      "Epoch: 69, Batch: 500, loss: 33.65378652153365\n",
      "Epoch: 70, Batch: 0, loss: 20.062691707815123\n",
      "Epoch: 70, Batch: 100, loss: 38.29342909955808\n",
      "Epoch: 70, Batch: 200, loss: 32.684060945354986\n",
      "Epoch: 70, Batch: 300, loss: 29.865144991378585\n",
      "Epoch: 70, Batch: 400, loss: 29.859852675770906\n",
      "Epoch: 70, Batch: 500, loss: 28.714129604882874\n",
      "Epoch: 71, Batch: 0, loss: 1.4539789069163211\n",
      "Epoch: 71, Batch: 100, loss: 29.83595629825016\n",
      "Epoch: 71, Batch: 200, loss: 30.112735806912568\n",
      "Epoch: 71, Batch: 300, loss: 28.858276525086055\n",
      "Epoch: 71, Batch: 400, loss: 34.55060857995103\n",
      "Epoch: 71, Batch: 500, loss: 33.06572982732135\n",
      "Epoch: 72, Batch: 0, loss: 266.00991964753445\n",
      "Epoch: 72, Batch: 100, loss: 36.27709656843097\n",
      "Epoch: 72, Batch: 200, loss: 29.242234960592675\n",
      "Epoch: 72, Batch: 300, loss: 30.617897482473214\n",
      "Epoch: 72, Batch: 400, loss: 27.91408390159108\n",
      "Epoch: 72, Batch: 500, loss: 30.75343580045555\n",
      "Epoch: 73, Batch: 0, loss: 2.89309872471976\n",
      "Epoch: 73, Batch: 100, loss: 30.487105375582473\n",
      "Epoch: 73, Batch: 200, loss: 29.23312675665426\n",
      "Epoch: 73, Batch: 300, loss: 26.9448213370909\n",
      "Epoch: 73, Batch: 400, loss: 30.165039680813045\n",
      "Epoch: 73, Batch: 500, loss: 29.96964410623966\n",
      "Epoch: 74, Batch: 0, loss: 1.9182862582786504\n",
      "Epoch: 74, Batch: 100, loss: 29.361289853957203\n",
      "Epoch: 74, Batch: 200, loss: 33.28325411122837\n",
      "Epoch: 74, Batch: 300, loss: 32.355036031738074\n",
      "Epoch: 74, Batch: 400, loss: 33.765497928074495\n",
      "Epoch: 74, Batch: 500, loss: 31.04982015925226\n",
      "Epoch: 75, Batch: 0, loss: 5.193539460648481e-06\n",
      "Epoch: 75, Batch: 100, loss: 29.013074641075892\n",
      "Epoch: 75, Batch: 200, loss: 29.872290944564075\n",
      "Epoch: 75, Batch: 300, loss: 27.90140281564157\n",
      "Epoch: 75, Batch: 400, loss: 26.74359767474288\n",
      "Epoch: 75, Batch: 500, loss: 28.787171434560456\n",
      "Epoch: 76, Batch: 0, loss: 3.0387937840449757\n",
      "Epoch: 76, Batch: 100, loss: 28.573293115373808\n",
      "Epoch: 76, Batch: 200, loss: 36.07586231146388\n",
      "Epoch: 76, Batch: 300, loss: 33.46323128598504\n",
      "Epoch: 76, Batch: 400, loss: 34.42168308820863\n",
      "Epoch: 76, Batch: 500, loss: 33.36896856346415\n",
      "Epoch: 77, Batch: 0, loss: 47.60046349574445\n",
      "Epoch: 77, Batch: 100, loss: 40.47085858584558\n",
      "Epoch: 77, Batch: 200, loss: 35.06771150388789\n",
      "Epoch: 77, Batch: 300, loss: 36.44313769004401\n",
      "Epoch: 77, Batch: 400, loss: 34.31501414892465\n",
      "Epoch: 77, Batch: 500, loss: 33.081475016136366\n",
      "Epoch: 78, Batch: 0, loss: 3.574818638186254\n",
      "Epoch: 78, Batch: 100, loss: 29.68097735008753\n",
      "Epoch: 78, Batch: 200, loss: 26.442149206171255\n",
      "Epoch: 78, Batch: 300, loss: 28.96195192931903\n",
      "Epoch: 78, Batch: 400, loss: 29.577072621909835\n",
      "Epoch: 78, Batch: 500, loss: 30.603402771005253\n",
      "Epoch: 79, Batch: 0, loss: 176.48218996737708\n",
      "Epoch: 79, Batch: 100, loss: 33.101386230879854\n",
      "Epoch: 79, Batch: 200, loss: 32.52579561458027\n",
      "Epoch: 79, Batch: 300, loss: 33.45281089383448\n",
      "Epoch: 79, Batch: 400, loss: 31.998552811587356\n",
      "Epoch: 79, Batch: 500, loss: 30.00047672621255\n",
      "Epoch: 80, Batch: 0, loss: 106.90264836842381\n",
      "Epoch: 80, Batch: 100, loss: 36.378225701696664\n",
      "Epoch: 80, Batch: 200, loss: 35.0849459566853\n",
      "Epoch: 80, Batch: 300, loss: 34.02481289635926\n",
      "Epoch: 80, Batch: 400, loss: 31.364208641948498\n",
      "Epoch: 80, Batch: 500, loss: 31.908530169204138\n",
      "Epoch: 81, Batch: 0, loss: 77.36374781125177\n",
      "Epoch: 81, Batch: 100, loss: 20.48094954446718\n",
      "Epoch: 81, Batch: 200, loss: 26.111563975170146\n",
      "Epoch: 81, Batch: 300, loss: 25.77173334650013\n",
      "Epoch: 81, Batch: 400, loss: 27.50818681383035\n",
      "Epoch: 81, Batch: 500, loss: 27.920105981721047\n",
      "Epoch: 82, Batch: 0, loss: 2.7613042893180064\n",
      "Epoch: 82, Batch: 100, loss: 26.333110212187268\n",
      "Epoch: 82, Batch: 200, loss: 33.701805137550785\n",
      "Epoch: 82, Batch: 300, loss: 35.62865802860835\n",
      "Epoch: 82, Batch: 400, loss: 34.22618907895286\n",
      "Epoch: 82, Batch: 500, loss: 34.90431683713187\n",
      "Epoch: 83, Batch: 0, loss: 102.63763462708472\n",
      "Epoch: 83, Batch: 100, loss: 36.34445847209145\n",
      "Epoch: 83, Batch: 200, loss: 34.68975293644761\n",
      "Epoch: 83, Batch: 300, loss: 31.472308937746973\n",
      "Epoch: 83, Batch: 400, loss: 29.92566219809052\n",
      "Epoch: 83, Batch: 500, loss: 32.01873561570891\n",
      "Epoch: 84, Batch: 0, loss: 0.8520501144469809\n",
      "Epoch: 84, Batch: 100, loss: 22.632157422989135\n",
      "Epoch: 84, Batch: 200, loss: 25.926101998217696\n",
      "Epoch: 84, Batch: 300, loss: 30.79799549776256\n",
      "Epoch: 84, Batch: 400, loss: 32.921565022635036\n",
      "Epoch: 84, Batch: 500, loss: 32.802929429165545\n",
      "Epoch: 85, Batch: 0, loss: 27.96153396225017\n",
      "Epoch: 85, Batch: 100, loss: 37.98326899459553\n",
      "Epoch: 85, Batch: 200, loss: 31.02046079447852\n",
      "Epoch: 85, Batch: 300, loss: 29.170989415268995\n",
      "Epoch: 85, Batch: 400, loss: 30.177763779950716\n",
      "Epoch: 85, Batch: 500, loss: 30.581716378890178\n",
      "Epoch: 86, Batch: 0, loss: 0.17315250457320888\n",
      "Epoch: 86, Batch: 100, loss: 28.047152524194765\n",
      "Epoch: 86, Batch: 200, loss: 28.512781226332393\n",
      "Epoch: 86, Batch: 300, loss: 25.087975442891533\n",
      "Epoch: 86, Batch: 400, loss: 24.035472314243773\n",
      "Epoch: 86, Batch: 500, loss: 25.27654693024966\n",
      "Epoch: 87, Batch: 0, loss: 23.891654581892922\n",
      "Epoch: 87, Batch: 100, loss: 36.25316063794725\n",
      "Epoch: 87, Batch: 200, loss: 35.091782377435024\n",
      "Epoch: 87, Batch: 300, loss: 35.593846135051805\n",
      "Epoch: 87, Batch: 400, loss: 33.320168525277154\n",
      "Epoch: 87, Batch: 500, loss: 32.407318809348354\n",
      "Epoch: 88, Batch: 0, loss: 328.4929044983289\n",
      "Epoch: 88, Batch: 100, loss: 34.21398161375578\n",
      "Epoch: 88, Batch: 200, loss: 25.957966102852808\n",
      "Epoch: 88, Batch: 300, loss: 24.44343589522557\n",
      "Epoch: 88, Batch: 400, loss: 25.47592637188162\n",
      "Epoch: 88, Batch: 500, loss: 27.108303915010502\n",
      "Epoch: 89, Batch: 0, loss: 66.76827426734177\n",
      "Epoch: 89, Batch: 100, loss: 30.169798104627585\n",
      "Epoch: 89, Batch: 200, loss: 37.702332112926065\n",
      "Epoch: 89, Batch: 300, loss: 36.28042626391165\n",
      "Epoch: 89, Batch: 400, loss: 37.147032762115444\n",
      "Epoch: 89, Batch: 500, loss: 36.22864128796826\n",
      "Epoch: 90, Batch: 0, loss: 19.413751319639346\n",
      "Epoch: 90, Batch: 100, loss: 38.945273707431966\n",
      "Epoch: 90, Batch: 200, loss: 33.933559106425456\n",
      "Epoch: 90, Batch: 300, loss: 33.090252961885035\n",
      "Epoch: 90, Batch: 400, loss: 29.991991440881158\n",
      "Epoch: 90, Batch: 500, loss: 31.12058984914541\n",
      "Epoch: 91, Batch: 0, loss: 8.195419512202418\n",
      "Epoch: 91, Batch: 100, loss: 26.546885672700586\n",
      "Epoch: 91, Batch: 200, loss: 25.721975798815887\n",
      "Epoch: 91, Batch: 300, loss: 23.98456377285974\n",
      "Epoch: 91, Batch: 400, loss: 27.504465564493792\n",
      "Epoch: 91, Batch: 500, loss: 28.201944334429474\n",
      "Epoch: 92, Batch: 0, loss: 71.69446092132128\n",
      "Epoch: 92, Batch: 100, loss: 30.862633064204605\n",
      "Epoch: 92, Batch: 200, loss: 29.453617309713774\n",
      "Epoch: 92, Batch: 300, loss: 29.706937429782144\n",
      "Epoch: 92, Batch: 400, loss: 32.02482945322238\n",
      "Epoch: 92, Batch: 500, loss: 32.207617138742336\n",
      "Epoch: 93, Batch: 0, loss: 2.255680884769418\n",
      "Epoch: 93, Batch: 100, loss: 29.2375801868141\n",
      "Epoch: 93, Batch: 200, loss: 33.60890543241565\n",
      "Epoch: 93, Batch: 300, loss: 30.75036787083414\n",
      "Epoch: 93, Batch: 400, loss: 28.367114560127696\n",
      "Epoch: 93, Batch: 500, loss: 27.8019637725988\n",
      "Epoch: 94, Batch: 0, loss: 6.746072755495724\n",
      "Epoch: 94, Batch: 100, loss: 21.594191865604675\n",
      "Epoch: 94, Batch: 200, loss: 38.451923354109056\n",
      "Epoch: 94, Batch: 300, loss: 34.96385259801116\n",
      "Epoch: 94, Batch: 400, loss: 35.61589963515951\n",
      "Epoch: 94, Batch: 500, loss: 34.894246583857075\n",
      "Epoch: 95, Batch: 0, loss: 0.9082519163940876\n",
      "Epoch: 95, Batch: 100, loss: 23.884015694860217\n",
      "Epoch: 95, Batch: 200, loss: 31.89015678685511\n",
      "Epoch: 95, Batch: 300, loss: 28.058118181803263\n",
      "Epoch: 95, Batch: 400, loss: 28.08084277226934\n",
      "Epoch: 95, Batch: 500, loss: 26.453311380811527\n",
      "Epoch: 96, Batch: 0, loss: 69.14744461058555\n",
      "Epoch: 96, Batch: 100, loss: 26.568063391462264\n",
      "Epoch: 96, Batch: 200, loss: 29.413879635536436\n",
      "Epoch: 96, Batch: 300, loss: 27.722137763840582\n",
      "Epoch: 96, Batch: 400, loss: 30.06847575330198\n",
      "Epoch: 96, Batch: 500, loss: 29.858453693972173\n",
      "Epoch: 97, Batch: 0, loss: 6.794750365467628\n",
      "Epoch: 97, Batch: 100, loss: 47.42081139735772\n",
      "Epoch: 97, Batch: 200, loss: 44.5281346551262\n",
      "Epoch: 97, Batch: 300, loss: 36.64365220471932\n",
      "Epoch: 97, Batch: 400, loss: 33.6133466648777\n",
      "Epoch: 97, Batch: 500, loss: 34.94311635134604\n",
      "Epoch: 98, Batch: 0, loss: 36.8071938247794\n",
      "Epoch: 98, Batch: 100, loss: 22.056113224788465\n",
      "Epoch: 98, Batch: 200, loss: 24.037662031547686\n",
      "Epoch: 98, Batch: 300, loss: 26.461409379362557\n",
      "Epoch: 98, Batch: 400, loss: 27.467074734831478\n",
      "Epoch: 98, Batch: 500, loss: 29.774083764753588\n",
      "Epoch: 99, Batch: 0, loss: 6.543956008805461\n",
      "Epoch: 99, Batch: 100, loss: 32.78065572380553\n",
      "Epoch: 99, Batch: 200, loss: 32.309056595281255\n",
      "Epoch: 99, Batch: 300, loss: 33.1194067954744\n",
      "Epoch: 99, Batch: 400, loss: 31.737911478842786\n",
      "Epoch: 99, Batch: 500, loss: 30.08386260310562\n",
      "Epoch: 100, Batch: 0, loss: 18.182114776573687\n",
      "Epoch: 100, Batch: 100, loss: 44.73200273890404\n",
      "Epoch: 100, Batch: 200, loss: 41.88986775344459\n",
      "Epoch: 100, Batch: 300, loss: 36.86601654638593\n",
      "Epoch: 100, Batch: 400, loss: 35.40507503203254\n",
      "Epoch: 100, Batch: 500, loss: 34.75405867655222\n",
      "Epoch: 101, Batch: 0, loss: 13.616717325916364\n",
      "Epoch: 101, Batch: 100, loss: 19.681668589780458\n",
      "Epoch: 101, Batch: 200, loss: 28.915746733992957\n",
      "Epoch: 101, Batch: 300, loss: 32.168564531979285\n",
      "Epoch: 101, Batch: 400, loss: 30.63231763688138\n",
      "Epoch: 101, Batch: 500, loss: 33.60013870949156\n",
      "Epoch: 102, Batch: 0, loss: 20.037203897273635\n",
      "Epoch: 102, Batch: 100, loss: 28.935579240998866\n",
      "Epoch: 102, Batch: 200, loss: 28.116986970372707\n",
      "Epoch: 102, Batch: 300, loss: 28.427609149711948\n",
      "Epoch: 102, Batch: 400, loss: 27.95388611005986\n",
      "Epoch: 102, Batch: 500, loss: 27.67177605410786\n",
      "Epoch: 103, Batch: 0, loss: 308.1863174043792\n",
      "Epoch: 103, Batch: 100, loss: 28.190168702465986\n",
      "Epoch: 103, Batch: 200, loss: 31.207728297332935\n",
      "Epoch: 103, Batch: 300, loss: 29.59134212016022\n",
      "Epoch: 103, Batch: 400, loss: 32.660317166477604\n",
      "Epoch: 103, Batch: 500, loss: 34.90132068086861\n",
      "Epoch: 104, Batch: 0, loss: 45.61394151555974\n",
      "Epoch: 104, Batch: 100, loss: 20.639098156190965\n",
      "Epoch: 104, Batch: 200, loss: 28.906091200032694\n",
      "Epoch: 104, Batch: 300, loss: 29.191947875410616\n",
      "Epoch: 104, Batch: 400, loss: 28.100837357075672\n",
      "Epoch: 104, Batch: 500, loss: 28.396071516045083\n",
      "Epoch: 105, Batch: 0, loss: 1.4064437296456072\n",
      "Epoch: 105, Batch: 100, loss: 36.68972361026234\n",
      "Epoch: 105, Batch: 200, loss: 34.240957190052036\n",
      "Epoch: 105, Batch: 300, loss: 33.519234651856955\n",
      "Epoch: 105, Batch: 400, loss: 32.24805059445114\n",
      "Epoch: 105, Batch: 500, loss: 30.04093682799037\n",
      "Epoch: 106, Batch: 0, loss: 1.470457230985701\n",
      "Epoch: 106, Batch: 100, loss: 28.48601677946738\n",
      "Epoch: 106, Batch: 200, loss: 26.458528231118795\n",
      "Epoch: 106, Batch: 300, loss: 25.483881242226325\n",
      "Epoch: 106, Batch: 400, loss: 25.4990884882143\n",
      "Epoch: 106, Batch: 500, loss: 27.22849807323616\n",
      "Epoch: 107, Batch: 0, loss: 0.7177457786693007\n",
      "Epoch: 107, Batch: 100, loss: 30.09146416093049\n",
      "Epoch: 107, Batch: 200, loss: 35.651054831816715\n",
      "Epoch: 107, Batch: 300, loss: 32.97727596703362\n",
      "Epoch: 107, Batch: 400, loss: 33.50788184596364\n",
      "Epoch: 107, Batch: 500, loss: 33.18888691016782\n",
      "Epoch: 108, Batch: 0, loss: 40.67689621351244\n",
      "Epoch: 108, Batch: 100, loss: 31.781864387495382\n",
      "Epoch: 108, Batch: 200, loss: 29.438063156395767\n",
      "Epoch: 108, Batch: 300, loss: 29.29518006189607\n",
      "Epoch: 108, Batch: 400, loss: 30.052387963034317\n",
      "Epoch: 108, Batch: 500, loss: 30.553893392136803\n",
      "Epoch: 109, Batch: 0, loss: 11.528893044707356\n",
      "Epoch: 109, Batch: 100, loss: 25.96634994511592\n",
      "Epoch: 109, Batch: 200, loss: 28.41853717569715\n",
      "Epoch: 109, Batch: 300, loss: 28.46183229963974\n",
      "Epoch: 109, Batch: 400, loss: 27.699345310091307\n",
      "Epoch: 109, Batch: 500, loss: 29.509162184792597\n",
      "Epoch: 110, Batch: 0, loss: 18.131087300053768\n",
      "Epoch: 110, Batch: 100, loss: 24.71207843115476\n",
      "Epoch: 110, Batch: 200, loss: 27.437070358884263\n",
      "Epoch: 110, Batch: 300, loss: 24.648531334649416\n",
      "Epoch: 110, Batch: 400, loss: 26.800941714681386\n",
      "Epoch: 110, Batch: 500, loss: 30.296596640917652\n",
      "Epoch: 111, Batch: 0, loss: 28.25270553138759\n",
      "Epoch: 111, Batch: 100, loss: 35.227076082148905\n",
      "Epoch: 111, Batch: 200, loss: 31.961999767045807\n",
      "Epoch: 111, Batch: 300, loss: 29.033045430765924\n",
      "Epoch: 111, Batch: 400, loss: 29.420817830323116\n",
      "Epoch: 111, Batch: 500, loss: 28.842881488276976\n",
      "Epoch: 112, Batch: 0, loss: 42.735401725798134\n",
      "Epoch: 112, Batch: 100, loss: 26.86687248317398\n",
      "Epoch: 112, Batch: 200, loss: 23.165063977242074\n",
      "Epoch: 112, Batch: 300, loss: 26.219739945632984\n",
      "Epoch: 112, Batch: 400, loss: 29.345188345957066\n",
      "Epoch: 112, Batch: 500, loss: 30.277194804626582\n",
      "Epoch: 113, Batch: 0, loss: 19.164003848086256\n",
      "Epoch: 113, Batch: 100, loss: 28.79324866383348\n",
      "Epoch: 113, Batch: 200, loss: 31.852527132914744\n",
      "Epoch: 113, Batch: 300, loss: 31.684427971179776\n",
      "Epoch: 113, Batch: 400, loss: 33.393291185528085\n",
      "Epoch: 113, Batch: 500, loss: 32.95007196906398\n",
      "Epoch: 114, Batch: 0, loss: 10.592748992830824\n",
      "Epoch: 114, Batch: 100, loss: 24.42150700945942\n",
      "Epoch: 114, Batch: 200, loss: 27.802917310186057\n",
      "Epoch: 114, Batch: 300, loss: 33.57596848871008\n",
      "Epoch: 114, Batch: 400, loss: 30.64263829528857\n",
      "Epoch: 114, Batch: 500, loss: 30.680726100326936\n",
      "Epoch: 115, Batch: 0, loss: 1.4339279622471712\n",
      "Epoch: 115, Batch: 100, loss: 32.54098939233295\n",
      "Epoch: 115, Batch: 200, loss: 26.415233572154072\n",
      "Epoch: 115, Batch: 300, loss: 26.01271437067623\n",
      "Epoch: 115, Batch: 400, loss: 28.668626161413446\n",
      "Epoch: 115, Batch: 500, loss: 30.685431100593966\n",
      "Epoch: 116, Batch: 0, loss: 0.022548999525268204\n",
      "Epoch: 116, Batch: 100, loss: 27.257399359333277\n",
      "Epoch: 116, Batch: 200, loss: 24.614007323171844\n",
      "Epoch: 116, Batch: 300, loss: 26.957550155219185\n",
      "Epoch: 116, Batch: 400, loss: 26.9796181892888\n",
      "Epoch: 116, Batch: 500, loss: 27.061686443642422\n",
      "Epoch: 117, Batch: 0, loss: 19.036270138806827\n",
      "Epoch: 117, Batch: 100, loss: 29.962735902425642\n",
      "Epoch: 117, Batch: 200, loss: 32.79384154783365\n",
      "Epoch: 117, Batch: 300, loss: 30.028958811846884\n",
      "Epoch: 117, Batch: 400, loss: 32.01471543615432\n",
      "Epoch: 117, Batch: 500, loss: 31.616091736949432\n",
      "Epoch: 118, Batch: 0, loss: 100.81367688551958\n",
      "Epoch: 118, Batch: 100, loss: 24.866373443158718\n",
      "Epoch: 118, Batch: 200, loss: 27.166399845727078\n",
      "Epoch: 118, Batch: 300, loss: 26.72120728307541\n",
      "Epoch: 118, Batch: 400, loss: 27.63770543591049\n",
      "Epoch: 118, Batch: 500, loss: 28.553933478591684\n",
      "Epoch: 119, Batch: 0, loss: 2.647121962858894\n",
      "Epoch: 119, Batch: 100, loss: 35.16257309073221\n",
      "Epoch: 119, Batch: 200, loss: 36.304454663526215\n",
      "Epoch: 119, Batch: 300, loss: 31.966991418536004\n",
      "Epoch: 119, Batch: 400, loss: 30.030675530502602\n",
      "Epoch: 119, Batch: 500, loss: 32.818782019107076\n",
      "Epoch: 120, Batch: 0, loss: 28.581203026521106\n",
      "Epoch: 120, Batch: 100, loss: 30.315414513310117\n",
      "Epoch: 120, Batch: 200, loss: 34.658015287547734\n",
      "Epoch: 120, Batch: 300, loss: 35.75304426862791\n",
      "Epoch: 120, Batch: 400, loss: 34.4177417041665\n",
      "Epoch: 120, Batch: 500, loss: 33.460356628384424\n",
      "Epoch: 121, Batch: 0, loss: 71.320556486293\n",
      "Epoch: 121, Batch: 100, loss: 24.943785800437954\n",
      "Epoch: 121, Batch: 200, loss: 29.45655989823099\n",
      "Epoch: 121, Batch: 300, loss: 26.96978334278949\n",
      "Epoch: 121, Batch: 400, loss: 29.525029618700973\n",
      "Epoch: 121, Batch: 500, loss: 32.86716441480508\n",
      "Epoch: 122, Batch: 0, loss: 46.840658420003415\n",
      "Epoch: 122, Batch: 100, loss: 24.41233963219508\n",
      "Epoch: 122, Batch: 200, loss: 27.04292811799598\n",
      "Epoch: 122, Batch: 300, loss: 25.77870098558155\n",
      "Epoch: 122, Batch: 400, loss: 25.16061621727463\n",
      "Epoch: 122, Batch: 500, loss: 27.201348756140426\n",
      "Epoch: 123, Batch: 0, loss: 11.274863552822731\n",
      "Epoch: 123, Batch: 100, loss: 32.49194321147673\n",
      "Epoch: 123, Batch: 200, loss: 25.67961339273483\n",
      "Epoch: 123, Batch: 300, loss: 29.262250726550473\n",
      "Epoch: 123, Batch: 400, loss: 28.08848824589255\n",
      "Epoch: 123, Batch: 500, loss: 29.511311265731905\n",
      "Epoch: 124, Batch: 0, loss: 23.748517266068102\n",
      "Epoch: 124, Batch: 100, loss: 29.27258415162428\n",
      "Epoch: 124, Batch: 200, loss: 31.45387654994206\n",
      "Epoch: 124, Batch: 300, loss: 31.53378518174073\n",
      "Epoch: 124, Batch: 400, loss: 30.961801848830415\n",
      "Epoch: 124, Batch: 500, loss: 30.48927364110294\n",
      "Epoch: 125, Batch: 0, loss: 11.050376216233785\n",
      "Epoch: 125, Batch: 100, loss: 30.008186204517983\n",
      "Epoch: 125, Batch: 200, loss: 26.236667882761093\n",
      "Epoch: 125, Batch: 300, loss: 29.361695626937045\n",
      "Epoch: 125, Batch: 400, loss: 28.87329419285636\n",
      "Epoch: 125, Batch: 500, loss: 29.1925848014425\n",
      "Epoch: 126, Batch: 0, loss: 1.3715636023179116\n",
      "Epoch: 126, Batch: 100, loss: 25.277478739521335\n",
      "Epoch: 126, Batch: 200, loss: 31.709205669231466\n",
      "Epoch: 126, Batch: 300, loss: 30.92254335405577\n",
      "Epoch: 126, Batch: 400, loss: 30.713813094221916\n",
      "Epoch: 126, Batch: 500, loss: 30.437610624782234\n",
      "Epoch: 127, Batch: 0, loss: 1.0090123316331994\n",
      "Epoch: 127, Batch: 100, loss: 47.43135986007975\n",
      "Epoch: 127, Batch: 200, loss: 42.89113039647818\n",
      "Epoch: 127, Batch: 300, loss: 37.20803610056584\n",
      "Epoch: 127, Batch: 400, loss: 33.36200995517\n",
      "Epoch: 127, Batch: 500, loss: 30.585880949025324\n",
      "Epoch: 128, Batch: 0, loss: 2.3192360530346923\n",
      "Epoch: 128, Batch: 100, loss: 20.79003885933697\n",
      "Epoch: 128, Batch: 200, loss: 29.455542133072772\n",
      "Epoch: 128, Batch: 300, loss: 28.192970237141907\n",
      "Epoch: 128, Batch: 400, loss: 29.011199601467496\n",
      "Epoch: 128, Batch: 500, loss: 27.02659108371702\n",
      "Epoch: 129, Batch: 0, loss: 7.065630450475486\n",
      "Epoch: 129, Batch: 100, loss: 27.335765510911187\n",
      "Epoch: 129, Batch: 200, loss: 27.58776722240747\n",
      "Epoch: 129, Batch: 300, loss: 26.21900863372329\n",
      "Epoch: 129, Batch: 400, loss: 31.361892045747755\n",
      "Epoch: 129, Batch: 500, loss: 32.67653132204287\n",
      "Epoch: 130, Batch: 0, loss: 2.7751513007221758\n",
      "Epoch: 130, Batch: 100, loss: 28.52756327765455\n",
      "Epoch: 130, Batch: 200, loss: 29.360923063390562\n",
      "Epoch: 130, Batch: 300, loss: 31.098900995113148\n",
      "Epoch: 130, Batch: 400, loss: 28.83868073701426\n",
      "Epoch: 130, Batch: 500, loss: 27.413387105971864\n",
      "Epoch: 131, Batch: 0, loss: 9.44373170434905\n",
      "Epoch: 131, Batch: 100, loss: 22.617112261842014\n",
      "Epoch: 131, Batch: 200, loss: 24.381119393320663\n",
      "Epoch: 131, Batch: 300, loss: 23.511308806329467\n",
      "Epoch: 131, Batch: 400, loss: 27.854529236952786\n",
      "Epoch: 131, Batch: 500, loss: 26.30181783062332\n",
      "Epoch: 132, Batch: 0, loss: 6.111906490379427\n",
      "Epoch: 132, Batch: 100, loss: 22.23430272093315\n",
      "Epoch: 132, Batch: 200, loss: 30.131150564048934\n",
      "Epoch: 132, Batch: 300, loss: 26.933390221874223\n",
      "Epoch: 132, Batch: 400, loss: 27.322530495983287\n",
      "Epoch: 132, Batch: 500, loss: 27.361633729387687\n",
      "Epoch: 133, Batch: 0, loss: 64.54096120590916\n",
      "Epoch: 133, Batch: 100, loss: 25.136529758757913\n",
      "Epoch: 133, Batch: 200, loss: 26.967183785691468\n",
      "Epoch: 133, Batch: 300, loss: 27.022289481940998\n",
      "Epoch: 133, Batch: 400, loss: 30.77575751127846\n",
      "Epoch: 133, Batch: 500, loss: 31.69428240587877\n",
      "Epoch: 134, Batch: 0, loss: 6.196041013550289\n",
      "Epoch: 134, Batch: 100, loss: 42.250872709072716\n",
      "Epoch: 134, Batch: 200, loss: 36.80688652435294\n",
      "Epoch: 134, Batch: 300, loss: 33.4607534563941\n",
      "Epoch: 134, Batch: 400, loss: 31.798844234274082\n",
      "Epoch: 134, Batch: 500, loss: 30.60371729519629\n",
      "Epoch: 135, Batch: 0, loss: 16.288082330631003\n",
      "Epoch: 135, Batch: 100, loss: 30.79915964224075\n",
      "Epoch: 135, Batch: 200, loss: 35.3440569241475\n",
      "Epoch: 135, Batch: 300, loss: 30.717236907924388\n",
      "Epoch: 135, Batch: 400, loss: 29.89809811970573\n",
      "Epoch: 135, Batch: 500, loss: 27.548065533050785\n",
      "Epoch: 136, Batch: 0, loss: 7.562071814779283\n",
      "Epoch: 136, Batch: 100, loss: 30.769087981653282\n",
      "Epoch: 136, Batch: 200, loss: 32.329491020273224\n",
      "Epoch: 136, Batch: 300, loss: 29.20785477799403\n",
      "Epoch: 136, Batch: 400, loss: 30.867713015628876\n",
      "Epoch: 136, Batch: 500, loss: 31.905564828093233\n",
      "Epoch: 137, Batch: 0, loss: 25.62043077772103\n",
      "Epoch: 137, Batch: 100, loss: 35.200372972811394\n",
      "Epoch: 137, Batch: 200, loss: 36.598882398239724\n",
      "Epoch: 137, Batch: 300, loss: 31.543848601174314\n",
      "Epoch: 137, Batch: 400, loss: 32.880916193457935\n",
      "Epoch: 137, Batch: 500, loss: 29.823696591473468\n",
      "Epoch: 138, Batch: 0, loss: 13.804891259288345\n",
      "Epoch: 138, Batch: 100, loss: 60.25655617333571\n",
      "Epoch: 138, Batch: 200, loss: 46.53313216435886\n",
      "Epoch: 138, Batch: 300, loss: 43.33834111579405\n",
      "Epoch: 138, Batch: 400, loss: 39.27357190229447\n",
      "Epoch: 138, Batch: 500, loss: 38.81396424928409\n",
      "Epoch: 139, Batch: 0, loss: 5.93948243531948\n",
      "Epoch: 139, Batch: 100, loss: 27.12102244456354\n",
      "Epoch: 139, Batch: 200, loss: 32.49236416969308\n",
      "Epoch: 139, Batch: 300, loss: 33.80413628948424\n",
      "Epoch: 139, Batch: 400, loss: 31.549046731324445\n",
      "Epoch: 139, Batch: 500, loss: 31.198471778886894\n",
      "Epoch: 140, Batch: 0, loss: 114.10097179801099\n",
      "Epoch: 140, Batch: 100, loss: 38.10106740085979\n",
      "Epoch: 140, Batch: 200, loss: 43.3651370926174\n",
      "Epoch: 140, Batch: 300, loss: 38.115522488191665\n",
      "Epoch: 140, Batch: 400, loss: 35.560273653367986\n",
      "Epoch: 140, Batch: 500, loss: 35.33439672348925\n",
      "Epoch: 141, Batch: 0, loss: 30.696782029101932\n",
      "Epoch: 141, Batch: 100, loss: 31.879416077052767\n",
      "Epoch: 141, Batch: 200, loss: 29.202567812724\n",
      "Epoch: 141, Batch: 300, loss: 25.790117572045013\n",
      "Epoch: 141, Batch: 400, loss: 24.615916228263465\n",
      "Epoch: 141, Batch: 500, loss: 24.427399325609542\n",
      "Epoch: 142, Batch: 0, loss: 1.2544381581273556\n",
      "Epoch: 142, Batch: 100, loss: 38.93027072757935\n",
      "Epoch: 142, Batch: 200, loss: 34.47922460951225\n",
      "Epoch: 142, Batch: 300, loss: 30.691088240114233\n",
      "Epoch: 142, Batch: 400, loss: 29.384248926328866\n",
      "Epoch: 142, Batch: 500, loss: 29.15591771226257\n",
      "Epoch: 143, Batch: 0, loss: 8.082724944142644\n",
      "Epoch: 143, Batch: 100, loss: 32.61712709909028\n",
      "Epoch: 143, Batch: 200, loss: 30.910967804390104\n",
      "Epoch: 143, Batch: 300, loss: 28.28904172439088\n",
      "Epoch: 143, Batch: 400, loss: 30.5603912070184\n",
      "Epoch: 143, Batch: 500, loss: 32.232976010538174\n",
      "Epoch: 144, Batch: 0, loss: 48.31569451392679\n",
      "Epoch: 144, Batch: 100, loss: 16.2983768908494\n",
      "Epoch: 144, Batch: 200, loss: 23.106109915110192\n",
      "Epoch: 144, Batch: 300, loss: 22.91341535396332\n",
      "Epoch: 144, Batch: 400, loss: 25.656865984441648\n",
      "Epoch: 144, Batch: 500, loss: 25.00740792942851\n",
      "Epoch: 145, Batch: 0, loss: 8.397319670437216\n",
      "Epoch: 145, Batch: 100, loss: 27.93683894487995\n",
      "Epoch: 145, Batch: 200, loss: 27.037478034896374\n",
      "Epoch: 145, Batch: 300, loss: 27.088514038466958\n",
      "Epoch: 145, Batch: 400, loss: 27.78869801448748\n",
      "Epoch: 145, Batch: 500, loss: 28.677591260401208\n",
      "Epoch: 146, Batch: 0, loss: 0.4104167099663052\n",
      "Epoch: 146, Batch: 100, loss: 36.60523643428643\n",
      "Epoch: 146, Batch: 200, loss: 30.70199279145927\n",
      "Epoch: 146, Batch: 300, loss: 28.986772461976088\n",
      "Epoch: 146, Batch: 400, loss: 26.80386354593609\n",
      "Epoch: 146, Batch: 500, loss: 30.176497702607616\n",
      "Epoch: 147, Batch: 0, loss: 0.0007680478687795531\n",
      "Epoch: 147, Batch: 100, loss: 18.959666100563055\n",
      "Epoch: 147, Batch: 200, loss: 28.955782745207138\n",
      "Epoch: 147, Batch: 300, loss: 32.43019185769984\n",
      "Epoch: 147, Batch: 400, loss: 31.86799392958451\n",
      "Epoch: 147, Batch: 500, loss: 31.682708505648396\n",
      "Epoch: 148, Batch: 0, loss: 1.3270626785972135\n",
      "Epoch: 148, Batch: 100, loss: 25.82016519221566\n",
      "Epoch: 148, Batch: 200, loss: 24.991843216903213\n",
      "Epoch: 148, Batch: 300, loss: 26.00932250406105\n",
      "Epoch: 148, Batch: 400, loss: 27.383641452874453\n",
      "Epoch: 148, Batch: 500, loss: 29.743375370308957\n",
      "Epoch: 149, Batch: 0, loss: 160.50488379355414\n",
      "Epoch: 149, Batch: 100, loss: 30.79938540740844\n",
      "Epoch: 149, Batch: 200, loss: 29.06256600029835\n",
      "Epoch: 149, Batch: 300, loss: 30.01785025318209\n",
      "Epoch: 149, Batch: 400, loss: 28.929513552075345\n",
      "Epoch: 149, Batch: 500, loss: 30.46041404513863\n",
      "Epoch: 150, Batch: 0, loss: 4.173177542614161\n",
      "Epoch: 150, Batch: 100, loss: 29.137809292361098\n",
      "Epoch: 150, Batch: 200, loss: 25.286620454882936\n",
      "Epoch: 150, Batch: 300, loss: 22.73354046120439\n",
      "Epoch: 150, Batch: 400, loss: 23.79160116496326\n",
      "Epoch: 150, Batch: 500, loss: 24.100574541446434\n",
      "Epoch: 151, Batch: 0, loss: 27.431577035281926\n",
      "Epoch: 151, Batch: 100, loss: 33.72984618290818\n",
      "Epoch: 151, Batch: 200, loss: 29.600249393229088\n",
      "Epoch: 151, Batch: 300, loss: 32.61960164790755\n",
      "Epoch: 151, Batch: 400, loss: 31.357727800945955\n",
      "Epoch: 151, Batch: 500, loss: 31.60046132894617\n",
      "Epoch: 152, Batch: 0, loss: 2.869857877517061\n",
      "Epoch: 152, Batch: 100, loss: 28.78245746661597\n",
      "Epoch: 152, Batch: 200, loss: 31.840723365091996\n",
      "Epoch: 152, Batch: 300, loss: 29.459741354153458\n",
      "Epoch: 152, Batch: 400, loss: 29.41593105966386\n",
      "Epoch: 152, Batch: 500, loss: 33.299849312767094\n",
      "Epoch: 153, Batch: 0, loss: 5.609908827557937\n",
      "Epoch: 153, Batch: 100, loss: 39.294391722103136\n",
      "Epoch: 153, Batch: 200, loss: 31.720337955637383\n",
      "Epoch: 153, Batch: 300, loss: 31.385497955608663\n",
      "Epoch: 153, Batch: 400, loss: 32.403079913527435\n",
      "Epoch: 153, Batch: 500, loss: 35.21748618493375\n",
      "Epoch: 154, Batch: 0, loss: 60.16614672986076\n",
      "Epoch: 154, Batch: 100, loss: 37.68535023432286\n",
      "Epoch: 154, Batch: 200, loss: 34.779505307915315\n",
      "Epoch: 154, Batch: 300, loss: 31.985239918429954\n",
      "Epoch: 154, Batch: 400, loss: 32.25502005455947\n",
      "Epoch: 154, Batch: 500, loss: 33.79182502955712\n",
      "Epoch: 155, Batch: 0, loss: 0.25388611569823755\n",
      "Epoch: 155, Batch: 100, loss: 23.494930915894102\n",
      "Epoch: 155, Batch: 200, loss: 26.82008528607739\n",
      "Epoch: 155, Batch: 300, loss: 28.10463657622443\n",
      "Epoch: 155, Batch: 400, loss: 29.86383226429388\n",
      "Epoch: 155, Batch: 500, loss: 29.14621189298424\n",
      "Epoch: 156, Batch: 0, loss: 11.29198238328715\n",
      "Epoch: 156, Batch: 100, loss: 35.7012107209749\n",
      "Epoch: 156, Batch: 200, loss: 38.38182803704035\n",
      "Epoch: 156, Batch: 300, loss: 35.06885644616628\n",
      "Epoch: 156, Batch: 400, loss: 33.73042569220225\n",
      "Epoch: 156, Batch: 500, loss: 32.7272749596937\n",
      "Epoch: 157, Batch: 0, loss: 11.046970090390214\n",
      "Epoch: 157, Batch: 100, loss: 52.77004864548424\n",
      "Epoch: 157, Batch: 200, loss: 37.10377189571925\n",
      "Epoch: 157, Batch: 300, loss: 36.22813541729936\n",
      "Epoch: 157, Batch: 400, loss: 34.81034609089854\n",
      "Epoch: 157, Batch: 500, loss: 35.11828715215663\n",
      "Epoch: 158, Batch: 0, loss: 17.52402281055705\n",
      "Epoch: 158, Batch: 100, loss: 45.72761056250662\n",
      "Epoch: 158, Batch: 200, loss: 41.34091291120817\n",
      "Epoch: 158, Batch: 300, loss: 37.52259455051883\n",
      "Epoch: 158, Batch: 400, loss: 38.579344338263255\n",
      "Epoch: 158, Batch: 500, loss: 35.612116981944\n",
      "Epoch: 159, Batch: 0, loss: 6.33145794304291\n",
      "Epoch: 159, Batch: 100, loss: 33.72133072462247\n",
      "Epoch: 159, Batch: 200, loss: 31.05931787744691\n",
      "Epoch: 159, Batch: 300, loss: 29.54591038514986\n",
      "Epoch: 159, Batch: 400, loss: 27.494757145380355\n",
      "Epoch: 159, Batch: 500, loss: 25.709517558003537\n",
      "Epoch: 160, Batch: 0, loss: 1.4725117089204451\n",
      "Epoch: 160, Batch: 100, loss: 27.677262701752912\n",
      "Epoch: 160, Batch: 200, loss: 40.43190194455575\n",
      "Epoch: 160, Batch: 300, loss: 35.24433647346857\n",
      "Epoch: 160, Batch: 400, loss: 34.67539632770838\n",
      "Epoch: 160, Batch: 500, loss: 34.19117888049873\n",
      "Epoch: 161, Batch: 0, loss: 2.1536054651495906\n",
      "Epoch: 161, Batch: 100, loss: 28.261557286240468\n",
      "Epoch: 161, Batch: 200, loss: 30.868728829059005\n",
      "Epoch: 161, Batch: 300, loss: 32.19287322059525\n",
      "Epoch: 161, Batch: 400, loss: 28.00292222614201\n",
      "Epoch: 161, Batch: 500, loss: 27.008742669854836\n",
      "Epoch: 162, Batch: 0, loss: 8.973548569750156\n",
      "Epoch: 162, Batch: 100, loss: 22.895182154738194\n",
      "Epoch: 162, Batch: 200, loss: 23.477201432904884\n",
      "Epoch: 162, Batch: 300, loss: 23.793890083297025\n",
      "Epoch: 162, Batch: 400, loss: 27.258836090400084\n",
      "Epoch: 162, Batch: 500, loss: 29.349104613090702\n",
      "Epoch: 163, Batch: 0, loss: 0.09839856893214773\n",
      "Epoch: 163, Batch: 100, loss: 23.624356873052474\n",
      "Epoch: 163, Batch: 200, loss: 25.76325558273833\n",
      "Epoch: 163, Batch: 300, loss: 27.195758159313705\n",
      "Epoch: 163, Batch: 400, loss: 27.063433444605014\n",
      "Epoch: 163, Batch: 500, loss: 26.02194631533491\n",
      "Epoch: 164, Batch: 0, loss: 4.305399697064785\n",
      "Epoch: 164, Batch: 100, loss: 43.66120862781871\n",
      "Epoch: 164, Batch: 200, loss: 36.24523509819351\n",
      "Epoch: 164, Batch: 300, loss: 38.207567631063796\n",
      "Epoch: 164, Batch: 400, loss: 37.085967790595\n",
      "Epoch: 164, Batch: 500, loss: 36.55664834981685\n",
      "Epoch: 165, Batch: 0, loss: 0.051292643480323016\n",
      "Epoch: 165, Batch: 100, loss: 18.419025833813524\n",
      "Epoch: 165, Batch: 200, loss: 28.593135640857785\n",
      "Epoch: 165, Batch: 300, loss: 28.496527917824153\n",
      "Epoch: 165, Batch: 400, loss: 28.264848144893875\n",
      "Epoch: 165, Batch: 500, loss: 29.106227114002966\n",
      "Epoch: 166, Batch: 0, loss: 2.7230604553132\n",
      "Epoch: 166, Batch: 100, loss: 33.113523875853986\n",
      "Epoch: 166, Batch: 200, loss: 36.76231864318917\n",
      "Epoch: 166, Batch: 300, loss: 34.39993656191332\n",
      "Epoch: 166, Batch: 400, loss: 35.89239868368694\n",
      "Epoch: 166, Batch: 500, loss: 32.01222456939281\n",
      "Epoch: 167, Batch: 0, loss: 1.6285331000364793\n",
      "Epoch: 167, Batch: 100, loss: 39.017125023197345\n",
      "Epoch: 167, Batch: 200, loss: 33.21037755975817\n",
      "Epoch: 167, Batch: 300, loss: 38.43603302870609\n",
      "Epoch: 167, Batch: 400, loss: 35.85739107705674\n",
      "Epoch: 167, Batch: 500, loss: 34.04103963604393\n",
      "Epoch: 168, Batch: 0, loss: 5.946486336265674\n",
      "Epoch: 168, Batch: 100, loss: 29.792332911629472\n",
      "Epoch: 168, Batch: 200, loss: 37.55777050927183\n",
      "Epoch: 168, Batch: 300, loss: 35.34653379565213\n",
      "Epoch: 168, Batch: 400, loss: 36.3279578326597\n",
      "Epoch: 168, Batch: 500, loss: 34.403952548019845\n",
      "Epoch: 169, Batch: 0, loss: 155.56486629729986\n",
      "Epoch: 169, Batch: 100, loss: 26.26344594266635\n",
      "Epoch: 169, Batch: 200, loss: 23.654474119733234\n",
      "Epoch: 169, Batch: 300, loss: 23.465181027714596\n",
      "Epoch: 169, Batch: 400, loss: 26.51544653683481\n",
      "Epoch: 169, Batch: 500, loss: 31.184415203313186\n",
      "Epoch: 170, Batch: 0, loss: 0.2466998711538749\n",
      "Epoch: 170, Batch: 100, loss: 16.886962479633038\n",
      "Epoch: 170, Batch: 200, loss: 25.21761889686492\n",
      "Epoch: 170, Batch: 300, loss: 28.215909139340603\n",
      "Epoch: 170, Batch: 400, loss: 27.3264149666513\n",
      "Epoch: 170, Batch: 500, loss: 27.77778990413441\n",
      "Epoch: 171, Batch: 0, loss: 0.6345293011453426\n",
      "Epoch: 171, Batch: 100, loss: 20.287012176987957\n",
      "Epoch: 171, Batch: 200, loss: 26.99172089169566\n",
      "Epoch: 171, Batch: 300, loss: 30.559519463585694\n",
      "Epoch: 171, Batch: 400, loss: 33.49935536323421\n",
      "Epoch: 171, Batch: 500, loss: 33.34943863256058\n",
      "Epoch: 172, Batch: 0, loss: 6.413519544874998\n",
      "Epoch: 172, Batch: 100, loss: 29.655272033032798\n",
      "Epoch: 172, Batch: 200, loss: 23.896073297660234\n",
      "Epoch: 172, Batch: 300, loss: 22.167625974997584\n",
      "Epoch: 172, Batch: 400, loss: 22.32747201443876\n",
      "Epoch: 172, Batch: 500, loss: 22.9618968653144\n",
      "Epoch: 173, Batch: 0, loss: 4.775359315562435\n",
      "Epoch: 173, Batch: 100, loss: 39.095013204949545\n",
      "Epoch: 173, Batch: 200, loss: 35.58535345821083\n",
      "Epoch: 173, Batch: 300, loss: 34.27205953766677\n",
      "Epoch: 173, Batch: 400, loss: 35.21507859812548\n",
      "Epoch: 173, Batch: 500, loss: 32.14742085175198\n",
      "Epoch: 174, Batch: 0, loss: 161.89400685367872\n",
      "Epoch: 174, Batch: 100, loss: 33.14203095430157\n",
      "Epoch: 174, Batch: 200, loss: 29.25868537366464\n",
      "Epoch: 174, Batch: 300, loss: 28.229977246110415\n",
      "Epoch: 174, Batch: 400, loss: 28.29104591623995\n",
      "Epoch: 174, Batch: 500, loss: 26.980036575016612\n",
      "Epoch: 175, Batch: 0, loss: 22.955039659196263\n",
      "Epoch: 175, Batch: 100, loss: 26.95721070899796\n",
      "Epoch: 175, Batch: 200, loss: 27.858039402770107\n",
      "Epoch: 175, Batch: 300, loss: 30.48183340696708\n",
      "Epoch: 175, Batch: 400, loss: 29.420553238205404\n",
      "Epoch: 175, Batch: 500, loss: 29.85010765438402\n",
      "Epoch: 176, Batch: 0, loss: 2.2544335378589984\n",
      "Epoch: 176, Batch: 100, loss: 31.18472602478389\n",
      "Epoch: 176, Batch: 200, loss: 24.90125409695074\n",
      "Epoch: 176, Batch: 300, loss: 24.832420802854955\n",
      "Epoch: 176, Batch: 400, loss: 23.92694888022272\n",
      "Epoch: 176, Batch: 500, loss: 24.65323931827008\n",
      "Epoch: 177, Batch: 0, loss: 0.8386132988453372\n",
      "Epoch: 177, Batch: 100, loss: 15.430471357388353\n",
      "Epoch: 177, Batch: 200, loss: 17.98527493259464\n",
      "Epoch: 177, Batch: 300, loss: 20.844065873440368\n",
      "Epoch: 177, Batch: 400, loss: 22.304183223026058\n",
      "Epoch: 177, Batch: 500, loss: 22.699872865480533\n",
      "Epoch: 178, Batch: 0, loss: 3.466250615538483\n",
      "Epoch: 178, Batch: 100, loss: 42.82772951087713\n",
      "Epoch: 178, Batch: 200, loss: 28.588881119165016\n",
      "Epoch: 178, Batch: 300, loss: 27.88791441694881\n",
      "Epoch: 178, Batch: 400, loss: 30.521779631591382\n",
      "Epoch: 178, Batch: 500, loss: 33.4287856682203\n",
      "Epoch: 179, Batch: 0, loss: 25.604842087282986\n",
      "Epoch: 179, Batch: 100, loss: 17.408807443372872\n",
      "Epoch: 179, Batch: 200, loss: 28.105238073441555\n",
      "Epoch: 179, Batch: 300, loss: 30.797665932757095\n",
      "Epoch: 179, Batch: 400, loss: 31.914681133164223\n",
      "Epoch: 179, Batch: 500, loss: 30.426904249804103\n",
      "Epoch: 180, Batch: 0, loss: 2.9824232743185815\n",
      "Epoch: 180, Batch: 100, loss: 29.41352749366555\n",
      "Epoch: 180, Batch: 200, loss: 35.84300223630624\n",
      "Epoch: 180, Batch: 300, loss: 32.9054436318123\n",
      "Epoch: 180, Batch: 400, loss: 33.885473962553\n",
      "Epoch: 180, Batch: 500, loss: 33.06651968357459\n",
      "Epoch: 181, Batch: 0, loss: 1.083035590498323\n",
      "Epoch: 181, Batch: 100, loss: 28.54406785749762\n",
      "Epoch: 181, Batch: 200, loss: 29.600499396089678\n",
      "Epoch: 181, Batch: 300, loss: 27.73110425148796\n",
      "Epoch: 181, Batch: 400, loss: 30.871938001979583\n",
      "Epoch: 181, Batch: 500, loss: 30.83643136286935\n",
      "Epoch: 182, Batch: 0, loss: 21.848852345415896\n",
      "Epoch: 182, Batch: 100, loss: 23.690011822935436\n",
      "Epoch: 182, Batch: 200, loss: 24.705230663936163\n",
      "Epoch: 182, Batch: 300, loss: 24.693819677154263\n",
      "Epoch: 182, Batch: 400, loss: 26.130751008951226\n",
      "Epoch: 182, Batch: 500, loss: 29.131841081875116\n",
      "Epoch: 183, Batch: 0, loss: 39.50169899128609\n",
      "Epoch: 183, Batch: 100, loss: 37.71340578242291\n",
      "Epoch: 183, Batch: 200, loss: 36.44082139255571\n",
      "Epoch: 183, Batch: 300, loss: 32.92637743635792\n",
      "Epoch: 183, Batch: 400, loss: 29.27573204610807\n",
      "Epoch: 183, Batch: 500, loss: 32.060208918548746\n",
      "Epoch: 184, Batch: 0, loss: 8.880119877997217\n",
      "Epoch: 184, Batch: 100, loss: 26.452139249200034\n",
      "Epoch: 184, Batch: 200, loss: 28.845668487931807\n",
      "Epoch: 184, Batch: 300, loss: 29.39679060167411\n",
      "Epoch: 184, Batch: 400, loss: 33.14996112409656\n",
      "Epoch: 184, Batch: 500, loss: 32.63132942596668\n",
      "Epoch: 185, Batch: 0, loss: 0.0723171821315014\n",
      "Epoch: 185, Batch: 100, loss: 34.90619615383259\n",
      "Epoch: 185, Batch: 200, loss: 33.8407577105348\n",
      "Epoch: 185, Batch: 300, loss: 32.390994940982516\n",
      "Epoch: 185, Batch: 400, loss: 34.32353543232528\n",
      "Epoch: 185, Batch: 500, loss: 32.92413909357088\n",
      "Epoch: 186, Batch: 0, loss: 1.9138172182758113\n",
      "Epoch: 186, Batch: 100, loss: 28.960410047660226\n",
      "Epoch: 186, Batch: 200, loss: 33.03479486559903\n",
      "Epoch: 186, Batch: 300, loss: 30.72474899458671\n",
      "Epoch: 186, Batch: 400, loss: 30.317516014461695\n",
      "Epoch: 186, Batch: 500, loss: 32.42739704499818\n",
      "Epoch: 187, Batch: 0, loss: 0.14351916273918408\n",
      "Epoch: 187, Batch: 100, loss: 34.48476247688065\n",
      "Epoch: 187, Batch: 200, loss: 31.21238488872172\n",
      "Epoch: 187, Batch: 300, loss: 29.577008469147312\n",
      "Epoch: 187, Batch: 400, loss: 29.566045080374685\n",
      "Epoch: 187, Batch: 500, loss: 30.345855857268546\n",
      "Epoch: 188, Batch: 0, loss: 0.12101626291379454\n",
      "Epoch: 188, Batch: 100, loss: 24.04117413408914\n",
      "Epoch: 188, Batch: 200, loss: 21.385268837548164\n",
      "Epoch: 188, Batch: 300, loss: 24.257605787207638\n",
      "Epoch: 188, Batch: 400, loss: 25.904233062800603\n",
      "Epoch: 188, Batch: 500, loss: 29.953223747305437\n",
      "Epoch: 189, Batch: 0, loss: 0.3340276202985021\n",
      "Epoch: 189, Batch: 100, loss: 46.58332976381042\n",
      "Epoch: 189, Batch: 200, loss: 36.105492222790396\n",
      "Epoch: 189, Batch: 300, loss: 35.94793398967093\n",
      "Epoch: 189, Batch: 400, loss: 36.45810334565314\n",
      "Epoch: 189, Batch: 500, loss: 34.0386515744814\n",
      "Epoch: 190, Batch: 0, loss: 1.124495084232466\n",
      "Epoch: 190, Batch: 100, loss: 48.90626266014668\n",
      "Epoch: 190, Batch: 200, loss: 45.690913549242126\n",
      "Epoch: 190, Batch: 300, loss: 38.36127784815562\n",
      "Epoch: 190, Batch: 400, loss: 37.34904272232163\n",
      "Epoch: 190, Batch: 500, loss: 37.596428447648584\n",
      "Epoch: 191, Batch: 0, loss: 26.988997327213628\n",
      "Epoch: 191, Batch: 100, loss: 39.82123543113601\n",
      "Epoch: 191, Batch: 200, loss: 37.8374797516211\n",
      "Epoch: 191, Batch: 300, loss: 34.73099267826081\n",
      "Epoch: 191, Batch: 400, loss: 38.71378010714644\n",
      "Epoch: 191, Batch: 500, loss: 37.36571637289588\n",
      "Epoch: 192, Batch: 0, loss: 32.21371417901871\n",
      "Epoch: 192, Batch: 100, loss: 27.3599787904492\n",
      "Epoch: 192, Batch: 200, loss: 30.33143952985761\n",
      "Epoch: 192, Batch: 300, loss: 29.406268160780755\n",
      "Epoch: 192, Batch: 400, loss: 30.425817701565293\n",
      "Epoch: 192, Batch: 500, loss: 28.613827678541313\n",
      "Epoch: 193, Batch: 0, loss: 8.177937961476065\n",
      "Epoch: 193, Batch: 100, loss: 20.349060836719215\n",
      "Epoch: 193, Batch: 200, loss: 19.057145235922395\n",
      "Epoch: 193, Batch: 300, loss: 22.591593154782018\n",
      "Epoch: 193, Batch: 400, loss: 24.947233657948125\n",
      "Epoch: 193, Batch: 500, loss: 26.347464559271707\n",
      "Epoch: 194, Batch: 0, loss: 728.6835488382704\n",
      "Epoch: 194, Batch: 100, loss: 45.3879539157251\n",
      "Epoch: 194, Batch: 200, loss: 35.29696786453344\n",
      "Epoch: 194, Batch: 300, loss: 32.81853013546823\n",
      "Epoch: 194, Batch: 400, loss: 31.446178674960233\n",
      "Epoch: 194, Batch: 500, loss: 31.324717390360597\n",
      "Epoch: 195, Batch: 0, loss: 6.893620313305624\n",
      "Epoch: 195, Batch: 100, loss: 25.546069995916312\n",
      "Epoch: 195, Batch: 200, loss: 26.072983023954222\n",
      "Epoch: 195, Batch: 300, loss: 27.10791115287152\n",
      "Epoch: 195, Batch: 400, loss: 27.390211965927314\n",
      "Epoch: 195, Batch: 500, loss: 28.523186118301332\n",
      "Epoch: 196, Batch: 0, loss: 14.545424143422226\n",
      "Epoch: 196, Batch: 100, loss: 29.34187685140932\n",
      "Epoch: 196, Batch: 200, loss: 24.84592838464649\n",
      "Epoch: 196, Batch: 300, loss: 25.969725480599376\n",
      "Epoch: 196, Batch: 400, loss: 27.191564737199663\n",
      "Epoch: 196, Batch: 500, loss: 30.78975578312957\n",
      "Epoch: 197, Batch: 0, loss: 6.356829918244008\n",
      "Epoch: 197, Batch: 100, loss: 35.74811208600449\n",
      "Epoch: 197, Batch: 200, loss: 40.90232566572839\n",
      "Epoch: 197, Batch: 300, loss: 37.17200213449241\n",
      "Epoch: 197, Batch: 400, loss: 36.327318952487914\n",
      "Epoch: 197, Batch: 500, loss: 33.285047535005745\n",
      "Epoch: 198, Batch: 0, loss: 13.300701466483051\n",
      "Epoch: 198, Batch: 100, loss: 27.958811442855637\n",
      "Epoch: 198, Batch: 200, loss: 32.00088345706831\n",
      "Epoch: 198, Batch: 300, loss: 33.9996001350261\n",
      "Epoch: 198, Batch: 400, loss: 31.897549760187793\n",
      "Epoch: 198, Batch: 500, loss: 31.39613092434797\n",
      "Epoch: 199, Batch: 0, loss: 20.0478160639273\n",
      "Epoch: 199, Batch: 100, loss: 27.963210991965667\n",
      "Epoch: 199, Batch: 200, loss: 25.609516581094436\n",
      "Epoch: 199, Batch: 300, loss: 25.601720995889803\n",
      "Epoch: 199, Batch: 400, loss: 29.689633120581632\n",
      "Epoch: 199, Batch: 500, loss: 28.308274447364248\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logstic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\n",
    "housing_price = load_boston()\n",
    "dataframe = pd.DataFrame(housing_price['data'])\n",
    "dataframe.columns = housing_price['feature_names']\n",
    "dataframe['price'] = housing_price['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lst = dataframe['LSTAT']\n",
    "price = dataframe['price']\n",
    "print(np.percentile(price, 66))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.53\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# plt.hist(target)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > np.percentile(price, 66)))\n",
    "expensive = dataframe['expensive']\n",
    "\n",
    "# print(dataframe.head())\n",
    "print(dataframe['expensive'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "501    0\n",
      "502    0\n",
      "503    1\n",
      "504    0\n",
      "505    0\n",
      "Name: expensive, Length: 506, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -1 * np.sum(y*np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "\n",
    "def partial_w(x1, x2, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x1), np.sum((yhat - y) * x2)])\n",
    "\n",
    "\n",
    "def partial_b(x1, x2, y, yhat):\n",
    "    return np.sum(yhat - y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "w = np.random.random_sample((1, 2))\n",
    "print(w)\n",
    "b = 0\n",
    "alpha = 1e-5\n",
    "\n",
    "epoch = 200\n",
    "history = []\n",
    "\n",
    "history_k_b_loss = []"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.63342409 0.81206015]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for e in range(epoch):\n",
    "    losses = []\n",
    "    for batch in range(len(rm)):\n",
    "        random_index = random.choice(range(len(rm)))\n",
    "\n",
    "        x1, x2 = rm[random_index], lst[random_index]\n",
    "        y = expensive[random_index]\n",
    "\n",
    "        yhat = model(np.array([x1, x2]), w, b)\n",
    "        loss_v = loss(yhat, y)\n",
    "\n",
    "        w = w - partial_w(x1, x2, y, yhat) * alpha\n",
    "        b = b - partial_b(x1, x2, y, yhat) * alpha\n",
    "\n",
    "        losses.append(loss_v)\n",
    "\n",
    "        history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, loss: {}'.format(e, batch, np.mean(losses)))\n",
    "\n",
    "    history.append(np.mean(losses))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Batch: 0, loss: 14.699317286911464\n",
      "Epoch: 0, Batch: 100, loss: 11.205575525306255\n",
      "Epoch: 0, Batch: 200, loss: 11.534464885300075\n",
      "Epoch: 0, Batch: 300, loss: 11.093510633701065\n",
      "Epoch: 0, Batch: 400, loss: 10.917305387961797\n",
      "Epoch: 0, Batch: 500, loss: 10.859245639107462\n",
      "Epoch: 1, Batch: 0, loss: 0.00040833587454561655\n",
      "Epoch: 1, Batch: 100, loss: 11.618180859749076\n",
      "Epoch: 1, Batch: 200, loss: 10.765679001233881\n",
      "Epoch: 1, Batch: 300, loss: 10.578470615258915\n",
      "Epoch: 1, Batch: 400, loss: 10.492004158205743\n",
      "Epoch: 1, Batch: 500, loss: 10.26292722982353\n",
      "Epoch: 2, Batch: 0, loss: 0.001954987453217921\n",
      "Epoch: 2, Batch: 100, loss: 9.368271022949564\n",
      "Epoch: 2, Batch: 200, loss: 9.558935647511127\n",
      "Epoch: 2, Batch: 300, loss: 9.543718295085956\n",
      "Epoch: 2, Batch: 400, loss: 9.43020484214525\n",
      "Epoch: 2, Batch: 500, loss: 9.706852518621982\n",
      "Epoch: 3, Batch: 0, loss: 25.49683935100504\n",
      "Epoch: 3, Batch: 100, loss: 8.642653497468816\n",
      "Epoch: 3, Batch: 200, loss: 8.859557409942477\n",
      "Epoch: 3, Batch: 300, loss: 8.761364001464427\n",
      "Epoch: 3, Batch: 400, loss: 8.944084807366842\n",
      "Epoch: 3, Batch: 500, loss: 8.777047032234293\n",
      "Epoch: 4, Batch: 0, loss: 8.824655282043924\n",
      "Epoch: 4, Batch: 100, loss: 7.68549676295287\n",
      "Epoch: 4, Batch: 200, loss: 8.117730621023618\n",
      "Epoch: 4, Batch: 300, loss: 8.04464087298242\n",
      "Epoch: 4, Batch: 400, loss: 8.145606260148597\n",
      "Epoch: 4, Batch: 500, loss: 7.927606814651613\n",
      "Epoch: 5, Batch: 0, loss: 0.01217183796923693\n",
      "Epoch: 5, Batch: 100, loss: 7.787952129973753\n",
      "Epoch: 5, Batch: 200, loss: 7.934889536148236\n",
      "Epoch: 5, Batch: 300, loss: 8.30334026052309\n",
      "Epoch: 5, Batch: 400, loss: 8.127415422807939\n",
      "Epoch: 5, Batch: 500, loss: 8.20473559400806\n",
      "Epoch: 6, Batch: 0, loss: 0.00013907472999769507\n",
      "Epoch: 6, Batch: 100, loss: 7.018763925692767\n",
      "Epoch: 6, Batch: 200, loss: 7.095460996544538\n",
      "Epoch: 6, Batch: 300, loss: 7.380387421554859\n",
      "Epoch: 6, Batch: 400, loss: 7.12781388664669\n",
      "Epoch: 6, Batch: 500, loss: 7.081110873973795\n",
      "Epoch: 7, Batch: 0, loss: 14.036983192332869\n",
      "Epoch: 7, Batch: 100, loss: 6.977357796443799\n",
      "Epoch: 7, Batch: 200, loss: 6.364255315396096\n",
      "Epoch: 7, Batch: 300, loss: 6.346483932031761\n",
      "Epoch: 7, Batch: 400, loss: 6.35669275651827\n",
      "Epoch: 7, Batch: 500, loss: 6.374477401201111\n",
      "Epoch: 8, Batch: 0, loss: 6.248472528641923\n",
      "Epoch: 8, Batch: 100, loss: 5.364672284650808\n",
      "Epoch: 8, Batch: 200, loss: 5.546949918016178\n",
      "Epoch: 8, Batch: 300, loss: 5.724951335708324\n",
      "Epoch: 8, Batch: 400, loss: 5.453438940811646\n",
      "Epoch: 8, Batch: 500, loss: 5.538540622408066\n",
      "Epoch: 9, Batch: 0, loss: 8.928577556731147\n",
      "Epoch: 9, Batch: 100, loss: 5.685002381613829\n",
      "Epoch: 9, Batch: 200, loss: 5.2367614262037065\n",
      "Epoch: 9, Batch: 300, loss: 5.053598138000275\n",
      "Epoch: 9, Batch: 400, loss: 4.804410443060037\n",
      "Epoch: 9, Batch: 500, loss: 4.8857317606856965\n",
      "Epoch: 10, Batch: 0, loss: 0.009392089624947187\n",
      "Epoch: 10, Batch: 100, loss: 4.8282243698028235\n",
      "Epoch: 10, Batch: 200, loss: 4.775860928464381\n",
      "Epoch: 10, Batch: 300, loss: 4.623737961375786\n",
      "Epoch: 10, Batch: 400, loss: 4.479533488658198\n",
      "Epoch: 10, Batch: 500, loss: 4.328586898344305\n",
      "Epoch: 11, Batch: 0, loss: 0.023709846389820557\n",
      "Epoch: 11, Batch: 100, loss: 3.5773094645338523\n",
      "Epoch: 11, Batch: 200, loss: 3.624883520754815\n",
      "Epoch: 11, Batch: 300, loss: 3.6167899277371336\n",
      "Epoch: 11, Batch: 400, loss: 3.479602659123632\n",
      "Epoch: 11, Batch: 500, loss: 3.4102865751808555\n",
      "Epoch: 12, Batch: 0, loss: 0.01845870318749186\n",
      "Epoch: 12, Batch: 100, loss: 3.097176110858637\n",
      "Epoch: 12, Batch: 200, loss: 3.161561073543215\n",
      "Epoch: 12, Batch: 300, loss: 3.090874199483782\n",
      "Epoch: 12, Batch: 400, loss: 3.012809840061506\n",
      "Epoch: 12, Batch: 500, loss: 3.0058374514074178\n",
      "Epoch: 13, Batch: 0, loss: 3.1279428273499414\n",
      "Epoch: 13, Batch: 100, loss: 2.5993254054270625\n",
      "Epoch: 13, Batch: 200, loss: 2.5912551375212884\n",
      "Epoch: 13, Batch: 300, loss: 2.4154800726100967\n",
      "Epoch: 13, Batch: 400, loss: 2.371716116021084\n",
      "Epoch: 13, Batch: 500, loss: 2.303712645168558\n",
      "Epoch: 14, Batch: 0, loss: 2.9410698408397544\n",
      "Epoch: 14, Batch: 100, loss: 1.9310396954362388\n",
      "Epoch: 14, Batch: 200, loss: 1.8665431898926772\n",
      "Epoch: 14, Batch: 300, loss: 1.8761134540680418\n",
      "Epoch: 14, Batch: 400, loss: 1.7880689265011405\n",
      "Epoch: 14, Batch: 500, loss: 1.7506778099592164\n",
      "Epoch: 15, Batch: 0, loss: 2.253672937627707\n",
      "Epoch: 15, Batch: 100, loss: 1.4832232041758044\n",
      "Epoch: 15, Batch: 200, loss: 1.4322258699880632\n",
      "Epoch: 15, Batch: 300, loss: 1.4187574970489107\n",
      "Epoch: 15, Batch: 400, loss: 1.3541625807672732\n",
      "Epoch: 15, Batch: 500, loss: 1.3408744086625553\n",
      "Epoch: 16, Batch: 0, loss: 1.5523036489854465\n",
      "Epoch: 16, Batch: 100, loss: 1.0464017645904682\n",
      "Epoch: 16, Batch: 200, loss: 0.9868143645858342\n",
      "Epoch: 16, Batch: 300, loss: 0.9395808746165036\n",
      "Epoch: 16, Batch: 400, loss: 0.9236872691219786\n",
      "Epoch: 16, Batch: 500, loss: 0.9056537758578541\n",
      "Epoch: 17, Batch: 0, loss: 0.7391650884092977\n",
      "Epoch: 17, Batch: 100, loss: 0.7449306196538004\n",
      "Epoch: 17, Batch: 200, loss: 0.738931052314457\n",
      "Epoch: 17, Batch: 300, loss: 0.7405629427569591\n",
      "Epoch: 17, Batch: 400, loss: 0.7206803104958565\n",
      "Epoch: 17, Batch: 500, loss: 0.6991486327891893\n",
      "Epoch: 18, Batch: 0, loss: 0.8332540668186806\n",
      "Epoch: 18, Batch: 100, loss: 0.6758595031981057\n",
      "Epoch: 18, Batch: 200, loss: 0.6467449309641599\n",
      "Epoch: 18, Batch: 300, loss: 0.6462333752886434\n",
      "Epoch: 18, Batch: 400, loss: 0.6225340346525069\n",
      "Epoch: 18, Batch: 500, loss: 0.6105110163369805\n",
      "Epoch: 19, Batch: 0, loss: 0.8462573298739401\n",
      "Epoch: 19, Batch: 100, loss: 0.6198134861142747\n",
      "Epoch: 19, Batch: 200, loss: 0.5778724910468137\n",
      "Epoch: 19, Batch: 300, loss: 0.5499905318438748\n",
      "Epoch: 19, Batch: 400, loss: 0.5418173946769507\n",
      "Epoch: 19, Batch: 500, loss: 0.5334413960435902\n",
      "Epoch: 20, Batch: 0, loss: 0.29041259908025363\n",
      "Epoch: 20, Batch: 100, loss: 0.45559097013290895\n",
      "Epoch: 20, Batch: 200, loss: 0.4622665286869092\n",
      "Epoch: 20, Batch: 300, loss: 0.47532298676467316\n",
      "Epoch: 20, Batch: 400, loss: 0.4663968995721147\n",
      "Epoch: 20, Batch: 500, loss: 0.46715643914666566\n",
      "Epoch: 21, Batch: 0, loss: 0.39520296000837324\n",
      "Epoch: 21, Batch: 100, loss: 0.4568871819757579\n",
      "Epoch: 21, Batch: 200, loss: 0.4418217902110458\n",
      "Epoch: 21, Batch: 300, loss: 0.44069648210798784\n",
      "Epoch: 21, Batch: 400, loss: 0.4444400443480132\n",
      "Epoch: 21, Batch: 500, loss: 0.4405540193372743\n",
      "Epoch: 22, Batch: 0, loss: 0.01665587354840824\n",
      "Epoch: 22, Batch: 100, loss: 0.3911349563039248\n",
      "Epoch: 22, Batch: 200, loss: 0.4135902201930736\n",
      "Epoch: 22, Batch: 300, loss: 0.4101789393211195\n",
      "Epoch: 22, Batch: 400, loss: 0.4193860213290057\n",
      "Epoch: 22, Batch: 500, loss: 0.426891632962285\n",
      "Epoch: 23, Batch: 0, loss: 0.1926736052881017\n",
      "Epoch: 23, Batch: 100, loss: 0.3983759033112624\n",
      "Epoch: 23, Batch: 200, loss: 0.3907489889962239\n",
      "Epoch: 23, Batch: 300, loss: 0.4059200623072576\n",
      "Epoch: 23, Batch: 400, loss: 0.42505244856137275\n",
      "Epoch: 23, Batch: 500, loss: 0.4166488736531109\n",
      "Epoch: 24, Batch: 0, loss: 0.3785692705365048\n",
      "Epoch: 24, Batch: 100, loss: 0.48886622835258026\n",
      "Epoch: 24, Batch: 200, loss: 0.44227994096501216\n",
      "Epoch: 24, Batch: 300, loss: 0.44289145261475454\n",
      "Epoch: 24, Batch: 400, loss: 0.4516780278022963\n",
      "Epoch: 24, Batch: 500, loss: 0.4570291196826886\n",
      "Epoch: 25, Batch: 0, loss: 0.58924489777652\n",
      "Epoch: 25, Batch: 100, loss: 0.45002746858313847\n",
      "Epoch: 25, Batch: 200, loss: 0.40317193250063166\n",
      "Epoch: 25, Batch: 300, loss: 0.4034704644602185\n",
      "Epoch: 25, Batch: 400, loss: 0.4214775261529668\n",
      "Epoch: 25, Batch: 500, loss: 0.4247478584453935\n",
      "Epoch: 26, Batch: 0, loss: 0.16386130662939208\n",
      "Epoch: 26, Batch: 100, loss: 0.4151568886779403\n",
      "Epoch: 26, Batch: 200, loss: 0.39263813034589556\n",
      "Epoch: 26, Batch: 300, loss: 0.377585325775229\n",
      "Epoch: 26, Batch: 400, loss: 0.3904887415856285\n",
      "Epoch: 26, Batch: 500, loss: 0.3846737124631256\n",
      "Epoch: 27, Batch: 0, loss: 0.2977907208732994\n",
      "Epoch: 27, Batch: 100, loss: 0.3900863943623353\n",
      "Epoch: 27, Batch: 200, loss: 0.36502260925959323\n",
      "Epoch: 27, Batch: 300, loss: 0.38295826508575875\n",
      "Epoch: 27, Batch: 400, loss: 0.38563538330955305\n",
      "Epoch: 27, Batch: 500, loss: 0.3805721683032822\n",
      "Epoch: 28, Batch: 0, loss: 0.5088585008870485\n",
      "Epoch: 28, Batch: 100, loss: 0.48689582061245795\n",
      "Epoch: 28, Batch: 200, loss: 0.4436555441872411\n",
      "Epoch: 28, Batch: 300, loss: 0.4172189338268849\n",
      "Epoch: 28, Batch: 400, loss: 0.42297608114265905\n",
      "Epoch: 28, Batch: 500, loss: 0.40907341082594156\n",
      "Epoch: 29, Batch: 0, loss: 0.23217412769028353\n",
      "Epoch: 29, Batch: 100, loss: 0.3582324241789437\n",
      "Epoch: 29, Batch: 200, loss: 0.40760332333875166\n",
      "Epoch: 29, Batch: 300, loss: 0.41465040854493257\n",
      "Epoch: 29, Batch: 400, loss: 0.4087185659396036\n",
      "Epoch: 29, Batch: 500, loss: 0.40818828132907026\n",
      "Epoch: 30, Batch: 0, loss: 0.47744779008084715\n",
      "Epoch: 30, Batch: 100, loss: 0.34151993853100143\n",
      "Epoch: 30, Batch: 200, loss: 0.3848808888879032\n",
      "Epoch: 30, Batch: 300, loss: 0.37682125915130277\n",
      "Epoch: 30, Batch: 400, loss: 0.3737524292413491\n",
      "Epoch: 30, Batch: 500, loss: 0.3742564290650695\n",
      "Epoch: 31, Batch: 0, loss: 0.15058744323000325\n",
      "Epoch: 31, Batch: 100, loss: 0.312406629183417\n",
      "Epoch: 31, Batch: 200, loss: 0.32562654722186507\n",
      "Epoch: 31, Batch: 300, loss: 0.33361315286782833\n",
      "Epoch: 31, Batch: 400, loss: 0.3536547692526019\n",
      "Epoch: 31, Batch: 500, loss: 0.35746607006266257\n",
      "Epoch: 32, Batch: 0, loss: 0.4422088931473617\n",
      "Epoch: 32, Batch: 100, loss: 0.3350940181262195\n",
      "Epoch: 32, Batch: 200, loss: 0.3559296140469394\n",
      "Epoch: 32, Batch: 300, loss: 0.3625532663366466\n",
      "Epoch: 32, Batch: 400, loss: 0.3700150110334213\n",
      "Epoch: 32, Batch: 500, loss: 0.3812917142431033\n",
      "Epoch: 33, Batch: 0, loss: 0.26375930548055915\n",
      "Epoch: 33, Batch: 100, loss: 0.34361959190225777\n",
      "Epoch: 33, Batch: 200, loss: 0.3556628384878418\n",
      "Epoch: 33, Batch: 300, loss: 0.35726588661793446\n",
      "Epoch: 33, Batch: 400, loss: 0.372807861269216\n",
      "Epoch: 33, Batch: 500, loss: 0.3785447605151274\n",
      "Epoch: 34, Batch: 0, loss: 0.21223283633142676\n",
      "Epoch: 34, Batch: 100, loss: 0.42841637681817646\n",
      "Epoch: 34, Batch: 200, loss: 0.3903453475831182\n",
      "Epoch: 34, Batch: 300, loss: 0.392277397162335\n",
      "Epoch: 34, Batch: 400, loss: 0.3782648392811958\n",
      "Epoch: 34, Batch: 500, loss: 0.373633752195496\n",
      "Epoch: 35, Batch: 0, loss: 0.027249201265598835\n",
      "Epoch: 35, Batch: 100, loss: 0.34506357792113557\n",
      "Epoch: 35, Batch: 200, loss: 0.37054782041455336\n",
      "Epoch: 35, Batch: 300, loss: 0.37112686895435454\n",
      "Epoch: 35, Batch: 400, loss: 0.3758353817134925\n",
      "Epoch: 35, Batch: 500, loss: 0.3696944370101972\n",
      "Epoch: 36, Batch: 0, loss: 0.42063176391050483\n",
      "Epoch: 36, Batch: 100, loss: 0.46351942963798526\n",
      "Epoch: 36, Batch: 200, loss: 0.4177585412912303\n",
      "Epoch: 36, Batch: 300, loss: 0.41340175584144406\n",
      "Epoch: 36, Batch: 400, loss: 0.3877137944438768\n",
      "Epoch: 36, Batch: 500, loss: 0.38782996521411384\n",
      "Epoch: 37, Batch: 0, loss: 0.4957944800612087\n",
      "Epoch: 37, Batch: 100, loss: 0.31683938690818125\n",
      "Epoch: 37, Batch: 200, loss: 0.37043366269832495\n",
      "Epoch: 37, Batch: 300, loss: 0.3679178098537974\n",
      "Epoch: 37, Batch: 400, loss: 0.3682048759129872\n",
      "Epoch: 37, Batch: 500, loss: 0.3628610041686837\n",
      "Epoch: 38, Batch: 0, loss: 0.02754224088788671\n",
      "Epoch: 38, Batch: 100, loss: 0.3708834360952741\n",
      "Epoch: 38, Batch: 200, loss: 0.36233384670177543\n",
      "Epoch: 38, Batch: 300, loss: 0.37155594020565896\n",
      "Epoch: 38, Batch: 400, loss: 0.36516715674218236\n",
      "Epoch: 38, Batch: 500, loss: 0.35591898683686596\n",
      "Epoch: 39, Batch: 0, loss: 0.4433676789497918\n",
      "Epoch: 39, Batch: 100, loss: 0.39679805739086205\n",
      "Epoch: 39, Batch: 200, loss: 0.3557721639554207\n",
      "Epoch: 39, Batch: 300, loss: 0.3558267693290307\n",
      "Epoch: 39, Batch: 400, loss: 0.3525859898716678\n",
      "Epoch: 39, Batch: 500, loss: 0.34948248501306306\n",
      "Epoch: 40, Batch: 0, loss: 0.08826359628639917\n",
      "Epoch: 40, Batch: 100, loss: 0.3935169222304424\n",
      "Epoch: 40, Batch: 200, loss: 0.3807651490048458\n",
      "Epoch: 40, Batch: 300, loss: 0.38630631439772395\n",
      "Epoch: 40, Batch: 400, loss: 0.37391659926947646\n",
      "Epoch: 40, Batch: 500, loss: 0.37357592501738524\n",
      "Epoch: 41, Batch: 0, loss: 0.27542584955267363\n",
      "Epoch: 41, Batch: 100, loss: 0.42058420045232603\n",
      "Epoch: 41, Batch: 200, loss: 0.37311787867709506\n",
      "Epoch: 41, Batch: 300, loss: 0.37421464700983054\n",
      "Epoch: 41, Batch: 400, loss: 0.3520407269139024\n",
      "Epoch: 41, Batch: 500, loss: 0.3458820152906445\n",
      "Epoch: 42, Batch: 0, loss: 0.2602145059378577\n",
      "Epoch: 42, Batch: 100, loss: 0.35324194149612537\n",
      "Epoch: 42, Batch: 200, loss: 0.37985929257734585\n",
      "Epoch: 42, Batch: 300, loss: 0.3868012572951117\n",
      "Epoch: 42, Batch: 400, loss: 0.38681333930847733\n",
      "Epoch: 42, Batch: 500, loss: 0.371014459945629\n",
      "Epoch: 43, Batch: 0, loss: 0.1845484331688341\n",
      "Epoch: 43, Batch: 100, loss: 0.3841307409602925\n",
      "Epoch: 43, Batch: 200, loss: 0.3639752021544472\n",
      "Epoch: 43, Batch: 300, loss: 0.3600553145482951\n",
      "Epoch: 43, Batch: 400, loss: 0.36262359653975473\n",
      "Epoch: 43, Batch: 500, loss: 0.3677251227073755\n",
      "Epoch: 44, Batch: 0, loss: 1.5073319610090672\n",
      "Epoch: 44, Batch: 100, loss: 0.38731986743582403\n",
      "Epoch: 44, Batch: 200, loss: 0.36005704861216314\n",
      "Epoch: 44, Batch: 300, loss: 0.3792180483686479\n",
      "Epoch: 44, Batch: 400, loss: 0.37588381615554717\n",
      "Epoch: 44, Batch: 500, loss: 0.3761199725309306\n",
      "Epoch: 45, Batch: 0, loss: 0.06294220687376346\n",
      "Epoch: 45, Batch: 100, loss: 0.4030247970223679\n",
      "Epoch: 45, Batch: 200, loss: 0.4083135139444938\n",
      "Epoch: 45, Batch: 300, loss: 0.40991280424125703\n",
      "Epoch: 45, Batch: 400, loss: 0.3979571188500211\n",
      "Epoch: 45, Batch: 500, loss: 0.3886845497821165\n",
      "Epoch: 46, Batch: 0, loss: 0.09226593834171139\n",
      "Epoch: 46, Batch: 100, loss: 0.5190180030976309\n",
      "Epoch: 46, Batch: 200, loss: 0.44635769046303947\n",
      "Epoch: 46, Batch: 300, loss: 0.41390771842706275\n",
      "Epoch: 46, Batch: 400, loss: 0.40536003511098145\n",
      "Epoch: 46, Batch: 500, loss: 0.3966810513436687\n",
      "Epoch: 47, Batch: 0, loss: 0.5246157767979419\n",
      "Epoch: 47, Batch: 100, loss: 0.3752724482427996\n",
      "Epoch: 47, Batch: 200, loss: 0.3822932709442318\n",
      "Epoch: 47, Batch: 300, loss: 0.39314847745807224\n",
      "Epoch: 47, Batch: 400, loss: 0.41407692115128175\n",
      "Epoch: 47, Batch: 500, loss: 0.40574290146845626\n",
      "Epoch: 48, Batch: 0, loss: 0.06252701056257243\n",
      "Epoch: 48, Batch: 100, loss: 0.3810016137753407\n",
      "Epoch: 48, Batch: 200, loss: 0.37542813604347985\n",
      "Epoch: 48, Batch: 300, loss: 0.37567535660920415\n",
      "Epoch: 48, Batch: 400, loss: 0.39038781491203034\n",
      "Epoch: 48, Batch: 500, loss: 0.3836543124534728\n",
      "Epoch: 49, Batch: 0, loss: 0.1957799512853438\n",
      "Epoch: 49, Batch: 100, loss: 0.35147664595106903\n",
      "Epoch: 49, Batch: 200, loss: 0.3696111242044693\n",
      "Epoch: 49, Batch: 300, loss: 0.36724050595610547\n",
      "Epoch: 49, Batch: 400, loss: 0.3556933977970883\n",
      "Epoch: 49, Batch: 500, loss: 0.36655774939889213\n",
      "Epoch: 50, Batch: 0, loss: 1.0080255071985906\n",
      "Epoch: 50, Batch: 100, loss: 0.3810468049618932\n",
      "Epoch: 50, Batch: 200, loss: 0.34117743132273565\n",
      "Epoch: 50, Batch: 300, loss: 0.351348948440225\n",
      "Epoch: 50, Batch: 400, loss: 0.35619608974548533\n",
      "Epoch: 50, Batch: 500, loss: 0.365538216404743\n",
      "Epoch: 51, Batch: 0, loss: 0.06313356735348698\n",
      "Epoch: 51, Batch: 100, loss: 0.38684027571092566\n",
      "Epoch: 51, Batch: 200, loss: 0.37375071184616665\n",
      "Epoch: 51, Batch: 300, loss: 0.3780662797863084\n",
      "Epoch: 51, Batch: 400, loss: 0.3748336905093671\n",
      "Epoch: 51, Batch: 500, loss: 0.37466912882390674\n",
      "Epoch: 52, Batch: 0, loss: 0.31542902898491254\n",
      "Epoch: 52, Batch: 100, loss: 0.39190879848765153\n",
      "Epoch: 52, Batch: 200, loss: 0.3916904380003165\n",
      "Epoch: 52, Batch: 300, loss: 0.39857422300716755\n",
      "Epoch: 52, Batch: 400, loss: 0.40659414595907795\n",
      "Epoch: 52, Batch: 500, loss: 0.385595439265646\n",
      "Epoch: 53, Batch: 0, loss: 0.20869026524650353\n",
      "Epoch: 53, Batch: 100, loss: 0.3236202962381728\n",
      "Epoch: 53, Batch: 200, loss: 0.3549593570783117\n",
      "Epoch: 53, Batch: 300, loss: 0.34936901728235625\n",
      "Epoch: 53, Batch: 400, loss: 0.375286187685627\n",
      "Epoch: 53, Batch: 500, loss: 0.3624734967778657\n",
      "Epoch: 54, Batch: 0, loss: 0.24025304142643147\n",
      "Epoch: 54, Batch: 100, loss: 0.36205830254664517\n",
      "Epoch: 54, Batch: 200, loss: 0.38272683583196043\n",
      "Epoch: 54, Batch: 300, loss: 0.36999452584681813\n",
      "Epoch: 54, Batch: 400, loss: 0.3608708269747735\n",
      "Epoch: 54, Batch: 500, loss: 0.3644734649627296\n",
      "Epoch: 55, Batch: 0, loss: 0.007827020861482565\n",
      "Epoch: 55, Batch: 100, loss: 0.3648350340149035\n",
      "Epoch: 55, Batch: 200, loss: 0.3472033075599324\n",
      "Epoch: 55, Batch: 300, loss: 0.3593486930235576\n",
      "Epoch: 55, Batch: 400, loss: 0.35931953495680885\n",
      "Epoch: 55, Batch: 500, loss: 0.36476227658652305\n",
      "Epoch: 56, Batch: 0, loss: 1.1401819685258392\n",
      "Epoch: 56, Batch: 100, loss: 0.3837705075948821\n",
      "Epoch: 56, Batch: 200, loss: 0.3466544082788951\n",
      "Epoch: 56, Batch: 300, loss: 0.36540172378831925\n",
      "Epoch: 56, Batch: 400, loss: 0.3612673455583607\n",
      "Epoch: 56, Batch: 500, loss: 0.3704170106379489\n",
      "Epoch: 57, Batch: 0, loss: 0.07823704016380502\n",
      "Epoch: 57, Batch: 100, loss: 0.3623477314904208\n",
      "Epoch: 57, Batch: 200, loss: 0.36946214828284124\n",
      "Epoch: 57, Batch: 300, loss: 0.38174432021823734\n",
      "Epoch: 57, Batch: 400, loss: 0.3856517527358285\n",
      "Epoch: 57, Batch: 500, loss: 0.377520287073084\n",
      "Epoch: 58, Batch: 0, loss: 0.10683773749998048\n",
      "Epoch: 58, Batch: 100, loss: 0.38361946345103937\n",
      "Epoch: 58, Batch: 200, loss: 0.3488846784626378\n",
      "Epoch: 58, Batch: 300, loss: 0.33206751174558574\n",
      "Epoch: 58, Batch: 400, loss: 0.34284760263918757\n",
      "Epoch: 58, Batch: 500, loss: 0.3587436775103618\n",
      "Epoch: 59, Batch: 0, loss: 0.01682018227750012\n",
      "Epoch: 59, Batch: 100, loss: 0.4175203232044571\n",
      "Epoch: 59, Batch: 200, loss: 0.38325978276040934\n",
      "Epoch: 59, Batch: 300, loss: 0.40588060942879245\n",
      "Epoch: 59, Batch: 400, loss: 0.38678370078649565\n",
      "Epoch: 59, Batch: 500, loss: 0.3870990119511256\n",
      "Epoch: 60, Batch: 0, loss: 0.7678098635037893\n",
      "Epoch: 60, Batch: 100, loss: 0.39661756870863557\n",
      "Epoch: 60, Batch: 200, loss: 0.3609212444891136\n",
      "Epoch: 60, Batch: 300, loss: 0.372583519582809\n",
      "Epoch: 60, Batch: 400, loss: 0.3581141816838088\n",
      "Epoch: 60, Batch: 500, loss: 0.3563725207712204\n",
      "Epoch: 61, Batch: 0, loss: 0.623069516031517\n",
      "Epoch: 61, Batch: 100, loss: 0.2714244275055634\n",
      "Epoch: 61, Batch: 200, loss: 0.34367147003897064\n",
      "Epoch: 61, Batch: 300, loss: 0.3467887734218918\n",
      "Epoch: 61, Batch: 400, loss: 0.3870762165706379\n",
      "Epoch: 61, Batch: 500, loss: 0.37749423373843116\n",
      "Epoch: 62, Batch: 0, loss: 0.5821313277184357\n",
      "Epoch: 62, Batch: 100, loss: 0.34931325973823424\n",
      "Epoch: 62, Batch: 200, loss: 0.36914913828385404\n",
      "Epoch: 62, Batch: 300, loss: 0.3425027817967289\n",
      "Epoch: 62, Batch: 400, loss: 0.33741789149616125\n",
      "Epoch: 62, Batch: 500, loss: 0.35252308532880483\n",
      "Epoch: 63, Batch: 0, loss: 0.06198151996155619\n",
      "Epoch: 63, Batch: 100, loss: 0.31180889271431117\n",
      "Epoch: 63, Batch: 200, loss: 0.3135690536129932\n",
      "Epoch: 63, Batch: 300, loss: 0.3534453752233151\n",
      "Epoch: 63, Batch: 400, loss: 0.35720881666511317\n",
      "Epoch: 63, Batch: 500, loss: 0.35584623346954153\n",
      "Epoch: 64, Batch: 0, loss: 0.3808898473354766\n",
      "Epoch: 64, Batch: 100, loss: 0.30766577595136907\n",
      "Epoch: 64, Batch: 200, loss: 0.3555617559860682\n",
      "Epoch: 64, Batch: 300, loss: 0.35955133355058233\n",
      "Epoch: 64, Batch: 400, loss: 0.37725838941055284\n",
      "Epoch: 64, Batch: 500, loss: 0.377195633564486\n",
      "Epoch: 65, Batch: 0, loss: 0.00030712626773579665\n",
      "Epoch: 65, Batch: 100, loss: 0.3884095827875198\n",
      "Epoch: 65, Batch: 200, loss: 0.37780741725674744\n",
      "Epoch: 65, Batch: 300, loss: 0.35522890777538635\n",
      "Epoch: 65, Batch: 400, loss: 0.3651789501807838\n",
      "Epoch: 65, Batch: 500, loss: 0.3712138182346018\n",
      "Epoch: 66, Batch: 0, loss: 0.24465386674792144\n",
      "Epoch: 66, Batch: 100, loss: 0.29405475517851976\n",
      "Epoch: 66, Batch: 200, loss: 0.31881152319019257\n",
      "Epoch: 66, Batch: 300, loss: 0.3443376088864808\n",
      "Epoch: 66, Batch: 400, loss: 0.34572363141783297\n",
      "Epoch: 66, Batch: 500, loss: 0.354004545883906\n",
      "Epoch: 67, Batch: 0, loss: 0.07325302516548021\n",
      "Epoch: 67, Batch: 100, loss: 0.3587619204426813\n",
      "Epoch: 67, Batch: 200, loss: 0.3851757252357696\n",
      "Epoch: 67, Batch: 300, loss: 0.36594933359780457\n",
      "Epoch: 67, Batch: 400, loss: 0.3601490497716337\n",
      "Epoch: 67, Batch: 500, loss: 0.35529761133962284\n",
      "Epoch: 68, Batch: 0, loss: 0.4367145853811327\n",
      "Epoch: 68, Batch: 100, loss: 0.42089984927704954\n",
      "Epoch: 68, Batch: 200, loss: 0.4374543225847556\n",
      "Epoch: 68, Batch: 300, loss: 0.4074209246427027\n",
      "Epoch: 68, Batch: 400, loss: 0.3868370754843534\n",
      "Epoch: 68, Batch: 500, loss: 0.3806435525818647\n",
      "Epoch: 69, Batch: 0, loss: 0.4355220245672929\n",
      "Epoch: 69, Batch: 100, loss: 0.2927953505206124\n",
      "Epoch: 69, Batch: 200, loss: 0.341419275625554\n",
      "Epoch: 69, Batch: 300, loss: 0.3607876723457297\n",
      "Epoch: 69, Batch: 400, loss: 0.3720866243940844\n",
      "Epoch: 69, Batch: 500, loss: 0.35969661432765054\n",
      "Epoch: 70, Batch: 0, loss: 0.07622523814174793\n",
      "Epoch: 70, Batch: 100, loss: 0.39892043989865517\n",
      "Epoch: 70, Batch: 200, loss: 0.35871874558541095\n",
      "Epoch: 70, Batch: 300, loss: 0.3695734211413167\n",
      "Epoch: 70, Batch: 400, loss: 0.3954309823161593\n",
      "Epoch: 70, Batch: 500, loss: 0.38809867132478515\n",
      "Epoch: 71, Batch: 0, loss: 0.0015287905341953652\n",
      "Epoch: 71, Batch: 100, loss: 0.36168002127346516\n",
      "Epoch: 71, Batch: 200, loss: 0.3269936739017256\n",
      "Epoch: 71, Batch: 300, loss: 0.3389853610933605\n",
      "Epoch: 71, Batch: 400, loss: 0.3465085643701565\n",
      "Epoch: 71, Batch: 500, loss: 0.3462360213331013\n",
      "Epoch: 72, Batch: 0, loss: 0.4038766451419477\n",
      "Epoch: 72, Batch: 100, loss: 0.32574229175931946\n",
      "Epoch: 72, Batch: 200, loss: 0.3441881177971646\n",
      "Epoch: 72, Batch: 300, loss: 0.3508094015895568\n",
      "Epoch: 72, Batch: 400, loss: 0.37627020094741814\n",
      "Epoch: 72, Batch: 500, loss: 0.378549195078522\n",
      "Epoch: 73, Batch: 0, loss: 0.8713366545669651\n",
      "Epoch: 73, Batch: 100, loss: 0.41134506037055785\n",
      "Epoch: 73, Batch: 200, loss: 0.37689572848487585\n",
      "Epoch: 73, Batch: 300, loss: 0.39419066451579543\n",
      "Epoch: 73, Batch: 400, loss: 0.3937336446607827\n",
      "Epoch: 73, Batch: 500, loss: 0.4200862814016241\n",
      "Epoch: 74, Batch: 0, loss: 0.18420772949081896\n",
      "Epoch: 74, Batch: 100, loss: 0.3313022853104613\n",
      "Epoch: 74, Batch: 200, loss: 0.36222384197056257\n",
      "Epoch: 74, Batch: 300, loss: 0.3579048371543244\n",
      "Epoch: 74, Batch: 400, loss: 0.3557481474165493\n",
      "Epoch: 74, Batch: 500, loss: 0.347906021277151\n",
      "Epoch: 75, Batch: 0, loss: 0.36897812513041434\n",
      "Epoch: 75, Batch: 100, loss: 0.3639647459886462\n",
      "Epoch: 75, Batch: 200, loss: 0.35649505498982775\n",
      "Epoch: 75, Batch: 300, loss: 0.3602195271943849\n",
      "Epoch: 75, Batch: 400, loss: 0.3588589942524864\n",
      "Epoch: 75, Batch: 500, loss: 0.3651465722712955\n",
      "Epoch: 76, Batch: 0, loss: 0.003455630280727408\n",
      "Epoch: 76, Batch: 100, loss: 0.3205122351788515\n",
      "Epoch: 76, Batch: 200, loss: 0.3387940409897103\n",
      "Epoch: 76, Batch: 300, loss: 0.3558895756525132\n",
      "Epoch: 76, Batch: 400, loss: 0.3698518420581159\n",
      "Epoch: 76, Batch: 500, loss: 0.36306306824124945\n",
      "Epoch: 77, Batch: 0, loss: 0.15374700977431208\n",
      "Epoch: 77, Batch: 100, loss: 0.4082731949931644\n",
      "Epoch: 77, Batch: 200, loss: 0.3645843013173065\n",
      "Epoch: 77, Batch: 300, loss: 0.3766076349087718\n",
      "Epoch: 77, Batch: 400, loss: 0.3802804591166783\n",
      "Epoch: 77, Batch: 500, loss: 0.4064840425169917\n",
      "Epoch: 78, Batch: 0, loss: 0.8699858638302282\n",
      "Epoch: 78, Batch: 100, loss: 0.3220101464120502\n",
      "Epoch: 78, Batch: 200, loss: 0.34847901929205444\n",
      "Epoch: 78, Batch: 300, loss: 0.3315252202884891\n",
      "Epoch: 78, Batch: 400, loss: 0.33067601864742696\n",
      "Epoch: 78, Batch: 500, loss: 0.329144341111914\n",
      "Epoch: 79, Batch: 0, loss: 0.6165898685733984\n",
      "Epoch: 79, Batch: 100, loss: 0.41700019474592964\n",
      "Epoch: 79, Batch: 200, loss: 0.3460226497110323\n",
      "Epoch: 79, Batch: 300, loss: 0.3503601381862674\n",
      "Epoch: 79, Batch: 400, loss: 0.3477379914815097\n",
      "Epoch: 79, Batch: 500, loss: 0.3466636214245155\n",
      "Epoch: 80, Batch: 0, loss: 0.24907456361650535\n",
      "Epoch: 80, Batch: 100, loss: 0.3975658811983222\n",
      "Epoch: 80, Batch: 200, loss: 0.3754551993992704\n",
      "Epoch: 80, Batch: 300, loss: 0.35123951639732054\n",
      "Epoch: 80, Batch: 400, loss: 0.3422481464563836\n",
      "Epoch: 80, Batch: 500, loss: 0.360717126282201\n",
      "Epoch: 81, Batch: 0, loss: 0.0794339915796659\n",
      "Epoch: 81, Batch: 100, loss: 0.32911875354337133\n",
      "Epoch: 81, Batch: 200, loss: 0.2965498553155416\n",
      "Epoch: 81, Batch: 300, loss: 0.2987033734972392\n",
      "Epoch: 81, Batch: 400, loss: 0.32318967154030026\n",
      "Epoch: 81, Batch: 500, loss: 0.31857396879045297\n",
      "Epoch: 82, Batch: 0, loss: 0.015201188691751934\n",
      "Epoch: 82, Batch: 100, loss: 0.42604232229883937\n",
      "Epoch: 82, Batch: 200, loss: 0.420530188218715\n",
      "Epoch: 82, Batch: 300, loss: 0.3962983129905233\n",
      "Epoch: 82, Batch: 400, loss: 0.39522585361963725\n",
      "Epoch: 82, Batch: 500, loss: 0.3985709633706981\n",
      "Epoch: 83, Batch: 0, loss: 0.001290454686189239\n",
      "Epoch: 83, Batch: 100, loss: 0.28311480923991106\n",
      "Epoch: 83, Batch: 200, loss: 0.3489739232469882\n",
      "Epoch: 83, Batch: 300, loss: 0.35784935341488167\n",
      "Epoch: 83, Batch: 400, loss: 0.36417261388916\n",
      "Epoch: 83, Batch: 500, loss: 0.3684716329029904\n",
      "Epoch: 84, Batch: 0, loss: 0.05948283534669118\n",
      "Epoch: 84, Batch: 100, loss: 0.36164234528506845\n",
      "Epoch: 84, Batch: 200, loss: 0.33988996788585013\n",
      "Epoch: 84, Batch: 300, loss: 0.32905954009975663\n",
      "Epoch: 84, Batch: 400, loss: 0.3359487568682769\n",
      "Epoch: 84, Batch: 500, loss: 0.33731748191242755\n",
      "Epoch: 85, Batch: 0, loss: 0.003301626866727329\n",
      "Epoch: 85, Batch: 100, loss: 0.35943027710284753\n",
      "Epoch: 85, Batch: 200, loss: 0.38003116998149483\n",
      "Epoch: 85, Batch: 300, loss: 0.37809471574368814\n",
      "Epoch: 85, Batch: 400, loss: 0.3820803773713934\n",
      "Epoch: 85, Batch: 500, loss: 0.3768096367742136\n",
      "Epoch: 86, Batch: 0, loss: 0.08146336537859057\n",
      "Epoch: 86, Batch: 100, loss: 0.33304015062964304\n",
      "Epoch: 86, Batch: 200, loss: 0.362807324581688\n",
      "Epoch: 86, Batch: 300, loss: 0.3721071940630724\n",
      "Epoch: 86, Batch: 400, loss: 0.369559861172409\n",
      "Epoch: 86, Batch: 500, loss: 0.37345953794868364\n",
      "Epoch: 87, Batch: 0, loss: 0.3672347837143879\n",
      "Epoch: 87, Batch: 100, loss: 0.3926111593533089\n",
      "Epoch: 87, Batch: 200, loss: 0.3996358384529929\n",
      "Epoch: 87, Batch: 300, loss: 0.40120210262539485\n",
      "Epoch: 87, Batch: 400, loss: 0.39341514857506155\n",
      "Epoch: 87, Batch: 500, loss: 0.38086853543732985\n",
      "Epoch: 88, Batch: 0, loss: 0.26296408413778605\n",
      "Epoch: 88, Batch: 100, loss: 0.3714480524132529\n",
      "Epoch: 88, Batch: 200, loss: 0.3652419761192934\n",
      "Epoch: 88, Batch: 300, loss: 0.3436676619017975\n",
      "Epoch: 88, Batch: 400, loss: 0.34756331395273315\n",
      "Epoch: 88, Batch: 500, loss: 0.33782362023387225\n",
      "Epoch: 89, Batch: 0, loss: 0.7203768965901879\n",
      "Epoch: 89, Batch: 100, loss: 0.417655580757384\n",
      "Epoch: 89, Batch: 200, loss: 0.37958510379327526\n",
      "Epoch: 89, Batch: 300, loss: 0.3722135900224097\n",
      "Epoch: 89, Batch: 400, loss: 0.3673933405378294\n",
      "Epoch: 89, Batch: 500, loss: 0.38145380350610647\n",
      "Epoch: 90, Batch: 0, loss: 0.931041805589927\n",
      "Epoch: 90, Batch: 100, loss: 0.33388463978417515\n",
      "Epoch: 90, Batch: 200, loss: 0.35277042144111953\n",
      "Epoch: 90, Batch: 300, loss: 0.35028352885615355\n",
      "Epoch: 90, Batch: 400, loss: 0.346423585025548\n",
      "Epoch: 90, Batch: 500, loss: 0.342169097860416\n",
      "Epoch: 91, Batch: 0, loss: 0.0011551014176701389\n",
      "Epoch: 91, Batch: 100, loss: 0.2815139981404067\n",
      "Epoch: 91, Batch: 200, loss: 0.29567020364524693\n",
      "Epoch: 91, Batch: 300, loss: 0.3365844256825257\n",
      "Epoch: 91, Batch: 400, loss: 0.3169352193427977\n",
      "Epoch: 91, Batch: 500, loss: 0.3283102127244542\n",
      "Epoch: 92, Batch: 0, loss: 0.59365732001949\n",
      "Epoch: 92, Batch: 100, loss: 0.40930182876282484\n",
      "Epoch: 92, Batch: 200, loss: 0.403053377966716\n",
      "Epoch: 92, Batch: 300, loss: 0.3840397867981652\n",
      "Epoch: 92, Batch: 400, loss: 0.38690527064267527\n",
      "Epoch: 92, Batch: 500, loss: 0.37457771602234236\n",
      "Epoch: 93, Batch: 0, loss: 0.021056902898843075\n",
      "Epoch: 93, Batch: 100, loss: 0.37277228910022403\n",
      "Epoch: 93, Batch: 200, loss: 0.3341958789916848\n",
      "Epoch: 93, Batch: 300, loss: 0.3160408104427551\n",
      "Epoch: 93, Batch: 400, loss: 0.32734491612272976\n",
      "Epoch: 93, Batch: 500, loss: 0.3466699429494455\n",
      "Epoch: 94, Batch: 0, loss: 0.25835218481367606\n",
      "Epoch: 94, Batch: 100, loss: 0.44627052024764013\n",
      "Epoch: 94, Batch: 200, loss: 0.37091092603534115\n",
      "Epoch: 94, Batch: 300, loss: 0.389927852763156\n",
      "Epoch: 94, Batch: 400, loss: 0.37708216716347814\n",
      "Epoch: 94, Batch: 500, loss: 0.38180205512967963\n",
      "Epoch: 95, Batch: 0, loss: 0.20438161054104106\n",
      "Epoch: 95, Batch: 100, loss: 0.40948851730088387\n",
      "Epoch: 95, Batch: 200, loss: 0.3865360450158574\n",
      "Epoch: 95, Batch: 300, loss: 0.3582042274412683\n",
      "Epoch: 95, Batch: 400, loss: 0.3766088811376695\n",
      "Epoch: 95, Batch: 500, loss: 0.38291982370375743\n",
      "Epoch: 96, Batch: 0, loss: 0.29506551523537067\n",
      "Epoch: 96, Batch: 100, loss: 0.30609476852400214\n",
      "Epoch: 96, Batch: 200, loss: 0.3643104502170486\n",
      "Epoch: 96, Batch: 300, loss: 0.3669756611301069\n",
      "Epoch: 96, Batch: 400, loss: 0.37873422080019564\n",
      "Epoch: 96, Batch: 500, loss: 0.3806549330248481\n",
      "Epoch: 97, Batch: 0, loss: 0.5123924832591353\n",
      "Epoch: 97, Batch: 100, loss: 0.36682725275528794\n",
      "Epoch: 97, Batch: 200, loss: 0.3384770120912882\n",
      "Epoch: 97, Batch: 300, loss: 0.33330950556746675\n",
      "Epoch: 97, Batch: 400, loss: 0.33716793339243467\n",
      "Epoch: 97, Batch: 500, loss: 0.3466527275894205\n",
      "Epoch: 98, Batch: 0, loss: 0.020452734090367585\n",
      "Epoch: 98, Batch: 100, loss: 0.3712539976379919\n",
      "Epoch: 98, Batch: 200, loss: 0.42567642094967334\n",
      "Epoch: 98, Batch: 300, loss: 0.38619483113387243\n",
      "Epoch: 98, Batch: 400, loss: 0.377480875345666\n",
      "Epoch: 98, Batch: 500, loss: 0.3796379859983195\n",
      "Epoch: 99, Batch: 0, loss: 0.891291417883726\n",
      "Epoch: 99, Batch: 100, loss: 0.334100086926711\n",
      "Epoch: 99, Batch: 200, loss: 0.3947711985618199\n",
      "Epoch: 99, Batch: 300, loss: 0.38584717461352164\n",
      "Epoch: 99, Batch: 400, loss: 0.4004003395529616\n",
      "Epoch: 99, Batch: 500, loss: 0.3940549240781277\n",
      "Epoch: 100, Batch: 0, loss: 0.05652034169385045\n",
      "Epoch: 100, Batch: 100, loss: 0.316775704147344\n",
      "Epoch: 100, Batch: 200, loss: 0.32147935129881433\n",
      "Epoch: 100, Batch: 300, loss: 0.34467737190037107\n",
      "Epoch: 100, Batch: 400, loss: 0.3542524192934173\n",
      "Epoch: 100, Batch: 500, loss: 0.35168960265537813\n",
      "Epoch: 101, Batch: 0, loss: 0.5484112907462971\n",
      "Epoch: 101, Batch: 100, loss: 0.31608240193822623\n",
      "Epoch: 101, Batch: 200, loss: 0.32984260506637325\n",
      "Epoch: 101, Batch: 300, loss: 0.35323948296166524\n",
      "Epoch: 101, Batch: 400, loss: 0.34219315328314487\n",
      "Epoch: 101, Batch: 500, loss: 0.33802747731883864\n",
      "Epoch: 102, Batch: 0, loss: 0.013928056791984543\n",
      "Epoch: 102, Batch: 100, loss: 0.39713402332006204\n",
      "Epoch: 102, Batch: 200, loss: 0.36937699425635206\n",
      "Epoch: 102, Batch: 300, loss: 0.3938437448093434\n",
      "Epoch: 102, Batch: 400, loss: 0.39882157787886935\n",
      "Epoch: 102, Batch: 500, loss: 0.39095196219766765\n",
      "Epoch: 103, Batch: 0, loss: 0.14661558168894429\n",
      "Epoch: 103, Batch: 100, loss: 0.3267764698142089\n",
      "Epoch: 103, Batch: 200, loss: 0.36353480729459287\n",
      "Epoch: 103, Batch: 300, loss: 0.341676402384392\n",
      "Epoch: 103, Batch: 400, loss: 0.34584153914409893\n",
      "Epoch: 103, Batch: 500, loss: 0.35788733681963464\n",
      "Epoch: 104, Batch: 0, loss: 0.9904442549307227\n",
      "Epoch: 104, Batch: 100, loss: 0.3586501921906357\n",
      "Epoch: 104, Batch: 200, loss: 0.33139634737701235\n",
      "Epoch: 104, Batch: 300, loss: 0.3453868199379847\n",
      "Epoch: 104, Batch: 400, loss: 0.33870834688051826\n",
      "Epoch: 104, Batch: 500, loss: 0.35239702555575586\n",
      "Epoch: 105, Batch: 0, loss: 0.5114386520460621\n",
      "Epoch: 105, Batch: 100, loss: 0.3875170186063675\n",
      "Epoch: 105, Batch: 200, loss: 0.3496502958901988\n",
      "Epoch: 105, Batch: 300, loss: 0.3338264843819451\n",
      "Epoch: 105, Batch: 400, loss: 0.3533445052463472\n",
      "Epoch: 105, Batch: 500, loss: 0.3489991342817473\n",
      "Epoch: 106, Batch: 0, loss: 0.8559338681819033\n",
      "Epoch: 106, Batch: 100, loss: 0.2648378745909258\n",
      "Epoch: 106, Batch: 200, loss: 0.272591986849757\n",
      "Epoch: 106, Batch: 300, loss: 0.2818368234969564\n",
      "Epoch: 106, Batch: 400, loss: 0.2835441821928133\n",
      "Epoch: 106, Batch: 500, loss: 0.3009238593617231\n",
      "Epoch: 107, Batch: 0, loss: 0.6427376336733537\n",
      "Epoch: 107, Batch: 100, loss: 0.3872748335282773\n",
      "Epoch: 107, Batch: 200, loss: 0.3924313821116178\n",
      "Epoch: 107, Batch: 300, loss: 0.37751207405494336\n",
      "Epoch: 107, Batch: 400, loss: 0.36222256205603126\n",
      "Epoch: 107, Batch: 500, loss: 0.3583767656297181\n",
      "Epoch: 108, Batch: 0, loss: 0.05330544783555703\n",
      "Epoch: 108, Batch: 100, loss: 0.41440490095127797\n",
      "Epoch: 108, Batch: 200, loss: 0.41213762275231486\n",
      "Epoch: 108, Batch: 300, loss: 0.40194359966375526\n",
      "Epoch: 108, Batch: 400, loss: 0.38099284499929575\n",
      "Epoch: 108, Batch: 500, loss: 0.3790473285007954\n",
      "Epoch: 109, Batch: 0, loss: 0.057071135076210235\n",
      "Epoch: 109, Batch: 100, loss: 0.28177909967449116\n",
      "Epoch: 109, Batch: 200, loss: 0.3258689951426103\n",
      "Epoch: 109, Batch: 300, loss: 0.32718455923913287\n",
      "Epoch: 109, Batch: 400, loss: 0.3578743136953607\n",
      "Epoch: 109, Batch: 500, loss: 0.37915558389148163\n",
      "Epoch: 110, Batch: 0, loss: 0.19266220865841507\n",
      "Epoch: 110, Batch: 100, loss: 0.4315298988112695\n",
      "Epoch: 110, Batch: 200, loss: 0.39884386226806307\n",
      "Epoch: 110, Batch: 300, loss: 0.3692939560867483\n",
      "Epoch: 110, Batch: 400, loss: 0.35293247718921883\n",
      "Epoch: 110, Batch: 500, loss: 0.3513205476881985\n",
      "Epoch: 111, Batch: 0, loss: 0.553519103159921\n",
      "Epoch: 111, Batch: 100, loss: 0.32384805931030614\n",
      "Epoch: 111, Batch: 200, loss: 0.3522836705589658\n",
      "Epoch: 111, Batch: 300, loss: 0.3334752060411728\n",
      "Epoch: 111, Batch: 400, loss: 0.34594069072784406\n",
      "Epoch: 111, Batch: 500, loss: 0.3679712437969109\n",
      "Epoch: 112, Batch: 0, loss: 0.6050238484769493\n",
      "Epoch: 112, Batch: 100, loss: 0.3153741707281883\n",
      "Epoch: 112, Batch: 200, loss: 0.3645895388171214\n",
      "Epoch: 112, Batch: 300, loss: 0.34591464260211974\n",
      "Epoch: 112, Batch: 400, loss: 0.34180425238423806\n",
      "Epoch: 112, Batch: 500, loss: 0.3533116794481214\n",
      "Epoch: 113, Batch: 0, loss: 0.6307260968855599\n",
      "Epoch: 113, Batch: 100, loss: 0.3633749700961147\n",
      "Epoch: 113, Batch: 200, loss: 0.36878039701627546\n",
      "Epoch: 113, Batch: 300, loss: 0.35143552067547845\n",
      "Epoch: 113, Batch: 400, loss: 0.3479251177833124\n",
      "Epoch: 113, Batch: 500, loss: 0.3437416843338718\n",
      "Epoch: 114, Batch: 0, loss: 0.17633572807944775\n",
      "Epoch: 114, Batch: 100, loss: 0.3944278510646011\n",
      "Epoch: 114, Batch: 200, loss: 0.35158271080403447\n",
      "Epoch: 114, Batch: 300, loss: 0.35185025008444437\n",
      "Epoch: 114, Batch: 400, loss: 0.33905957531661607\n",
      "Epoch: 114, Batch: 500, loss: 0.3385044154659592\n",
      "Epoch: 115, Batch: 0, loss: 0.08089581821570743\n",
      "Epoch: 115, Batch: 100, loss: 0.4280258897256761\n",
      "Epoch: 115, Batch: 200, loss: 0.3667567524229474\n",
      "Epoch: 115, Batch: 300, loss: 0.3869789446673123\n",
      "Epoch: 115, Batch: 400, loss: 0.38235757768645573\n",
      "Epoch: 115, Batch: 500, loss: 0.3899558919539019\n",
      "Epoch: 116, Batch: 0, loss: 0.2597403214831943\n",
      "Epoch: 116, Batch: 100, loss: 0.3315113112690856\n",
      "Epoch: 116, Batch: 200, loss: 0.353138181719994\n",
      "Epoch: 116, Batch: 300, loss: 0.36959365133669014\n",
      "Epoch: 116, Batch: 400, loss: 0.36549746572985986\n",
      "Epoch: 116, Batch: 500, loss: 0.3528493069340382\n",
      "Epoch: 117, Batch: 0, loss: 0.34437796882222105\n",
      "Epoch: 117, Batch: 100, loss: 0.3058173604100197\n",
      "Epoch: 117, Batch: 200, loss: 0.33782315959010306\n",
      "Epoch: 117, Batch: 300, loss: 0.341194347478867\n",
      "Epoch: 117, Batch: 400, loss: 0.3400429432633342\n",
      "Epoch: 117, Batch: 500, loss: 0.3506544407108334\n",
      "Epoch: 118, Batch: 0, loss: 0.12338924313857573\n",
      "Epoch: 118, Batch: 100, loss: 0.37375320198524176\n",
      "Epoch: 118, Batch: 200, loss: 0.3639975771449126\n",
      "Epoch: 118, Batch: 300, loss: 0.34129573667269275\n",
      "Epoch: 118, Batch: 400, loss: 0.35846880419519306\n",
      "Epoch: 118, Batch: 500, loss: 0.3696321900683971\n",
      "Epoch: 119, Batch: 0, loss: 0.28941117378682063\n",
      "Epoch: 119, Batch: 100, loss: 0.3519152864930029\n",
      "Epoch: 119, Batch: 200, loss: 0.3987239871915741\n",
      "Epoch: 119, Batch: 300, loss: 0.4077266475151517\n",
      "Epoch: 119, Batch: 400, loss: 0.4023409063569062\n",
      "Epoch: 119, Batch: 500, loss: 0.3930091855307336\n",
      "Epoch: 120, Batch: 0, loss: 0.19180882073563316\n",
      "Epoch: 120, Batch: 100, loss: 0.3795023731788232\n",
      "Epoch: 120, Batch: 200, loss: 0.32556010807092\n",
      "Epoch: 120, Batch: 300, loss: 0.338547354493781\n",
      "Epoch: 120, Batch: 400, loss: 0.3586435183213205\n",
      "Epoch: 120, Batch: 500, loss: 0.3690261119039307\n",
      "Epoch: 121, Batch: 0, loss: 0.21931110664361883\n",
      "Epoch: 121, Batch: 100, loss: 0.34001637012523755\n",
      "Epoch: 121, Batch: 200, loss: 0.36346202728004023\n",
      "Epoch: 121, Batch: 300, loss: 0.3601234635129553\n",
      "Epoch: 121, Batch: 400, loss: 0.37917920071043243\n",
      "Epoch: 121, Batch: 500, loss: 0.38764394992179946\n",
      "Epoch: 122, Batch: 0, loss: 0.3220172505334545\n",
      "Epoch: 122, Batch: 100, loss: 0.3546857817888201\n",
      "Epoch: 122, Batch: 200, loss: 0.3628822786446666\n",
      "Epoch: 122, Batch: 300, loss: 0.34101433603801673\n",
      "Epoch: 122, Batch: 400, loss: 0.3293761576598923\n",
      "Epoch: 122, Batch: 500, loss: 0.33186066581612267\n",
      "Epoch: 123, Batch: 0, loss: 0.002424834639378027\n",
      "Epoch: 123, Batch: 100, loss: 0.357911183809602\n",
      "Epoch: 123, Batch: 200, loss: 0.33095237342108524\n",
      "Epoch: 123, Batch: 300, loss: 0.32245842266869645\n",
      "Epoch: 123, Batch: 400, loss: 0.3463037359136446\n",
      "Epoch: 123, Batch: 500, loss: 0.34189394353799885\n",
      "Epoch: 124, Batch: 0, loss: 0.5023418549433465\n",
      "Epoch: 124, Batch: 100, loss: 0.32674677932976953\n",
      "Epoch: 124, Batch: 200, loss: 0.3433476791595563\n",
      "Epoch: 124, Batch: 300, loss: 0.34730176665785245\n",
      "Epoch: 124, Batch: 400, loss: 0.3683618316049756\n",
      "Epoch: 124, Batch: 500, loss: 0.36525055293391456\n",
      "Epoch: 125, Batch: 0, loss: 0.16954816692766014\n",
      "Epoch: 125, Batch: 100, loss: 0.30661553679268944\n",
      "Epoch: 125, Batch: 200, loss: 0.3280769237899001\n",
      "Epoch: 125, Batch: 300, loss: 0.3621440105302933\n",
      "Epoch: 125, Batch: 400, loss: 0.3619526877157737\n",
      "Epoch: 125, Batch: 500, loss: 0.36027603890435866\n",
      "Epoch: 126, Batch: 0, loss: 0.042813616223257245\n",
      "Epoch: 126, Batch: 100, loss: 0.4337100288496595\n",
      "Epoch: 126, Batch: 200, loss: 0.38098024738075104\n",
      "Epoch: 126, Batch: 300, loss: 0.34836566163867233\n",
      "Epoch: 126, Batch: 400, loss: 0.3649956812311863\n",
      "Epoch: 126, Batch: 500, loss: 0.3634426167489156\n",
      "Epoch: 127, Batch: 0, loss: 0.3853923428897907\n",
      "Epoch: 127, Batch: 100, loss: 0.34325862056791895\n",
      "Epoch: 127, Batch: 200, loss: 0.35843130557054814\n",
      "Epoch: 127, Batch: 300, loss: 0.3523064734830512\n",
      "Epoch: 127, Batch: 400, loss: 0.35612675157573737\n",
      "Epoch: 127, Batch: 500, loss: 0.3554156903681346\n",
      "Epoch: 128, Batch: 0, loss: 0.4361027255425814\n",
      "Epoch: 128, Batch: 100, loss: 0.3686746316741056\n",
      "Epoch: 128, Batch: 200, loss: 0.3729145385259582\n",
      "Epoch: 128, Batch: 300, loss: 0.3627595305674989\n",
      "Epoch: 128, Batch: 400, loss: 0.3926157467085586\n",
      "Epoch: 128, Batch: 500, loss: 0.4027791681085891\n",
      "Epoch: 129, Batch: 0, loss: 0.31457362691935226\n",
      "Epoch: 129, Batch: 100, loss: 0.3204043683570816\n",
      "Epoch: 129, Batch: 200, loss: 0.3387432724411734\n",
      "Epoch: 129, Batch: 300, loss: 0.3297877486386394\n",
      "Epoch: 129, Batch: 400, loss: 0.3283195330167335\n",
      "Epoch: 129, Batch: 500, loss: 0.3387552620654711\n",
      "Epoch: 130, Batch: 0, loss: 0.558265446976411\n",
      "Epoch: 130, Batch: 100, loss: 0.3194366770508902\n",
      "Epoch: 130, Batch: 200, loss: 0.29750992083331945\n",
      "Epoch: 130, Batch: 300, loss: 0.31660991016148554\n",
      "Epoch: 130, Batch: 400, loss: 0.3315776081096474\n",
      "Epoch: 130, Batch: 500, loss: 0.3288737739799261\n",
      "Epoch: 131, Batch: 0, loss: 0.08812855909920154\n",
      "Epoch: 131, Batch: 100, loss: 0.35671414753229813\n",
      "Epoch: 131, Batch: 200, loss: 0.329608424189374\n",
      "Epoch: 131, Batch: 300, loss: 0.32454934696802046\n",
      "Epoch: 131, Batch: 400, loss: 0.32580414961510573\n",
      "Epoch: 131, Batch: 500, loss: 0.32785846668673335\n",
      "Epoch: 132, Batch: 0, loss: 0.21298503342725697\n",
      "Epoch: 132, Batch: 100, loss: 0.4146929092534466\n",
      "Epoch: 132, Batch: 200, loss: 0.37735184390790316\n",
      "Epoch: 132, Batch: 300, loss: 0.36840925633306565\n",
      "Epoch: 132, Batch: 400, loss: 0.373409896085172\n",
      "Epoch: 132, Batch: 500, loss: 0.37693619240486476\n",
      "Epoch: 133, Batch: 0, loss: 0.14006971715831437\n",
      "Epoch: 133, Batch: 100, loss: 0.4209679768556021\n",
      "Epoch: 133, Batch: 200, loss: 0.4195891730069327\n",
      "Epoch: 133, Batch: 300, loss: 0.397681407064652\n",
      "Epoch: 133, Batch: 400, loss: 0.3891080103948532\n",
      "Epoch: 133, Batch: 500, loss: 0.3715579195939103\n",
      "Epoch: 134, Batch: 0, loss: 0.9611295958611574\n",
      "Epoch: 134, Batch: 100, loss: 0.34358285340815875\n",
      "Epoch: 134, Batch: 200, loss: 0.3553904565476753\n",
      "Epoch: 134, Batch: 300, loss: 0.3494860718863576\n",
      "Epoch: 134, Batch: 400, loss: 0.34945292487470375\n",
      "Epoch: 134, Batch: 500, loss: 0.35959112961397754\n",
      "Epoch: 135, Batch: 0, loss: 0.36978726188078254\n",
      "Epoch: 135, Batch: 100, loss: 0.33794011393512247\n",
      "Epoch: 135, Batch: 200, loss: 0.36052982486522417\n",
      "Epoch: 135, Batch: 300, loss: 0.35480718132766015\n",
      "Epoch: 135, Batch: 400, loss: 0.36240487533673826\n",
      "Epoch: 135, Batch: 500, loss: 0.35877395221363456\n",
      "Epoch: 136, Batch: 0, loss: 0.013120562041190963\n",
      "Epoch: 136, Batch: 100, loss: 0.30582065294445193\n",
      "Epoch: 136, Batch: 200, loss: 0.31195683141908215\n",
      "Epoch: 136, Batch: 300, loss: 0.33360246974430224\n",
      "Epoch: 136, Batch: 400, loss: 0.35160704549036526\n",
      "Epoch: 136, Batch: 500, loss: 0.3480413553519976\n",
      "Epoch: 137, Batch: 0, loss: 0.24739783467761473\n",
      "Epoch: 137, Batch: 100, loss: 0.318058437961079\n",
      "Epoch: 137, Batch: 200, loss: 0.30852618591925546\n",
      "Epoch: 137, Batch: 300, loss: 0.30986876863721735\n",
      "Epoch: 137, Batch: 400, loss: 0.3367885492892412\n",
      "Epoch: 137, Batch: 500, loss: 0.34618848923569845\n",
      "Epoch: 138, Batch: 0, loss: 6.409453233089671\n",
      "Epoch: 138, Batch: 100, loss: 0.42888305658650094\n",
      "Epoch: 138, Batch: 200, loss: 0.3948445961025739\n",
      "Epoch: 138, Batch: 300, loss: 0.370491743944222\n",
      "Epoch: 138, Batch: 400, loss: 0.38736121227319026\n",
      "Epoch: 138, Batch: 500, loss: 0.3807067267849522\n",
      "Epoch: 139, Batch: 0, loss: 0.5190022661004663\n",
      "Epoch: 139, Batch: 100, loss: 0.329948080443958\n",
      "Epoch: 139, Batch: 200, loss: 0.3376367355885678\n",
      "Epoch: 139, Batch: 300, loss: 0.35613962884597045\n",
      "Epoch: 139, Batch: 400, loss: 0.34214907772598296\n",
      "Epoch: 139, Batch: 500, loss: 0.3376169726735761\n",
      "Epoch: 140, Batch: 0, loss: 0.819247110725651\n",
      "Epoch: 140, Batch: 100, loss: 0.3088134520247041\n",
      "Epoch: 140, Batch: 200, loss: 0.3709769687483396\n",
      "Epoch: 140, Batch: 300, loss: 0.36376910726476624\n",
      "Epoch: 140, Batch: 400, loss: 0.37354904814201295\n",
      "Epoch: 140, Batch: 500, loss: 0.35536405188754133\n",
      "Epoch: 141, Batch: 0, loss: 0.34136330896921924\n",
      "Epoch: 141, Batch: 100, loss: 0.33925237176423423\n",
      "Epoch: 141, Batch: 200, loss: 0.32982146801217666\n",
      "Epoch: 141, Batch: 300, loss: 0.32418481241745056\n",
      "Epoch: 141, Batch: 400, loss: 0.3261100255813741\n",
      "Epoch: 141, Batch: 500, loss: 0.3482643720274077\n",
      "Epoch: 142, Batch: 0, loss: 0.6691253429769575\n",
      "Epoch: 142, Batch: 100, loss: 0.4853332840859605\n",
      "Epoch: 142, Batch: 200, loss: 0.3955626378209569\n",
      "Epoch: 142, Batch: 300, loss: 0.3813316909546518\n",
      "Epoch: 142, Batch: 400, loss: 0.3736703835998404\n",
      "Epoch: 142, Batch: 500, loss: 0.3655691435743272\n",
      "Epoch: 143, Batch: 0, loss: 0.039646613797011725\n",
      "Epoch: 143, Batch: 100, loss: 0.3022597411563415\n",
      "Epoch: 143, Batch: 200, loss: 0.32305292908417194\n",
      "Epoch: 143, Batch: 300, loss: 0.3221267993136531\n",
      "Epoch: 143, Batch: 400, loss: 0.35104296562367604\n",
      "Epoch: 143, Batch: 500, loss: 0.3581318404541645\n",
      "Epoch: 144, Batch: 0, loss: 0.11523899506408855\n",
      "Epoch: 144, Batch: 100, loss: 0.3433393742022106\n",
      "Epoch: 144, Batch: 200, loss: 0.32169211786336893\n",
      "Epoch: 144, Batch: 300, loss: 0.34159112600981717\n",
      "Epoch: 144, Batch: 400, loss: 0.334416555229479\n",
      "Epoch: 144, Batch: 500, loss: 0.3391657478338953\n",
      "Epoch: 145, Batch: 0, loss: 1.264180347173051\n",
      "Epoch: 145, Batch: 100, loss: 0.3334979442337058\n",
      "Epoch: 145, Batch: 200, loss: 0.34592922864570685\n",
      "Epoch: 145, Batch: 300, loss: 0.3415232303330932\n",
      "Epoch: 145, Batch: 400, loss: 0.3531250647691319\n",
      "Epoch: 145, Batch: 500, loss: 0.3404145086194059\n",
      "Epoch: 146, Batch: 0, loss: 1.1993587568417883\n",
      "Epoch: 146, Batch: 100, loss: 0.2489165309964716\n",
      "Epoch: 146, Batch: 200, loss: 0.3714161334733469\n",
      "Epoch: 146, Batch: 300, loss: 0.4030813674008875\n",
      "Epoch: 146, Batch: 400, loss: 0.3812592920056337\n",
      "Epoch: 146, Batch: 500, loss: 0.37130937638658307\n",
      "Epoch: 147, Batch: 0, loss: 0.49352828352452227\n",
      "Epoch: 147, Batch: 100, loss: 0.30786112595049525\n",
      "Epoch: 147, Batch: 200, loss: 0.30623971791687044\n",
      "Epoch: 147, Batch: 300, loss: 0.3385234950267476\n",
      "Epoch: 147, Batch: 400, loss: 0.35085065584533115\n",
      "Epoch: 147, Batch: 500, loss: 0.33743297563933367\n",
      "Epoch: 148, Batch: 0, loss: 0.2372451837304887\n",
      "Epoch: 148, Batch: 100, loss: 0.3460750162361926\n",
      "Epoch: 148, Batch: 200, loss: 0.3065422538084507\n",
      "Epoch: 148, Batch: 300, loss: 0.3466651872815952\n",
      "Epoch: 148, Batch: 400, loss: 0.35401944208439107\n",
      "Epoch: 148, Batch: 500, loss: 0.3442443235164595\n",
      "Epoch: 149, Batch: 0, loss: 0.23254033893298298\n",
      "Epoch: 149, Batch: 100, loss: 0.32546016279460227\n",
      "Epoch: 149, Batch: 200, loss: 0.30638161112710965\n",
      "Epoch: 149, Batch: 300, loss: 0.32451215819339246\n",
      "Epoch: 149, Batch: 400, loss: 0.335227854812001\n",
      "Epoch: 149, Batch: 500, loss: 0.3473832843839285\n",
      "Epoch: 150, Batch: 0, loss: 0.3950118038484179\n",
      "Epoch: 150, Batch: 100, loss: 0.39913000017448164\n",
      "Epoch: 150, Batch: 200, loss: 0.37859360924740937\n",
      "Epoch: 150, Batch: 300, loss: 0.3727831770628463\n",
      "Epoch: 150, Batch: 400, loss: 0.3985241394891593\n",
      "Epoch: 150, Batch: 500, loss: 0.3816513809694382\n",
      "Epoch: 151, Batch: 0, loss: 0.29959404522478617\n",
      "Epoch: 151, Batch: 100, loss: 0.2894179574590088\n",
      "Epoch: 151, Batch: 200, loss: 0.2996405636881863\n",
      "Epoch: 151, Batch: 300, loss: 0.31174834941821616\n",
      "Epoch: 151, Batch: 400, loss: 0.3457811400067302\n",
      "Epoch: 151, Batch: 500, loss: 0.34011699419205776\n",
      "Epoch: 152, Batch: 0, loss: 0.8875593972470427\n",
      "Epoch: 152, Batch: 100, loss: 0.5040787835021215\n",
      "Epoch: 152, Batch: 200, loss: 0.4004462876199851\n",
      "Epoch: 152, Batch: 300, loss: 0.37962755917264457\n",
      "Epoch: 152, Batch: 400, loss: 0.38529276844698007\n",
      "Epoch: 152, Batch: 500, loss: 0.37511953726089303\n",
      "Epoch: 153, Batch: 0, loss: 0.8716915867637417\n",
      "Epoch: 153, Batch: 100, loss: 0.3824538953562075\n",
      "Epoch: 153, Batch: 200, loss: 0.42403095952909564\n",
      "Epoch: 153, Batch: 300, loss: 0.4041425119271976\n",
      "Epoch: 153, Batch: 400, loss: 0.39629203915326\n",
      "Epoch: 153, Batch: 500, loss: 0.38215972337729726\n",
      "Epoch: 154, Batch: 0, loss: 0.6630943545789333\n",
      "Epoch: 154, Batch: 100, loss: 0.34599444968627174\n",
      "Epoch: 154, Batch: 200, loss: 0.34514518166005476\n",
      "Epoch: 154, Batch: 300, loss: 0.36044829998895167\n",
      "Epoch: 154, Batch: 400, loss: 0.3475138510175302\n",
      "Epoch: 154, Batch: 500, loss: 0.32604381653490444\n",
      "Epoch: 155, Batch: 0, loss: 0.12268439001736721\n",
      "Epoch: 155, Batch: 100, loss: 0.3166600893363281\n",
      "Epoch: 155, Batch: 200, loss: 0.3214115580451693\n",
      "Epoch: 155, Batch: 300, loss: 0.3326928029810259\n",
      "Epoch: 155, Batch: 400, loss: 0.33891547131436095\n",
      "Epoch: 155, Batch: 500, loss: 0.33600864667235575\n",
      "Epoch: 156, Batch: 0, loss: 0.1499630755336624\n",
      "Epoch: 156, Batch: 100, loss: 0.39385584556397935\n",
      "Epoch: 156, Batch: 200, loss: 0.368742353713519\n",
      "Epoch: 156, Batch: 300, loss: 0.3574186789518203\n",
      "Epoch: 156, Batch: 400, loss: 0.3659051595588813\n",
      "Epoch: 156, Batch: 500, loss: 0.3510608591760643\n",
      "Epoch: 157, Batch: 0, loss: 0.12384825666260356\n",
      "Epoch: 157, Batch: 100, loss: 0.5044685751236347\n",
      "Epoch: 157, Batch: 200, loss: 0.43082780611392685\n",
      "Epoch: 157, Batch: 300, loss: 0.3936614466154921\n",
      "Epoch: 157, Batch: 400, loss: 0.37834698288635477\n",
      "Epoch: 157, Batch: 500, loss: 0.3631057762589648\n",
      "Epoch: 158, Batch: 0, loss: 0.30040502555650245\n",
      "Epoch: 158, Batch: 100, loss: 0.48495160500554946\n",
      "Epoch: 158, Batch: 200, loss: 0.4652226654831537\n",
      "Epoch: 158, Batch: 300, loss: 0.4213406740461287\n",
      "Epoch: 158, Batch: 400, loss: 0.3986186808915395\n",
      "Epoch: 158, Batch: 500, loss: 0.3954352763306453\n",
      "Epoch: 159, Batch: 0, loss: 0.053345786326832186\n",
      "Epoch: 159, Batch: 100, loss: 0.3148538549120926\n",
      "Epoch: 159, Batch: 200, loss: 0.3218142987198305\n",
      "Epoch: 159, Batch: 300, loss: 0.3239704550286782\n",
      "Epoch: 159, Batch: 400, loss: 0.33891029246027904\n",
      "Epoch: 159, Batch: 500, loss: 0.3410572826792532\n",
      "Epoch: 160, Batch: 0, loss: 0.14201759980715767\n",
      "Epoch: 160, Batch: 100, loss: 0.5158109647973468\n",
      "Epoch: 160, Batch: 200, loss: 0.418263248902793\n",
      "Epoch: 160, Batch: 300, loss: 0.40334667131351865\n",
      "Epoch: 160, Batch: 400, loss: 0.3853315116820266\n",
      "Epoch: 160, Batch: 500, loss: 0.3714193699473731\n",
      "Epoch: 161, Batch: 0, loss: 0.9652911217001321\n",
      "Epoch: 161, Batch: 100, loss: 0.560431597199868\n",
      "Epoch: 161, Batch: 200, loss: 0.46888531361012714\n",
      "Epoch: 161, Batch: 300, loss: 0.4049391480051208\n",
      "Epoch: 161, Batch: 400, loss: 0.38637332887347403\n",
      "Epoch: 161, Batch: 500, loss: 0.38674227176103915\n",
      "Epoch: 162, Batch: 0, loss: 0.0011537877766251417\n",
      "Epoch: 162, Batch: 100, loss: 0.3191505632423149\n",
      "Epoch: 162, Batch: 200, loss: 0.3106117787235569\n",
      "Epoch: 162, Batch: 300, loss: 0.30757482326324703\n",
      "Epoch: 162, Batch: 400, loss: 0.30910323852103033\n",
      "Epoch: 162, Batch: 500, loss: 0.33767422328941477\n",
      "Epoch: 163, Batch: 0, loss: 0.5442504345795125\n",
      "Epoch: 163, Batch: 100, loss: 0.3981148277404783\n",
      "Epoch: 163, Batch: 200, loss: 0.3647941192757338\n",
      "Epoch: 163, Batch: 300, loss: 0.37339682311904204\n",
      "Epoch: 163, Batch: 400, loss: 0.35396635676443094\n",
      "Epoch: 163, Batch: 500, loss: 0.3504976673995269\n",
      "Epoch: 164, Batch: 0, loss: 0.5848219098677968\n",
      "Epoch: 164, Batch: 100, loss: 0.4012494010631465\n",
      "Epoch: 164, Batch: 200, loss: 0.39382745755921095\n",
      "Epoch: 164, Batch: 300, loss: 0.3572178068912551\n",
      "Epoch: 164, Batch: 400, loss: 0.34192653830092495\n",
      "Epoch: 164, Batch: 500, loss: 0.34651296864071884\n",
      "Epoch: 165, Batch: 0, loss: 0.07837463850209175\n",
      "Epoch: 165, Batch: 100, loss: 0.296617768988489\n",
      "Epoch: 165, Batch: 200, loss: 0.34326798738974656\n",
      "Epoch: 165, Batch: 300, loss: 0.3400453166035775\n",
      "Epoch: 165, Batch: 400, loss: 0.35443889504007897\n",
      "Epoch: 165, Batch: 500, loss: 0.3650094612184115\n",
      "Epoch: 166, Batch: 0, loss: 0.3340084952562109\n",
      "Epoch: 166, Batch: 100, loss: 0.42331166885295063\n",
      "Epoch: 166, Batch: 200, loss: 0.3609638529583288\n",
      "Epoch: 166, Batch: 300, loss: 0.3548946492144632\n",
      "Epoch: 166, Batch: 400, loss: 0.3768412115486671\n",
      "Epoch: 166, Batch: 500, loss: 0.36111703981949356\n",
      "Epoch: 167, Batch: 0, loss: 1.0457607362063517\n",
      "Epoch: 167, Batch: 100, loss: 0.3262180257403727\n",
      "Epoch: 167, Batch: 200, loss: 0.3465479366007241\n",
      "Epoch: 167, Batch: 300, loss: 0.3369296090431113\n",
      "Epoch: 167, Batch: 400, loss: 0.3376859744157061\n",
      "Epoch: 167, Batch: 500, loss: 0.33247194782251516\n",
      "Epoch: 168, Batch: 0, loss: 0.8821360661383055\n",
      "Epoch: 168, Batch: 100, loss: 0.36027669076560576\n",
      "Epoch: 168, Batch: 200, loss: 0.32576780846289227\n",
      "Epoch: 168, Batch: 300, loss: 0.32570343117481587\n",
      "Epoch: 168, Batch: 400, loss: 0.33215371125554544\n",
      "Epoch: 168, Batch: 500, loss: 0.3497453724929588\n",
      "Epoch: 169, Batch: 0, loss: 1.175856482982316\n",
      "Epoch: 169, Batch: 100, loss: 0.4009041420928953\n",
      "Epoch: 169, Batch: 200, loss: 0.36819690934043653\n",
      "Epoch: 169, Batch: 300, loss: 0.32970246075913207\n",
      "Epoch: 169, Batch: 400, loss: 0.323273808567222\n",
      "Epoch: 169, Batch: 500, loss: 0.35411331085866865\n",
      "Epoch: 170, Batch: 0, loss: 0.1976176939433646\n",
      "Epoch: 170, Batch: 100, loss: 0.3001424206362856\n",
      "Epoch: 170, Batch: 200, loss: 0.33837516779571236\n",
      "Epoch: 170, Batch: 300, loss: 0.33537251432972615\n",
      "Epoch: 170, Batch: 400, loss: 0.3321290722330617\n",
      "Epoch: 170, Batch: 500, loss: 0.3305971887887176\n",
      "Epoch: 171, Batch: 0, loss: 0.28048050525684576\n",
      "Epoch: 171, Batch: 100, loss: 0.3067633324009869\n",
      "Epoch: 171, Batch: 200, loss: 0.37459275981643225\n",
      "Epoch: 171, Batch: 300, loss: 0.36493248991300964\n",
      "Epoch: 171, Batch: 400, loss: 0.36002377006870934\n",
      "Epoch: 171, Batch: 500, loss: 0.3486889449148483\n",
      "Epoch: 172, Batch: 0, loss: 0.3759657191706105\n",
      "Epoch: 172, Batch: 100, loss: 0.3338729753061722\n",
      "Epoch: 172, Batch: 200, loss: 0.322179494642696\n",
      "Epoch: 172, Batch: 300, loss: 0.32308773573186655\n",
      "Epoch: 172, Batch: 400, loss: 0.3420729642527161\n",
      "Epoch: 172, Batch: 500, loss: 0.34879455909861407\n",
      "Epoch: 173, Batch: 0, loss: 0.05220928531202713\n",
      "Epoch: 173, Batch: 100, loss: 0.37507656359182984\n",
      "Epoch: 173, Batch: 200, loss: 0.3357531369829943\n",
      "Epoch: 173, Batch: 300, loss: 0.349841918449768\n",
      "Epoch: 173, Batch: 400, loss: 0.34974945855562667\n",
      "Epoch: 173, Batch: 500, loss: 0.3479600434822255\n",
      "Epoch: 174, Batch: 0, loss: 0.05937608778584138\n",
      "Epoch: 174, Batch: 100, loss: 0.21420446811619934\n",
      "Epoch: 174, Batch: 200, loss: 0.26415587706521926\n",
      "Epoch: 174, Batch: 300, loss: 0.27780296816775346\n",
      "Epoch: 174, Batch: 400, loss: 0.29166007207572303\n",
      "Epoch: 174, Batch: 500, loss: 0.2915627116592786\n",
      "Epoch: 175, Batch: 0, loss: 0.09537555534429258\n",
      "Epoch: 175, Batch: 100, loss: 0.2747226452584135\n",
      "Epoch: 175, Batch: 200, loss: 0.31881775902902354\n",
      "Epoch: 175, Batch: 300, loss: 0.3082756186617856\n",
      "Epoch: 175, Batch: 400, loss: 0.31974888077739355\n",
      "Epoch: 175, Batch: 500, loss: 0.3202043033396013\n",
      "Epoch: 176, Batch: 0, loss: 0.3931731155851775\n",
      "Epoch: 176, Batch: 100, loss: 0.27802185218648096\n",
      "Epoch: 176, Batch: 200, loss: 0.3040237216646542\n",
      "Epoch: 176, Batch: 300, loss: 0.32325995400543256\n",
      "Epoch: 176, Batch: 400, loss: 0.31626658668227636\n",
      "Epoch: 176, Batch: 500, loss: 0.3240010689234526\n",
      "Epoch: 177, Batch: 0, loss: 0.1681694901869653\n",
      "Epoch: 177, Batch: 100, loss: 0.27401483200730375\n",
      "Epoch: 177, Batch: 200, loss: 0.2812047609513597\n",
      "Epoch: 177, Batch: 300, loss: 0.28491489735572495\n",
      "Epoch: 177, Batch: 400, loss: 0.2985757729699562\n",
      "Epoch: 177, Batch: 500, loss: 0.31894237240967904\n",
      "Epoch: 178, Batch: 0, loss: 0.67994251045889\n",
      "Epoch: 178, Batch: 100, loss: 0.3648319285208008\n",
      "Epoch: 178, Batch: 200, loss: 0.3832333259327782\n",
      "Epoch: 178, Batch: 300, loss: 0.3494686154738698\n",
      "Epoch: 178, Batch: 400, loss: 0.33691775662529333\n",
      "Epoch: 178, Batch: 500, loss: 0.3299606861121449\n",
      "Epoch: 179, Batch: 0, loss: 0.8540889646921704\n",
      "Epoch: 179, Batch: 100, loss: 0.3776907724936952\n",
      "Epoch: 179, Batch: 200, loss: 0.36420151408972995\n",
      "Epoch: 179, Batch: 300, loss: 0.3816902338688119\n",
      "Epoch: 179, Batch: 400, loss: 0.38505870535454406\n",
      "Epoch: 179, Batch: 500, loss: 0.3862680482512379\n",
      "Epoch: 180, Batch: 0, loss: 0.008422943666952386\n",
      "Epoch: 180, Batch: 100, loss: 0.40745631635357354\n",
      "Epoch: 180, Batch: 200, loss: 0.36815304390186476\n",
      "Epoch: 180, Batch: 300, loss: 0.39736831559657654\n",
      "Epoch: 180, Batch: 400, loss: 0.3971568493882251\n",
      "Epoch: 180, Batch: 500, loss: 0.3932265608284405\n",
      "Epoch: 181, Batch: 0, loss: 0.625862544348752\n",
      "Epoch: 181, Batch: 100, loss: 0.40001627606597673\n",
      "Epoch: 181, Batch: 200, loss: 0.36453452789833896\n",
      "Epoch: 181, Batch: 300, loss: 0.34982720259255723\n",
      "Epoch: 181, Batch: 400, loss: 0.33455187492048144\n",
      "Epoch: 181, Batch: 500, loss: 0.32512689717280285\n",
      "Epoch: 182, Batch: 0, loss: 0.006930677239841727\n",
      "Epoch: 182, Batch: 100, loss: 0.368645050018709\n",
      "Epoch: 182, Batch: 200, loss: 0.3806725152571062\n",
      "Epoch: 182, Batch: 300, loss: 0.38197066604139307\n",
      "Epoch: 182, Batch: 400, loss: 0.3543423094741437\n",
      "Epoch: 182, Batch: 500, loss: 0.351101779140937\n",
      "Epoch: 183, Batch: 0, loss: 0.5055528525235387\n",
      "Epoch: 183, Batch: 100, loss: 0.3766919455682088\n",
      "Epoch: 183, Batch: 200, loss: 0.34291088134845815\n",
      "Epoch: 183, Batch: 300, loss: 0.30727268130956836\n",
      "Epoch: 183, Batch: 400, loss: 0.30353595658510085\n",
      "Epoch: 183, Batch: 500, loss: 0.3095906503586397\n",
      "Epoch: 184, Batch: 0, loss: 0.5430875104209061\n",
      "Epoch: 184, Batch: 100, loss: 0.26453233457680664\n",
      "Epoch: 184, Batch: 200, loss: 0.2874717443710633\n",
      "Epoch: 184, Batch: 300, loss: 0.32855847044709\n",
      "Epoch: 184, Batch: 400, loss: 0.3281526018766117\n",
      "Epoch: 184, Batch: 500, loss: 0.325296717373505\n",
      "Epoch: 185, Batch: 0, loss: 0.45136413250397805\n",
      "Epoch: 185, Batch: 100, loss: 0.29809829151728023\n",
      "Epoch: 185, Batch: 200, loss: 0.3378322081644121\n",
      "Epoch: 185, Batch: 300, loss: 0.3546469518991427\n",
      "Epoch: 185, Batch: 400, loss: 0.39386975874922425\n",
      "Epoch: 185, Batch: 500, loss: 0.3872695341792904\n",
      "Epoch: 186, Batch: 0, loss: 0.389114474516975\n",
      "Epoch: 186, Batch: 100, loss: 0.24705723678526917\n",
      "Epoch: 186, Batch: 200, loss: 0.340184031828092\n",
      "Epoch: 186, Batch: 300, loss: 0.35206197946476664\n",
      "Epoch: 186, Batch: 400, loss: 0.347749339542125\n",
      "Epoch: 186, Batch: 500, loss: 0.33517447535115685\n",
      "Epoch: 187, Batch: 0, loss: 1.0185417684992504\n",
      "Epoch: 187, Batch: 100, loss: 0.33400262432610517\n",
      "Epoch: 187, Batch: 200, loss: 0.31823637637977414\n",
      "Epoch: 187, Batch: 300, loss: 0.3412892472617829\n",
      "Epoch: 187, Batch: 400, loss: 0.349776488930199\n",
      "Epoch: 187, Batch: 500, loss: 0.34747262612964475\n",
      "Epoch: 188, Batch: 0, loss: 0.14657640904609875\n",
      "Epoch: 188, Batch: 100, loss: 0.34939917721041214\n",
      "Epoch: 188, Batch: 200, loss: 0.36104434871911756\n",
      "Epoch: 188, Batch: 300, loss: 0.35547115709021193\n",
      "Epoch: 188, Batch: 400, loss: 0.3613179591846543\n",
      "Epoch: 188, Batch: 500, loss: 0.3822923663795782\n",
      "Epoch: 189, Batch: 0, loss: 0.0634907757328713\n",
      "Epoch: 189, Batch: 100, loss: 0.36241274732504836\n",
      "Epoch: 189, Batch: 200, loss: 0.35460940429093696\n",
      "Epoch: 189, Batch: 300, loss: 0.32480842518933223\n",
      "Epoch: 189, Batch: 400, loss: 0.34841830436925286\n",
      "Epoch: 189, Batch: 500, loss: 0.3595314800654613\n",
      "Epoch: 190, Batch: 0, loss: 0.0006752815217992897\n",
      "Epoch: 190, Batch: 100, loss: 0.34389427256191146\n",
      "Epoch: 190, Batch: 200, loss: 0.3255978063514628\n",
      "Epoch: 190, Batch: 300, loss: 0.34435010794167736\n",
      "Epoch: 190, Batch: 400, loss: 0.3335462113598869\n",
      "Epoch: 190, Batch: 500, loss: 0.3455435291563088\n",
      "Epoch: 191, Batch: 0, loss: 0.002468516029849062\n",
      "Epoch: 191, Batch: 100, loss: 0.4742195771960771\n",
      "Epoch: 191, Batch: 200, loss: 0.383241282126997\n",
      "Epoch: 191, Batch: 300, loss: 0.37284280670654035\n",
      "Epoch: 191, Batch: 400, loss: 0.39775700795432845\n",
      "Epoch: 191, Batch: 500, loss: 0.3882588830351665\n",
      "Epoch: 192, Batch: 0, loss: 0.22757015429089805\n",
      "Epoch: 192, Batch: 100, loss: 0.3771536251829288\n",
      "Epoch: 192, Batch: 200, loss: 0.35679694520105865\n",
      "Epoch: 192, Batch: 300, loss: 0.35102855930782245\n",
      "Epoch: 192, Batch: 400, loss: 0.3555738863649108\n",
      "Epoch: 192, Batch: 500, loss: 0.3567779038531577\n",
      "Epoch: 193, Batch: 0, loss: 0.7662730123817557\n",
      "Epoch: 193, Batch: 100, loss: 0.29761507135120807\n",
      "Epoch: 193, Batch: 200, loss: 0.3549314913225534\n",
      "Epoch: 193, Batch: 300, loss: 0.3548543518702587\n",
      "Epoch: 193, Batch: 400, loss: 0.3504843551049716\n",
      "Epoch: 193, Batch: 500, loss: 0.3564936999015963\n",
      "Epoch: 194, Batch: 0, loss: 0.0016701983675219759\n",
      "Epoch: 194, Batch: 100, loss: 0.447389923394796\n",
      "Epoch: 194, Batch: 200, loss: 0.38075100815636664\n",
      "Epoch: 194, Batch: 300, loss: 0.3671395529926689\n",
      "Epoch: 194, Batch: 400, loss: 0.347423092209277\n",
      "Epoch: 194, Batch: 500, loss: 0.3438128930678195\n",
      "Epoch: 195, Batch: 0, loss: 0.3369168042125806\n",
      "Epoch: 195, Batch: 100, loss: 0.42330071164719696\n",
      "Epoch: 195, Batch: 200, loss: 0.3985223360763419\n",
      "Epoch: 195, Batch: 300, loss: 0.3751787896422855\n",
      "Epoch: 195, Batch: 400, loss: 0.37214895184950797\n",
      "Epoch: 195, Batch: 500, loss: 0.36179113014226116\n",
      "Epoch: 196, Batch: 0, loss: 0.39040483319761643\n",
      "Epoch: 196, Batch: 100, loss: 0.36198789065935855\n",
      "Epoch: 196, Batch: 200, loss: 0.38034692459935227\n",
      "Epoch: 196, Batch: 300, loss: 0.3544763273972303\n",
      "Epoch: 196, Batch: 400, loss: 0.3710819399186013\n",
      "Epoch: 196, Batch: 500, loss: 0.36031239385228664\n",
      "Epoch: 197, Batch: 0, loss: 0.06252701929548259\n",
      "Epoch: 197, Batch: 100, loss: 0.336225261742287\n",
      "Epoch: 197, Batch: 200, loss: 0.3313942478803538\n",
      "Epoch: 197, Batch: 300, loss: 0.3131619704126346\n",
      "Epoch: 197, Batch: 400, loss: 0.3385606316110511\n",
      "Epoch: 197, Batch: 500, loss: 0.3430097169479651\n",
      "Epoch: 198, Batch: 0, loss: 0.24552674620449647\n",
      "Epoch: 198, Batch: 100, loss: 0.3495702914257274\n",
      "Epoch: 198, Batch: 200, loss: 0.3355727083186441\n",
      "Epoch: 198, Batch: 300, loss: 0.35267439551643115\n",
      "Epoch: 198, Batch: 400, loss: 0.37022430243759946\n",
      "Epoch: 198, Batch: 500, loss: 0.3698948861333298\n",
      "Epoch: 199, Batch: 0, loss: 0.5168614627777959\n",
      "Epoch: 199, Batch: 100, loss: 0.2816586168006586\n",
      "Epoch: 199, Batch: 200, loss: 0.3073753920754954\n",
      "Epoch: 199, Batch: 300, loss: 0.3157487139673819\n",
      "Epoch: 199, Batch: 400, loss: 0.32677562346918243\n",
      "Epoch: 199, Batch: 500, loss: 0.3295978466874961\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "predicated = [model(np.array([x1, x2]), w, b) for x1, x2 in zip(rm, lst)]\n",
    "true = expensive"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def accuracy(y, yhat):\n",
    "    return sum(1 if i == j else 0 for i, j in zip(y, yhat)) / len(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(accuracy(true, predicated))\n",
    "\n",
    "# decision boundary"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "实现了回归，其中包括线性函数的定义，为什么要用线性函数，loss的意义，梯度下降的意义，stochastic gradient descent\n",
    "Use Boston house price dataset.\n",
    "北京2020年房价的数据集，为什么我没有用北京房价的数据集呢？\n",
    "Boston: room size, subway, highway, crime rate 有一个比较明显的关系，所以就观察关系比较容易\n",
    "北京的房价：！远近，！房况 ==》 学区！！！！ => 非常贵 海淀区"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dataset = load_boston()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# print(dataframe.corr()) # show the correlation of dataframe variables\n",
    "# correlation => 如果一个值的增大，会引起另外一个值一定增大，而且是定比例增大 相关系数就越接近于1\n",
    "# correlation => 0 就是两者之间没有任何关系\n",
    "# correlation => -1 一个值增大 另外一个值一定减小 而且减小是成相等比例的\n",
    "\n",
    "# sns.heatmap(dataframe.corr())\n",
    "# plt.show()\n",
    "\n",
    "# RM：小区平均的卧室个数\n",
    "# LSTAT: 低收入人群在周围的比例\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def linear(x, w, b):\n",
    "    # vectorized model\n",
    "    return np.dot(x, w.T) + b\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    # numpy broadcast numpy广播方法\n",
    "    return np.mean( (yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([2 * np.mean((yhat - y) * x[0]), 2 * np.mean((yhat - y) * x[1])])\n",
    "\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return 2 * np.mean((yhat - y))\n",
    "\n",
    "\n",
    "def optimize(w, b, x, y, yhat, pw, pb, learning_rate):\n",
    "    w = w + -1 * pw(x, y, yhat) * learning_rate\n",
    "    b = b + -1 * pb(x, y, yhat) * learning_rate\n",
    "\n",
    "    return w, b"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "\n",
    "    w = np.random.random_sample((1, 2)) # w normal\n",
    "    b = np.random.random() # 0 深度学习的时候会和大家详细解释\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            # batch training\n",
    "            index = random.choice(range(len(rm)))\n",
    "            rm_x, lstat_x = rm[index], lstat[index]\n",
    "            x = np.array([rm_x, lstat_x])\n",
    "            y = target[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "\n",
    "            w, b = optimize(w, b, x, y, yhat, pw, pb, learning_rate)\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch: {} Batch: {}, loss: {}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "\n",
    "    return model_to_be_train, w, b, losses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    target = dataframe['price']\n",
    "\n",
    "    model, w, b, losses = train(linear, target, loss, partial_w, partial_b)\n",
    "    plt.plot(losses)\n",
    "    predicate = model(np.array([19, 7]), w, b)\n",
    "    print(predicate)\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Batch: 0, loss: 15.217773984289908\n",
      "Epoch: 0 Batch: 100, loss: 423.39907672323375\n",
      "Epoch: 0 Batch: 200, loss: 49.28852704246203\n",
      "Epoch: 0 Batch: 300, loss: 102.63376580841799\n",
      "Epoch: 0 Batch: 400, loss: 0.17425008764267713\n",
      "Epoch: 0 Batch: 500, loss: 4.64099955397965\n",
      "Epoch: 1 Batch: 0, loss: 299.0760381747491\n",
      "Epoch: 1 Batch: 100, loss: 9.024342964530318\n",
      "Epoch: 1 Batch: 200, loss: 48.25128381427064\n",
      "Epoch: 1 Batch: 300, loss: 55.053060910925865\n",
      "Epoch: 1 Batch: 400, loss: 104.72282947772126\n",
      "Epoch: 1 Batch: 500, loss: 0.04210199560346581\n",
      "Epoch: 2 Batch: 0, loss: 19.09019942544631\n",
      "Epoch: 2 Batch: 100, loss: 67.2662172684278\n",
      "Epoch: 2 Batch: 200, loss: 312.97798784326227\n",
      "Epoch: 2 Batch: 300, loss: 155.2722922281679\n",
      "Epoch: 2 Batch: 400, loss: 58.468407514384864\n",
      "Epoch: 2 Batch: 500, loss: 959.9552116675985\n",
      "Epoch: 3 Batch: 0, loss: 1503.562962644161\n",
      "Epoch: 3 Batch: 100, loss: 0.9838898907525981\n",
      "Epoch: 3 Batch: 200, loss: 127.99396510004044\n",
      "Epoch: 3 Batch: 300, loss: 178.6489414918126\n",
      "Epoch: 3 Batch: 400, loss: 267.5575494314487\n",
      "Epoch: 3 Batch: 500, loss: 17.968066344504443\n",
      "Epoch: 4 Batch: 0, loss: 307.3515792698091\n",
      "Epoch: 4 Batch: 100, loss: 134.73042876763117\n",
      "Epoch: 4 Batch: 200, loss: 83.41350355335834\n",
      "Epoch: 4 Batch: 300, loss: 31.690010184497808\n",
      "Epoch: 4 Batch: 400, loss: 34.6259447390854\n",
      "Epoch: 4 Batch: 500, loss: 0.20521928281143292\n",
      "Epoch: 5 Batch: 0, loss: 59.111823985582895\n",
      "Epoch: 5 Batch: 100, loss: 0.7661059315655164\n",
      "Epoch: 5 Batch: 200, loss: 1.1869018959068762\n",
      "Epoch: 5 Batch: 300, loss: 203.15428063766961\n",
      "Epoch: 5 Batch: 400, loss: 16.284420028695873\n",
      "Epoch: 5 Batch: 500, loss: 38.85472569460325\n",
      "Epoch: 6 Batch: 0, loss: 21.727830948989194\n",
      "Epoch: 6 Batch: 100, loss: 299.89151085858725\n",
      "Epoch: 6 Batch: 200, loss: 20.913734205918544\n",
      "Epoch: 6 Batch: 300, loss: 27.152750792315484\n",
      "Epoch: 6 Batch: 400, loss: 80.5571426556117\n",
      "Epoch: 6 Batch: 500, loss: 3.0725651822902225\n",
      "Epoch: 7 Batch: 0, loss: 0.38118487921511024\n",
      "Epoch: 7 Batch: 100, loss: 102.34811971079688\n",
      "Epoch: 7 Batch: 200, loss: 160.32054923011006\n",
      "Epoch: 7 Batch: 300, loss: 2.416128713703467\n",
      "Epoch: 7 Batch: 400, loss: 127.90356146268259\n",
      "Epoch: 7 Batch: 500, loss: 9.283831227624084\n",
      "Epoch: 8 Batch: 0, loss: 9.339375540163998\n",
      "Epoch: 8 Batch: 100, loss: 6.338507653441427\n",
      "Epoch: 8 Batch: 200, loss: 6.635270362832542\n",
      "Epoch: 8 Batch: 300, loss: 15.954809337352438\n",
      "Epoch: 8 Batch: 400, loss: 9.578153240811162\n",
      "Epoch: 8 Batch: 500, loss: 106.42699087609688\n",
      "Epoch: 9 Batch: 0, loss: 462.52404420949193\n",
      "Epoch: 9 Batch: 100, loss: 2.340271919048502\n",
      "Epoch: 9 Batch: 200, loss: 5.992350498484808\n",
      "Epoch: 9 Batch: 300, loss: 0.06119606973771477\n",
      "Epoch: 9 Batch: 400, loss: 4.638349928009206\n",
      "Epoch: 9 Batch: 500, loss: 2.56937475269061\n",
      "Epoch: 10 Batch: 0, loss: 2.1120406564266645\n",
      "Epoch: 10 Batch: 100, loss: 512.6912821438292\n",
      "Epoch: 10 Batch: 200, loss: 0.018959926261297316\n",
      "Epoch: 10 Batch: 300, loss: 248.32898954453267\n",
      "Epoch: 10 Batch: 400, loss: 2.5276629679410725\n",
      "Epoch: 10 Batch: 500, loss: 13.393182361561626\n",
      "Epoch: 11 Batch: 0, loss: 2.145742683425559\n",
      "Epoch: 11 Batch: 100, loss: 250.5268727090906\n",
      "Epoch: 11 Batch: 200, loss: 3.261339753385001\n",
      "Epoch: 11 Batch: 300, loss: 2.7477692937834313\n",
      "Epoch: 11 Batch: 400, loss: 0.008841629880849735\n",
      "Epoch: 11 Batch: 500, loss: 2.165587041540959\n",
      "Epoch: 12 Batch: 0, loss: 16.155420158628655\n",
      "Epoch: 12 Batch: 100, loss: 2.0964930640672255\n",
      "Epoch: 12 Batch: 200, loss: 74.92674166380903\n",
      "Epoch: 12 Batch: 300, loss: 7.56252735229638\n",
      "Epoch: 12 Batch: 400, loss: 321.08746182111605\n",
      "Epoch: 12 Batch: 500, loss: 0.6553571910554052\n",
      "Epoch: 13 Batch: 0, loss: 5.396292003075804\n",
      "Epoch: 13 Batch: 100, loss: 369.22045473619943\n",
      "Epoch: 13 Batch: 200, loss: 3.2816321582254115\n",
      "Epoch: 13 Batch: 300, loss: 18.470885510387465\n",
      "Epoch: 13 Batch: 400, loss: 285.44764382692154\n",
      "Epoch: 13 Batch: 500, loss: 14.168486117346069\n",
      "Epoch: 14 Batch: 0, loss: 36.139665910029294\n",
      "Epoch: 14 Batch: 100, loss: 69.6135775538662\n",
      "Epoch: 14 Batch: 200, loss: 6.456160941438594\n",
      "Epoch: 14 Batch: 300, loss: 94.11822744322923\n",
      "Epoch: 14 Batch: 400, loss: 0.10343388538847968\n",
      "Epoch: 14 Batch: 500, loss: 0.6733117696208477\n",
      "Epoch: 15 Batch: 0, loss: 84.02420908290792\n",
      "Epoch: 15 Batch: 100, loss: 0.0012773695892247233\n",
      "Epoch: 15 Batch: 200, loss: 0.8548142077779979\n",
      "Epoch: 15 Batch: 300, loss: 67.72053485703769\n",
      "Epoch: 15 Batch: 400, loss: 0.33853741519022745\n",
      "Epoch: 15 Batch: 500, loss: 38.80156691842469\n",
      "Epoch: 16 Batch: 0, loss: 153.89130321063473\n",
      "Epoch: 16 Batch: 100, loss: 0.9863291590470674\n",
      "Epoch: 16 Batch: 200, loss: 1.9150753621022614\n",
      "Epoch: 16 Batch: 300, loss: 11.466531890062065\n",
      "Epoch: 16 Batch: 400, loss: 2.9600772732999037\n",
      "Epoch: 16 Batch: 500, loss: 1.8293949227307307\n",
      "Epoch: 17 Batch: 0, loss: 7.2883943181181134\n",
      "Epoch: 17 Batch: 100, loss: 4.66737937582789\n",
      "Epoch: 17 Batch: 200, loss: 5.786264045943619\n",
      "Epoch: 17 Batch: 300, loss: 28.67847966909807\n",
      "Epoch: 17 Batch: 400, loss: 0.529713200820047\n",
      "Epoch: 17 Batch: 500, loss: 3.359297489271931\n",
      "Epoch: 18 Batch: 0, loss: 1.4673033629593928\n",
      "Epoch: 18 Batch: 100, loss: 27.499011583506846\n",
      "Epoch: 18 Batch: 200, loss: 16.503658348369193\n",
      "Epoch: 18 Batch: 300, loss: 0.06221210153185676\n",
      "Epoch: 18 Batch: 400, loss: 0.4407157726110331\n",
      "Epoch: 18 Batch: 500, loss: 0.05582998247955065\n",
      "Epoch: 19 Batch: 0, loss: 8.764736952307993\n",
      "Epoch: 19 Batch: 100, loss: 1.006705373324886\n",
      "Epoch: 19 Batch: 200, loss: 50.90221817110569\n",
      "Epoch: 19 Batch: 300, loss: 2.6822000897535627\n",
      "Epoch: 19 Batch: 400, loss: 34.35158911677351\n",
      "Epoch: 19 Batch: 500, loss: 1.3400494150232058\n",
      "Epoch: 20 Batch: 0, loss: 44.180596119296894\n",
      "Epoch: 20 Batch: 100, loss: 0.00046393787122426877\n",
      "Epoch: 20 Batch: 200, loss: 1.6966943810229942\n",
      "Epoch: 20 Batch: 300, loss: 2.3184603444950707\n",
      "Epoch: 20 Batch: 400, loss: 1.2811852831341817\n",
      "Epoch: 20 Batch: 500, loss: 23.349245149975527\n",
      "Epoch: 21 Batch: 0, loss: 8.06187398946694\n",
      "Epoch: 21 Batch: 100, loss: 7.373581031191665\n",
      "Epoch: 21 Batch: 200, loss: 119.95828787857586\n",
      "Epoch: 21 Batch: 300, loss: 33.233839784918\n",
      "Epoch: 21 Batch: 400, loss: 5.83243347413492\n",
      "Epoch: 21 Batch: 500, loss: 32.425493774539405\n",
      "Epoch: 22 Batch: 0, loss: 1.904524054506118\n",
      "Epoch: 22 Batch: 100, loss: 7.138360996072644\n",
      "Epoch: 22 Batch: 200, loss: 34.127684173924145\n",
      "Epoch: 22 Batch: 300, loss: 0.7613638989036162\n",
      "Epoch: 22 Batch: 400, loss: 1.7147894992188009\n",
      "Epoch: 22 Batch: 500, loss: 16.444534919454533\n",
      "Epoch: 23 Batch: 0, loss: 211.60060266286163\n",
      "Epoch: 23 Batch: 100, loss: 8.259187133709888\n",
      "Epoch: 23 Batch: 200, loss: 38.04330374215105\n",
      "Epoch: 23 Batch: 300, loss: 9.020218632241244\n",
      "Epoch: 23 Batch: 400, loss: 0.10447455877830861\n",
      "Epoch: 23 Batch: 500, loss: 12.223809899361733\n",
      "Epoch: 24 Batch: 0, loss: 3.731643436843722\n",
      "Epoch: 24 Batch: 100, loss: 0.6260186689300505\n",
      "Epoch: 24 Batch: 200, loss: 2.621553586343539\n",
      "Epoch: 24 Batch: 300, loss: 41.27575651993181\n",
      "Epoch: 24 Batch: 400, loss: 22.95138342139661\n",
      "Epoch: 24 Batch: 500, loss: 32.284082458707815\n",
      "Epoch: 25 Batch: 0, loss: 15.747037749730076\n",
      "Epoch: 25 Batch: 100, loss: 11.289419672830823\n",
      "Epoch: 25 Batch: 200, loss: 1.2765039529796123\n",
      "Epoch: 25 Batch: 300, loss: 5.183495864631729\n",
      "Epoch: 25 Batch: 400, loss: 43.42060136529613\n",
      "Epoch: 25 Batch: 500, loss: 4.561302138037633\n",
      "Epoch: 26 Batch: 0, loss: 4.820507267892066\n",
      "Epoch: 26 Batch: 100, loss: 28.630829748203244\n",
      "Epoch: 26 Batch: 200, loss: 2.7978150435059423\n",
      "Epoch: 26 Batch: 300, loss: 8.86001174230407\n",
      "Epoch: 26 Batch: 400, loss: 0.061246997114544566\n",
      "Epoch: 26 Batch: 500, loss: 0.6509753647116995\n",
      "Epoch: 27 Batch: 0, loss: 0.024178343010775642\n",
      "Epoch: 27 Batch: 100, loss: 7.045094675706444\n",
      "Epoch: 27 Batch: 200, loss: 1.2741211877483878\n",
      "Epoch: 27 Batch: 300, loss: 6.910104378709721\n",
      "Epoch: 27 Batch: 400, loss: 1.6964084921979714\n",
      "Epoch: 27 Batch: 500, loss: 9.598682983944952\n",
      "Epoch: 28 Batch: 0, loss: 40.694798835635524\n",
      "Epoch: 28 Batch: 100, loss: 27.137124625711476\n",
      "Epoch: 28 Batch: 200, loss: 0.6341263629268398\n",
      "Epoch: 28 Batch: 300, loss: 2.0566390302388093\n",
      "Epoch: 28 Batch: 400, loss: 10.85275839792176\n",
      "Epoch: 28 Batch: 500, loss: 0.19720115016208997\n",
      "Epoch: 29 Batch: 0, loss: 0.7398425168307177\n",
      "Epoch: 29 Batch: 100, loss: 100.16772879288487\n",
      "Epoch: 29 Batch: 200, loss: 3.2174470937328996\n",
      "Epoch: 29 Batch: 300, loss: 0.17765199733602574\n",
      "Epoch: 29 Batch: 400, loss: 101.03066295733528\n",
      "Epoch: 29 Batch: 500, loss: 23.24203261075202\n",
      "Epoch: 30 Batch: 0, loss: 15.744499403079391\n",
      "Epoch: 30 Batch: 100, loss: 40.42453929158833\n",
      "Epoch: 30 Batch: 200, loss: 0.3383352799623238\n",
      "Epoch: 30 Batch: 300, loss: 0.16390594555194643\n",
      "Epoch: 30 Batch: 400, loss: 3.7358784980968833\n",
      "Epoch: 30 Batch: 500, loss: 3.2105162795033784\n",
      "Epoch: 31 Batch: 0, loss: 1.5459717732781482\n",
      "Epoch: 31 Batch: 100, loss: 8.369760581235372\n",
      "Epoch: 31 Batch: 200, loss: 3.8522108756516973\n",
      "Epoch: 31 Batch: 300, loss: 0.7526585760803659\n",
      "Epoch: 31 Batch: 400, loss: 5.755247415978887\n",
      "Epoch: 31 Batch: 500, loss: 0.4297219888855317\n",
      "Epoch: 32 Batch: 0, loss: 1.1531943071207367\n",
      "Epoch: 32 Batch: 100, loss: 145.13164031359375\n",
      "Epoch: 32 Batch: 200, loss: 314.0154822139644\n",
      "Epoch: 32 Batch: 300, loss: 29.143155283614828\n",
      "Epoch: 32 Batch: 400, loss: 1.655770040893113\n",
      "Epoch: 32 Batch: 500, loss: 3.9550240817771027\n",
      "Epoch: 33 Batch: 0, loss: 0.30396515859529905\n",
      "Epoch: 33 Batch: 100, loss: 1.6086666340267375\n",
      "Epoch: 33 Batch: 200, loss: 12.368473678117804\n",
      "Epoch: 33 Batch: 300, loss: 38.435446928459996\n",
      "Epoch: 33 Batch: 400, loss: 41.856486859740016\n",
      "Epoch: 33 Batch: 500, loss: 2.6759958385209592\n",
      "Epoch: 34 Batch: 0, loss: 2.8626292998490843\n",
      "Epoch: 34 Batch: 100, loss: 63.611126799650265\n",
      "Epoch: 34 Batch: 200, loss: 8.532402590644828\n",
      "Epoch: 34 Batch: 300, loss: 9.649620467740093\n",
      "Epoch: 34 Batch: 400, loss: 20.07428075971142\n",
      "Epoch: 34 Batch: 500, loss: 1.9612483127550746\n",
      "Epoch: 35 Batch: 0, loss: 48.81581478002763\n",
      "Epoch: 35 Batch: 100, loss: 10.61930112926138\n",
      "Epoch: 35 Batch: 200, loss: 0.020897703351563306\n",
      "Epoch: 35 Batch: 300, loss: 0.0014978816458750001\n",
      "Epoch: 35 Batch: 400, loss: 34.83771897656481\n",
      "Epoch: 35 Batch: 500, loss: 24.868249932294432\n",
      "Epoch: 36 Batch: 0, loss: 0.05322327860823541\n",
      "Epoch: 36 Batch: 100, loss: 12.846146452118296\n",
      "Epoch: 36 Batch: 200, loss: 17.619649821387735\n",
      "Epoch: 36 Batch: 300, loss: 10.525066448673902\n",
      "Epoch: 36 Batch: 400, loss: 12.095271818082857\n",
      "Epoch: 36 Batch: 500, loss: 131.9159649234287\n",
      "Epoch: 37 Batch: 0, loss: 10.299815552361618\n",
      "Epoch: 37 Batch: 100, loss: 2.34419782441277\n",
      "Epoch: 37 Batch: 200, loss: 37.99665309077295\n",
      "Epoch: 37 Batch: 300, loss: 30.30101872732426\n",
      "Epoch: 37 Batch: 400, loss: 2.25639310468923\n",
      "Epoch: 37 Batch: 500, loss: 214.4492189127867\n",
      "Epoch: 38 Batch: 0, loss: 10.22529163740131\n",
      "Epoch: 38 Batch: 100, loss: 48.28102062139404\n",
      "Epoch: 38 Batch: 200, loss: 2.2939826863738713\n",
      "Epoch: 38 Batch: 300, loss: 3.896167383992127\n",
      "Epoch: 38 Batch: 400, loss: 1.083841025589473\n",
      "Epoch: 38 Batch: 500, loss: 9.617190085106257\n",
      "Epoch: 39 Batch: 0, loss: 120.07718547867844\n",
      "Epoch: 39 Batch: 100, loss: 98.3699783301539\n",
      "Epoch: 39 Batch: 200, loss: 31.19597601559632\n",
      "Epoch: 39 Batch: 300, loss: 0.5836668278300952\n",
      "Epoch: 39 Batch: 400, loss: 12.960734176361678\n",
      "Epoch: 39 Batch: 500, loss: 2.3191158134474494\n",
      "Epoch: 40 Batch: 0, loss: 18.386771117469284\n",
      "Epoch: 40 Batch: 100, loss: 1.1753282616566791\n",
      "Epoch: 40 Batch: 200, loss: 28.608616712889734\n",
      "Epoch: 40 Batch: 300, loss: 47.30686653575805\n",
      "Epoch: 40 Batch: 400, loss: 46.39361520447917\n",
      "Epoch: 40 Batch: 500, loss: 2.593268064199087\n",
      "Epoch: 41 Batch: 0, loss: 14.998752820411575\n",
      "Epoch: 41 Batch: 100, loss: 1.257695366731527\n",
      "Epoch: 41 Batch: 200, loss: 0.42813497601104183\n",
      "Epoch: 41 Batch: 300, loss: 39.898627348675205\n",
      "Epoch: 41 Batch: 400, loss: 0.20885044974207312\n",
      "Epoch: 41 Batch: 500, loss: 7.941764145537604\n",
      "Epoch: 42 Batch: 0, loss: 2.301255591577288\n",
      "Epoch: 42 Batch: 100, loss: 11.679828888818948\n",
      "Epoch: 42 Batch: 200, loss: 0.9016630785678943\n",
      "Epoch: 42 Batch: 300, loss: 25.368394695468506\n",
      "Epoch: 42 Batch: 400, loss: 4.206610318453228\n",
      "Epoch: 42 Batch: 500, loss: 3.2289344106698024\n",
      "Epoch: 43 Batch: 0, loss: 0.764217083564913\n",
      "Epoch: 43 Batch: 100, loss: 11.197985313685285\n",
      "Epoch: 43 Batch: 200, loss: 4.548755874523039\n",
      "Epoch: 43 Batch: 300, loss: 4.005608780083836\n",
      "Epoch: 43 Batch: 400, loss: 7.155365051371337\n",
      "Epoch: 43 Batch: 500, loss: 3.795599391758117\n",
      "Epoch: 44 Batch: 0, loss: 43.08942023486357\n",
      "Epoch: 44 Batch: 100, loss: 0.05102202343441483\n",
      "Epoch: 44 Batch: 200, loss: 68.81404904979715\n",
      "Epoch: 44 Batch: 300, loss: 11.4485177215835\n",
      "Epoch: 44 Batch: 400, loss: 2.215621396380924\n",
      "Epoch: 44 Batch: 500, loss: 128.83585213833035\n",
      "Epoch: 45 Batch: 0, loss: 35.044757655169136\n",
      "Epoch: 45 Batch: 100, loss: 3.9243198270167525\n",
      "Epoch: 45 Batch: 200, loss: 20.673174552674027\n",
      "Epoch: 45 Batch: 300, loss: 0.1716948914857805\n",
      "Epoch: 45 Batch: 400, loss: 6.038608947172634\n",
      "Epoch: 45 Batch: 500, loss: 54.26999456525923\n",
      "Epoch: 46 Batch: 0, loss: 90.92494313011754\n",
      "Epoch: 46 Batch: 100, loss: 3.356225521887672\n",
      "Epoch: 46 Batch: 200, loss: 13.653156114565364\n",
      "Epoch: 46 Batch: 300, loss: 1.1541456911424064\n",
      "Epoch: 46 Batch: 400, loss: 6.9773877251403045\n",
      "Epoch: 46 Batch: 500, loss: 0.36729765062166764\n",
      "Epoch: 47 Batch: 0, loss: 26.115546517563555\n",
      "Epoch: 47 Batch: 100, loss: 36.73771242685928\n",
      "Epoch: 47 Batch: 200, loss: 12.329557584171154\n",
      "Epoch: 47 Batch: 300, loss: 9.393924959451097\n",
      "Epoch: 47 Batch: 400, loss: 16.692472426669443\n",
      "Epoch: 47 Batch: 500, loss: 8.164449065571048\n",
      "Epoch: 48 Batch: 0, loss: 23.03229580515596\n",
      "Epoch: 48 Batch: 100, loss: 1.4572151299959868\n",
      "Epoch: 48 Batch: 200, loss: 3.5467735816281287\n",
      "Epoch: 48 Batch: 300, loss: 17.188114506356552\n",
      "Epoch: 48 Batch: 400, loss: 19.047553974184993\n",
      "Epoch: 48 Batch: 500, loss: 75.31165090295168\n",
      "Epoch: 49 Batch: 0, loss: 0.09815841551657499\n",
      "Epoch: 49 Batch: 100, loss: 6.492142643622755\n",
      "Epoch: 49 Batch: 200, loss: 150.15823484736967\n",
      "Epoch: 49 Batch: 300, loss: 17.35389623364354\n",
      "Epoch: 49 Batch: 400, loss: 6.473218899904105\n",
      "Epoch: 49 Batch: 500, loss: 0.5489638340376248\n",
      "Epoch: 50 Batch: 0, loss: 36.7903941659447\n",
      "Epoch: 50 Batch: 100, loss: 32.837918623398906\n",
      "Epoch: 50 Batch: 200, loss: 34.816834652458176\n",
      "Epoch: 50 Batch: 300, loss: 6.013895661382077\n",
      "Epoch: 50 Batch: 400, loss: 0.502823549881689\n",
      "Epoch: 50 Batch: 500, loss: 1.744177930008695\n",
      "Epoch: 51 Batch: 0, loss: 0.7635867973396013\n",
      "Epoch: 51 Batch: 100, loss: 1.7766498818744447\n",
      "Epoch: 51 Batch: 200, loss: 112.6965366357869\n",
      "Epoch: 51 Batch: 300, loss: 6.618562880923216\n",
      "Epoch: 51 Batch: 400, loss: 16.14486907047534\n",
      "Epoch: 51 Batch: 500, loss: 0.5838057317362177\n",
      "Epoch: 52 Batch: 0, loss: 55.054830593010465\n",
      "Epoch: 52 Batch: 100, loss: 4.90420671951512\n",
      "Epoch: 52 Batch: 200, loss: 106.1926594125563\n",
      "Epoch: 52 Batch: 300, loss: 207.31583524883254\n",
      "Epoch: 52 Batch: 400, loss: 0.5576993291583099\n",
      "Epoch: 52 Batch: 500, loss: 19.618384565215354\n",
      "Epoch: 53 Batch: 0, loss: 77.43062677602846\n",
      "Epoch: 53 Batch: 100, loss: 6.078238151112904\n",
      "Epoch: 53 Batch: 200, loss: 17.950234987370045\n",
      "Epoch: 53 Batch: 300, loss: 8.811241271873396\n",
      "Epoch: 53 Batch: 400, loss: 42.027816587778794\n",
      "Epoch: 53 Batch: 500, loss: 0.10991380325250902\n",
      "Epoch: 54 Batch: 0, loss: 1.6715829466644745\n",
      "Epoch: 54 Batch: 100, loss: 1.4233700363270918\n",
      "Epoch: 54 Batch: 200, loss: 45.733319849505314\n",
      "Epoch: 54 Batch: 300, loss: 200.15297988901963\n",
      "Epoch: 54 Batch: 400, loss: 15.860718708445795\n",
      "Epoch: 54 Batch: 500, loss: 14.242935120926733\n",
      "Epoch: 55 Batch: 0, loss: 40.30580302990519\n",
      "Epoch: 55 Batch: 100, loss: 3.5892873536587566\n",
      "Epoch: 55 Batch: 200, loss: 17.28321835342675\n",
      "Epoch: 55 Batch: 300, loss: 16.141172448881463\n",
      "Epoch: 55 Batch: 400, loss: 1.1296040107844205\n",
      "Epoch: 55 Batch: 500, loss: 180.72754895328717\n",
      "Epoch: 56 Batch: 0, loss: 0.08379307257621912\n",
      "Epoch: 56 Batch: 100, loss: 62.71608099793449\n",
      "Epoch: 56 Batch: 200, loss: 4.730113287924849\n",
      "Epoch: 56 Batch: 300, loss: 19.946107976066514\n",
      "Epoch: 56 Batch: 400, loss: 0.743068807093118\n",
      "Epoch: 56 Batch: 500, loss: 112.09425349941017\n",
      "Epoch: 57 Batch: 0, loss: 0.5913781301315443\n",
      "Epoch: 57 Batch: 100, loss: 6.808992694943106\n",
      "Epoch: 57 Batch: 200, loss: 17.213731435342787\n",
      "Epoch: 57 Batch: 300, loss: 53.161061859722764\n",
      "Epoch: 57 Batch: 400, loss: 9.755251290086521\n",
      "Epoch: 57 Batch: 500, loss: 40.05183983625058\n",
      "Epoch: 58 Batch: 0, loss: 0.4513397448800293\n",
      "Epoch: 58 Batch: 100, loss: 0.05729683226145423\n",
      "Epoch: 58 Batch: 200, loss: 11.925896393993625\n",
      "Epoch: 58 Batch: 300, loss: 17.316441841708052\n",
      "Epoch: 58 Batch: 400, loss: 0.5264486712359455\n",
      "Epoch: 58 Batch: 500, loss: 1.6693055908594003\n",
      "Epoch: 59 Batch: 0, loss: 6.827058683567103\n",
      "Epoch: 59 Batch: 100, loss: 0.04752896270230749\n",
      "Epoch: 59 Batch: 200, loss: 26.70614184393178\n",
      "Epoch: 59 Batch: 300, loss: 4.774883781476281\n",
      "Epoch: 59 Batch: 400, loss: 16.546260771048676\n",
      "Epoch: 59 Batch: 500, loss: 28.39298924951999\n",
      "Epoch: 60 Batch: 0, loss: 21.61998374795748\n",
      "Epoch: 60 Batch: 100, loss: 8.143521085472843\n",
      "Epoch: 60 Batch: 200, loss: 0.5230442202756186\n",
      "Epoch: 60 Batch: 300, loss: 6.44022431007154\n",
      "Epoch: 60 Batch: 400, loss: 18.681679091086192\n",
      "Epoch: 60 Batch: 500, loss: 2.6461266807495334\n",
      "Epoch: 61 Batch: 0, loss: 0.5371903393837043\n",
      "Epoch: 61 Batch: 100, loss: 11.168756081426901\n",
      "Epoch: 61 Batch: 200, loss: 0.2664005633895441\n",
      "Epoch: 61 Batch: 300, loss: 12.94759264130273\n",
      "Epoch: 61 Batch: 400, loss: 4.140710510127312\n",
      "Epoch: 61 Batch: 500, loss: 41.46687916462899\n",
      "Epoch: 62 Batch: 0, loss: 24.0419642592028\n",
      "Epoch: 62 Batch: 100, loss: 8.159648074580465\n",
      "Epoch: 62 Batch: 200, loss: 20.72503438682763\n",
      "Epoch: 62 Batch: 300, loss: 0.8001611484271798\n",
      "Epoch: 62 Batch: 400, loss: 36.13254813955942\n",
      "Epoch: 62 Batch: 500, loss: 3.110076659335099\n",
      "Epoch: 63 Batch: 0, loss: 44.54329511993653\n",
      "Epoch: 63 Batch: 100, loss: 298.84643208041626\n",
      "Epoch: 63 Batch: 200, loss: 0.5342037599220872\n",
      "Epoch: 63 Batch: 300, loss: 5.001177507592211\n",
      "Epoch: 63 Batch: 400, loss: 7.995183320565966\n",
      "Epoch: 63 Batch: 500, loss: 66.30901171207807\n",
      "Epoch: 64 Batch: 0, loss: 1.2271314863915963\n",
      "Epoch: 64 Batch: 100, loss: 13.198491403974515\n",
      "Epoch: 64 Batch: 200, loss: 1.065203558219041\n",
      "Epoch: 64 Batch: 300, loss: 0.9224428205499905\n",
      "Epoch: 64 Batch: 400, loss: 15.48770566248291\n",
      "Epoch: 64 Batch: 500, loss: 6.632541631094821\n",
      "Epoch: 65 Batch: 0, loss: 31.420903650517147\n",
      "Epoch: 65 Batch: 100, loss: 5.1977319746875335\n",
      "Epoch: 65 Batch: 200, loss: 2.8697247221191957\n",
      "Epoch: 65 Batch: 300, loss: 1.936807449493959\n",
      "Epoch: 65 Batch: 400, loss: 0.5213685512851752\n",
      "Epoch: 65 Batch: 500, loss: 0.7778588594668147\n",
      "Epoch: 66 Batch: 0, loss: 13.1992441850363\n",
      "Epoch: 66 Batch: 100, loss: 40.603629934056265\n",
      "Epoch: 66 Batch: 200, loss: 3.961135184543308\n",
      "Epoch: 66 Batch: 300, loss: 0.17157316049004256\n",
      "Epoch: 66 Batch: 400, loss: 112.90073042173086\n",
      "Epoch: 66 Batch: 500, loss: 21.473896361452603\n",
      "Epoch: 67 Batch: 0, loss: 1.6520902373280513\n",
      "Epoch: 67 Batch: 100, loss: 117.43317519424556\n",
      "Epoch: 67 Batch: 200, loss: 142.2088953146705\n",
      "Epoch: 67 Batch: 300, loss: 1.002765198186414\n",
      "Epoch: 67 Batch: 400, loss: 21.359748266750117\n",
      "Epoch: 67 Batch: 500, loss: 17.343164397584694\n",
      "Epoch: 68 Batch: 0, loss: 15.283563936779954\n",
      "Epoch: 68 Batch: 100, loss: 106.34419190648897\n",
      "Epoch: 68 Batch: 200, loss: 8.525405554907941\n",
      "Epoch: 68 Batch: 300, loss: 0.29746485971308917\n",
      "Epoch: 68 Batch: 400, loss: 0.33111329313427174\n",
      "Epoch: 68 Batch: 500, loss: 34.984718140982686\n",
      "Epoch: 69 Batch: 0, loss: 27.684435570472296\n",
      "Epoch: 69 Batch: 100, loss: 0.8166039759201372\n",
      "Epoch: 69 Batch: 200, loss: 3.390659430660551\n",
      "Epoch: 69 Batch: 300, loss: 8.03554881142735\n",
      "Epoch: 69 Batch: 400, loss: 14.561071626040004\n",
      "Epoch: 69 Batch: 500, loss: 22.766454455406286\n",
      "Epoch: 70 Batch: 0, loss: 0.18698767901807875\n",
      "Epoch: 70 Batch: 100, loss: 0.1871213662995117\n",
      "Epoch: 70 Batch: 200, loss: 13.422541697978868\n",
      "Epoch: 70 Batch: 300, loss: 10.145375208580957\n",
      "Epoch: 70 Batch: 400, loss: 2.8305885856253123\n",
      "Epoch: 70 Batch: 500, loss: 17.79708832790887\n",
      "Epoch: 71 Batch: 0, loss: 16.346413580856307\n",
      "Epoch: 71 Batch: 100, loss: 10.106071967948115\n",
      "Epoch: 71 Batch: 200, loss: 2.9086183147670703\n",
      "Epoch: 71 Batch: 300, loss: 24.218856159798438\n",
      "Epoch: 71 Batch: 400, loss: 0.006414428890578785\n",
      "Epoch: 71 Batch: 500, loss: 26.0617285158935\n",
      "Epoch: 72 Batch: 0, loss: 13.751147150366666\n",
      "Epoch: 72 Batch: 100, loss: 1.1914515249270763\n",
      "Epoch: 72 Batch: 200, loss: 15.426535051541006\n",
      "Epoch: 72 Batch: 300, loss: 107.76702031227188\n",
      "Epoch: 72 Batch: 400, loss: 0.050667064243253755\n",
      "Epoch: 72 Batch: 500, loss: 5.618842092893401\n",
      "Epoch: 73 Batch: 0, loss: 0.6659884170348634\n",
      "Epoch: 73 Batch: 100, loss: 2.830786930135226\n",
      "Epoch: 73 Batch: 200, loss: 18.54886270130324\n",
      "Epoch: 73 Batch: 300, loss: 18.58466537953131\n",
      "Epoch: 73 Batch: 400, loss: 2.704847962278002\n",
      "Epoch: 73 Batch: 500, loss: 45.86577645451921\n",
      "Epoch: 74 Batch: 0, loss: 17.917396177538524\n",
      "Epoch: 74 Batch: 100, loss: 51.27884024909306\n",
      "Epoch: 74 Batch: 200, loss: 39.90221676724694\n",
      "Epoch: 74 Batch: 300, loss: 1.2190558740149473\n",
      "Epoch: 74 Batch: 400, loss: 0.10696822904099697\n",
      "Epoch: 74 Batch: 500, loss: 15.277869180861158\n",
      "Epoch: 75 Batch: 0, loss: 14.165424527118923\n",
      "Epoch: 75 Batch: 100, loss: 5.629732453748502\n",
      "Epoch: 75 Batch: 200, loss: 4.822016874184048\n",
      "Epoch: 75 Batch: 300, loss: 19.39988162898239\n",
      "Epoch: 75 Batch: 400, loss: 41.76020741859173\n",
      "Epoch: 75 Batch: 500, loss: 0.4603986467896639\n",
      "Epoch: 76 Batch: 0, loss: 4.402999229002658\n",
      "Epoch: 76 Batch: 100, loss: 4.899686791596041\n",
      "Epoch: 76 Batch: 200, loss: 29.11545764602926\n",
      "Epoch: 76 Batch: 300, loss: 385.3963663954101\n",
      "Epoch: 76 Batch: 400, loss: 9.158680304225523\n",
      "Epoch: 76 Batch: 500, loss: 154.44677095693444\n",
      "Epoch: 77 Batch: 0, loss: 36.42818516113567\n",
      "Epoch: 77 Batch: 100, loss: 80.77807316854148\n",
      "Epoch: 77 Batch: 200, loss: 246.77980321651057\n",
      "Epoch: 77 Batch: 300, loss: 117.30897902315148\n",
      "Epoch: 77 Batch: 400, loss: 1.8968242949464549\n",
      "Epoch: 77 Batch: 500, loss: 1.442432163238994\n",
      "Epoch: 78 Batch: 0, loss: 7.479851775992773\n",
      "Epoch: 78 Batch: 100, loss: 17.343155023960744\n",
      "Epoch: 78 Batch: 200, loss: 9.002821928929604\n",
      "Epoch: 78 Batch: 300, loss: 0.22572011271333642\n",
      "Epoch: 78 Batch: 400, loss: 0.45619724239092974\n",
      "Epoch: 78 Batch: 500, loss: 3.1477076591223274\n",
      "Epoch: 79 Batch: 0, loss: 1.6861056897341271\n",
      "Epoch: 79 Batch: 100, loss: 0.716327812079344\n",
      "Epoch: 79 Batch: 200, loss: 0.053126637667273685\n",
      "Epoch: 79 Batch: 300, loss: 10.589997425787468\n",
      "Epoch: 79 Batch: 400, loss: 117.36448916439056\n",
      "Epoch: 79 Batch: 500, loss: 0.06684596357656196\n",
      "Epoch: 80 Batch: 0, loss: 16.91961147990615\n",
      "Epoch: 80 Batch: 100, loss: 19.95803104016418\n",
      "Epoch: 80 Batch: 200, loss: 33.46375146379257\n",
      "Epoch: 80 Batch: 300, loss: 11.881661278640847\n",
      "Epoch: 80 Batch: 400, loss: 16.574154672977457\n",
      "Epoch: 80 Batch: 500, loss: 35.09535788152365\n",
      "Epoch: 81 Batch: 0, loss: 0.8510219861563261\n",
      "Epoch: 81 Batch: 100, loss: 17.55010052826962\n",
      "Epoch: 81 Batch: 200, loss: 323.7950804353228\n",
      "Epoch: 81 Batch: 300, loss: 0.37218744327473063\n",
      "Epoch: 81 Batch: 400, loss: 3.187409890006815\n",
      "Epoch: 81 Batch: 500, loss: 167.37466135355797\n",
      "Epoch: 82 Batch: 0, loss: 0.12724479646735107\n",
      "Epoch: 82 Batch: 100, loss: 0.4926172894077596\n",
      "Epoch: 82 Batch: 200, loss: 1.4013727418878058e-05\n",
      "Epoch: 82 Batch: 300, loss: 140.59014497011012\n",
      "Epoch: 82 Batch: 400, loss: 17.400895487363993\n",
      "Epoch: 82 Batch: 500, loss: 0.0014370068480470215\n",
      "Epoch: 83 Batch: 0, loss: 1.29359442802745\n",
      "Epoch: 83 Batch: 100, loss: 22.718308068614004\n",
      "Epoch: 83 Batch: 200, loss: 0.47253167468759893\n",
      "Epoch: 83 Batch: 300, loss: 0.428709232568082\n",
      "Epoch: 83 Batch: 400, loss: 55.367806740996805\n",
      "Epoch: 83 Batch: 500, loss: 0.0743112785190951\n",
      "Epoch: 84 Batch: 0, loss: 9.881930860934638\n",
      "Epoch: 84 Batch: 100, loss: 143.9986965727517\n",
      "Epoch: 84 Batch: 200, loss: 0.13314166614379708\n",
      "Epoch: 84 Batch: 300, loss: 30.07111988456659\n",
      "Epoch: 84 Batch: 400, loss: 41.7290785788065\n",
      "Epoch: 84 Batch: 500, loss: 0.03915189005560871\n",
      "Epoch: 85 Batch: 0, loss: 13.762796492289604\n",
      "Epoch: 85 Batch: 100, loss: 27.789119688012672\n",
      "Epoch: 85 Batch: 200, loss: 5.536866995717304\n",
      "Epoch: 85 Batch: 300, loss: 35.44789664265593\n",
      "Epoch: 85 Batch: 400, loss: 29.036960144228694\n",
      "Epoch: 85 Batch: 500, loss: 7.821779774297325\n",
      "Epoch: 86 Batch: 0, loss: 0.24131990342094597\n",
      "Epoch: 86 Batch: 100, loss: 126.04601703316945\n",
      "Epoch: 86 Batch: 200, loss: 0.578238419893191\n",
      "Epoch: 86 Batch: 300, loss: 14.783935822243807\n",
      "Epoch: 86 Batch: 400, loss: 5.032340537657264\n",
      "Epoch: 86 Batch: 500, loss: 0.07457558152639092\n",
      "Epoch: 87 Batch: 0, loss: 4.405889448526539\n",
      "Epoch: 87 Batch: 100, loss: 8.193455156017938\n",
      "Epoch: 87 Batch: 200, loss: 196.51260479573887\n",
      "Epoch: 87 Batch: 300, loss: 1.1101272514447584\n",
      "Epoch: 87 Batch: 400, loss: 4.75810071311088\n",
      "Epoch: 87 Batch: 500, loss: 1.524913407524406\n",
      "Epoch: 88 Batch: 0, loss: 6.972283342546859\n",
      "Epoch: 88 Batch: 100, loss: 1.1324348976183896\n",
      "Epoch: 88 Batch: 200, loss: 1.3883017239752444\n",
      "Epoch: 88 Batch: 300, loss: 33.127856385769725\n",
      "Epoch: 88 Batch: 400, loss: 54.19083571058954\n",
      "Epoch: 88 Batch: 500, loss: 2.931143021767379\n",
      "Epoch: 89 Batch: 0, loss: 0.7271727462888744\n",
      "Epoch: 89 Batch: 100, loss: 36.52314526067396\n",
      "Epoch: 89 Batch: 200, loss: 118.12915971884057\n",
      "Epoch: 89 Batch: 300, loss: 42.666063536255194\n",
      "Epoch: 89 Batch: 400, loss: 0.9607029373613282\n",
      "Epoch: 89 Batch: 500, loss: 14.793733213057143\n",
      "Epoch: 90 Batch: 0, loss: 66.51806765838484\n",
      "Epoch: 90 Batch: 100, loss: 121.38973314795322\n",
      "Epoch: 90 Batch: 200, loss: 121.16881600892276\n",
      "Epoch: 90 Batch: 300, loss: 5.738188433713473\n",
      "Epoch: 90 Batch: 400, loss: 1.2858562284695934\n",
      "Epoch: 90 Batch: 500, loss: 102.45539835985333\n",
      "Epoch: 91 Batch: 0, loss: 57.80763727134234\n",
      "Epoch: 91 Batch: 100, loss: 8.750211204931563\n",
      "Epoch: 91 Batch: 200, loss: 23.166284679246132\n",
      "Epoch: 91 Batch: 300, loss: 11.122044728329604\n",
      "Epoch: 91 Batch: 400, loss: 156.7619474352662\n",
      "Epoch: 91 Batch: 500, loss: 57.77459201154134\n",
      "Epoch: 92 Batch: 0, loss: 0.5626352363189626\n",
      "Epoch: 92 Batch: 100, loss: 5.840786303062232\n",
      "Epoch: 92 Batch: 200, loss: 8.541419370027466\n",
      "Epoch: 92 Batch: 300, loss: 27.311806359821635\n",
      "Epoch: 92 Batch: 400, loss: 28.11055966511191\n",
      "Epoch: 92 Batch: 500, loss: 42.230024733294385\n",
      "Epoch: 93 Batch: 0, loss: 18.005606628363196\n",
      "Epoch: 93 Batch: 100, loss: 3.2192649725697167\n",
      "Epoch: 93 Batch: 200, loss: 2.4732305708444584\n",
      "Epoch: 93 Batch: 300, loss: 9.748103981868239\n",
      "Epoch: 93 Batch: 400, loss: 5.726002496815293\n",
      "Epoch: 93 Batch: 500, loss: 0.8788889242222953\n",
      "Epoch: 94 Batch: 0, loss: 2.532644538497402\n",
      "Epoch: 94 Batch: 100, loss: 0.040918540851205394\n",
      "Epoch: 94 Batch: 200, loss: 0.47631977138480297\n",
      "Epoch: 94 Batch: 300, loss: 0.9342637331220829\n",
      "Epoch: 94 Batch: 400, loss: 1.9966742910670194\n",
      "Epoch: 94 Batch: 500, loss: 20.16521612617044\n",
      "Epoch: 95 Batch: 0, loss: 2.583634556427901\n",
      "Epoch: 95 Batch: 100, loss: 281.7947841283171\n",
      "Epoch: 95 Batch: 200, loss: 1.0053395990304077\n",
      "Epoch: 95 Batch: 300, loss: 33.98741159787694\n",
      "Epoch: 95 Batch: 400, loss: 0.6687426144012525\n",
      "Epoch: 95 Batch: 500, loss: 650.6765562095794\n",
      "Epoch: 96 Batch: 0, loss: 62.605915135382816\n",
      "Epoch: 96 Batch: 100, loss: 0.5691989169486109\n",
      "Epoch: 96 Batch: 200, loss: 3.0054647765836804\n",
      "Epoch: 96 Batch: 300, loss: 3.930009970733551\n",
      "Epoch: 96 Batch: 400, loss: 0.5448357718596629\n",
      "Epoch: 96 Batch: 500, loss: 17.995345392585445\n",
      "Epoch: 97 Batch: 0, loss: 33.19424702143038\n",
      "Epoch: 97 Batch: 100, loss: 159.86969799440024\n",
      "Epoch: 97 Batch: 200, loss: 9.269643293370358\n",
      "Epoch: 97 Batch: 300, loss: 17.005863629430927\n",
      "Epoch: 97 Batch: 400, loss: 44.33887404966033\n",
      "Epoch: 97 Batch: 500, loss: 2.544339405257962\n",
      "Epoch: 98 Batch: 0, loss: 0.00033039380011363746\n",
      "Epoch: 98 Batch: 100, loss: 0.9008729932629598\n",
      "Epoch: 98 Batch: 200, loss: 25.54771995893078\n",
      "Epoch: 98 Batch: 300, loss: 34.15950333728113\n",
      "Epoch: 98 Batch: 400, loss: 42.744105853686975\n",
      "Epoch: 98 Batch: 500, loss: 24.92378965402083\n",
      "Epoch: 99 Batch: 0, loss: 1.7605367866648565\n",
      "Epoch: 99 Batch: 100, loss: 13.76552693961309\n",
      "Epoch: 99 Batch: 200, loss: 11.400497863370932\n",
      "Epoch: 99 Batch: 300, loss: 119.1548162460394\n",
      "Epoch: 99 Batch: 400, loss: 78.9350575893029\n",
      "Epoch: 99 Batch: 500, loss: 51.50593742667556\n",
      "Epoch: 100 Batch: 0, loss: 8.165671588019093\n",
      "Epoch: 100 Batch: 100, loss: 10.52794973142296\n",
      "Epoch: 100 Batch: 200, loss: 4.2111454477109005\n",
      "Epoch: 100 Batch: 300, loss: 0.15744576352177067\n",
      "Epoch: 100 Batch: 400, loss: 23.902072437720754\n",
      "Epoch: 100 Batch: 500, loss: 0.09525287206116581\n",
      "Epoch: 101 Batch: 0, loss: 172.53291000264085\n",
      "Epoch: 101 Batch: 100, loss: 9.635119748562927\n",
      "Epoch: 101 Batch: 200, loss: 0.02931238646713378\n",
      "Epoch: 101 Batch: 300, loss: 0.3004926840907938\n",
      "Epoch: 101 Batch: 400, loss: 39.59172184207459\n",
      "Epoch: 101 Batch: 500, loss: 5.595419155430341\n",
      "Epoch: 102 Batch: 0, loss: 759.6597475004932\n",
      "Epoch: 102 Batch: 100, loss: 26.758819724335712\n",
      "Epoch: 102 Batch: 200, loss: 332.62866403346754\n",
      "Epoch: 102 Batch: 300, loss: 30.908305304585802\n",
      "Epoch: 102 Batch: 400, loss: 8.548052685176954\n",
      "Epoch: 102 Batch: 500, loss: 2.6422467338851425\n",
      "Epoch: 103 Batch: 0, loss: 9.233640267152913\n",
      "Epoch: 103 Batch: 100, loss: 5.4588520142283885\n",
      "Epoch: 103 Batch: 200, loss: 4.987393399039278\n",
      "Epoch: 103 Batch: 300, loss: 22.07970837061068\n",
      "Epoch: 103 Batch: 400, loss: 2.4640714420305083\n",
      "Epoch: 103 Batch: 500, loss: 4.692856689622617\n",
      "Epoch: 104 Batch: 0, loss: 12.066892209057865\n",
      "Epoch: 104 Batch: 100, loss: 0.795071023746224\n",
      "Epoch: 104 Batch: 200, loss: 14.437489792945554\n",
      "Epoch: 104 Batch: 300, loss: 17.19069944208836\n",
      "Epoch: 104 Batch: 400, loss: 21.572448384375235\n",
      "Epoch: 104 Batch: 500, loss: 1.2530808219329372\n",
      "Epoch: 105 Batch: 0, loss: 1.0672466494746071\n",
      "Epoch: 105 Batch: 100, loss: 0.058197786366628514\n",
      "Epoch: 105 Batch: 200, loss: 12.60507014654539\n",
      "Epoch: 105 Batch: 300, loss: 44.65799581419113\n",
      "Epoch: 105 Batch: 400, loss: 10.736554049561716\n",
      "Epoch: 105 Batch: 500, loss: 4.34112870339569\n",
      "Epoch: 106 Batch: 0, loss: 15.250094032998783\n",
      "Epoch: 106 Batch: 100, loss: 10.289805758544153\n",
      "Epoch: 106 Batch: 200, loss: 25.964582059193877\n",
      "Epoch: 106 Batch: 300, loss: 0.01008467752609077\n",
      "Epoch: 106 Batch: 400, loss: 59.22383685969044\n",
      "Epoch: 106 Batch: 500, loss: 0.0901130074057675\n",
      "Epoch: 107 Batch: 0, loss: 42.12530286306818\n",
      "Epoch: 107 Batch: 100, loss: 39.231509446167166\n",
      "Epoch: 107 Batch: 200, loss: 1.1185064796133666\n",
      "Epoch: 107 Batch: 300, loss: 15.125139920573494\n",
      "Epoch: 107 Batch: 400, loss: 33.665225142097704\n",
      "Epoch: 107 Batch: 500, loss: 327.92905518582694\n",
      "Epoch: 108 Batch: 0, loss: 0.6779919785895188\n",
      "Epoch: 108 Batch: 100, loss: 18.635000357082035\n",
      "Epoch: 108 Batch: 200, loss: 12.12864156887321\n",
      "Epoch: 108 Batch: 300, loss: 5.449875680401199\n",
      "Epoch: 108 Batch: 400, loss: 16.644116546069004\n",
      "Epoch: 108 Batch: 500, loss: 37.833150439959205\n",
      "Epoch: 109 Batch: 0, loss: 0.3478844178937121\n",
      "Epoch: 109 Batch: 100, loss: 3.6130227249581646\n",
      "Epoch: 109 Batch: 200, loss: 27.207807554496075\n",
      "Epoch: 109 Batch: 300, loss: 24.113139288378328\n",
      "Epoch: 109 Batch: 400, loss: 1.4659176963773144\n",
      "Epoch: 109 Batch: 500, loss: 3.5754126431130735\n",
      "Epoch: 110 Batch: 0, loss: 1.345971480319873\n",
      "Epoch: 110 Batch: 100, loss: 1.2855752569152648\n",
      "Epoch: 110 Batch: 200, loss: 0.010500367603646353\n",
      "Epoch: 110 Batch: 300, loss: 4.76598310258869\n",
      "Epoch: 110 Batch: 400, loss: 2.0427110521320073\n",
      "Epoch: 110 Batch: 500, loss: 0.4778488076732879\n",
      "Epoch: 111 Batch: 0, loss: 2.9933578854483662\n",
      "Epoch: 111 Batch: 100, loss: 7.575481901902427\n",
      "Epoch: 111 Batch: 200, loss: 0.33176923090203025\n",
      "Epoch: 111 Batch: 300, loss: 11.624567811630387\n",
      "Epoch: 111 Batch: 400, loss: 1.2079089563888743\n",
      "Epoch: 111 Batch: 500, loss: 12.51109743034779\n",
      "Epoch: 112 Batch: 0, loss: 7.488474394733278\n",
      "Epoch: 112 Batch: 100, loss: 13.676378805536807\n",
      "Epoch: 112 Batch: 200, loss: 0.1431301647670816\n",
      "Epoch: 112 Batch: 300, loss: 3.8690855978417753\n",
      "Epoch: 112 Batch: 400, loss: 0.02599169823017575\n",
      "Epoch: 112 Batch: 500, loss: 1.6272022173973197\n",
      "Epoch: 113 Batch: 0, loss: 84.41229668963405\n",
      "Epoch: 113 Batch: 100, loss: 212.11428166468318\n",
      "Epoch: 113 Batch: 200, loss: 13.009388266939082\n",
      "Epoch: 113 Batch: 300, loss: 21.643755593621783\n",
      "Epoch: 113 Batch: 400, loss: 1.5863539654569294\n",
      "Epoch: 113 Batch: 500, loss: 10.8911957744537\n",
      "Epoch: 114 Batch: 0, loss: 0.8208060809963368\n",
      "Epoch: 114 Batch: 100, loss: 2.9853926987039623\n",
      "Epoch: 114 Batch: 200, loss: 10.004289580238252\n",
      "Epoch: 114 Batch: 300, loss: 3.504158715191771\n",
      "Epoch: 114 Batch: 400, loss: 1.1426829567535985\n",
      "Epoch: 114 Batch: 500, loss: 203.02117835300984\n",
      "Epoch: 115 Batch: 0, loss: 13.746731784323435\n",
      "Epoch: 115 Batch: 100, loss: 10.878684335301772\n",
      "Epoch: 115 Batch: 200, loss: 0.8939415791209304\n",
      "Epoch: 115 Batch: 300, loss: 178.77591632680097\n",
      "Epoch: 115 Batch: 400, loss: 3.2674196429442675\n",
      "Epoch: 115 Batch: 500, loss: 1.7431373067363787\n",
      "Epoch: 116 Batch: 0, loss: 305.7061938558283\n",
      "Epoch: 116 Batch: 100, loss: 22.611545874422248\n",
      "Epoch: 116 Batch: 200, loss: 304.6886969863228\n",
      "Epoch: 116 Batch: 300, loss: 16.99474237310688\n",
      "Epoch: 116 Batch: 400, loss: 29.98918656284229\n",
      "Epoch: 116 Batch: 500, loss: 34.600471943142544\n",
      "Epoch: 117 Batch: 0, loss: 13.292647566292253\n",
      "Epoch: 117 Batch: 100, loss: 18.02570649812049\n",
      "Epoch: 117 Batch: 200, loss: 72.6865168477326\n",
      "Epoch: 117 Batch: 300, loss: 23.92955722628456\n",
      "Epoch: 117 Batch: 400, loss: 0.06761165580588654\n",
      "Epoch: 117 Batch: 500, loss: 9.795890099701118\n",
      "Epoch: 118 Batch: 0, loss: 16.542381788438032\n",
      "Epoch: 118 Batch: 100, loss: 0.12809570002530454\n",
      "Epoch: 118 Batch: 200, loss: 1.485116155325994\n",
      "Epoch: 118 Batch: 300, loss: 1.3509919756722857\n",
      "Epoch: 118 Batch: 400, loss: 33.78169803763507\n",
      "Epoch: 118 Batch: 500, loss: 18.40431344500139\n",
      "Epoch: 119 Batch: 0, loss: 34.67761361151857\n",
      "Epoch: 119 Batch: 100, loss: 0.5057883073672095\n",
      "Epoch: 119 Batch: 200, loss: 3.6955762558768557\n",
      "Epoch: 119 Batch: 300, loss: 0.6784329101958457\n",
      "Epoch: 119 Batch: 400, loss: 8.459814765274388\n",
      "Epoch: 119 Batch: 500, loss: 8.001781730700914\n",
      "Epoch: 120 Batch: 0, loss: 41.66355967906684\n",
      "Epoch: 120 Batch: 100, loss: 13.521829636243714\n",
      "Epoch: 120 Batch: 200, loss: 5.535519899663679\n",
      "Epoch: 120 Batch: 300, loss: 4.86058274547402\n",
      "Epoch: 120 Batch: 400, loss: 213.40232102429528\n",
      "Epoch: 120 Batch: 500, loss: 4.313752756623205\n",
      "Epoch: 121 Batch: 0, loss: 3.445950861689131\n",
      "Epoch: 121 Batch: 100, loss: 108.15035724826002\n",
      "Epoch: 121 Batch: 200, loss: 0.03808804539982109\n",
      "Epoch: 121 Batch: 300, loss: 8.46090098553226\n",
      "Epoch: 121 Batch: 400, loss: 68.0252324369938\n",
      "Epoch: 121 Batch: 500, loss: 0.019682961037246607\n",
      "Epoch: 122 Batch: 0, loss: 6.662425744703334\n",
      "Epoch: 122 Batch: 100, loss: 2.8647885170106924\n",
      "Epoch: 122 Batch: 200, loss: 0.6497845944622325\n",
      "Epoch: 122 Batch: 300, loss: 23.75654638077405\n",
      "Epoch: 122 Batch: 400, loss: 7.847458454018727\n",
      "Epoch: 122 Batch: 500, loss: 147.84725635688667\n",
      "Epoch: 123 Batch: 0, loss: 1.1612072792824746\n",
      "Epoch: 123 Batch: 100, loss: 2.399685451276419\n",
      "Epoch: 123 Batch: 200, loss: 100.36074794649956\n",
      "Epoch: 123 Batch: 300, loss: 78.05796318890933\n",
      "Epoch: 123 Batch: 400, loss: 0.38896735658589415\n",
      "Epoch: 123 Batch: 500, loss: 13.152216581345375\n",
      "Epoch: 124 Batch: 0, loss: 16.596332720346325\n",
      "Epoch: 124 Batch: 100, loss: 8.323949998395442\n",
      "Epoch: 124 Batch: 200, loss: 2.2688256448367325\n",
      "Epoch: 124 Batch: 300, loss: 17.529532434517858\n",
      "Epoch: 124 Batch: 400, loss: 5.010687427078248\n",
      "Epoch: 124 Batch: 500, loss: 26.973131948263458\n",
      "Epoch: 125 Batch: 0, loss: 0.44681016327929707\n",
      "Epoch: 125 Batch: 100, loss: 2.655580369131264\n",
      "Epoch: 125 Batch: 200, loss: 304.1401182684432\n",
      "Epoch: 125 Batch: 300, loss: 7.20137278557019\n",
      "Epoch: 125 Batch: 400, loss: 1.0863826646515544\n",
      "Epoch: 125 Batch: 500, loss: 2.110306283541652\n",
      "Epoch: 126 Batch: 0, loss: 1.9104705973967793\n",
      "Epoch: 126 Batch: 100, loss: 15.37120192465246\n",
      "Epoch: 126 Batch: 200, loss: 162.46159069000808\n",
      "Epoch: 126 Batch: 300, loss: 0.18441759605511737\n",
      "Epoch: 126 Batch: 400, loss: 8.28311624444241\n",
      "Epoch: 126 Batch: 500, loss: 1.2063565668680387\n",
      "Epoch: 127 Batch: 0, loss: 110.10597866199845\n",
      "Epoch: 127 Batch: 100, loss: 22.573374554813945\n",
      "Epoch: 127 Batch: 200, loss: 5.273739858378517\n",
      "Epoch: 127 Batch: 300, loss: 0.26355229183178924\n",
      "Epoch: 127 Batch: 400, loss: 0.24493563641337393\n",
      "Epoch: 127 Batch: 500, loss: 67.32167294963757\n",
      "Epoch: 128 Batch: 0, loss: 293.77916414309163\n",
      "Epoch: 128 Batch: 100, loss: 0.22434364810493448\n",
      "Epoch: 128 Batch: 200, loss: 0.00024922850159011633\n",
      "Epoch: 128 Batch: 300, loss: 2.699432058940697\n",
      "Epoch: 128 Batch: 400, loss: 217.26761067967394\n",
      "Epoch: 128 Batch: 500, loss: 13.898361787948541\n",
      "Epoch: 129 Batch: 0, loss: 13.27253617725076\n",
      "Epoch: 129 Batch: 100, loss: 0.45760117723112187\n",
      "Epoch: 129 Batch: 200, loss: 9.384530464615658\n",
      "Epoch: 129 Batch: 300, loss: 18.079414286149778\n",
      "Epoch: 129 Batch: 400, loss: 10.51836205031159\n",
      "Epoch: 129 Batch: 500, loss: 1.8834263680931167\n",
      "Epoch: 130 Batch: 0, loss: 6.271196259234049\n",
      "Epoch: 130 Batch: 100, loss: 1.9942412048000913\n",
      "Epoch: 130 Batch: 200, loss: 4.553196078620634\n",
      "Epoch: 130 Batch: 300, loss: 9.550895828135774\n",
      "Epoch: 130 Batch: 400, loss: 54.47131826031858\n",
      "Epoch: 130 Batch: 500, loss: 8.323037825146\n",
      "Epoch: 131 Batch: 0, loss: 2.3787006219803977\n",
      "Epoch: 131 Batch: 100, loss: 2.1869561245774802\n",
      "Epoch: 131 Batch: 200, loss: 2.8964990086665012\n",
      "Epoch: 131 Batch: 300, loss: 0.9648841546603135\n",
      "Epoch: 131 Batch: 400, loss: 21.517266125458555\n",
      "Epoch: 131 Batch: 500, loss: 210.0974308355945\n",
      "Epoch: 132 Batch: 0, loss: 18.010092362703336\n",
      "Epoch: 132 Batch: 100, loss: 0.6702404119583731\n",
      "Epoch: 132 Batch: 200, loss: 6.184319568455233\n",
      "Epoch: 132 Batch: 300, loss: 3.0321488191355064\n",
      "Epoch: 132 Batch: 400, loss: 11.273611240900152\n",
      "Epoch: 132 Batch: 500, loss: 9.580851273817334\n",
      "Epoch: 133 Batch: 0, loss: 24.02893464784933\n",
      "Epoch: 133 Batch: 100, loss: 0.7644874813486329\n",
      "Epoch: 133 Batch: 200, loss: 15.578161419360162\n",
      "Epoch: 133 Batch: 300, loss: 0.5830308647660755\n",
      "Epoch: 133 Batch: 400, loss: 6.618992248082224\n",
      "Epoch: 133 Batch: 500, loss: 9.763701001602787\n",
      "Epoch: 134 Batch: 0, loss: 8.69856301570754\n",
      "Epoch: 134 Batch: 100, loss: 107.82397629720242\n",
      "Epoch: 134 Batch: 200, loss: 151.33171255802955\n",
      "Epoch: 134 Batch: 300, loss: 1.0710708287200854\n",
      "Epoch: 134 Batch: 400, loss: 4.836695901850196\n",
      "Epoch: 134 Batch: 500, loss: 4.35673011640888\n",
      "Epoch: 135 Batch: 0, loss: 36.8373771395649\n",
      "Epoch: 135 Batch: 100, loss: 0.36611321248808354\n",
      "Epoch: 135 Batch: 200, loss: 15.971644509990012\n",
      "Epoch: 135 Batch: 300, loss: 65.5235917239163\n",
      "Epoch: 135 Batch: 400, loss: 8.802080093182882\n",
      "Epoch: 135 Batch: 500, loss: 147.67682588233765\n",
      "Epoch: 136 Batch: 0, loss: 118.68477182069304\n",
      "Epoch: 136 Batch: 100, loss: 5.239040009548553\n",
      "Epoch: 136 Batch: 200, loss: 1.0622817120525698\n",
      "Epoch: 136 Batch: 300, loss: 24.037219518753975\n",
      "Epoch: 136 Batch: 400, loss: 7.728891307598097\n",
      "Epoch: 136 Batch: 500, loss: 0.16787141072694867\n",
      "Epoch: 137 Batch: 0, loss: 7.590253112271308\n",
      "Epoch: 137 Batch: 100, loss: 7.603775728281186\n",
      "Epoch: 137 Batch: 200, loss: 5.473332116389246\n",
      "Epoch: 137 Batch: 300, loss: 26.504525846363777\n",
      "Epoch: 137 Batch: 400, loss: 6.936143542151355\n",
      "Epoch: 137 Batch: 500, loss: 31.411299501772717\n",
      "Epoch: 138 Batch: 0, loss: 4.529478765379597\n",
      "Epoch: 138 Batch: 100, loss: 36.12844183027704\n",
      "Epoch: 138 Batch: 200, loss: 0.05566282570159332\n",
      "Epoch: 138 Batch: 300, loss: 53.543531275958934\n",
      "Epoch: 138 Batch: 400, loss: 0.1623671576807473\n",
      "Epoch: 138 Batch: 500, loss: 5.893468037320811\n",
      "Epoch: 139 Batch: 0, loss: 161.07595667700042\n",
      "Epoch: 139 Batch: 100, loss: 2.4155257093458573\n",
      "Epoch: 139 Batch: 200, loss: 11.63640591294979\n",
      "Epoch: 139 Batch: 300, loss: 82.0628618580143\n",
      "Epoch: 139 Batch: 400, loss: 50.62163484937778\n",
      "Epoch: 139 Batch: 500, loss: 5.15438671727909\n",
      "Epoch: 140 Batch: 0, loss: 8.9862925648114\n",
      "Epoch: 140 Batch: 100, loss: 22.953514522515935\n",
      "Epoch: 140 Batch: 200, loss: 165.33992769730787\n",
      "Epoch: 140 Batch: 300, loss: 4.232904284325986\n",
      "Epoch: 140 Batch: 400, loss: 12.220823426788046\n",
      "Epoch: 140 Batch: 500, loss: 9.641770426438226\n",
      "Epoch: 141 Batch: 0, loss: 1.802626516051315\n",
      "Epoch: 141 Batch: 100, loss: 0.4235541079766425\n",
      "Epoch: 141 Batch: 200, loss: 32.51270783027823\n",
      "Epoch: 141 Batch: 300, loss: 7.672986263426289\n",
      "Epoch: 141 Batch: 400, loss: 2.2194523381449422\n",
      "Epoch: 141 Batch: 500, loss: 27.988209465031154\n",
      "Epoch: 142 Batch: 0, loss: 67.40441060995967\n",
      "Epoch: 142 Batch: 100, loss: 49.14830317760175\n",
      "Epoch: 142 Batch: 200, loss: 10.117907186118288\n",
      "Epoch: 142 Batch: 300, loss: 1.951056094535288\n",
      "Epoch: 142 Batch: 400, loss: 0.18250411339854355\n",
      "Epoch: 142 Batch: 500, loss: 14.39561974207904\n",
      "Epoch: 143 Batch: 0, loss: 3.5115591642298227\n",
      "Epoch: 143 Batch: 100, loss: 149.64049462271873\n",
      "Epoch: 143 Batch: 200, loss: 2.498333418672811\n",
      "Epoch: 143 Batch: 300, loss: 29.82351673798547\n",
      "Epoch: 143 Batch: 400, loss: 4.836368917393248\n",
      "Epoch: 143 Batch: 500, loss: 9.63998944837507\n",
      "Epoch: 144 Batch: 0, loss: 14.236795590451935\n",
      "Epoch: 144 Batch: 100, loss: 21.938645926567517\n",
      "Epoch: 144 Batch: 200, loss: 7.492265309432416\n",
      "Epoch: 144 Batch: 300, loss: 34.82446767880443\n",
      "Epoch: 144 Batch: 400, loss: 2.037112747383839\n",
      "Epoch: 144 Batch: 500, loss: 89.17818083446325\n",
      "Epoch: 145 Batch: 0, loss: 26.262337893222465\n",
      "Epoch: 145 Batch: 100, loss: 23.811856450201503\n",
      "Epoch: 145 Batch: 200, loss: 7.603657945553677\n",
      "Epoch: 145 Batch: 300, loss: 1.0318551639630007\n",
      "Epoch: 145 Batch: 400, loss: 124.4162268578692\n",
      "Epoch: 145 Batch: 500, loss: 5.520830186061407\n",
      "Epoch: 146 Batch: 0, loss: 9.136296073442207\n",
      "Epoch: 146 Batch: 100, loss: 2.853282130392366\n",
      "Epoch: 146 Batch: 200, loss: 0.16691333058113508\n",
      "Epoch: 146 Batch: 300, loss: 0.6403337379081678\n",
      "Epoch: 146 Batch: 400, loss: 6.173171340632697\n",
      "Epoch: 146 Batch: 500, loss: 10.384254305286168\n",
      "Epoch: 147 Batch: 0, loss: 187.15107725165433\n",
      "Epoch: 147 Batch: 100, loss: 0.021923273750359292\n",
      "Epoch: 147 Batch: 200, loss: 5.073802177607332\n",
      "Epoch: 147 Batch: 300, loss: 0.05731053315937625\n",
      "Epoch: 147 Batch: 400, loss: 11.54355372560162\n",
      "Epoch: 147 Batch: 500, loss: 7.083977769705883e-05\n",
      "Epoch: 148 Batch: 0, loss: 26.28496348201411\n",
      "Epoch: 148 Batch: 100, loss: 8.86414844558774\n",
      "Epoch: 148 Batch: 200, loss: 20.675769435686654\n",
      "Epoch: 148 Batch: 300, loss: 0.34658483721825895\n",
      "Epoch: 148 Batch: 400, loss: 3.2740809594260254\n",
      "Epoch: 148 Batch: 500, loss: 0.08833361712871918\n",
      "Epoch: 149 Batch: 0, loss: 5.039568788177126\n",
      "Epoch: 149 Batch: 100, loss: 6.035323432845833\n",
      "Epoch: 149 Batch: 200, loss: 0.00458543976554051\n",
      "Epoch: 149 Batch: 300, loss: 1.7847243066033012\n",
      "Epoch: 149 Batch: 400, loss: 0.0004258157945371311\n",
      "Epoch: 149 Batch: 500, loss: 7.976640418794172\n",
      "Epoch: 150 Batch: 0, loss: 2.0189200660206064\n",
      "Epoch: 150 Batch: 100, loss: 0.12484713490316986\n",
      "Epoch: 150 Batch: 200, loss: 42.668754110511124\n",
      "Epoch: 150 Batch: 300, loss: 15.62491861695986\n",
      "Epoch: 150 Batch: 400, loss: 38.67551243713114\n",
      "Epoch: 150 Batch: 500, loss: 94.85681848197046\n",
      "Epoch: 151 Batch: 0, loss: 0.14943341578628513\n",
      "Epoch: 151 Batch: 100, loss: 11.751110909910379\n",
      "Epoch: 151 Batch: 200, loss: 7.171567612579148\n",
      "Epoch: 151 Batch: 300, loss: 8.573932584539435\n",
      "Epoch: 151 Batch: 400, loss: 0.027340354815486082\n",
      "Epoch: 151 Batch: 500, loss: 18.94486236524507\n",
      "Epoch: 152 Batch: 0, loss: 93.13285537526481\n",
      "Epoch: 152 Batch: 100, loss: 4.455619757882106\n",
      "Epoch: 152 Batch: 200, loss: 4.559895597901706\n",
      "Epoch: 152 Batch: 300, loss: 1.4267473024184971\n",
      "Epoch: 152 Batch: 400, loss: 37.84534660555156\n",
      "Epoch: 152 Batch: 500, loss: 5.305548748147135\n",
      "Epoch: 153 Batch: 0, loss: 3.1695295490707287\n",
      "Epoch: 153 Batch: 100, loss: 0.5107956851687794\n",
      "Epoch: 153 Batch: 200, loss: 1.9893068990049483\n",
      "Epoch: 153 Batch: 300, loss: 217.74681746396413\n",
      "Epoch: 153 Batch: 400, loss: 12.160892189066821\n",
      "Epoch: 153 Batch: 500, loss: 11.584856072265794\n",
      "Epoch: 154 Batch: 0, loss: 0.6565627117477888\n",
      "Epoch: 154 Batch: 100, loss: 2.8818254153547955\n",
      "Epoch: 154 Batch: 200, loss: 8.174627312292674\n",
      "Epoch: 154 Batch: 300, loss: 2.0037726905694604\n",
      "Epoch: 154 Batch: 400, loss: 59.717361621854266\n",
      "Epoch: 154 Batch: 500, loss: 17.58795509243063\n",
      "Epoch: 155 Batch: 0, loss: 1.765685849077722\n",
      "Epoch: 155 Batch: 100, loss: 17.912196590931632\n",
      "Epoch: 155 Batch: 200, loss: 9.2035501531711\n",
      "Epoch: 155 Batch: 300, loss: 1.7249139320657596\n",
      "Epoch: 155 Batch: 400, loss: 29.47427297777023\n",
      "Epoch: 155 Batch: 500, loss: 18.200996552257454\n",
      "Epoch: 156 Batch: 0, loss: 5.074054625901788\n",
      "Epoch: 156 Batch: 100, loss: 33.42390438496079\n",
      "Epoch: 156 Batch: 200, loss: 6.059957747517703\n",
      "Epoch: 156 Batch: 300, loss: 2.6191062166492296\n",
      "Epoch: 156 Batch: 400, loss: 3.4648242458358545\n",
      "Epoch: 156 Batch: 500, loss: 4.813936744603039\n",
      "Epoch: 157 Batch: 0, loss: 10.93045884644437\n",
      "Epoch: 157 Batch: 100, loss: 0.05921743013064872\n",
      "Epoch: 157 Batch: 200, loss: 4.949382171504075\n",
      "Epoch: 157 Batch: 300, loss: 39.02190178856933\n",
      "Epoch: 157 Batch: 400, loss: 1.7547755052498548\n",
      "Epoch: 157 Batch: 500, loss: 22.587099634216656\n",
      "Epoch: 158 Batch: 0, loss: 7.881751123596594\n",
      "Epoch: 158 Batch: 100, loss: 12.401002781532101\n",
      "Epoch: 158 Batch: 200, loss: 2.920965460264255\n",
      "Epoch: 158 Batch: 300, loss: 8.315770361241428\n",
      "Epoch: 158 Batch: 400, loss: 4.454979602751133\n",
      "Epoch: 158 Batch: 500, loss: 14.310838921174804\n",
      "Epoch: 159 Batch: 0, loss: 168.80238893023406\n",
      "Epoch: 159 Batch: 100, loss: 24.170811207360952\n",
      "Epoch: 159 Batch: 200, loss: 216.30275915147053\n",
      "Epoch: 159 Batch: 300, loss: 294.70191755349384\n",
      "Epoch: 159 Batch: 400, loss: 97.64008864238794\n",
      "Epoch: 159 Batch: 500, loss: 11.25599391940075\n",
      "Epoch: 160 Batch: 0, loss: 42.72285487528589\n",
      "Epoch: 160 Batch: 100, loss: 8.097283359233687\n",
      "Epoch: 160 Batch: 200, loss: 7.24289440764189\n",
      "Epoch: 160 Batch: 300, loss: 152.39862005449484\n",
      "Epoch: 160 Batch: 400, loss: 4.785207196936255\n",
      "Epoch: 160 Batch: 500, loss: 2.882416034796696\n",
      "Epoch: 161 Batch: 0, loss: 39.480977662064916\n",
      "Epoch: 161 Batch: 100, loss: 4.809037194353831\n",
      "Epoch: 161 Batch: 200, loss: 0.14136090341162094\n",
      "Epoch: 161 Batch: 300, loss: 0.7055133144989374\n",
      "Epoch: 161 Batch: 400, loss: 14.66023190697396\n",
      "Epoch: 161 Batch: 500, loss: 0.02216682360828751\n",
      "Epoch: 162 Batch: 0, loss: 21.38266212628996\n",
      "Epoch: 162 Batch: 100, loss: 51.52915085890097\n",
      "Epoch: 162 Batch: 200, loss: 53.21569137595285\n",
      "Epoch: 162 Batch: 300, loss: 0.07644437507959699\n",
      "Epoch: 162 Batch: 400, loss: 26.61530085150196\n",
      "Epoch: 162 Batch: 500, loss: 0.625977938743461\n",
      "Epoch: 163 Batch: 0, loss: 2.4389366311925578\n",
      "Epoch: 163 Batch: 100, loss: 2.255448274165223\n",
      "Epoch: 163 Batch: 200, loss: 32.50311841408912\n",
      "Epoch: 163 Batch: 300, loss: 1.030662239547901\n",
      "Epoch: 163 Batch: 400, loss: 1.4316704693882725\n",
      "Epoch: 163 Batch: 500, loss: 31.416204884120315\n",
      "Epoch: 164 Batch: 0, loss: 5.800622709238231\n",
      "Epoch: 164 Batch: 100, loss: 3.546960540981517\n",
      "Epoch: 164 Batch: 200, loss: 75.80450311822406\n",
      "Epoch: 164 Batch: 300, loss: 0.8354961860586496\n",
      "Epoch: 164 Batch: 400, loss: 0.004222665106230532\n",
      "Epoch: 164 Batch: 500, loss: 0.3234651064745833\n",
      "Epoch: 165 Batch: 0, loss: 0.28016334806481835\n",
      "Epoch: 165 Batch: 100, loss: 0.29055334714583186\n",
      "Epoch: 165 Batch: 200, loss: 12.07591534090401\n",
      "Epoch: 165 Batch: 300, loss: 4.675488839080987\n",
      "Epoch: 165 Batch: 400, loss: 37.48419395492516\n",
      "Epoch: 165 Batch: 500, loss: 0.20711592923846353\n",
      "Epoch: 166 Batch: 0, loss: 8.420671468408537\n",
      "Epoch: 166 Batch: 100, loss: 4.912693390087383\n",
      "Epoch: 166 Batch: 200, loss: 1.0518944900970222\n",
      "Epoch: 166 Batch: 300, loss: 0.8604305520877082\n",
      "Epoch: 166 Batch: 400, loss: 67.00579488135672\n",
      "Epoch: 166 Batch: 500, loss: 15.368450612467122\n",
      "Epoch: 167 Batch: 0, loss: 17.252058963392326\n",
      "Epoch: 167 Batch: 100, loss: 23.250552795744174\n",
      "Epoch: 167 Batch: 200, loss: 0.035342996140788695\n",
      "Epoch: 167 Batch: 300, loss: 43.088623458284786\n",
      "Epoch: 167 Batch: 400, loss: 4.071471045468697\n",
      "Epoch: 167 Batch: 500, loss: 6.708620989418844\n",
      "Epoch: 168 Batch: 0, loss: 16.496965780974985\n",
      "Epoch: 168 Batch: 100, loss: 12.776133161260017\n",
      "Epoch: 168 Batch: 200, loss: 1.2407366260429566\n",
      "Epoch: 168 Batch: 300, loss: 1.21579052219987\n",
      "Epoch: 168 Batch: 400, loss: 16.748044753707852\n",
      "Epoch: 168 Batch: 500, loss: 0.5053522349342916\n",
      "Epoch: 169 Batch: 0, loss: 16.725742019452166\n",
      "Epoch: 169 Batch: 100, loss: 2.9874650932224602\n",
      "Epoch: 169 Batch: 200, loss: 0.6420318287957362\n",
      "Epoch: 169 Batch: 300, loss: 3.598741406388845\n",
      "Epoch: 169 Batch: 400, loss: 3.1735450747373144\n",
      "Epoch: 169 Batch: 500, loss: 4.941932823175447\n",
      "Epoch: 170 Batch: 0, loss: 0.11770172135102061\n",
      "Epoch: 170 Batch: 100, loss: 0.2275166588101557\n",
      "Epoch: 170 Batch: 200, loss: 0.010411786000395194\n",
      "Epoch: 170 Batch: 300, loss: 1.1340388675774322\n",
      "Epoch: 170 Batch: 400, loss: 44.57073966388271\n",
      "Epoch: 170 Batch: 500, loss: 32.00134475718122\n",
      "Epoch: 171 Batch: 0, loss: 17.601692511799584\n",
      "Epoch: 171 Batch: 100, loss: 11.270746789685422\n",
      "Epoch: 171 Batch: 200, loss: 10.030529829283523\n",
      "Epoch: 171 Batch: 300, loss: 0.16510077223411512\n",
      "Epoch: 171 Batch: 400, loss: 12.003638554455911\n",
      "Epoch: 171 Batch: 500, loss: 6.399932923127939\n",
      "Epoch: 172 Batch: 0, loss: 3.8939020919177656\n",
      "Epoch: 172 Batch: 100, loss: 0.06651703910016311\n",
      "Epoch: 172 Batch: 200, loss: 37.32190743159482\n",
      "Epoch: 172 Batch: 300, loss: 1.4415160061279035\n",
      "Epoch: 172 Batch: 400, loss: 6.863313206906573\n",
      "Epoch: 172 Batch: 500, loss: 3.24047214866687\n",
      "Epoch: 173 Batch: 0, loss: 104.27096682796176\n",
      "Epoch: 173 Batch: 100, loss: 12.399047515904227\n",
      "Epoch: 173 Batch: 200, loss: 299.5678834200183\n",
      "Epoch: 173 Batch: 300, loss: 2.207082924140982\n",
      "Epoch: 173 Batch: 400, loss: 16.5586043130342\n",
      "Epoch: 173 Batch: 500, loss: 108.89983788018348\n",
      "Epoch: 174 Batch: 0, loss: 211.8253166299149\n",
      "Epoch: 174 Batch: 100, loss: 8.182264488853372\n",
      "Epoch: 174 Batch: 200, loss: 0.07291532171598304\n",
      "Epoch: 174 Batch: 300, loss: 70.68777522361997\n",
      "Epoch: 174 Batch: 400, loss: 6.7982220772605855\n",
      "Epoch: 174 Batch: 500, loss: 0.12828691102149517\n",
      "Epoch: 175 Batch: 0, loss: 0.03117180842134457\n",
      "Epoch: 175 Batch: 100, loss: 0.36843567035125124\n",
      "Epoch: 175 Batch: 200, loss: 20.654803129610254\n",
      "Epoch: 175 Batch: 300, loss: 7.566966161959531\n",
      "Epoch: 175 Batch: 400, loss: 5.579476639110499\n",
      "Epoch: 175 Batch: 500, loss: 24.322286224884774\n",
      "Epoch: 176 Batch: 0, loss: 1.2860070955241998\n",
      "Epoch: 176 Batch: 100, loss: 44.32924699763763\n",
      "Epoch: 176 Batch: 200, loss: 64.90017944718855\n",
      "Epoch: 176 Batch: 300, loss: 0.7415534940278969\n",
      "Epoch: 176 Batch: 400, loss: 0.0027018693317130463\n",
      "Epoch: 176 Batch: 500, loss: 306.01210792916186\n",
      "Epoch: 177 Batch: 0, loss: 27.96001676146959\n",
      "Epoch: 177 Batch: 100, loss: 176.0582683802319\n",
      "Epoch: 177 Batch: 200, loss: 13.116173928414167\n",
      "Epoch: 177 Batch: 300, loss: 0.02937803799505361\n",
      "Epoch: 177 Batch: 400, loss: 8.609737120865324\n",
      "Epoch: 177 Batch: 500, loss: 3.1266322312685864\n",
      "Epoch: 178 Batch: 0, loss: 0.047667610243790653\n",
      "Epoch: 178 Batch: 100, loss: 107.16678208436205\n",
      "Epoch: 178 Batch: 200, loss: 208.17844650475422\n",
      "Epoch: 178 Batch: 300, loss: 7.223478586068895\n",
      "Epoch: 178 Batch: 400, loss: 0.6833558135263219\n",
      "Epoch: 178 Batch: 500, loss: 10.01961521062868\n",
      "Epoch: 179 Batch: 0, loss: 21.274868835519953\n",
      "Epoch: 179 Batch: 100, loss: 5.8800860850142325\n",
      "Epoch: 179 Batch: 200, loss: 0.33517744927529075\n",
      "Epoch: 179 Batch: 300, loss: 1.985154266751672\n",
      "Epoch: 179 Batch: 400, loss: 3.28674924175301\n",
      "Epoch: 179 Batch: 500, loss: 1.4528404646628126\n",
      "Epoch: 180 Batch: 0, loss: 22.100998358492465\n",
      "Epoch: 180 Batch: 100, loss: 48.00864573114565\n",
      "Epoch: 180 Batch: 200, loss: 2.97413272497062\n",
      "Epoch: 180 Batch: 300, loss: 4.910631930853178\n",
      "Epoch: 180 Batch: 400, loss: 0.5162285124190582\n",
      "Epoch: 180 Batch: 500, loss: 4.726663262972804\n",
      "Epoch: 181 Batch: 0, loss: 24.066472571728916\n",
      "Epoch: 181 Batch: 100, loss: 22.879965060862585\n",
      "Epoch: 181 Batch: 200, loss: 31.78068305319492\n",
      "Epoch: 181 Batch: 300, loss: 3.561568276737582\n",
      "Epoch: 181 Batch: 400, loss: 112.08385714410143\n",
      "Epoch: 181 Batch: 500, loss: 24.931416884366833\n",
      "Epoch: 182 Batch: 0, loss: 1.7613894550267446\n",
      "Epoch: 182 Batch: 100, loss: 6.921158120450318\n",
      "Epoch: 182 Batch: 200, loss: 13.71943948036997\n",
      "Epoch: 182 Batch: 300, loss: 2.2109335115368194\n",
      "Epoch: 182 Batch: 400, loss: 0.32720862094099473\n",
      "Epoch: 182 Batch: 500, loss: 5.701387873828209\n",
      "Epoch: 183 Batch: 0, loss: 0.02188007868584527\n",
      "Epoch: 183 Batch: 100, loss: 48.47972802875554\n",
      "Epoch: 183 Batch: 200, loss: 0.5551507597641304\n",
      "Epoch: 183 Batch: 300, loss: 5.1372756825128425\n",
      "Epoch: 183 Batch: 400, loss: 50.75439974066295\n",
      "Epoch: 183 Batch: 500, loss: 2.9489697194513487\n",
      "Epoch: 184 Batch: 0, loss: 36.88116169058242\n",
      "Epoch: 184 Batch: 100, loss: 4.188562085766582\n",
      "Epoch: 184 Batch: 200, loss: 17.383697419964538\n",
      "Epoch: 184 Batch: 300, loss: 22.415241934862625\n",
      "Epoch: 184 Batch: 400, loss: 55.05378814534837\n",
      "Epoch: 184 Batch: 500, loss: 10.109968612785385\n",
      "Epoch: 185 Batch: 0, loss: 2.0027924056936572\n",
      "Epoch: 185 Batch: 100, loss: 0.36392110961715307\n",
      "Epoch: 185 Batch: 200, loss: 0.010661771471984875\n",
      "Epoch: 185 Batch: 300, loss: 5.496205654030037\n",
      "Epoch: 185 Batch: 400, loss: 8.724190111673732\n",
      "Epoch: 185 Batch: 500, loss: 0.03340829491114871\n",
      "Epoch: 186 Batch: 0, loss: 0.837194475512036\n",
      "Epoch: 186 Batch: 100, loss: 23.115728577697386\n",
      "Epoch: 186 Batch: 200, loss: 1.8844216591142853\n",
      "Epoch: 186 Batch: 300, loss: 107.60200709869288\n",
      "Epoch: 186 Batch: 400, loss: 66.9584073261485\n",
      "Epoch: 186 Batch: 500, loss: 4.0312995261803355\n",
      "Epoch: 187 Batch: 0, loss: 3.8460064949949597\n",
      "Epoch: 187 Batch: 100, loss: 1.4874557614235762\n",
      "Epoch: 187 Batch: 200, loss: 0.3390208850807318\n",
      "Epoch: 187 Batch: 300, loss: 41.535720485829145\n",
      "Epoch: 187 Batch: 400, loss: 0.4411793511408583\n",
      "Epoch: 187 Batch: 500, loss: 2.1415719155012334\n",
      "Epoch: 188 Batch: 0, loss: 51.86147841252814\n",
      "Epoch: 188 Batch: 100, loss: 0.32244784870847737\n",
      "Epoch: 188 Batch: 200, loss: 1.2427853975747791\n",
      "Epoch: 188 Batch: 300, loss: 1.3180284775263007\n",
      "Epoch: 188 Batch: 400, loss: 0.2996886151089877\n",
      "Epoch: 188 Batch: 500, loss: 0.7434368510519636\n",
      "Epoch: 189 Batch: 0, loss: 77.63548015739445\n",
      "Epoch: 189 Batch: 100, loss: 0.01047669040089145\n",
      "Epoch: 189 Batch: 200, loss: 19.877076530508873\n",
      "Epoch: 189 Batch: 300, loss: 3.564660886479485\n",
      "Epoch: 189 Batch: 400, loss: 16.541773625826597\n",
      "Epoch: 189 Batch: 500, loss: 60.21161128908454\n",
      "Epoch: 190 Batch: 0, loss: 203.37736868250744\n",
      "Epoch: 190 Batch: 100, loss: 0.034164138177546814\n",
      "Epoch: 190 Batch: 200, loss: 68.01893201301928\n",
      "Epoch: 190 Batch: 300, loss: 108.47127285629146\n",
      "Epoch: 190 Batch: 400, loss: 24.77840852170908\n",
      "Epoch: 190 Batch: 500, loss: 46.404497632232086\n",
      "Epoch: 191 Batch: 0, loss: 0.515926444981476\n",
      "Epoch: 191 Batch: 100, loss: 18.40769192904586\n",
      "Epoch: 191 Batch: 200, loss: 160.96339686031033\n",
      "Epoch: 191 Batch: 300, loss: 20.335284602579545\n",
      "Epoch: 191 Batch: 400, loss: 14.118009449044022\n",
      "Epoch: 191 Batch: 500, loss: 1.3927868090359101\n",
      "Epoch: 192 Batch: 0, loss: 0.12722291016932558\n",
      "Epoch: 192 Batch: 100, loss: 4.990898994290321\n",
      "Epoch: 192 Batch: 200, loss: 49.985898212626076\n",
      "Epoch: 192 Batch: 300, loss: 5.819948200524504\n",
      "Epoch: 192 Batch: 400, loss: 2.0815284781242283\n",
      "Epoch: 192 Batch: 500, loss: 11.486505338674743\n",
      "Epoch: 193 Batch: 0, loss: 1.303873733603203\n",
      "Epoch: 193 Batch: 100, loss: 3.105908033490596\n",
      "Epoch: 193 Batch: 200, loss: 16.419705927104193\n",
      "Epoch: 193 Batch: 300, loss: 35.61365950130617\n",
      "Epoch: 193 Batch: 400, loss: 4.989323217183129\n",
      "Epoch: 193 Batch: 500, loss: 666.5370032779995\n",
      "Epoch: 194 Batch: 0, loss: 14.451791860993183\n",
      "Epoch: 194 Batch: 100, loss: 8.561299387018398\n",
      "Epoch: 194 Batch: 200, loss: 21.51017765004667\n",
      "Epoch: 194 Batch: 300, loss: 0.061109637925816127\n",
      "Epoch: 194 Batch: 400, loss: 46.53404968158642\n",
      "Epoch: 194 Batch: 500, loss: 7.029532233490045\n",
      "Epoch: 195 Batch: 0, loss: 0.3429446573389878\n",
      "Epoch: 195 Batch: 100, loss: 0.5670846071315144\n",
      "Epoch: 195 Batch: 200, loss: 0.4778446981891395\n",
      "Epoch: 195 Batch: 300, loss: 0.7737669925838613\n",
      "Epoch: 195 Batch: 400, loss: 4.081983083762713\n",
      "Epoch: 195 Batch: 500, loss: 161.51085659459523\n",
      "Epoch: 196 Batch: 0, loss: 5.7545156238703825\n",
      "Epoch: 196 Batch: 100, loss: 8.394238356093071\n",
      "Epoch: 196 Batch: 200, loss: 2.5617480382449083\n",
      "Epoch: 196 Batch: 300, loss: 0.6924542750688649\n",
      "Epoch: 196 Batch: 400, loss: 10.900521595767822\n",
      "Epoch: 196 Batch: 500, loss: 2.4414725268654984\n",
      "Epoch: 197 Batch: 0, loss: 113.01760673329254\n",
      "Epoch: 197 Batch: 100, loss: 4.6619261235019875\n",
      "Epoch: 197 Batch: 200, loss: 221.87757028755647\n",
      "Epoch: 197 Batch: 300, loss: 3.614797502791166\n",
      "Epoch: 197 Batch: 400, loss: 2.973629642654887\n",
      "Epoch: 197 Batch: 500, loss: 0.5381497421123567\n",
      "Epoch: 198 Batch: 0, loss: 7.142687518087803\n",
      "Epoch: 198 Batch: 100, loss: 3.7119425038941434\n",
      "Epoch: 198 Batch: 200, loss: 0.8162832008057704\n",
      "Epoch: 198 Batch: 300, loss: 27.90841130723144\n",
      "Epoch: 198 Batch: 400, loss: 9.634794569879958\n",
      "Epoch: 198 Batch: 500, loss: 35.10724974096358\n",
      "Epoch: 199 Batch: 0, loss: 26.078123994795543\n",
      "Epoch: 199 Batch: 100, loss: 0.05447255292681944\n",
      "Epoch: 199 Batch: 200, loss: 0.9255806400032347\n",
      "Epoch: 199 Batch: 300, loss: 1.3591963576093222\n",
      "Epoch: 199 Batch: 400, loss: 38.21257999477358\n",
      "Epoch: 199 Batch: 500, loss: 90.42522456725656\n",
      "[87.53319431]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"297.190125pt\" version=\"1.1\" viewBox=\"0 0 397.6075 297.190125\" width=\"397.6075pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-09-02T11:48:49.547423</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 297.190125 \nL 397.6075 297.190125 \nL 397.6075 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 273.312 \nL 390.4075 273.312 \nL 390.4075 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m35f693d2b3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.520227\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(46.338977 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"90.305974\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(83.943474 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"131.091721\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(124.729221 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.877468\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(165.514968 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.663215\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(203.119465 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"253.448962\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(243.905212 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.234709\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(284.690959 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"335.020456\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(325.476706 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.806203\" xlink:href=\"#m35f693d2b3\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(366.262453 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"me06f76f4fe\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"259.735852\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 25 -->\n      <g transform=\"translate(13.5625 263.535071)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"228.901252\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 232.700471)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"198.066652\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 75 -->\n      <g transform=\"translate(13.5625 201.86587)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"167.232052\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 171.03127)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"136.397451\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 125 -->\n      <g transform=\"translate(7.2 140.19667)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"105.562851\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 109.36207)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"74.728251\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 175 -->\n      <g transform=\"translate(7.2 78.52747)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"43.893651\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 47.69287)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#me06f76f4fe\" y=\"13.059051\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 225 -->\n      <g transform=\"translate(7.2 16.858269)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#pd61cd17e2f)\" d=\"M 49.520227 19.296 \nL 51.151657 46.466908 \nL 52.783087 97.834827 \nL 54.414517 121.017798 \nL 56.045947 168.677905 \nL 57.677377 171.112865 \nL 59.308807 176.925737 \nL 60.940236 202.550025 \nL 62.571666 207.475593 \nL 64.203096 223.657698 \nL 65.834526 222.977254 \nL 67.465956 221.138883 \nL 69.097386 236.04329 \nL 70.728816 235.487265 \nL 72.360246 241.764195 \nL 73.991675 235.24414 \nL 77.254535 250.020854 \nL 78.885965 246.981331 \nL 80.517395 253.50352 \nL 82.148825 248.243984 \nL 83.780255 253.798103 \nL 85.411685 249.261268 \nL 87.043114 259.044245 \nL 88.674544 246.888551 \nL 90.305974 249.853327 \nL 91.937404 259.770655 \nL 93.568834 250.925955 \nL 95.200264 254.266555 \nL 96.831694 254.757089 \nL 98.463124 250.115339 \nL 100.094553 258.708323 \nL 101.725983 257.04848 \nL 103.357413 253.86736 \nL 104.988843 255.336177 \nL 106.620273 256.002309 \nL 108.251703 252.00248 \nL 109.883133 254.563439 \nL 111.514563 255.173734 \nL 113.145992 250.483582 \nL 114.777422 251.660106 \nL 116.408852 257.032828 \nL 118.040282 255.391119 \nL 119.671712 248.31673 \nL 121.303142 254.232855 \nL 122.934572 251.133631 \nL 124.566002 250.180281 \nL 126.197431 250.469775 \nL 127.828861 246.070693 \nL 129.460291 245.150812 \nL 131.091721 258.677024 \nL 132.723151 253.329881 \nL 134.354581 249.933594 \nL 135.986011 247.645354 \nL 137.617441 256.360492 \nL 139.24887 250.648946 \nL 140.8803 253.418549 \nL 142.51173 253.505445 \nL 144.14316 253.342006 \nL 145.77459 250.635015 \nL 147.40602 255.079286 \nL 149.03745 253.570826 \nL 150.66888 250.53614 \nL 152.30031 252.467057 \nL 153.931739 258.153359 \nL 155.563169 256.636403 \nL 157.194599 257.048395 \nL 158.826029 253.882341 \nL 160.457459 252.976679 \nL 162.088889 251.119965 \nL 165.351749 255.597256 \nL 166.983178 253.616926 \nL 168.614608 248.311089 \nL 171.877468 259.82421 \nL 173.508898 243.494755 \nL 175.140328 248.079973 \nL 176.771758 254.911391 \nL 178.403188 246.668583 \nL 180.034617 256.861771 \nL 181.666047 251.283422 \nL 183.297477 254.971489 \nL 184.928907 253.417536 \nL 186.560337 252.888616 \nL 188.191767 258.745907 \nL 189.823197 257.617467 \nL 191.454627 257.887093 \nL 193.086056 255.156101 \nL 196.348916 247.914839 \nL 197.980346 254.275764 \nL 199.611776 247.856969 \nL 201.243206 255.396084 \nL 202.874636 259.356302 \nL 204.506066 255.552228 \nL 206.137495 252.499351 \nL 207.768925 260.901475 \nL 209.400355 254.498027 \nL 211.031785 249.875267 \nL 212.663215 259.048047 \nL 214.294645 258.185197 \nL 215.926075 248.284403 \nL 217.557505 258.384042 \nL 220.820364 255.300469 \nL 222.451794 245.236605 \nL 224.083224 250.404358 \nL 225.714654 251.35574 \nL 227.346084 260.725827 \nL 228.977514 252.434216 \nL 230.608944 250.2585 \nL 232.240373 251.759363 \nL 233.871803 250.149116 \nL 235.503233 246.8598 \nL 237.134663 256.748897 \nL 238.766093 251.007116 \nL 240.397523 256.969939 \nL 242.028953 253.907298 \nL 243.660383 256.016634 \nL 245.291812 253.732093 \nL 246.923242 253.399991 \nL 248.554672 255.832282 \nL 250.186102 257.707583 \nL 253.448962 249.330937 \nL 255.080392 252.344677 \nL 256.711822 257.166321 \nL 258.343251 250.47692 \nL 259.974681 250.516339 \nL 261.606111 251.307786 \nL 263.237541 252.520664 \nL 264.868971 258.494179 \nL 266.500401 253.749153 \nL 268.131831 249.375494 \nL 269.763261 254.031069 \nL 271.39469 255.28747 \nL 273.02612 256.335625 \nL 274.65755 244.664218 \nL 276.28898 250.55804 \nL 277.92041 254.277645 \nL 279.55184 254.355962 \nL 281.18327 245.699065 \nL 282.8147 250.683124 \nL 284.44613 253.336931 \nL 286.077559 252.329875 \nL 287.708989 252.971448 \nL 289.340419 256.050518 \nL 290.971849 253.386702 \nL 292.603279 258.493574 \nL 294.234709 257.027005 \nL 295.866139 248.168995 \nL 297.497569 251.279217 \nL 299.128998 253.267748 \nL 300.760428 257.750139 \nL 304.023288 247.948142 \nL 305.654718 257.069157 \nL 307.286148 257.344018 \nL 308.917578 254.37955 \nL 310.549008 248.055294 \nL 312.180437 248.41928 \nL 313.811867 254.98009 \nL 315.443297 250.398536 \nL 317.074727 259.540314 \nL 318.706157 256.840787 \nL 320.337587 261.216 \nL 321.969017 255.459916 \nL 323.600447 254.268412 \nL 325.231876 260.149686 \nL 326.863306 254.958903 \nL 328.494736 254.021306 \nL 330.126166 257.574785 \nL 331.757596 253.3363 \nL 333.389026 255.133361 \nL 335.020456 251.396703 \nL 336.651886 253.911624 \nL 338.283315 252.198282 \nL 339.914745 257.041958 \nL 341.546175 252.532763 \nL 343.177605 257.61102 \nL 344.809035 253.379737 \nL 346.440465 255.436054 \nL 348.071895 256.622008 \nL 349.703325 253.900005 \nL 351.334754 256.4129 \nL 352.966184 251.49761 \nL 354.597614 260.29662 \nL 357.860474 252.111325 \nL 359.491904 252.207312 \nL 361.123334 251.36077 \nL 362.754764 256.775967 \nL 364.386193 252.560246 \nL 366.017623 249.479032 \nL 367.649053 254.199468 \nL 369.280483 257.602448 \nL 370.911913 249.83002 \nL 372.543343 256.427477 \nL 374.174773 255.536444 \nL 374.174773 255.536444 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 273.312 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 390.4075 273.312 \nL 390.4075 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 273.312 \nL 390.4075 273.312 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 390.4075 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd61cd17e2f\">\n   <rect height=\"266.112\" width=\"357.12\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logstic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "实现了回归，其中包括线性函数的定义，为什么要用线性函数，loss的意义，梯度下降的意义，stochastic gradient descent\n",
    "Use Boston house price dataset.\n",
    "北京2020年房价的数据集，为什么我没有用北京房价的数据集呢？\n",
    "Boston: room size, subway, highway, crime rate 有一个比较明显的关系，所以就观察关系比较容易\n",
    "北京的房价：！远近，！房况 ==》 学区！！！！ => 非常贵 海淀区\n",
    "Harder than deep learning:\n",
    "    \n",
    "1. compiler\n",
    "2. programming language & automata\n",
    "3. computer graphic\n",
    "4. complexity system\n",
    "5. computing complexity\n",
    "6. operating system"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "dataset = load_boston()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = target\n",
    "\n",
    "# print(dataframe.corr()) # show the correlation of dataframe variables\n",
    "# correlation => 如果一个值的增大，会引起另外一个值一定增大，而且是定比例增大 相关系数就越接近于1\n",
    "# correlation => 0 就是两者之间没有任何关系\n",
    "# correlation => -1 一个值增大 另外一个值一定减小 而且减小是成相等比例的\n",
    "\n",
    "# sns.heatmap(dataframe.corr())\n",
    "# plt.show()\n",
    "\n",
    "# RM：小区平均的卧室个数\n",
    "# LSTAT: 低收入人群在周围的比例\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']\n",
    "price = dataframe['price']\n",
    "greater_then_most = np.percentile(price, 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "target = dataframe['expensive']\n",
    "\n",
    "print(dataframe[:20])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
      "0   0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
      "1   0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
      "2   0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
      "3   0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
      "4   0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
      "5   0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
      "6   0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
      "7   0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
      "8   0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
      "9   0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
      "10  0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467  5.0  311.0   \n",
      "11  0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267  5.0  311.0   \n",
      "12  0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509  5.0  311.0   \n",
      "13  0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075  4.0  307.0   \n",
      "14  0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619  4.0  307.0   \n",
      "15  0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986  4.0  307.0   \n",
      "16  1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986  4.0  307.0   \n",
      "17  0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579  4.0  307.0   \n",
      "18  0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965  4.0  307.0   \n",
      "19  0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965  4.0  307.0   \n",
      "\n",
      "    PTRATIO       B  LSTAT  price  expensive  \n",
      "0      15.3  396.90   4.98   24.0          1  \n",
      "1      17.8  396.90   9.14   21.6          0  \n",
      "2      17.8  392.83   4.03   34.7          1  \n",
      "3      18.7  394.63   2.94   33.4          1  \n",
      "4      18.7  396.90   5.33   36.2          1  \n",
      "5      18.7  394.12   5.21   28.7          1  \n",
      "6      15.2  395.60  12.43   22.9          0  \n",
      "7      15.2  396.90  19.15   27.1          1  \n",
      "8      15.2  386.63  29.93   16.5          0  \n",
      "9      15.2  386.71  17.10   18.9          0  \n",
      "10     15.2  392.52  20.45   15.0          0  \n",
      "11     15.2  396.90  13.27   18.9          0  \n",
      "12     15.2  390.50  15.71   21.7          0  \n",
      "13     21.0  396.90   8.26   20.4          0  \n",
      "14     21.0  380.02  10.26   18.2          0  \n",
      "15     21.0  395.62   8.47   19.9          0  \n",
      "16     21.0  386.85   6.58   23.1          0  \n",
      "17     21.0  386.75  14.67   17.5          0  \n",
      "18     21.0  288.99  11.69   20.2          0  \n",
      "19     21.0  390.95  11.28   18.2          0  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def model(x, w, b):\n",
    "    return sigmoid(np.dot(x, w.T) + b)\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y*np.log(yhat) + (1 - y)*np.log(1 - yhat))\n",
    "\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "\n",
    "model, w, b, losses = train(model, target,loss, partial_w, partial_b)\n",
    "\n",
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Batch: 0, loss: 21.253067852266536\n",
      "Epoch: 0 Batch: 100, loss: 0.0006849557790341931\n",
      "Epoch: 0 Batch: 200, loss: 24.38334293723387\n",
      "Epoch: 0 Batch: 300, loss: 1.2742252610593014e-05\n",
      "Epoch: 0 Batch: 400, loss: 10.693694155096928\n",
      "Epoch: 0 Batch: 500, loss: 2.5396179842061183e-07\n",
      "Epoch: 1 Batch: 0, loss: 10.44026817450651\n",
      "Epoch: 1 Batch: 100, loss: 22.68306555112414\n",
      "Epoch: 1 Batch: 200, loss: 15.526704997223845\n",
      "Epoch: 1 Batch: 300, loss: 18.954875757516987\n",
      "Epoch: 1 Batch: 400, loss: 0.0004715977016895439\n",
      "Epoch: 1 Batch: 500, loss: 15.209040769267633\n",
      "Epoch: 2 Batch: 0, loss: 9.57715187927263\n",
      "Epoch: 2 Batch: 100, loss: 13.758766504545607\n",
      "Epoch: 2 Batch: 200, loss: 14.485884147083423\n",
      "Epoch: 2 Batch: 300, loss: 0.0003990841627994008\n",
      "Epoch: 2 Batch: 400, loss: 0.0008632851925113479\n",
      "Epoch: 2 Batch: 500, loss: 3.2861097960686407e-06\n",
      "Epoch: 3 Batch: 0, loss: 15.46258938120003\n",
      "Epoch: 3 Batch: 100, loss: 2.7040999790665627e-05\n",
      "Epoch: 3 Batch: 200, loss: 13.241293090591238\n",
      "Epoch: 3 Batch: 300, loss: 17.717337007395606\n",
      "Epoch: 3 Batch: 400, loss: 8.19403377991456\n",
      "Epoch: 3 Batch: 500, loss: 13.192157865668754\n",
      "Epoch: 4 Batch: 0, loss: 13.332762952872281\n",
      "Epoch: 4 Batch: 100, loss: 8.42286712385988\n",
      "Epoch: 4 Batch: 200, loss: 15.715393179856463\n",
      "Epoch: 4 Batch: 300, loss: 0.002313750405113182\n",
      "Epoch: 4 Batch: 400, loss: 8.19308473197551\n",
      "Epoch: 4 Batch: 500, loss: 14.95156240486382\n",
      "Epoch: 5 Batch: 0, loss: 14.430685566041769\n",
      "Epoch: 5 Batch: 100, loss: 12.854204858566343\n",
      "Epoch: 5 Batch: 200, loss: 13.845895282455844\n",
      "Epoch: 5 Batch: 300, loss: 11.182991614809113\n",
      "Epoch: 5 Batch: 400, loss: 11.856287307659125\n",
      "Epoch: 5 Batch: 500, loss: 10.3720032935\n",
      "Epoch: 6 Batch: 0, loss: 0.0005765088824221748\n",
      "Epoch: 6 Batch: 100, loss: 11.841410806234636\n",
      "Epoch: 6 Batch: 200, loss: 8.55812257974606\n",
      "Epoch: 6 Batch: 300, loss: 6.6361859522077795\n",
      "Epoch: 6 Batch: 400, loss: 7.623942497262654\n",
      "Epoch: 6 Batch: 500, loss: 12.853308300032541\n",
      "Epoch: 7 Batch: 0, loss: 16.310531224683462\n",
      "Epoch: 7 Batch: 100, loss: 12.76653141010888\n",
      "Epoch: 7 Batch: 200, loss: 0.00012842605420950438"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/lilithgames/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Epoch: 7 Batch: 300, loss: 12.26395472756537\n",
      "Epoch: 7 Batch: 400, loss: 10.71170793991407\n",
      "Epoch: 7 Batch: 500, loss: 8.770488222138587\n",
      "Epoch: 8 Batch: 0, loss: 0.009396408306717365\n",
      "Epoch: 8 Batch: 100, loss: 0.0012223350415579706\n",
      "Epoch: 8 Batch: 200, loss: 10.603741101614984\n",
      "Epoch: 8 Batch: 300, loss: 0.0027293483712676034\n",
      "Epoch: 8 Batch: 400, loss: 0.006428247336544404\n",
      "Epoch: 8 Batch: 500, loss: 6.400209779848934\n",
      "Epoch: 9 Batch: 0, loss: 8.24793991240017\n",
      "Epoch: 9 Batch: 100, loss: 11.717656872517725\n",
      "Epoch: 9 Batch: 200, loss: 8.732751742823925\n",
      "Epoch: 9 Batch: 300, loss: 0.0043503050124818095\n",
      "Epoch: 9 Batch: 400, loss: 0.004955051324836836\n",
      "Epoch: 9 Batch: 500, loss: 6.011895478365885\n",
      "Epoch: 10 Batch: 0, loss: 0.01707067558098244\n",
      "Epoch: 10 Batch: 100, loss: 16.645411098419558\n",
      "Epoch: 10 Batch: 200, loss: 5.145380221404705\n",
      "Epoch: 10 Batch: 300, loss: 9.750413216509811\n",
      "Epoch: 10 Batch: 400, loss: 0.0037027573257448453\n",
      "Epoch: 10 Batch: 500, loss: 6.8332027578141465\n",
      "Epoch: 11 Batch: 0, loss: 0.003099112136502051\n",
      "Epoch: 11 Batch: 100, loss: 5.928730842963002\n",
      "Epoch: 11 Batch: 200, loss: 5.259975776399335\n",
      "Epoch: 11 Batch: 300, loss: 12.027192389523824\n",
      "Epoch: 11 Batch: 400, loss: 0.0016983763257396873\n",
      "Epoch: 11 Batch: 500, loss: 6.600849511222668\n",
      "Epoch: 12 Batch: 0, loss: 8.356569598934769\n",
      "Epoch: 12 Batch: 100, loss: 7.095741307565237\n",
      "Epoch: 12 Batch: 200, loss: 0.00482978121391248\n",
      "Epoch: 12 Batch: 300, loss: 5.342024141930156\n",
      "Epoch: 12 Batch: 400, loss: 4.11705159499382\n",
      "Epoch: 12 Batch: 500, loss: 5.049295816462178\n",
      "Epoch: 13 Batch: 0, loss: 4.381510676967548\n",
      "Epoch: 13 Batch: 100, loss: 7.621330424274787\n",
      "Epoch: 13 Batch: 200, loss: 3.8878609823814583\n",
      "Epoch: 13 Batch: 300, loss: 5.31264317688531\n",
      "Epoch: 13 Batch: 400, loss: 4.298340376303435\n",
      "Epoch: 13 Batch: 500, loss: 5.053027375667738\n",
      "Epoch: 14 Batch: 0, loss: 0.029234870504633213\n",
      "Epoch: 14 Batch: 100, loss: 0.04680002030112368\n",
      "Epoch: 14 Batch: 200, loss: 5.059401135306144\n",
      "Epoch: 14 Batch: 300, loss: 4.247125552160361\n",
      "Epoch: 14 Batch: 400, loss: 0.04673076934016206\n",
      "Epoch: 14 Batch: 500, loss: 3.811703267884085\n",
      "Epoch: 15 Batch: 0, loss: 0.0858432622161627\n",
      "Epoch: 15 Batch: 100, loss: 2.956522532767855\n",
      "Epoch: 15 Batch: 200, loss: 0.07785959404214408\n",
      "Epoch: 15 Batch: 300, loss: 0.03720954897990113\n",
      "Epoch: 15 Batch: 400, loss: 0.0970216582905111\n",
      "Epoch: 15 Batch: 500, loss: 3.503149833683776\n",
      "Epoch: 16 Batch: 0, loss: 0.0946290221401441\n",
      "Epoch: 16 Batch: 100, loss: 3.2105357609112586\n",
      "Epoch: 16 Batch: 200, loss: 0.118245115683586\n",
      "Epoch: 16 Batch: 300, loss: 2.863240682836843\n",
      "Epoch: 16 Batch: 400, loss: 2.525262387626891\n",
      "Epoch: 16 Batch: 500, loss: 0.10450190804057827\n",
      "Epoch: 17 Batch: 0, loss: 2.9456682487362778\n",
      "Epoch: 17 Batch: 100, loss: 0.15093620204681082\n",
      "Epoch: 17 Batch: 200, loss: 1.9174647828449158\n",
      "Epoch: 17 Batch: 300, loss: 0.1758871818976216\n",
      "Epoch: 17 Batch: 400, loss: 0.15671923157356968\n",
      "Epoch: 17 Batch: 500, loss: 1.7222091145415024\n",
      "Epoch: 18 Batch: 0, loss: 1.7337016904803713\n",
      "Epoch: 18 Batch: 100, loss: 1.7083807530110808\n",
      "Epoch: 18 Batch: 200, loss: 0.20314385433145812\n",
      "Epoch: 18 Batch: 300, loss: 0.21401044523526552\n",
      "Epoch: 18 Batch: 400, loss: 0.22237857289836038\n",
      "Epoch: 18 Batch: 500, loss: 1.016372383979692\n",
      "Epoch: 19 Batch: 0, loss: 0.23834973450932398\n",
      "Epoch: 19 Batch: 100, loss: 0.2096681684925477\n",
      "Epoch: 19 Batch: 200, loss: 1.3422110014246784\n",
      "Epoch: 19 Batch: 300, loss: 1.1900409106341625\n",
      "Epoch: 19 Batch: 400, loss: 0.26612741345367696\n",
      "Epoch: 19 Batch: 500, loss: 0.9028533168861572\n",
      "Epoch: 20 Batch: 0, loss: 0.3174907200357967\n",
      "Epoch: 20 Batch: 100, loss: 0.22704458173367012\n",
      "Epoch: 20 Batch: 200, loss: 1.0665844577378822\n",
      "Epoch: 20 Batch: 300, loss: 0.7206375640352788\n",
      "Epoch: 20 Batch: 400, loss: 0.949406759958324\n",
      "Epoch: 20 Batch: 500, loss: 0.7037670666699832\n",
      "Epoch: 21 Batch: 0, loss: 0.6101255882900783\n",
      "Epoch: 21 Batch: 100, loss: 0.8328223992482533\n",
      "Epoch: 21 Batch: 200, loss: 0.40355084095306026\n",
      "Epoch: 21 Batch: 300, loss: 0.13033700011748375\n",
      "Epoch: 21 Batch: 400, loss: 0.35212147535546984\n",
      "Epoch: 21 Batch: 500, loss: 0.6065726237800283\n",
      "Epoch: 22 Batch: 0, loss: 0.3486675925020823\n",
      "Epoch: 22 Batch: 100, loss: 0.8558593867919358\n",
      "Epoch: 22 Batch: 200, loss: 0.5635236813555397\n",
      "Epoch: 22 Batch: 300, loss: 0.34925226856181135\n",
      "Epoch: 22 Batch: 400, loss: 0.702439934768612\n",
      "Epoch: 22 Batch: 500, loss: 0.8490011814392979\n",
      "Epoch: 23 Batch: 0, loss: 0.3323687651663174\n",
      "Epoch: 23 Batch: 100, loss: 1.2222205407039528\n",
      "Epoch: 23 Batch: 200, loss: 0.394185216545157\n",
      "Epoch: 23 Batch: 300, loss: 0.4768420831319481\n",
      "Epoch: 23 Batch: 400, loss: 0.31606261830175136\n",
      "Epoch: 23 Batch: 500, loss: 0.3117510857432748\n",
      "Epoch: 24 Batch: 0, loss: 0.3435572130859231\n",
      "Epoch: 24 Batch: 100, loss: 0.14007833034256378\n",
      "Epoch: 24 Batch: 200, loss: 0.6627706823180456\n",
      "Epoch: 24 Batch: 300, loss: 0.4678268435039386\n",
      "Epoch: 24 Batch: 400, loss: 0.31680251017451566\n",
      "Epoch: 24 Batch: 500, loss: 0.8034714486930737\n",
      "Epoch: 25 Batch: 0, loss: 0.8130309838088557\n",
      "Epoch: 25 Batch: 100, loss: 0.4360766202451574\n",
      "Epoch: 25 Batch: 200, loss: 0.39818599995985243\n",
      "Epoch: 25 Batch: 300, loss: 0.804571999537741\n",
      "Epoch: 25 Batch: 400, loss: 0.015946868821602588\n",
      "Epoch: 25 Batch: 500, loss: 0.47791894894222287\n",
      "Epoch: 26 Batch: 0, loss: 0.12901222140759144\n",
      "Epoch: 26 Batch: 100, loss: 0.2675165089989646\n",
      "Epoch: 26 Batch: 200, loss: 0.1704435427689168\n",
      "Epoch: 26 Batch: 300, loss: 0.24198115965849923\n",
      "Epoch: 26 Batch: 400, loss: 0.38839118551230356\n",
      "Epoch: 26 Batch: 500, loss: 0.7092907410397835\n",
      "Epoch: 27 Batch: 0, loss: 0.5455834061203193\n",
      "Epoch: 27 Batch: 100, loss: 0.1381295758429119\n",
      "Epoch: 27 Batch: 200, loss: 0.4649115569189834\n",
      "Epoch: 27 Batch: 300, loss: 0.0857209181930244\n",
      "Epoch: 27 Batch: 400, loss: 0.5765551228485299\n",
      "Epoch: 27 Batch: 500, loss: 0.09462904100884068\n",
      "Epoch: 28 Batch: 0, loss: 0.7212365833426918\n",
      "Epoch: 28 Batch: 100, loss: 0.1223927978711519\n",
      "Epoch: 28 Batch: 200, loss: 0.37250133611163416\n",
      "Epoch: 28 Batch: 300, loss: 0.6479976470088429\n",
      "Epoch: 28 Batch: 400, loss: 0.37381486516350076\n",
      "Epoch: 28 Batch: 500, loss: 0.16616710815903837\n",
      "Epoch: 29 Batch: 0, loss: 0.22105261833354825\n",
      "Epoch: 29 Batch: 100, loss: 0.9901443605647752\n",
      "Epoch: 29 Batch: 200, loss: 0.42791460253026536\n",
      "Epoch: 29 Batch: 300, loss: 0.62673524593656\n",
      "Epoch: 29 Batch: 400, loss: 0.39184880312724113\n",
      "Epoch: 29 Batch: 500, loss: 0.0662688782318074\n",
      "Epoch: 30 Batch: 0, loss: 0.05019524340860099\n",
      "Epoch: 30 Batch: 100, loss: 0.4400848550089784\n",
      "Epoch: 30 Batch: 200, loss: 0.1599312471946271\n",
      "Epoch: 30 Batch: 300, loss: 0.07062924329393352\n",
      "Epoch: 30 Batch: 400, loss: 0.522898915484851\n",
      "Epoch: 30 Batch: 500, loss: 0.6070269556653489\n",
      "Epoch: 31 Batch: 0, loss: 0.6988725006089507\n",
      "Epoch: 31 Batch: 100, loss: 0.14985420473511338\n",
      "Epoch: 31 Batch: 200, loss: 1.1447479217599636\n",
      "Epoch: 31 Batch: 300, loss: 0.20953037444205294\n",
      "Epoch: 31 Batch: 400, loss: 0.6364553903560058\n",
      "Epoch: 31 Batch: 500, loss: 0.6176066691767245\n",
      "Epoch: 32 Batch: 0, loss: 0.8107584606835244\n",
      "Epoch: 32 Batch: 100, loss: 0.34315341900253415\n",
      "Epoch: 32 Batch: 200, loss: 0.23961868519934806\n",
      "Epoch: 32 Batch: 300, loss: 0.09889693434087726\n",
      "Epoch: 32 Batch: 400, loss: 0.6699489127815978\n",
      "Epoch: 32 Batch: 500, loss: 0.5679283571062862\n",
      "Epoch: 33 Batch: 0, loss: 0.7008977137242451\n",
      "Epoch: 33 Batch: 100, loss: 0.34528014426823583\n",
      "Epoch: 33 Batch: 200, loss: 0.28340494110000286\n",
      "Epoch: 33 Batch: 300, loss: 0.922230744910113\n",
      "Epoch: 33 Batch: 400, loss: 0.601075135822062\n",
      "Epoch: 33 Batch: 500, loss: 0.012142964051953484\n",
      "Epoch: 34 Batch: 0, loss: 0.4484509327314722\n",
      "Epoch: 34 Batch: 100, loss: 0.04812227932649168\n",
      "Epoch: 34 Batch: 200, loss: 0.4956529381756969\n",
      "Epoch: 34 Batch: 300, loss: 0.014607968482410805\n",
      "Epoch: 34 Batch: 400, loss: 0.33159266675782745\n",
      "Epoch: 34 Batch: 500, loss: 0.12762058741908336\n",
      "Epoch: 35 Batch: 0, loss: 0.7023219521293019\n",
      "Epoch: 35 Batch: 100, loss: 0.08842390355405814\n",
      "Epoch: 35 Batch: 200, loss: 1.1170868860785006\n",
      "Epoch: 35 Batch: 300, loss: 0.01678517240131246\n",
      "Epoch: 35 Batch: 400, loss: 0.031245642621303582\n",
      "Epoch: 35 Batch: 500, loss: 0.07213595951818631\n",
      "Epoch: 36 Batch: 0, loss: 0.03969657828953035\n",
      "Epoch: 36 Batch: 100, loss: 0.7550465707686178\n",
      "Epoch: 36 Batch: 200, loss: 0.11591517944321636\n",
      "Epoch: 36 Batch: 300, loss: 0.5866997616189321\n",
      "Epoch: 36 Batch: 400, loss: 0.0508849311418272\n",
      "Epoch: 36 Batch: 500, loss: 0.3133868158094289\n",
      "Epoch: 37 Batch: 0, loss: 0.026148528475242468\n",
      "Epoch: 37 Batch: 100, loss: 0.7454528626821552\n",
      "Epoch: 37 Batch: 200, loss: 0.22128987143003806\n",
      "Epoch: 37 Batch: 300, loss: 0.037093099690152904\n",
      "Epoch: 37 Batch: 400, loss: 0.08207449123281191\n",
      "Epoch: 37 Batch: 500, loss: 0.41111394599448664\n",
      "Epoch: 38 Batch: 0, loss: 0.48785967781218503\n",
      "Epoch: 38 Batch: 100, loss: 0.12233182431181233\n",
      "Epoch: 38 Batch: 200, loss: 0.0810340959687476\n",
      "Epoch: 38 Batch: 300, loss: 0.9547949059921549\n",
      "Epoch: 38 Batch: 400, loss: 0.5730447245080554\n",
      "Epoch: 38 Batch: 500, loss: 0.011035630197673642\n",
      "Epoch: 39 Batch: 0, loss: 0.9603435795077817\n",
      "Epoch: 39 Batch: 100, loss: 0.4045928700474186\n",
      "Epoch: 39 Batch: 200, loss: 0.496533418780952\n",
      "Epoch: 39 Batch: 300, loss: 0.299753295423134\n",
      "Epoch: 39 Batch: 400, loss: 0.008439482610875376\n",
      "Epoch: 39 Batch: 500, loss: 0.46252753484595205\n",
      "Epoch: 40 Batch: 0, loss: 1.353197294126374\n",
      "Epoch: 40 Batch: 100, loss: 0.6721915260186407\n",
      "Epoch: 40 Batch: 200, loss: 0.393470560425774\n",
      "Epoch: 40 Batch: 300, loss: 0.2846886707188852\n",
      "Epoch: 40 Batch: 400, loss: 0.3600642916426102\n",
      "Epoch: 40 Batch: 500, loss: 0.21973553068340426\n",
      "Epoch: 41 Batch: 0, loss: 0.40578770689413884\n",
      "Epoch: 41 Batch: 100, loss: 0.028588047808218345\n",
      "Epoch: 41 Batch: 200, loss: 0.13738080474636888\n",
      "Epoch: 41 Batch: 300, loss: 0.09239664793944224\n",
      "Epoch: 41 Batch: 400, loss: 0.15360703368238923\n",
      "Epoch: 41 Batch: 500, loss: 0.4636655817054293\n",
      "Epoch: 42 Batch: 0, loss: 0.2257129814896234\n",
      "Epoch: 42 Batch: 100, loss: 0.2931968390764176\n",
      "Epoch: 42 Batch: 200, loss: 0.5821744830036149\n",
      "Epoch: 42 Batch: 300, loss: 0.29240823455647336\n",
      "Epoch: 42 Batch: 400, loss: 0.2240258554158816\n",
      "Epoch: 42 Batch: 500, loss: 0.18113225697394725\n",
      "Epoch: 43 Batch: 0, loss: 0.1897694873060788\n",
      "Epoch: 43 Batch: 100, loss: 0.20255284245296862\n",
      "Epoch: 43 Batch: 200, loss: 0.5353120883482708\n",
      "Epoch: 43 Batch: 300, loss: 0.18313900620479304\n",
      "Epoch: 43 Batch: 400, loss: 0.48565291669532307\n",
      "Epoch: 43 Batch: 500, loss: 0.43357430927059687\n",
      "Epoch: 44 Batch: 0, loss: 0.0263056386425644\n",
      "Epoch: 44 Batch: 100, loss: 0.03815939579062025\n",
      "Epoch: 44 Batch: 200, loss: 0.008193489007424577\n",
      "Epoch: 44 Batch: 300, loss: 0.10840776738879442\n",
      "Epoch: 44 Batch: 400, loss: 0.4970181822606421\n",
      "Epoch: 44 Batch: 500, loss: 0.08386563846504591\n",
      "Epoch: 45 Batch: 0, loss: 1.6259396788908378\n",
      "Epoch: 45 Batch: 100, loss: 0.24959709862342663\n",
      "Epoch: 45 Batch: 200, loss: 0.8852270118655714\n",
      "Epoch: 45 Batch: 300, loss: 1.2186224243144665\n",
      "Epoch: 45 Batch: 400, loss: 0.3952798862462959\n",
      "Epoch: 45 Batch: 500, loss: 0.28198091490009985\n",
      "Epoch: 46 Batch: 0, loss: 0.6282916373279142\n",
      "Epoch: 46 Batch: 100, loss: 0.5356885124294676\n",
      "Epoch: 46 Batch: 200, loss: 0.5631183936369519\n",
      "Epoch: 46 Batch: 300, loss: 0.5330510600464308\n",
      "Epoch: 46 Batch: 400, loss: 0.3961154109610642\n",
      "Epoch: 46 Batch: 500, loss: 0.28785398068508805\n",
      "Epoch: 47 Batch: 0, loss: 0.3139222216377628\n",
      "Epoch: 47 Batch: 100, loss: 0.11442164485582429\n",
      "Epoch: 47 Batch: 200, loss: 0.5067586850418612\n",
      "Epoch: 47 Batch: 300, loss: 0.009836511141781313\n",
      "Epoch: 47 Batch: 400, loss: 1.020520559491204\n",
      "Epoch: 47 Batch: 500, loss: 0.6353293638898625\n",
      "Epoch: 48 Batch: 0, loss: 0.4969769776517884\n",
      "Epoch: 48 Batch: 100, loss: 0.9834088403248973\n",
      "Epoch: 48 Batch: 200, loss: 0.5094675174494108\n",
      "Epoch: 48 Batch: 300, loss: 0.9249057814924907\n",
      "Epoch: 48 Batch: 400, loss: 0.08743606431422554\n",
      "Epoch: 48 Batch: 500, loss: 0.8021716523958109\n",
      "Epoch: 49 Batch: 0, loss: 0.03442108557095752\n",
      "Epoch: 49 Batch: 100, loss: 0.016906536427905225\n",
      "Epoch: 49 Batch: 200, loss: 1.1309033686469787\n",
      "Epoch: 49 Batch: 300, loss: 1.0618906807424267\n",
      "Epoch: 49 Batch: 400, loss: 0.21441367244057488\n",
      "Epoch: 49 Batch: 500, loss: 0.5674889276556698\n",
      "Epoch: 50 Batch: 0, loss: 0.28270563954772404\n",
      "Epoch: 50 Batch: 100, loss: 0.1730799421986523\n",
      "Epoch: 50 Batch: 200, loss: 0.11932132579314833\n",
      "Epoch: 50 Batch: 300, loss: 0.49153757512055024\n",
      "Epoch: 50 Batch: 400, loss: 0.007654032621813352\n",
      "Epoch: 50 Batch: 500, loss: 0.9697544491950849\n",
      "Epoch: 51 Batch: 0, loss: 0.11360338735278683\n",
      "Epoch: 51 Batch: 100, loss: 0.27894335895642935\n",
      "Epoch: 51 Batch: 200, loss: 0.32604924716839967\n",
      "Epoch: 51 Batch: 300, loss: 0.017833375540576697\n",
      "Epoch: 51 Batch: 400, loss: 0.18883867192415157\n",
      "Epoch: 51 Batch: 500, loss: 0.5131985952108841\n",
      "Epoch: 52 Batch: 0, loss: 0.3740714382615062\n",
      "Epoch: 52 Batch: 100, loss: 0.3127404728564571\n",
      "Epoch: 52 Batch: 200, loss: 0.23949693424766524\n",
      "Epoch: 52 Batch: 300, loss: 0.006788861975279293\n",
      "Epoch: 52 Batch: 400, loss: 0.14002807445418955\n",
      "Epoch: 52 Batch: 500, loss: 0.0018291776925362581\n",
      "Epoch: 53 Batch: 0, loss: 0.0350463924140421\n",
      "Epoch: 53 Batch: 100, loss: 0.3515032679277313\n",
      "Epoch: 53 Batch: 200, loss: 0.11228241670268088\n",
      "Epoch: 53 Batch: 300, loss: 0.008358419690431093\n",
      "Epoch: 53 Batch: 400, loss: 1.0022930568767128\n",
      "Epoch: 53 Batch: 500, loss: 0.15068612005634274\n",
      "Epoch: 54 Batch: 0, loss: 0.25587845545960064\n",
      "Epoch: 54 Batch: 100, loss: 0.6685535588135972\n",
      "Epoch: 54 Batch: 200, loss: 0.29903304529806796\n",
      "Epoch: 54 Batch: 300, loss: 0.013955713586465563\n",
      "Epoch: 54 Batch: 400, loss: 0.34868308551444127\n",
      "Epoch: 54 Batch: 500, loss: 0.4668703006174877\n",
      "Epoch: 55 Batch: 0, loss: 0.1596122335864298\n",
      "Epoch: 55 Batch: 100, loss: 0.33610366848822576\n",
      "Epoch: 55 Batch: 200, loss: 0.030186601743350524\n",
      "Epoch: 55 Batch: 300, loss: 0.2929051522368894\n",
      "Epoch: 55 Batch: 400, loss: 0.45790033445467193\n",
      "Epoch: 55 Batch: 500, loss: 0.4575240720665052\n",
      "Epoch: 56 Batch: 0, loss: 0.054757224668421436\n",
      "Epoch: 56 Batch: 100, loss: 0.5884252504059949\n",
      "Epoch: 56 Batch: 200, loss: 0.5030790831974487\n",
      "Epoch: 56 Batch: 300, loss: 0.4193547255143064\n",
      "Epoch: 56 Batch: 400, loss: 0.3018903968955002\n",
      "Epoch: 56 Batch: 500, loss: 0.24073785680299645\n",
      "Epoch: 57 Batch: 0, loss: 0.6141444738243577\n",
      "Epoch: 57 Batch: 100, loss: 1.004752423707553\n",
      "Epoch: 57 Batch: 200, loss: 0.37177623959569744\n",
      "Epoch: 57 Batch: 300, loss: 0.49556999136145685\n",
      "Epoch: 57 Batch: 400, loss: 0.57085259309224\n",
      "Epoch: 57 Batch: 500, loss: 0.37853415895994863\n",
      "Epoch: 58 Batch: 0, loss: 0.08586191879814793\n",
      "Epoch: 58 Batch: 100, loss: 0.08050261622135423\n",
      "Epoch: 58 Batch: 200, loss: 0.2647595379108727\n",
      "Epoch: 58 Batch: 300, loss: 0.052945024286401535\n",
      "Epoch: 58 Batch: 400, loss: 0.6994904412353817\n",
      "Epoch: 58 Batch: 500, loss: 0.2845821005549886\n",
      "Epoch: 59 Batch: 0, loss: 0.4704131890550587\n",
      "Epoch: 59 Batch: 100, loss: 0.6492662601240253\n",
      "Epoch: 59 Batch: 200, loss: 0.255912433715513\n",
      "Epoch: 59 Batch: 300, loss: 0.5235879538834752\n",
      "Epoch: 59 Batch: 400, loss: 0.9851243331364479\n",
      "Epoch: 59 Batch: 500, loss: 0.6851884849926483\n",
      "Epoch: 60 Batch: 0, loss: 0.36667002675170157\n",
      "Epoch: 60 Batch: 100, loss: 0.36856467037895685\n",
      "Epoch: 60 Batch: 200, loss: 0.3827811582498071\n",
      "Epoch: 60 Batch: 300, loss: 0.01664712076758677\n",
      "Epoch: 60 Batch: 400, loss: 0.02875122574438536\n",
      "Epoch: 60 Batch: 500, loss: 0.24877856702854492\n",
      "Epoch: 61 Batch: 0, loss: 0.1252988977662219\n",
      "Epoch: 61 Batch: 100, loss: 0.24883470211468997\n",
      "Epoch: 61 Batch: 200, loss: 0.03536212758121411\n",
      "Epoch: 61 Batch: 300, loss: 0.6245947799518341\n",
      "Epoch: 61 Batch: 400, loss: 0.44883593123086174\n",
      "Epoch: 61 Batch: 500, loss: 0.1776455098658821\n",
      "Epoch: 62 Batch: 0, loss: 0.09121087735888285\n",
      "Epoch: 62 Batch: 100, loss: 0.116019765886569\n",
      "Epoch: 62 Batch: 200, loss: 0.08352064661386145\n",
      "Epoch: 62 Batch: 300, loss: 0.159351810832579\n",
      "Epoch: 62 Batch: 400, loss: 0.07437718801238653\n",
      "Epoch: 62 Batch: 500, loss: 0.6723423108738611\n",
      "Epoch: 63 Batch: 0, loss: 0.4712451008840935\n",
      "Epoch: 63 Batch: 100, loss: 0.24349782846549217\n",
      "Epoch: 63 Batch: 200, loss: 0.8187045965722878\n",
      "Epoch: 63 Batch: 300, loss: 0.5428460348424856\n",
      "Epoch: 63 Batch: 400, loss: 0.022622530711011116\n",
      "Epoch: 63 Batch: 500, loss: 0.04789783144736063\n",
      "Epoch: 64 Batch: 0, loss: 0.03182387048219098\n",
      "Epoch: 64 Batch: 100, loss: 0.7692855956385365\n",
      "Epoch: 64 Batch: 200, loss: 1.6979373879504838\n",
      "Epoch: 64 Batch: 300, loss: 0.5437522645825654\n",
      "Epoch: 64 Batch: 400, loss: 0.18599122358004824\n",
      "Epoch: 64 Batch: 500, loss: 0.6428073272790832\n",
      "Epoch: 65 Batch: 0, loss: 0.041362432060431685\n",
      "Epoch: 65 Batch: 100, loss: 0.005278621742328314\n",
      "Epoch: 65 Batch: 200, loss: 0.17264778797229474\n",
      "Epoch: 65 Batch: 300, loss: 0.7110983411822648\n",
      "Epoch: 65 Batch: 400, loss: 0.012025194974459951\n",
      "Epoch: 65 Batch: 500, loss: 0.5408806161318201\n",
      "Epoch: 66 Batch: 0, loss: 0.15900778149682726\n",
      "Epoch: 66 Batch: 100, loss: 0.4848466168119982\n",
      "Epoch: 66 Batch: 200, loss: 0.07558004497193525\n",
      "Epoch: 66 Batch: 300, loss: 0.17423109227628764\n",
      "Epoch: 66 Batch: 400, loss: 0.024376267625643346\n",
      "Epoch: 66 Batch: 500, loss: 0.39719712386527123\n",
      "Epoch: 67 Batch: 0, loss: 0.7884790091523453\n",
      "Epoch: 67 Batch: 100, loss: 0.378700891297008\n",
      "Epoch: 67 Batch: 200, loss: 0.010862464362078947\n",
      "Epoch: 67 Batch: 300, loss: 0.39109011206106287\n",
      "Epoch: 67 Batch: 400, loss: 0.01949897709811414\n",
      "Epoch: 67 Batch: 500, loss: 0.38496354096905033\n",
      "Epoch: 68 Batch: 0, loss: 0.38127246911243023\n",
      "Epoch: 68 Batch: 100, loss: 0.034347413781567616\n",
      "Epoch: 68 Batch: 200, loss: 0.1950318285197247\n",
      "Epoch: 68 Batch: 300, loss: 0.13896669101619577\n",
      "Epoch: 68 Batch: 400, loss: 0.6312211422938788\n",
      "Epoch: 68 Batch: 500, loss: 0.36724878311758413\n",
      "Epoch: 69 Batch: 0, loss: 0.013816942064316502\n",
      "Epoch: 69 Batch: 100, loss: 0.01841486411169629\n",
      "Epoch: 69 Batch: 200, loss: 0.1297818122870161\n",
      "Epoch: 69 Batch: 300, loss: 0.04686245772401594\n",
      "Epoch: 69 Batch: 400, loss: 0.4119141239664785\n",
      "Epoch: 69 Batch: 500, loss: 0.047763252863726346\n",
      "Epoch: 70 Batch: 0, loss: 0.2392209934322365\n",
      "Epoch: 70 Batch: 100, loss: 0.4455185065722325\n",
      "Epoch: 70 Batch: 200, loss: 0.0026489467531292028\n",
      "Epoch: 70 Batch: 300, loss: 0.368499962286187\n",
      "Epoch: 70 Batch: 400, loss: 0.7614302324169234\n",
      "Epoch: 70 Batch: 500, loss: 0.18649739792751427\n",
      "Epoch: 71 Batch: 0, loss: 0.6516861022207421\n",
      "Epoch: 71 Batch: 100, loss: 0.4808197678856823\n",
      "Epoch: 71 Batch: 200, loss: 0.3889904403088346\n",
      "Epoch: 71 Batch: 300, loss: 0.44588118203703603\n",
      "Epoch: 71 Batch: 400, loss: 0.33649070183035357\n",
      "Epoch: 71 Batch: 500, loss: 0.050882314058512304\n",
      "Epoch: 72 Batch: 0, loss: 0.30737585403612905\n",
      "Epoch: 72 Batch: 100, loss: 0.5676057877721176\n",
      "Epoch: 72 Batch: 200, loss: 0.61259251515052\n",
      "Epoch: 72 Batch: 300, loss: 0.399000178606528\n",
      "Epoch: 72 Batch: 400, loss: 0.9428340766146136\n",
      "Epoch: 72 Batch: 500, loss: 0.1921050543602421\n",
      "Epoch: 73 Batch: 0, loss: 1.7119245955409752\n",
      "Epoch: 73 Batch: 100, loss: 0.05364262448159041\n",
      "Epoch: 73 Batch: 200, loss: 1.0720076297945067\n",
      "Epoch: 73 Batch: 300, loss: 0.3643882153549773\n",
      "Epoch: 73 Batch: 400, loss: 0.06673186964513139\n",
      "Epoch: 73 Batch: 500, loss: 0.5054538573749842\n",
      "Epoch: 74 Batch: 0, loss: 0.5274241451976713\n",
      "Epoch: 74 Batch: 100, loss: 0.5033322140381694\n",
      "Epoch: 74 Batch: 200, loss: 0.08606338077677868\n",
      "Epoch: 74 Batch: 300, loss: 1.2236964055962378\n",
      "Epoch: 74 Batch: 400, loss: 0.6267067064178269\n",
      "Epoch: 74 Batch: 500, loss: 0.35039418528462773\n",
      "Epoch: 75 Batch: 0, loss: 0.016346093408535572\n",
      "Epoch: 75 Batch: 100, loss: 0.6326844965594707\n",
      "Epoch: 75 Batch: 200, loss: 0.04101846278357384\n",
      "Epoch: 75 Batch: 300, loss: 0.03502998316611792\n",
      "Epoch: 75 Batch: 400, loss: 0.7879523733877459\n",
      "Epoch: 75 Batch: 500, loss: 0.8608291175725487\n",
      "Epoch: 76 Batch: 0, loss: 0.34203768390296974\n",
      "Epoch: 76 Batch: 100, loss: 0.1549585360993982\n",
      "Epoch: 76 Batch: 200, loss: 0.5444365938264784\n",
      "Epoch: 76 Batch: 300, loss: 0.018316754008996072\n",
      "Epoch: 76 Batch: 400, loss: 0.044379662670016445\n",
      "Epoch: 76 Batch: 500, loss: 0.0876560769813257\n",
      "Epoch: 77 Batch: 0, loss: 0.24689733299547045\n",
      "Epoch: 77 Batch: 100, loss: 0.1921998468507211\n",
      "Epoch: 77 Batch: 200, loss: 0.14982898897432628\n",
      "Epoch: 77 Batch: 300, loss: 1.0538250860379605\n",
      "Epoch: 77 Batch: 400, loss: 0.28629865150792794\n",
      "Epoch: 77 Batch: 500, loss: 0.11207131466772872\n",
      "Epoch: 78 Batch: 0, loss: 0.022081401060884482\n",
      "Epoch: 78 Batch: 100, loss: 0.11191097634282389\n",
      "Epoch: 78 Batch: 200, loss: 0.214194340189622\n",
      "Epoch: 78 Batch: 300, loss: 0.4793774804892165\n",
      "Epoch: 78 Batch: 400, loss: 0.010394644674536803\n",
      "Epoch: 78 Batch: 500, loss: 1.055472977631835\n",
      "Epoch: 79 Batch: 0, loss: 0.6361770261017188\n",
      "Epoch: 79 Batch: 100, loss: 0.3398096866711457\n",
      "Epoch: 79 Batch: 200, loss: 0.3463193966995567\n",
      "Epoch: 79 Batch: 300, loss: 0.6572898981757003\n",
      "Epoch: 79 Batch: 400, loss: 0.7973789644940048\n",
      "Epoch: 79 Batch: 500, loss: 0.3271114310313507\n",
      "Epoch: 80 Batch: 0, loss: 0.393670642339103\n",
      "Epoch: 80 Batch: 100, loss: 0.4489384017724926\n",
      "Epoch: 80 Batch: 200, loss: 0.18146591713152646\n",
      "Epoch: 80 Batch: 300, loss: 0.14039452909968927\n",
      "Epoch: 80 Batch: 400, loss: 0.3797676138040378\n",
      "Epoch: 80 Batch: 500, loss: 0.7470829017757236\n",
      "Epoch: 81 Batch: 0, loss: 0.29630566422725096\n",
      "Epoch: 81 Batch: 100, loss: 0.559505001431706\n",
      "Epoch: 81 Batch: 200, loss: 0.26256494077109427\n",
      "Epoch: 81 Batch: 300, loss: 0.0038859601064257154\n",
      "Epoch: 81 Batch: 400, loss: 0.0379505387058627\n",
      "Epoch: 81 Batch: 500, loss: 0.21731409326633103\n",
      "Epoch: 82 Batch: 0, loss: 0.08390454401367638\n",
      "Epoch: 82 Batch: 100, loss: 0.6056442185597118\n",
      "Epoch: 82 Batch: 200, loss: 0.5313926039507146\n",
      "Epoch: 82 Batch: 300, loss: 0.46990509452812507\n",
      "Epoch: 82 Batch: 400, loss: 0.12515617824739098\n",
      "Epoch: 82 Batch: 500, loss: 0.5963517248342093\n",
      "Epoch: 83 Batch: 0, loss: 0.04985977400249173\n",
      "Epoch: 83 Batch: 100, loss: 1.2367534876920687\n",
      "Epoch: 83 Batch: 200, loss: 0.2947680522211007\n",
      "Epoch: 83 Batch: 300, loss: 1.6032555531464008\n",
      "Epoch: 83 Batch: 400, loss: 0.2835179801885612\n",
      "Epoch: 83 Batch: 500, loss: 0.0646391361359936\n",
      "Epoch: 84 Batch: 0, loss: 0.600781829679578\n",
      "Epoch: 84 Batch: 100, loss: 0.019240275762991473\n",
      "Epoch: 84 Batch: 200, loss: 0.2793638149827596\n",
      "Epoch: 84 Batch: 300, loss: 0.9098044675454721\n",
      "Epoch: 84 Batch: 400, loss: 0.4690675520069993\n",
      "Epoch: 84 Batch: 500, loss: 0.42280741130246097\n",
      "Epoch: 85 Batch: 0, loss: 0.43530048062266896\n",
      "Epoch: 85 Batch: 100, loss: 0.5874397463440304\n",
      "Epoch: 85 Batch: 200, loss: 0.025435809493541125\n",
      "Epoch: 85 Batch: 300, loss: 0.15166345316985402\n",
      "Epoch: 85 Batch: 400, loss: 0.11840360165117145\n",
      "Epoch: 85 Batch: 500, loss: 0.8704064734531226\n",
      "Epoch: 86 Batch: 0, loss: 0.29509789826519667\n",
      "Epoch: 86 Batch: 100, loss: 0.1518098523086387\n",
      "Epoch: 86 Batch: 200, loss: 0.5097034762641031\n",
      "Epoch: 86 Batch: 300, loss: 0.8851386717829138\n",
      "Epoch: 86 Batch: 400, loss: 0.2761999900686369\n",
      "Epoch: 86 Batch: 500, loss: 0.09155133220598242\n",
      "Epoch: 87 Batch: 0, loss: 0.6880660979675481\n",
      "Epoch: 87 Batch: 100, loss: 1.2299689505939142\n",
      "Epoch: 87 Batch: 200, loss: 0.12527629729746267\n",
      "Epoch: 87 Batch: 300, loss: 0.14888716559884674\n",
      "Epoch: 87 Batch: 400, loss: 0.01407584957263124\n",
      "Epoch: 87 Batch: 500, loss: 0.6310194581698064\n",
      "Epoch: 88 Batch: 0, loss: 0.029527649549930788\n",
      "Epoch: 88 Batch: 100, loss: 0.2890518828225479\n",
      "Epoch: 88 Batch: 200, loss: 0.23332744763837035\n",
      "Epoch: 88 Batch: 300, loss: 0.22442088284843537\n",
      "Epoch: 88 Batch: 400, loss: 1.8795229678414562\n",
      "Epoch: 88 Batch: 500, loss: 0.7098962945694887\n",
      "Epoch: 89 Batch: 0, loss: 0.0007339336700525312\n",
      "Epoch: 89 Batch: 100, loss: 0.44267512382103613\n",
      "Epoch: 89 Batch: 200, loss: 0.017139994892538323\n",
      "Epoch: 89 Batch: 300, loss: 0.09083205401603646\n",
      "Epoch: 89 Batch: 400, loss: 0.5995047812941859\n",
      "Epoch: 89 Batch: 500, loss: 0.9637758720638598\n",
      "Epoch: 90 Batch: 0, loss: 0.1118847233813082\n",
      "Epoch: 90 Batch: 100, loss: 5.36104069022269\n",
      "Epoch: 90 Batch: 200, loss: 0.4358668054441857\n",
      "Epoch: 90 Batch: 300, loss: 0.24906618807449335\n",
      "Epoch: 90 Batch: 400, loss: 0.0012525096331643681\n",
      "Epoch: 90 Batch: 500, loss: 0.4196722275331314\n",
      "Epoch: 91 Batch: 0, loss: 0.5345639148331204\n",
      "Epoch: 91 Batch: 100, loss: 0.47518682504087273\n",
      "Epoch: 91 Batch: 200, loss: 0.10002982077930407\n",
      "Epoch: 91 Batch: 300, loss: 0.12098038675045461\n",
      "Epoch: 91 Batch: 400, loss: 0.10054740573969592\n",
      "Epoch: 91 Batch: 500, loss: 0.016666539133493755\n",
      "Epoch: 92 Batch: 0, loss: 0.09023563974144241\n",
      "Epoch: 92 Batch: 100, loss: 0.6722073622556103\n",
      "Epoch: 92 Batch: 200, loss: 0.8233361505349226\n",
      "Epoch: 92 Batch: 300, loss: 0.002858415046243926\n",
      "Epoch: 92 Batch: 400, loss: 0.27539274204210823\n",
      "Epoch: 92 Batch: 500, loss: 0.4637007560807176\n",
      "Epoch: 93 Batch: 0, loss: 0.5443766070193513\n",
      "Epoch: 93 Batch: 100, loss: 0.0004920190715987369\n",
      "Epoch: 93 Batch: 200, loss: 0.9930361065998923\n",
      "Epoch: 93 Batch: 300, loss: 0.40195724016307394\n",
      "Epoch: 93 Batch: 400, loss: 0.9158925653682485\n",
      "Epoch: 93 Batch: 500, loss: 1.1126971043867107\n",
      "Epoch: 94 Batch: 0, loss: 0.691002952388394\n",
      "Epoch: 94 Batch: 100, loss: 0.39591949531362325\n",
      "Epoch: 94 Batch: 200, loss: 0.07320100211519232\n",
      "Epoch: 94 Batch: 300, loss: 0.07231621920336084\n",
      "Epoch: 94 Batch: 400, loss: 0.06189001154954026\n",
      "Epoch: 94 Batch: 500, loss: 0.5780739268952302\n",
      "Epoch: 95 Batch: 0, loss: 1.118178027922758\n",
      "Epoch: 95 Batch: 100, loss: 0.9687002947015575\n",
      "Epoch: 95 Batch: 200, loss: 1.6452136843749547\n",
      "Epoch: 95 Batch: 300, loss: 0.30183009100179947\n",
      "Epoch: 95 Batch: 400, loss: 0.3582843551198342\n",
      "Epoch: 95 Batch: 500, loss: 0.140091334998681\n",
      "Epoch: 96 Batch: 0, loss: 0.9631035092094601\n",
      "Epoch: 96 Batch: 100, loss: 0.04414164587219934\n",
      "Epoch: 96 Batch: 200, loss: 0.10127866144288393\n",
      "Epoch: 96 Batch: 300, loss: 0.5110141585290597\n",
      "Epoch: 96 Batch: 400, loss: 0.0037257841759302875\n",
      "Epoch: 96 Batch: 500, loss: 0.10175419605458129\n",
      "Epoch: 97 Batch: 0, loss: 0.15251605828755088\n",
      "Epoch: 97 Batch: 100, loss: 0.5138369647922\n",
      "Epoch: 97 Batch: 200, loss: 0.685640658768843\n",
      "Epoch: 97 Batch: 300, loss: 0.11515095293435819\n",
      "Epoch: 97 Batch: 400, loss: 0.19794008101795102\n",
      "Epoch: 97 Batch: 500, loss: 0.654540325392804\n",
      "Epoch: 98 Batch: 0, loss: 0.5256185069480197\n",
      "Epoch: 98 Batch: 100, loss: 0.423827950025014\n",
      "Epoch: 98 Batch: 200, loss: 0.14409311639424657\n",
      "Epoch: 98 Batch: 300, loss: 1.065055642257106\n",
      "Epoch: 98 Batch: 400, loss: 0.12740497249485278\n",
      "Epoch: 98 Batch: 500, loss: 0.08541504756134204\n",
      "Epoch: 99 Batch: 0, loss: 0.2942851890052119\n",
      "Epoch: 99 Batch: 100, loss: 0.1416759566703829\n",
      "Epoch: 99 Batch: 200, loss: 0.003322824085149353\n",
      "Epoch: 99 Batch: 300, loss: 0.2955361103681155\n",
      "Epoch: 99 Batch: 400, loss: 0.07823262465548245\n",
      "Epoch: 99 Batch: 500, loss: 0.9600358961546819\n",
      "Epoch: 100 Batch: 0, loss: 0.041311882672436046\n",
      "Epoch: 100 Batch: 100, loss: 0.40252126806606375\n",
      "Epoch: 100 Batch: 200, loss: 0.33521737207340885\n",
      "Epoch: 100 Batch: 300, loss: 1.539154774128284\n",
      "Epoch: 100 Batch: 400, loss: 0.24941549995496654\n",
      "Epoch: 100 Batch: 500, loss: 0.2263015185109425\n",
      "Epoch: 101 Batch: 0, loss: 0.2244548555860917\n",
      "Epoch: 101 Batch: 100, loss: 0.06946876125426182\n",
      "Epoch: 101 Batch: 200, loss: 0.1753154697397938\n",
      "Epoch: 101 Batch: 300, loss: 0.41969852806469093\n",
      "Epoch: 101 Batch: 400, loss: 0.8574576741670603\n",
      "Epoch: 101 Batch: 500, loss: 0.41716308911447825\n",
      "Epoch: 102 Batch: 0, loss: 0.011529770609371316\n",
      "Epoch: 102 Batch: 100, loss: 0.38843331470692544\n",
      "Epoch: 102 Batch: 200, loss: 0.007119526524154592\n",
      "Epoch: 102 Batch: 300, loss: 0.22648691839810997\n",
      "Epoch: 102 Batch: 400, loss: 0.6834658724673927\n",
      "Epoch: 102 Batch: 500, loss: 0.37208592048167494\n",
      "Epoch: 103 Batch: 0, loss: 0.2806665182693316\n",
      "Epoch: 103 Batch: 100, loss: 0.5513405007671264\n",
      "Epoch: 103 Batch: 200, loss: 0.3515153782338365\n",
      "Epoch: 103 Batch: 300, loss: 0.5629072030207872\n",
      "Epoch: 103 Batch: 400, loss: 0.3639029787312647\n",
      "Epoch: 103 Batch: 500, loss: 0.22880000271223352\n",
      "Epoch: 104 Batch: 0, loss: 0.020371976937325648\n",
      "Epoch: 104 Batch: 100, loss: 0.9062305044248692\n",
      "Epoch: 104 Batch: 200, loss: 0.4430206403503751\n",
      "Epoch: 104 Batch: 300, loss: 0.154581426443141\n",
      "Epoch: 104 Batch: 400, loss: 0.3304223744475568\n",
      "Epoch: 104 Batch: 500, loss: 0.22393993016578836\n",
      "Epoch: 105 Batch: 0, loss: 0.536814697770971\n",
      "Epoch: 105 Batch: 100, loss: 0.2205031964992409\n",
      "Epoch: 105 Batch: 200, loss: 1.225255531448192\n",
      "Epoch: 105 Batch: 300, loss: 0.05950958438563367\n",
      "Epoch: 105 Batch: 400, loss: 0.5078211663174822\n",
      "Epoch: 105 Batch: 500, loss: 0.01962163212016576\n",
      "Epoch: 106 Batch: 0, loss: 0.053260323593702745\n",
      "Epoch: 106 Batch: 100, loss: 0.40600537270531983\n",
      "Epoch: 106 Batch: 200, loss: 0.5291682482302118\n",
      "Epoch: 106 Batch: 300, loss: 0.23187778477517335\n",
      "Epoch: 106 Batch: 400, loss: 1.2207261875676838\n",
      "Epoch: 106 Batch: 500, loss: 0.35662534714209354\n",
      "Epoch: 107 Batch: 0, loss: 0.02313484089936491\n",
      "Epoch: 107 Batch: 100, loss: 0.23730684062233373\n",
      "Epoch: 107 Batch: 200, loss: 0.13751153235544109\n",
      "Epoch: 107 Batch: 300, loss: 0.10232058307391378\n",
      "Epoch: 107 Batch: 400, loss: 0.21297939177383493\n",
      "Epoch: 107 Batch: 500, loss: 0.1710392233674271\n",
      "Epoch: 108 Batch: 0, loss: 0.34527457235329434\n",
      "Epoch: 108 Batch: 100, loss: 0.8705422862668419\n",
      "Epoch: 108 Batch: 200, loss: 0.6058174307648122\n",
      "Epoch: 108 Batch: 300, loss: 0.4494205334772414\n",
      "Epoch: 108 Batch: 400, loss: 0.06610849225309273\n",
      "Epoch: 108 Batch: 500, loss: 0.22439965036823856\n",
      "Epoch: 109 Batch: 0, loss: 0.2616377965250805\n",
      "Epoch: 109 Batch: 100, loss: 0.44350227659590685\n",
      "Epoch: 109 Batch: 200, loss: 0.057080576751291245\n",
      "Epoch: 109 Batch: 300, loss: 0.03558862968625496\n",
      "Epoch: 109 Batch: 400, loss: 0.21713513586253794\n",
      "Epoch: 109 Batch: 500, loss: 0.22795189563021734\n",
      "Epoch: 110 Batch: 0, loss: 0.0648267708962873\n",
      "Epoch: 110 Batch: 100, loss: 0.030686491009785474\n",
      "Epoch: 110 Batch: 200, loss: 0.2530774384080423\n",
      "Epoch: 110 Batch: 300, loss: 0.3808305727187186\n",
      "Epoch: 110 Batch: 400, loss: 0.1549218841571312\n",
      "Epoch: 110 Batch: 500, loss: 0.38338073305360687\n",
      "Epoch: 111 Batch: 0, loss: 0.17197290126419817\n",
      "Epoch: 111 Batch: 100, loss: 0.02345221569986154\n",
      "Epoch: 111 Batch: 200, loss: 0.2245888783502294\n",
      "Epoch: 111 Batch: 300, loss: 0.06710462607411681\n",
      "Epoch: 111 Batch: 400, loss: 0.07815525903482834\n",
      "Epoch: 111 Batch: 500, loss: 0.3244629481986461\n",
      "Epoch: 112 Batch: 0, loss: 0.011972301656503072\n",
      "Epoch: 112 Batch: 100, loss: 0.025214280914801924\n",
      "Epoch: 112 Batch: 200, loss: 1.2490151234526927\n",
      "Epoch: 112 Batch: 300, loss: 0.002623412994620522\n",
      "Epoch: 112 Batch: 400, loss: 0.36243452750768657\n",
      "Epoch: 112 Batch: 500, loss: 0.02562384485137048\n",
      "Epoch: 113 Batch: 0, loss: 1.0035295670840427\n",
      "Epoch: 113 Batch: 100, loss: 0.14453356606787818\n",
      "Epoch: 113 Batch: 200, loss: 0.2480576685449342\n",
      "Epoch: 113 Batch: 300, loss: 0.9143287883380564\n",
      "Epoch: 113 Batch: 400, loss: 0.019781924465434687\n",
      "Epoch: 113 Batch: 500, loss: 0.5753847903712471\n",
      "Epoch: 114 Batch: 0, loss: 0.7241796016087051\n",
      "Epoch: 114 Batch: 100, loss: 0.7490910465573399\n",
      "Epoch: 114 Batch: 200, loss: 1.0033713923652823\n",
      "Epoch: 114 Batch: 300, loss: 0.14635551907492905\n",
      "Epoch: 114 Batch: 400, loss: 0.4863720945692725\n",
      "Epoch: 114 Batch: 500, loss: 0.492032761709797\n",
      "Epoch: 115 Batch: 0, loss: 0.3542025584763497\n",
      "Epoch: 115 Batch: 100, loss: 0.2106774387947156\n",
      "Epoch: 115 Batch: 200, loss: 0.05177430991677526\n",
      "Epoch: 115 Batch: 300, loss: 0.2730199670268637\n",
      "Epoch: 115 Batch: 400, loss: 0.028176540999670582\n",
      "Epoch: 115 Batch: 500, loss: 0.007271599366196837\n",
      "Epoch: 116 Batch: 0, loss: 0.020478949495368715\n",
      "Epoch: 116 Batch: 100, loss: 0.06870789481888305\n",
      "Epoch: 116 Batch: 200, loss: 0.3618936517022317\n",
      "Epoch: 116 Batch: 300, loss: 0.39099542161625683\n",
      "Epoch: 116 Batch: 400, loss: 0.6793474347109822\n",
      "Epoch: 116 Batch: 500, loss: 0.36641251851544065\n",
      "Epoch: 117 Batch: 0, loss: 0.32847665899317746\n",
      "Epoch: 117 Batch: 100, loss: 0.05437186267792005\n",
      "Epoch: 117 Batch: 200, loss: 0.10793015635909702\n",
      "Epoch: 117 Batch: 300, loss: 0.5455880324777778\n",
      "Epoch: 117 Batch: 400, loss: 0.1471494809313431\n",
      "Epoch: 117 Batch: 500, loss: 0.6059538717687517\n",
      "Epoch: 118 Batch: 0, loss: 0.24071174790134653\n",
      "Epoch: 118 Batch: 100, loss: 0.0015832111079180388\n",
      "Epoch: 118 Batch: 200, loss: 0.6014574430903359\n",
      "Epoch: 118 Batch: 300, loss: 0.001190737233893647\n",
      "Epoch: 118 Batch: 400, loss: 0.354523641305939\n",
      "Epoch: 118 Batch: 500, loss: 0.21585527544152855\n",
      "Epoch: 119 Batch: 0, loss: 0.05475521631108322\n",
      "Epoch: 119 Batch: 100, loss: 0.15217206424517002\n",
      "Epoch: 119 Batch: 200, loss: 1.4211726484075724\n",
      "Epoch: 119 Batch: 300, loss: 0.3701971113879384\n",
      "Epoch: 119 Batch: 400, loss: 0.027707682990402\n",
      "Epoch: 119 Batch: 500, loss: 0.005364391334047569\n",
      "Epoch: 120 Batch: 0, loss: 0.0507617651966993\n",
      "Epoch: 120 Batch: 100, loss: 0.3104535709904865\n",
      "Epoch: 120 Batch: 200, loss: 0.0002671912859994954\n",
      "Epoch: 120 Batch: 300, loss: 0.49733622177007747\n",
      "Epoch: 120 Batch: 400, loss: 0.0034977652985847102\n",
      "Epoch: 120 Batch: 500, loss: 0.5266589990185856\n",
      "Epoch: 121 Batch: 0, loss: 0.185510871764603\n",
      "Epoch: 121 Batch: 100, loss: 0.6117324544513555\n",
      "Epoch: 121 Batch: 200, loss: 0.15393600974739063\n",
      "Epoch: 121 Batch: 300, loss: 0.005554969710809115\n",
      "Epoch: 121 Batch: 400, loss: 0.06297090937258598\n",
      "Epoch: 121 Batch: 500, loss: 0.2805848422331409\n",
      "Epoch: 122 Batch: 0, loss: 0.10485497003782744\n",
      "Epoch: 122 Batch: 100, loss: 0.448722957103501\n",
      "Epoch: 122 Batch: 200, loss: 0.1733903935763911\n",
      "Epoch: 122 Batch: 300, loss: 0.19050082214627337\n",
      "Epoch: 122 Batch: 400, loss: 0.03721164352895129\n",
      "Epoch: 122 Batch: 500, loss: 1.248993786965179\n",
      "Epoch: 123 Batch: 0, loss: 0.08113665557553523\n",
      "Epoch: 123 Batch: 100, loss: 0.005639429537919869\n",
      "Epoch: 123 Batch: 200, loss: 0.4312375611625856\n",
      "Epoch: 123 Batch: 300, loss: 0.09854108855983017\n",
      "Epoch: 123 Batch: 400, loss: 0.6974172448203907\n",
      "Epoch: 123 Batch: 500, loss: 0.14847321825381768\n",
      "Epoch: 124 Batch: 0, loss: 0.3463843513622804\n",
      "Epoch: 124 Batch: 100, loss: 0.05220539617055484\n",
      "Epoch: 124 Batch: 200, loss: 0.40633118434439\n",
      "Epoch: 124 Batch: 300, loss: 0.10474702685422027\n",
      "Epoch: 124 Batch: 400, loss: 0.5359647295552024\n",
      "Epoch: 124 Batch: 500, loss: 0.6160986679257978\n",
      "Epoch: 125 Batch: 0, loss: 0.026482992903396577\n",
      "Epoch: 125 Batch: 100, loss: 0.33478427434564684\n",
      "Epoch: 125 Batch: 200, loss: 0.03264144811718425\n",
      "Epoch: 125 Batch: 300, loss: 0.0718353269666289\n",
      "Epoch: 125 Batch: 400, loss: 0.004097222509554892\n",
      "Epoch: 125 Batch: 500, loss: 0.3059388021928\n",
      "Epoch: 126 Batch: 0, loss: 0.14242612835813384\n",
      "Epoch: 126 Batch: 100, loss: 0.03562290852226824\n",
      "Epoch: 126 Batch: 200, loss: 0.23673414326242062\n",
      "Epoch: 126 Batch: 300, loss: 0.0026464106035561674\n",
      "Epoch: 126 Batch: 400, loss: 0.5919867327602493\n",
      "Epoch: 126 Batch: 500, loss: 0.6257401684476559\n",
      "Epoch: 127 Batch: 0, loss: 0.054170445566097764\n",
      "Epoch: 127 Batch: 100, loss: 0.39971593127711874\n",
      "Epoch: 127 Batch: 200, loss: 0.31700217018374127\n",
      "Epoch: 127 Batch: 300, loss: 0.3501517702610435\n",
      "Epoch: 127 Batch: 400, loss: 0.06769413736021458\n",
      "Epoch: 127 Batch: 500, loss: 0.0030681662496538867\n",
      "Epoch: 128 Batch: 0, loss: 0.5498249054646479\n",
      "Epoch: 128 Batch: 100, loss: 0.6092677432839455\n",
      "Epoch: 128 Batch: 200, loss: 0.011335377258178363\n",
      "Epoch: 128 Batch: 300, loss: 0.44281190988625846\n",
      "Epoch: 128 Batch: 400, loss: 0.31549320259756314\n",
      "Epoch: 128 Batch: 500, loss: 0.016244845832519426\n",
      "Epoch: 129 Batch: 0, loss: 0.5550042614260019\n",
      "Epoch: 129 Batch: 100, loss: 0.20747124690330088\n",
      "Epoch: 129 Batch: 200, loss: 0.1953644189084565\n",
      "Epoch: 129 Batch: 300, loss: 0.0053769455666754255\n",
      "Epoch: 129 Batch: 400, loss: 0.03632413575039338\n",
      "Epoch: 129 Batch: 500, loss: 0.5079749774710768\n",
      "Epoch: 130 Batch: 0, loss: 0.005410459673593087\n",
      "Epoch: 130 Batch: 100, loss: 0.18835110814772532\n",
      "Epoch: 130 Batch: 200, loss: 0.24589262507979176\n",
      "Epoch: 130 Batch: 300, loss: 0.440549608607918\n",
      "Epoch: 130 Batch: 400, loss: 1.006901458297492\n",
      "Epoch: 130 Batch: 500, loss: 0.40291001685857064\n",
      "Epoch: 131 Batch: 0, loss: 0.1125936180016241\n",
      "Epoch: 131 Batch: 100, loss: 0.45744995675593325\n",
      "Epoch: 131 Batch: 200, loss: 0.06328824326883065\n",
      "Epoch: 131 Batch: 300, loss: 0.4006103907926925\n",
      "Epoch: 131 Batch: 400, loss: 0.5225378733133491\n",
      "Epoch: 131 Batch: 500, loss: 1.2563978595853917\n",
      "Epoch: 132 Batch: 0, loss: 0.00651828919613719\n",
      "Epoch: 132 Batch: 100, loss: 0.23098569597163435\n",
      "Epoch: 132 Batch: 200, loss: 0.3817246666191391\n",
      "Epoch: 132 Batch: 300, loss: 0.3558022062548311\n",
      "Epoch: 132 Batch: 400, loss: 0.0025930971359519276\n",
      "Epoch: 132 Batch: 500, loss: 0.015542809526380005\n",
      "Epoch: 133 Batch: 0, loss: 0.2611338223990544\n",
      "Epoch: 133 Batch: 100, loss: 0.5011365549189309\n",
      "Epoch: 133 Batch: 200, loss: 0.2679906583728786\n",
      "Epoch: 133 Batch: 300, loss: 0.22563012779327382\n",
      "Epoch: 133 Batch: 400, loss: 0.007102497238982483\n",
      "Epoch: 133 Batch: 500, loss: 0.012617830706783302\n",
      "Epoch: 134 Batch: 0, loss: 0.14923458098849668\n",
      "Epoch: 134 Batch: 100, loss: 0.5198764352884824\n",
      "Epoch: 134 Batch: 200, loss: 0.502601924184231\n",
      "Epoch: 134 Batch: 300, loss: 0.16613837818790755\n",
      "Epoch: 134 Batch: 400, loss: 0.203526126112081\n",
      "Epoch: 134 Batch: 500, loss: 0.05834055294187349\n",
      "Epoch: 135 Batch: 0, loss: 0.3261909359590815\n",
      "Epoch: 135 Batch: 100, loss: 0.25083277084897376\n",
      "Epoch: 135 Batch: 200, loss: 0.002612192814654831\n",
      "Epoch: 135 Batch: 300, loss: 0.3160549172374782\n",
      "Epoch: 135 Batch: 400, loss: 0.11311326027978656\n",
      "Epoch: 135 Batch: 500, loss: 0.36205149558611477\n",
      "Epoch: 136 Batch: 0, loss: 0.36620151759609665\n",
      "Epoch: 136 Batch: 100, loss: 0.4565020695905807\n",
      "Epoch: 136 Batch: 200, loss: 0.27421923752459704\n",
      "Epoch: 136 Batch: 300, loss: 0.00285398137487975\n",
      "Epoch: 136 Batch: 400, loss: 0.1292471456308012\n",
      "Epoch: 136 Batch: 500, loss: 0.20988458730288606\n",
      "Epoch: 137 Batch: 0, loss: 0.36026985338829154\n",
      "Epoch: 137 Batch: 100, loss: 0.38809007685499664\n",
      "Epoch: 137 Batch: 200, loss: 0.6041071736658372\n",
      "Epoch: 137 Batch: 300, loss: 0.07074358850051492\n",
      "Epoch: 137 Batch: 400, loss: 0.23594467714701942\n",
      "Epoch: 137 Batch: 500, loss: 0.009012800648527974\n",
      "Epoch: 138 Batch: 0, loss: 0.014733760263916963\n",
      "Epoch: 138 Batch: 100, loss: 0.014830844313436713\n",
      "Epoch: 138 Batch: 200, loss: 0.17257138108541142\n",
      "Epoch: 138 Batch: 300, loss: 0.15970158630551695\n",
      "Epoch: 138 Batch: 400, loss: 0.32938919771610764\n",
      "Epoch: 138 Batch: 500, loss: 0.048835274811172266\n",
      "Epoch: 139 Batch: 0, loss: 0.33176327974249614\n",
      "Epoch: 139 Batch: 100, loss: 1.1093478748683956\n",
      "Epoch: 139 Batch: 200, loss: 0.050564045243997116\n",
      "Epoch: 139 Batch: 300, loss: 0.0017591516960423677\n",
      "Epoch: 139 Batch: 400, loss: 0.1723411004653089\n",
      "Epoch: 139 Batch: 500, loss: 0.8280681064645689\n",
      "Epoch: 140 Batch: 0, loss: 0.33382031693833386\n",
      "Epoch: 140 Batch: 100, loss: 0.46984735537440725\n",
      "Epoch: 140 Batch: 200, loss: 0.7855570790531521\n",
      "Epoch: 140 Batch: 300, loss: 0.14623227626023705\n",
      "Epoch: 140 Batch: 400, loss: 0.5338106344434914\n",
      "Epoch: 140 Batch: 500, loss: 0.048856625586116385\n",
      "Epoch: 141 Batch: 0, loss: 0.14455876467113385\n",
      "Epoch: 141 Batch: 100, loss: 0.04697800777327544\n",
      "Epoch: 141 Batch: 200, loss: 0.08997307449065158\n",
      "Epoch: 141 Batch: 300, loss: 0.24026856236368782\n",
      "Epoch: 141 Batch: 400, loss: 0.46882602435876514\n",
      "Epoch: 141 Batch: 500, loss: 0.8532797884110881\n",
      "Epoch: 142 Batch: 0, loss: 0.007874424861174996\n",
      "Epoch: 142 Batch: 100, loss: 0.0750590142352838\n",
      "Epoch: 142 Batch: 200, loss: 0.16825004924339373\n",
      "Epoch: 142 Batch: 300, loss: 0.046976431862840125\n",
      "Epoch: 142 Batch: 400, loss: 0.14343232028829928\n",
      "Epoch: 142 Batch: 500, loss: 0.37074286522674726\n",
      "Epoch: 143 Batch: 0, loss: 0.1763123182179808\n",
      "Epoch: 143 Batch: 100, loss: 0.2898789667768766\n",
      "Epoch: 143 Batch: 200, loss: 0.052990459122530684\n",
      "Epoch: 143 Batch: 300, loss: 0.008690247714689044\n",
      "Epoch: 143 Batch: 400, loss: 0.5006958387249127\n",
      "Epoch: 143 Batch: 500, loss: 0.9944511095858499\n",
      "Epoch: 144 Batch: 0, loss: 0.018143927359560247\n",
      "Epoch: 144 Batch: 100, loss: 0.2586495088648958\n",
      "Epoch: 144 Batch: 200, loss: 0.38360843451025795\n",
      "Epoch: 144 Batch: 300, loss: 0.08017807440007454\n",
      "Epoch: 144 Batch: 400, loss: 0.07151168766221673\n",
      "Epoch: 144 Batch: 500, loss: 0.0016771931073073436\n",
      "Epoch: 145 Batch: 0, loss: 0.1574381525604284\n",
      "Epoch: 145 Batch: 100, loss: 0.5535133223001695\n",
      "Epoch: 145 Batch: 200, loss: 0.9701056343514621\n",
      "Epoch: 145 Batch: 300, loss: 0.8963650727569848\n",
      "Epoch: 145 Batch: 400, loss: 0.2180826452661358\n",
      "Epoch: 145 Batch: 500, loss: 0.8237753421420868\n",
      "Epoch: 146 Batch: 0, loss: 1.0884895472177671\n",
      "Epoch: 146 Batch: 100, loss: 0.17996388563306634\n",
      "Epoch: 146 Batch: 200, loss: 0.1888283976727565\n",
      "Epoch: 146 Batch: 300, loss: 0.45757465786657386\n",
      "Epoch: 146 Batch: 400, loss: 0.00912002763345083\n",
      "Epoch: 146 Batch: 500, loss: 0.45446986589684857\n",
      "Epoch: 147 Batch: 0, loss: 1.21911087218947\n",
      "Epoch: 147 Batch: 100, loss: 0.06997329529436977\n",
      "Epoch: 147 Batch: 200, loss: 0.2190987772491227\n",
      "Epoch: 147 Batch: 300, loss: 0.2327841790470588\n",
      "Epoch: 147 Batch: 400, loss: 0.17028719952480006\n",
      "Epoch: 147 Batch: 500, loss: 0.40165530132981125\n",
      "Epoch: 148 Batch: 0, loss: 0.21568588431453636\n",
      "Epoch: 148 Batch: 100, loss: 0.33213493456587506\n",
      "Epoch: 148 Batch: 200, loss: 0.9630120229467167\n",
      "Epoch: 148 Batch: 300, loss: 0.03361818614820907\n",
      "Epoch: 148 Batch: 400, loss: 0.7000577087705129\n",
      "Epoch: 148 Batch: 500, loss: 0.1329399259682322\n",
      "Epoch: 149 Batch: 0, loss: 1.0559348477432051\n",
      "Epoch: 149 Batch: 100, loss: 0.13380562172077223\n",
      "Epoch: 149 Batch: 200, loss: 0.9144919619782739\n",
      "Epoch: 149 Batch: 300, loss: 0.09812163279764267\n",
      "Epoch: 149 Batch: 400, loss: 0.008023399442276955\n",
      "Epoch: 149 Batch: 500, loss: 0.00843015353254687\n",
      "Epoch: 150 Batch: 0, loss: 0.4916411602280757\n",
      "Epoch: 150 Batch: 100, loss: 0.02016777689888713\n",
      "Epoch: 150 Batch: 200, loss: 0.8188492831256844\n",
      "Epoch: 150 Batch: 300, loss: 0.5722639840830186\n",
      "Epoch: 150 Batch: 400, loss: 0.002701049495294054\n",
      "Epoch: 150 Batch: 500, loss: 0.4160133226106793\n",
      "Epoch: 151 Batch: 0, loss: 0.999144883991799\n",
      "Epoch: 151 Batch: 100, loss: 0.1993785058360643\n",
      "Epoch: 151 Batch: 200, loss: 0.5766970258054566\n",
      "Epoch: 151 Batch: 300, loss: 0.8178561703880299\n",
      "Epoch: 151 Batch: 400, loss: 0.2547312811111487\n",
      "Epoch: 151 Batch: 500, loss: 1.875333623706925\n",
      "Epoch: 152 Batch: 0, loss: 0.6173601131057247\n",
      "Epoch: 152 Batch: 100, loss: 0.004028339891479925\n",
      "Epoch: 152 Batch: 200, loss: 0.2013908731550457\n",
      "Epoch: 152 Batch: 300, loss: 0.20115092739530524\n",
      "Epoch: 152 Batch: 400, loss: 0.4616597751496369\n",
      "Epoch: 152 Batch: 500, loss: 0.3316082199678271\n",
      "Epoch: 153 Batch: 0, loss: 0.2880283684293799\n",
      "Epoch: 153 Batch: 100, loss: 0.05160908275745114\n",
      "Epoch: 153 Batch: 200, loss: 0.8193930429496622\n",
      "Epoch: 153 Batch: 300, loss: 0.537151999890705\n",
      "Epoch: 153 Batch: 400, loss: 0.007894278107550553\n",
      "Epoch: 153 Batch: 500, loss: 0.9702747740712423\n",
      "Epoch: 154 Batch: 0, loss: 0.9936194875797721\n",
      "Epoch: 154 Batch: 100, loss: 0.10068941054369543\n",
      "Epoch: 154 Batch: 200, loss: 0.015444494417212186\n",
      "Epoch: 154 Batch: 300, loss: 1.4553020500941747\n",
      "Epoch: 154 Batch: 400, loss: 0.15187832493238826\n",
      "Epoch: 154 Batch: 500, loss: 2.114600730552927\n",
      "Epoch: 155 Batch: 0, loss: 0.011200609733477607\n",
      "Epoch: 155 Batch: 100, loss: 0.5296006257362614\n",
      "Epoch: 155 Batch: 200, loss: 0.08431213938901423\n",
      "Epoch: 155 Batch: 300, loss: 0.206898430384486\n",
      "Epoch: 155 Batch: 400, loss: 0.04237555024015595\n",
      "Epoch: 155 Batch: 500, loss: 0.02537940838958688\n",
      "Epoch: 156 Batch: 0, loss: 0.23654789853809857\n",
      "Epoch: 156 Batch: 100, loss: 0.07522183572386323\n",
      "Epoch: 156 Batch: 200, loss: 0.6212005512517522\n",
      "Epoch: 156 Batch: 300, loss: 0.058721463943883466\n",
      "Epoch: 156 Batch: 400, loss: 0.042939726260237\n",
      "Epoch: 156 Batch: 500, loss: 0.19024096284248043\n",
      "Epoch: 157 Batch: 0, loss: 0.029199470183531067\n",
      "Epoch: 157 Batch: 100, loss: 0.2682069087432493\n",
      "Epoch: 157 Batch: 200, loss: 0.010545902679668066\n",
      "Epoch: 157 Batch: 300, loss: 0.021573570069903368\n",
      "Epoch: 157 Batch: 400, loss: 0.003981093504614571\n",
      "Epoch: 157 Batch: 500, loss: 0.1526528315553241\n",
      "Epoch: 158 Batch: 0, loss: 0.08650310651156311\n",
      "Epoch: 158 Batch: 100, loss: 1.5672804054657523\n",
      "Epoch: 158 Batch: 200, loss: 0.40218186478230983\n",
      "Epoch: 158 Batch: 300, loss: 0.23483365020014568\n",
      "Epoch: 158 Batch: 400, loss: 0.0017119165357198146\n",
      "Epoch: 158 Batch: 500, loss: 0.6061038796734302\n",
      "Epoch: 159 Batch: 0, loss: 0.3890328562837872\n",
      "Epoch: 159 Batch: 100, loss: 0.6444740036917841\n",
      "Epoch: 159 Batch: 200, loss: 0.7726281500769652\n",
      "Epoch: 159 Batch: 300, loss: 0.38968957717661346\n",
      "Epoch: 159 Batch: 400, loss: 0.0018724863811402878\n",
      "Epoch: 159 Batch: 500, loss: 0.13830785125131786\n",
      "Epoch: 160 Batch: 0, loss: 0.28652209273033874\n",
      "Epoch: 160 Batch: 100, loss: 0.37263352432911834\n",
      "Epoch: 160 Batch: 200, loss: 0.9938016712935882\n",
      "Epoch: 160 Batch: 300, loss: 0.10188729578360668\n",
      "Epoch: 160 Batch: 400, loss: 0.008579435240332249\n",
      "Epoch: 160 Batch: 500, loss: 0.35105263310208157\n",
      "Epoch: 161 Batch: 0, loss: 0.919866558161473\n",
      "Epoch: 161 Batch: 100, loss: 0.0035868639074626606\n",
      "Epoch: 161 Batch: 200, loss: 0.3216346327534505\n",
      "Epoch: 161 Batch: 300, loss: 0.15697888142032676\n",
      "Epoch: 161 Batch: 400, loss: 0.13202359592850552\n",
      "Epoch: 161 Batch: 500, loss: 0.4524398374439412\n",
      "Epoch: 162 Batch: 0, loss: 1.2660914691077705\n",
      "Epoch: 162 Batch: 100, loss: 0.1112401102347749\n",
      "Epoch: 162 Batch: 200, loss: 0.020303754291549906\n",
      "Epoch: 162 Batch: 300, loss: 0.006970963048811463\n",
      "Epoch: 162 Batch: 400, loss: 0.26928238813434735\n",
      "Epoch: 162 Batch: 500, loss: 0.22310112436193008\n",
      "Epoch: 163 Batch: 0, loss: 0.010956403321099829\n",
      "Epoch: 163 Batch: 100, loss: 0.3055180560147576\n",
      "Epoch: 163 Batch: 200, loss: 0.11589719214161628\n",
      "Epoch: 163 Batch: 300, loss: 0.3715202282510726\n",
      "Epoch: 163 Batch: 400, loss: 0.9593510199721684\n",
      "Epoch: 163 Batch: 500, loss: 0.3637623863544595\n",
      "Epoch: 164 Batch: 0, loss: 0.13162840897589825\n",
      "Epoch: 164 Batch: 100, loss: 0.27245058493681257\n",
      "Epoch: 164 Batch: 200, loss: 0.20179915476491914\n",
      "Epoch: 164 Batch: 300, loss: 0.35979104408453194\n",
      "Epoch: 164 Batch: 400, loss: 0.4154060292133187\n",
      "Epoch: 164 Batch: 500, loss: 0.615762324849244\n",
      "Epoch: 165 Batch: 0, loss: 0.17336203097028988\n",
      "Epoch: 165 Batch: 100, loss: 0.22717057807054133\n",
      "Epoch: 165 Batch: 200, loss: 0.9609140355176279\n",
      "Epoch: 165 Batch: 300, loss: 0.5969297475503047\n",
      "Epoch: 165 Batch: 400, loss: 3.2617463512328455\n",
      "Epoch: 165 Batch: 500, loss: 0.5098883689451963\n",
      "Epoch: 166 Batch: 0, loss: 0.19930745033806999\n",
      "Epoch: 166 Batch: 100, loss: 0.5588544808009479\n",
      "Epoch: 166 Batch: 200, loss: 0.01877352554881662\n",
      "Epoch: 166 Batch: 300, loss: 0.05903845337743792\n",
      "Epoch: 166 Batch: 400, loss: 0.10316196635130724\n",
      "Epoch: 166 Batch: 500, loss: 0.048244250330984915\n",
      "Epoch: 167 Batch: 0, loss: 0.627819172156654\n",
      "Epoch: 167 Batch: 100, loss: 0.11394975423188868\n",
      "Epoch: 167 Batch: 200, loss: 0.06021555811726366\n",
      "Epoch: 167 Batch: 300, loss: 0.07042220536666928\n",
      "Epoch: 167 Batch: 400, loss: 0.1987953455935734\n",
      "Epoch: 167 Batch: 500, loss: 0.4212710852378463\n",
      "Epoch: 168 Batch: 0, loss: 0.14834349178991088\n",
      "Epoch: 168 Batch: 100, loss: 0.35865077500913245\n",
      "Epoch: 168 Batch: 200, loss: 0.5710061657537463\n",
      "Epoch: 168 Batch: 300, loss: 0.6116653180754578\n",
      "Epoch: 168 Batch: 400, loss: 0.5250342968834205\n",
      "Epoch: 168 Batch: 500, loss: 0.9537375152474722\n",
      "Epoch: 169 Batch: 0, loss: 0.18559665803020362\n",
      "Epoch: 169 Batch: 100, loss: 0.26865876367437597\n",
      "Epoch: 169 Batch: 200, loss: 0.10804733815487527\n",
      "Epoch: 169 Batch: 300, loss: 0.28538501559432783\n",
      "Epoch: 169 Batch: 400, loss: 0.4134631041180997\n",
      "Epoch: 169 Batch: 500, loss: 0.10658093994853025\n",
      "Epoch: 170 Batch: 0, loss: 0.3603391002740055\n",
      "Epoch: 170 Batch: 100, loss: 0.3805778696320372\n",
      "Epoch: 170 Batch: 200, loss: 0.41613230234737114\n",
      "Epoch: 170 Batch: 300, loss: 0.3526277144468501\n",
      "Epoch: 170 Batch: 400, loss: 0.009264260845909521\n",
      "Epoch: 170 Batch: 500, loss: 0.04458995409156233\n",
      "Epoch: 171 Batch: 0, loss: 0.39981966282736914\n",
      "Epoch: 171 Batch: 100, loss: 0.03695900209011958\n",
      "Epoch: 171 Batch: 200, loss: 0.08737922189652711\n",
      "Epoch: 171 Batch: 300, loss: 1.0034026390321606\n",
      "Epoch: 171 Batch: 400, loss: 0.040186163698652876\n",
      "Epoch: 171 Batch: 500, loss: 0.12872938285108484\n",
      "Epoch: 172 Batch: 0, loss: 0.003464591845567781\n",
      "Epoch: 172 Batch: 100, loss: 0.9291029444882184\n",
      "Epoch: 172 Batch: 200, loss: 0.03886249543639189\n",
      "Epoch: 172 Batch: 300, loss: 0.36847685856693224\n",
      "Epoch: 172 Batch: 400, loss: 0.6170442125924062\n",
      "Epoch: 172 Batch: 500, loss: 0.0022038760774430633\n",
      "Epoch: 173 Batch: 0, loss: 0.12252090499125366\n",
      "Epoch: 173 Batch: 100, loss: 0.26924619140928785\n",
      "Epoch: 173 Batch: 200, loss: 0.010063733543848506\n",
      "Epoch: 173 Batch: 300, loss: 0.3215675629547204\n",
      "Epoch: 173 Batch: 400, loss: 0.35190234427020717\n",
      "Epoch: 173 Batch: 500, loss: 0.14739087936293824\n",
      "Epoch: 174 Batch: 0, loss: 0.4017067878675394\n",
      "Epoch: 174 Batch: 100, loss: 0.46554711411662447\n",
      "Epoch: 174 Batch: 200, loss: 0.32819794764183885\n",
      "Epoch: 174 Batch: 300, loss: 0.027862204290616987\n",
      "Epoch: 174 Batch: 400, loss: 0.15156050796442916\n",
      "Epoch: 174 Batch: 500, loss: 0.8392545060938646\n",
      "Epoch: 175 Batch: 0, loss: 0.10489234567674488\n",
      "Epoch: 175 Batch: 100, loss: 0.019959442134249144\n",
      "Epoch: 175 Batch: 200, loss: 0.20126844744966974\n",
      "Epoch: 175 Batch: 300, loss: 0.5127606590389383\n",
      "Epoch: 175 Batch: 400, loss: 0.16637262123926916\n",
      "Epoch: 175 Batch: 500, loss: 0.04534148691594121\n",
      "Epoch: 176 Batch: 0, loss: 0.039764778002340975\n",
      "Epoch: 176 Batch: 100, loss: 0.005899269949407011\n",
      "Epoch: 176 Batch: 200, loss: 0.9170085912128573\n",
      "Epoch: 176 Batch: 300, loss: 0.2757514066395967\n",
      "Epoch: 176 Batch: 400, loss: 0.007961550823831227\n",
      "Epoch: 176 Batch: 500, loss: 0.0014441502796962177\n",
      "Epoch: 177 Batch: 0, loss: 0.3590708186687861\n",
      "Epoch: 177 Batch: 100, loss: 0.21128072020960456\n",
      "Epoch: 177 Batch: 200, loss: 0.30461303620634755\n",
      "Epoch: 177 Batch: 300, loss: 0.653251610373682\n",
      "Epoch: 177 Batch: 400, loss: 0.6523151874393835\n",
      "Epoch: 177 Batch: 500, loss: 0.27414827009765347\n",
      "Epoch: 178 Batch: 0, loss: 0.5850062594672311\n",
      "Epoch: 178 Batch: 100, loss: 0.17216812383735397\n",
      "Epoch: 178 Batch: 200, loss: 0.18297506460149876\n",
      "Epoch: 178 Batch: 300, loss: 0.47092310007830135\n",
      "Epoch: 178 Batch: 400, loss: 0.3514365453540475\n",
      "Epoch: 178 Batch: 500, loss: 0.049717756370681744\n",
      "Epoch: 179 Batch: 0, loss: 0.0580333758227378\n",
      "Epoch: 179 Batch: 100, loss: 0.29778184822267895\n",
      "Epoch: 179 Batch: 200, loss: 0.02441157414284517\n",
      "Epoch: 179 Batch: 300, loss: 0.3814533005571306\n",
      "Epoch: 179 Batch: 400, loss: 0.31952496851825696\n",
      "Epoch: 179 Batch: 500, loss: 0.4173630961060518\n",
      "Epoch: 180 Batch: 0, loss: 0.11156709729871415\n",
      "Epoch: 180 Batch: 100, loss: 0.6951112325732434\n",
      "Epoch: 180 Batch: 200, loss: 0.28085794731406183\n",
      "Epoch: 180 Batch: 300, loss: 0.006735083650524674\n",
      "Epoch: 180 Batch: 400, loss: 0.3671561357098483\n",
      "Epoch: 180 Batch: 500, loss: 0.04916535845635423\n",
      "Epoch: 181 Batch: 0, loss: 0.14955726045282813\n",
      "Epoch: 181 Batch: 100, loss: 0.20825944236039357\n",
      "Epoch: 181 Batch: 200, loss: 0.885801258423017\n",
      "Epoch: 181 Batch: 300, loss: 0.2977852157730088\n",
      "Epoch: 181 Batch: 400, loss: 0.3202149812618013\n",
      "Epoch: 181 Batch: 500, loss: 0.009389956782541795\n",
      "Epoch: 182 Batch: 0, loss: 0.3246702316275582\n",
      "Epoch: 182 Batch: 100, loss: 1.0521459953750436\n",
      "Epoch: 182 Batch: 200, loss: 0.26359844457424714\n",
      "Epoch: 182 Batch: 300, loss: 0.08704290478476603\n",
      "Epoch: 182 Batch: 400, loss: 0.8860943646274854\n",
      "Epoch: 182 Batch: 500, loss: 0.08246955649496607\n",
      "Epoch: 183 Batch: 0, loss: 0.3147213970879801\n",
      "Epoch: 183 Batch: 100, loss: 0.005626782340298452\n",
      "Epoch: 183 Batch: 200, loss: 0.0017283739666601001\n",
      "Epoch: 183 Batch: 300, loss: 0.024016929335785437\n",
      "Epoch: 183 Batch: 400, loss: 0.3247570839262096\n",
      "Epoch: 183 Batch: 500, loss: 0.0936659612948353\n",
      "Epoch: 184 Batch: 0, loss: 0.869962912451576\n",
      "Epoch: 184 Batch: 100, loss: 0.47033555907468794\n",
      "Epoch: 184 Batch: 200, loss: 0.45729059238981185\n",
      "Epoch: 184 Batch: 300, loss: 0.5073553533028892\n",
      "Epoch: 184 Batch: 400, loss: 0.00742242364813415\n",
      "Epoch: 184 Batch: 500, loss: 0.052894113797910355\n",
      "Epoch: 185 Batch: 0, loss: 0.31413585264293997\n",
      "Epoch: 185 Batch: 100, loss: 0.017369880778676\n",
      "Epoch: 185 Batch: 200, loss: 0.07735167715481674\n",
      "Epoch: 185 Batch: 300, loss: 0.21224862523480137\n",
      "Epoch: 185 Batch: 400, loss: 0.33009769907494485\n",
      "Epoch: 185 Batch: 500, loss: 0.20508933613123806\n",
      "Epoch: 186 Batch: 0, loss: 0.3788918296240156\n",
      "Epoch: 186 Batch: 100, loss: 0.33136438737593665\n",
      "Epoch: 186 Batch: 200, loss: 0.6440683816014042\n",
      "Epoch: 186 Batch: 300, loss: 0.051622610436632035\n",
      "Epoch: 186 Batch: 400, loss: 0.14388235103332464\n",
      "Epoch: 186 Batch: 500, loss: 0.6100151307357059\n",
      "Epoch: 187 Batch: 0, loss: 0.18918503206102769\n",
      "Epoch: 187 Batch: 100, loss: 0.13547507283784707\n",
      "Epoch: 187 Batch: 200, loss: 0.21860439269734944\n",
      "Epoch: 187 Batch: 300, loss: 0.10964515707425225\n",
      "Epoch: 187 Batch: 400, loss: 0.05999326314105218\n",
      "Epoch: 187 Batch: 500, loss: 0.022523447073390702\n",
      "Epoch: 188 Batch: 0, loss: 0.4401742371312952\n",
      "Epoch: 188 Batch: 100, loss: 0.04255074821342532\n",
      "Epoch: 188 Batch: 200, loss: 0.009807899548496932\n",
      "Epoch: 188 Batch: 300, loss: 0.13229301999744744\n",
      "Epoch: 188 Batch: 400, loss: 0.021523516872867084\n",
      "Epoch: 188 Batch: 500, loss: 0.10417695885969541\n",
      "Epoch: 189 Batch: 0, loss: 0.04518459811603992\n",
      "Epoch: 189 Batch: 100, loss: 0.12568006591748765\n",
      "Epoch: 189 Batch: 200, loss: 0.9909415075032513\n",
      "Epoch: 189 Batch: 300, loss: 0.10070112143616393\n",
      "Epoch: 189 Batch: 400, loss: 0.2528048317233233\n",
      "Epoch: 189 Batch: 500, loss: 0.18179839173325757\n",
      "Epoch: 190 Batch: 0, loss: 0.19119952475925248\n",
      "Epoch: 190 Batch: 100, loss: 0.0035328328420181484\n",
      "Epoch: 190 Batch: 200, loss: 0.32491125098319634\n",
      "Epoch: 190 Batch: 300, loss: 0.1995912399067688\n",
      "Epoch: 190 Batch: 400, loss: 0.5120219260512865\n",
      "Epoch: 190 Batch: 500, loss: 0.49773503998491053\n",
      "Epoch: 191 Batch: 0, loss: 0.15619880380488496\n",
      "Epoch: 191 Batch: 100, loss: 0.9528501527598786\n",
      "Epoch: 191 Batch: 200, loss: 0.9412110013940957\n",
      "Epoch: 191 Batch: 300, loss: 0.7959102697628079\n",
      "Epoch: 191 Batch: 400, loss: 0.3603520941948064\n",
      "Epoch: 191 Batch: 500, loss: 0.003415549577941861\n",
      "Epoch: 192 Batch: 0, loss: 0.03657544001450531\n",
      "Epoch: 192 Batch: 100, loss: 0.37398527047101193\n",
      "Epoch: 192 Batch: 200, loss: 1.0121349802834063\n",
      "Epoch: 192 Batch: 300, loss: 0.09724777791815058\n",
      "Epoch: 192 Batch: 400, loss: 0.5272147261389395\n",
      "Epoch: 192 Batch: 500, loss: 0.04379283993571072\n",
      "Epoch: 193 Batch: 0, loss: 0.7043191106337137\n",
      "Epoch: 193 Batch: 100, loss: 0.12320253792431884\n",
      "Epoch: 193 Batch: 200, loss: 0.040991696054279866\n",
      "Epoch: 193 Batch: 300, loss: 0.4963666102462834\n",
      "Epoch: 193 Batch: 400, loss: 0.07793309584745309\n",
      "Epoch: 193 Batch: 500, loss: 0.1129350052284708\n",
      "Epoch: 194 Batch: 0, loss: 0.1381511547353905\n",
      "Epoch: 194 Batch: 100, loss: 1.0147845074398356\n",
      "Epoch: 194 Batch: 200, loss: 0.491811282822187\n",
      "Epoch: 194 Batch: 300, loss: 0.04374242243406622\n",
      "Epoch: 194 Batch: 400, loss: 0.2628302810090467\n",
      "Epoch: 194 Batch: 500, loss: 0.6205591448880249\n",
      "Epoch: 195 Batch: 0, loss: 0.057187820871852486\n",
      "Epoch: 195 Batch: 100, loss: 0.040176135017225875\n",
      "Epoch: 195 Batch: 200, loss: 0.02094895931949072\n",
      "Epoch: 195 Batch: 300, loss: 0.7087384483492325\n",
      "Epoch: 195 Batch: 400, loss: 0.2593920039876941\n",
      "Epoch: 195 Batch: 500, loss: 0.057238519361274276\n",
      "Epoch: 196 Batch: 0, loss: 0.04417298405623604\n",
      "Epoch: 196 Batch: 100, loss: 0.10776554707924897\n",
      "Epoch: 196 Batch: 200, loss: 0.43482013940561515\n",
      "Epoch: 196 Batch: 300, loss: 1.0014686933727155\n",
      "Epoch: 196 Batch: 400, loss: 0.05763325794326948\n",
      "Epoch: 196 Batch: 500, loss: 0.036066350768211665\n",
      "Epoch: 197 Batch: 0, loss: 0.17616954024804776\n",
      "Epoch: 197 Batch: 100, loss: 0.06771005699164039\n",
      "Epoch: 197 Batch: 200, loss: 0.3557137636566367\n",
      "Epoch: 197 Batch: 300, loss: 0.0585999347683167\n",
      "Epoch: 197 Batch: 400, loss: 0.7994281500393703\n",
      "Epoch: 197 Batch: 500, loss: 0.007479587331315655\n",
      "Epoch: 198 Batch: 0, loss: 0.1059679543532229\n",
      "Epoch: 198 Batch: 100, loss: 0.37585945069002086\n",
      "Epoch: 198 Batch: 200, loss: 0.005722658631909806\n",
      "Epoch: 198 Batch: 300, loss: 0.9587523131506945\n",
      "Epoch: 198 Batch: 400, loss: 0.1346282885757131\n",
      "Epoch: 198 Batch: 500, loss: 0.25351338016843433\n",
      "Epoch: 199 Batch: 0, loss: 0.2903206216241051\n",
      "Epoch: 199 Batch: 100, loss: 1.244108413816639\n",
      "Epoch: 199 Batch: 200, loss: 0.1986767782491345\n",
      "Epoch: 199 Batch: 300, loss: 1.0427330363064338\n",
      "Epoch: 199 Batch: 400, loss: 0.0781383436931467\n",
      "Epoch: 199 Batch: 500, loss: 0.6452547241821518\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], target[i]\n",
    "    predicate = model(np.array([x1, x2]), w, b)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM: {}, LSTAT: {}, EXPENSIVE: {}, Predicated: {}'.format(x1, x2, y, predicate_label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RM: 5.631, LSTAT: 29.93, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.186, LSTAT: 28.32, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.093, LSTAT: 29.68, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.203, LSTAT: 9.59, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 5.837, LSTAT: 15.69, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.642, LSTAT: 9.69, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.229, LSTAT: 12.87, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 3.863, LSTAT: 13.33, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.757, LSTAT: 17.31, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.402, LSTAT: 11.32, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.655, LSTAT: 17.73, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.856, LSTAT: 13.0, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.438, LSTAT: 3.59, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.458, LSTAT: 12.6, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.549, LSTAT: 7.39, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.51, LSTAT: 7.39, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 5.362, LSTAT: 10.19, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.961, LSTAT: 17.93, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.642, LSTAT: 9.69, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 7.203, LSTAT: 9.59, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.335, LSTAT: 16.96, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.405, LSTAT: 8.2, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.972, LSTAT: 9.97, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.404, LSTAT: 20.31, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 4.138, LSTAT: 23.34, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.431, LSTAT: 15.39, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.63, LSTAT: 4.7, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.536, LSTAT: 23.6, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.009, LSTAT: 13.27, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.127, LSTAT: 14.09, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.887, LSTAT: 16.35, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.333, LSTAT: 7.34, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.23, LSTAT: 12.93, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.036, LSTAT: 25.68, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.014, LSTAT: 10.53, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.878, LSTAT: 8.1, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.655, LSTAT: 17.73, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.148, LSTAT: 3.56, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.513, LSTAT: 10.29, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.857, LSTAT: 21.32, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.8, LSTAT: 5.03, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.169, LSTAT: 5.81, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.341, LSTAT: 17.79, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.167, LSTAT: 16.29, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.426, LSTAT: 7.2, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.803, LSTAT: 14.64, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.813, LSTAT: 19.88, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.49, LSTAT: 5.98, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.98, LSTAT: 11.66, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.749, LSTAT: 17.44, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.726, LSTAT: 8.05, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.206, LSTAT: 8.1, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.836, LSTAT: 18.66, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.731, LSTAT: 13.61, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.889, LSTAT: 15.71, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.489, LSTAT: 1.73, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.266, LSTAT: 7.9, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.56, LSTAT: 10.45, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.02, LSTAT: 10.11, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.86, LSTAT: 6.92, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.803, LSTAT: 14.64, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.525, LSTAT: 18.13, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.037, LSTAT: 8.01, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.242, LSTAT: 10.74, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.272, LSTAT: 16.14, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.148, LSTAT: 3.56, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.345, LSTAT: 4.97, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.606, LSTAT: 7.37, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.552, LSTAT: 3.76, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.03, LSTAT: 18.8, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.069, LSTAT: 9.55, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.021, LSTAT: 10.3, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.122, LSTAT: 5.98, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 7.42, LSTAT: 6.47, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.12, LSTAT: 9.08, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.794, LSTAT: 21.24, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.415, LSTAT: 6.12, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.849, LSTAT: 7.53, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.453, LSTAT: 30.59, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.696, LSTAT: 7.18, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.47, LSTAT: 3.16, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 4.628, LSTAT: 34.37, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.249, LSTAT: 4.81, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.147, LSTAT: 5.33, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 8.069, LSTAT: 4.21, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 8.266, LSTAT: 4.14, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.162, LSTAT: 7.43, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.759, LSTAT: 14.13, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.968, LSTAT: 9.29, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.546, LSTAT: 5.33, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.939, LSTAT: 5.89, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.333, LSTAT: 7.79, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.016, LSTAT: 2.96, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.208, LSTAT: 15.17, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.051, LSTAT: 18.76, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.762, LSTAT: 9.5, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.459, LSTAT: 23.98, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.998, LSTAT: 8.43, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.471, LSTAT: 17.12, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.29, LSTAT: 4.67, EXPENSIVE: 0, Predicated: 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "\n",
    "# 剩下一件事情，就是要检查我们这个模型的准确度到底如何！！\n",
    "\"\"\"\n",
    "如何衡量模型的好坏：\n",
    "1. accuracy 准确度\n",
    "2. precision 精确度\n",
    "3. recall 召回率\n",
    "4. f1, f2 score\n",
    "5. AUC-ROC 曲线\n",
    "引出一个非常非常重要的概念： =》 过拟合 和 欠拟合 （over-fitting and under-fitting）\n",
    "整个机器学习的过程，就是在不断的进行过拟合和欠拟合的调整！\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n如何衡量模型的好坏：\\n1. accuracy 准确度\\n2. precision 精确度\\n3. recall 召回率\\n4. f1, f2 score\\n5. AUC-ROC 曲线\\n引出一个非常非常重要的概念： =》 过拟合 和 欠拟合 （over-fitting and under-fitting）\\n整个机器学习的过程，就是在不断的进行过拟合和欠拟合的调整！\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "32732e49ddba1da8b293d0354da9484fcc377d4ba69e79a82935691a68d0ecf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}