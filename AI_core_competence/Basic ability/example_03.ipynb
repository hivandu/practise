{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Linear Regression Example\n",
    "\n",
    "Implement Linear Regression for Beijing House Price Problem\n",
    "\"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\"\n",
    "Part-01: Linear Regression\n",
    "\"\"\"\n",
    "\n",
    "housing_price = load_boston()\n",
    "dataframe = pd.DataFrame(housing_price['data'])\n",
    "dataframe.columns = housing_price['feature_names']\n",
    "dataframe['price'] = housing_price['target']\n",
    "\n",
    "# sns.heatmap(dataframe.corr(), annot=True, fmt='.1f')\n",
    "# plt.show()\n",
    "\n",
    "print(dataframe.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT', 'price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "rm = dataframe['RM']\n",
    "lst = dataframe['LSTAT']\n",
    "target = dataframe['price']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def model(x, w, b):\n",
    "    return np.dot(x, w.T) + b\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return np.mean( (yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def partial_w(x1, x2, y, yhat):\n",
    "    return np.array([2 *np.mean((yhat - y) * x1), 2 * np.mean((yhat - y)  * x2)])\n",
    "\n",
    "\n",
    "def partial_b(x1, x2, y, yhat):\n",
    "    return 2 * np.mean((yhat - y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "w = np.random.random_sample((1, 2))\n",
    "print(w)\n",
    "b = 0\n",
    "alpha = 1e-5\n",
    "\n",
    "epoch = 200\n",
    "history = []\n",
    "\n",
    "history_k_b_loss = []"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.76646144 0.3095512 ]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for e in range(epoch):\n",
    "    losses = []\n",
    "    for batch in range(len(rm)):\n",
    "        random_index = random.choice(range(len(rm)))\n",
    "\n",
    "        x1, x2 = rm[random_index], lst[random_index]\n",
    "        y = target[random_index]\n",
    "\n",
    "        yhat = model(np.array([x1, x2]), w, b)\n",
    "        loss_v = loss(yhat, y)\n",
    "\n",
    "        w = w - partial_w(x1, x2, y, yhat) * alpha\n",
    "        b = b - partial_b(x1, x2, y, yhat) * alpha\n",
    "\n",
    "        losses.append(loss_v)\n",
    "\n",
    "        history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, loss: {}'.format(e, batch, np.mean(losses)))\n",
    "\n",
    "    history.append(np.mean(losses))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Batch: 0, loss: 151.86271856102778\n",
      "Epoch: 0, Batch: 100, loss: 263.5872813250959\n",
      "Epoch: 0, Batch: 200, loss: 251.738169143727\n",
      "Epoch: 0, Batch: 300, loss: 265.0873434683313\n",
      "Epoch: 0, Batch: 400, loss: 246.81922554270534\n",
      "Epoch: 0, Batch: 500, loss: 235.3032255992267\n",
      "Epoch: 1, Batch: 0, loss: 19.57790198635195\n",
      "Epoch: 1, Batch: 100, loss: 159.31380412508983\n",
      "Epoch: 1, Batch: 200, loss: 149.39271607684955\n",
      "Epoch: 1, Batch: 300, loss: 166.24008703389129\n",
      "Epoch: 1, Batch: 400, loss: 160.65535981907715\n",
      "Epoch: 1, Batch: 500, loss: 159.46308073670542\n",
      "Epoch: 2, Batch: 0, loss: 218.59722447423346\n",
      "Epoch: 2, Batch: 100, loss: 136.07201691576378\n",
      "Epoch: 2, Batch: 200, loss: 161.51368122041697\n",
      "Epoch: 2, Batch: 300, loss: 159.4969141796809\n",
      "Epoch: 2, Batch: 400, loss: 146.21689426224953\n",
      "Epoch: 2, Batch: 500, loss: 138.22587212292893\n",
      "Epoch: 3, Batch: 0, loss: 69.70191445306189\n",
      "Epoch: 3, Batch: 100, loss: 116.16786760488094\n",
      "Epoch: 3, Batch: 200, loss: 119.71565030867042\n",
      "Epoch: 3, Batch: 300, loss: 119.72495468428124\n",
      "Epoch: 3, Batch: 400, loss: 116.70865835408661\n",
      "Epoch: 3, Batch: 500, loss: 111.52662518854393\n",
      "Epoch: 4, Batch: 0, loss: 301.1079696325349\n",
      "Epoch: 4, Batch: 100, loss: 101.1909070945794\n",
      "Epoch: 4, Batch: 200, loss: 100.01416445487479\n",
      "Epoch: 4, Batch: 300, loss: 90.97206766070506\n",
      "Epoch: 4, Batch: 400, loss: 86.95881766845801\n",
      "Epoch: 4, Batch: 500, loss: 88.33357502745008\n",
      "Epoch: 5, Batch: 0, loss: 687.0273172938508\n",
      "Epoch: 5, Batch: 100, loss: 87.36807188405818\n",
      "Epoch: 5, Batch: 200, loss: 74.37797938908042\n",
      "Epoch: 5, Batch: 300, loss: 75.59216012531017\n",
      "Epoch: 5, Batch: 400, loss: 78.77199270772117\n",
      "Epoch: 5, Batch: 500, loss: 77.72356050510173\n",
      "Epoch: 6, Batch: 0, loss: 142.03235346639255\n",
      "Epoch: 6, Batch: 100, loss: 82.12889078928916\n",
      "Epoch: 6, Batch: 200, loss: 80.40001132271382\n",
      "Epoch: 6, Batch: 300, loss: 79.73214799065559\n",
      "Epoch: 6, Batch: 400, loss: 78.41625605450311\n",
      "Epoch: 6, Batch: 500, loss: 73.61440886769903\n",
      "Epoch: 7, Batch: 0, loss: 2.999704782203545\n",
      "Epoch: 7, Batch: 100, loss: 53.73487423242271\n",
      "Epoch: 7, Batch: 200, loss: 69.25139129372873\n",
      "Epoch: 7, Batch: 300, loss: 71.43868136744443\n",
      "Epoch: 7, Batch: 400, loss: 74.62067875620376\n",
      "Epoch: 7, Batch: 500, loss: 71.88724308147587\n",
      "Epoch: 8, Batch: 0, loss: 36.896851330025626\n",
      "Epoch: 8, Batch: 100, loss: 69.68140462796016\n",
      "Epoch: 8, Batch: 200, loss: 69.0446454834692\n",
      "Epoch: 8, Batch: 300, loss: 66.61806321337968\n",
      "Epoch: 8, Batch: 400, loss: 64.1019048076429\n",
      "Epoch: 8, Batch: 500, loss: 64.57199748726141\n",
      "Epoch: 9, Batch: 0, loss: 1.5620537354076756\n",
      "Epoch: 9, Batch: 100, loss: 62.479252095999044\n",
      "Epoch: 9, Batch: 200, loss: 56.29570175037498\n",
      "Epoch: 9, Batch: 300, loss: 63.127310419096595\n",
      "Epoch: 9, Batch: 400, loss: 66.26081494988455\n",
      "Epoch: 9, Batch: 500, loss: 62.1994102965722\n",
      "Epoch: 10, Batch: 0, loss: 22.030416485290065\n",
      "Epoch: 10, Batch: 100, loss: 62.62437714937045\n",
      "Epoch: 10, Batch: 200, loss: 59.05630710317881\n",
      "Epoch: 10, Batch: 300, loss: 54.5041687174911\n",
      "Epoch: 10, Batch: 400, loss: 55.32999280381202\n",
      "Epoch: 10, Batch: 500, loss: 54.87343559518623\n",
      "Epoch: 11, Batch: 0, loss: 29.361104848422762\n",
      "Epoch: 11, Batch: 100, loss: 42.547683806003\n",
      "Epoch: 11, Batch: 200, loss: 35.99141361624825\n",
      "Epoch: 11, Batch: 300, loss: 34.940465018782014\n",
      "Epoch: 11, Batch: 400, loss: 40.66636646214102\n",
      "Epoch: 11, Batch: 500, loss: 38.28134421927383\n",
      "Epoch: 12, Batch: 0, loss: 59.49993038102367\n",
      "Epoch: 12, Batch: 100, loss: 39.89516680768858\n",
      "Epoch: 12, Batch: 200, loss: 34.19837436038725\n",
      "Epoch: 12, Batch: 300, loss: 33.48473431165181\n",
      "Epoch: 12, Batch: 400, loss: 34.69317741078055\n",
      "Epoch: 12, Batch: 500, loss: 33.12654176831267\n",
      "Epoch: 13, Batch: 0, loss: 25.271972178731048\n",
      "Epoch: 13, Batch: 100, loss: 31.612711881588854\n",
      "Epoch: 13, Batch: 200, loss: 39.35781727181857\n",
      "Epoch: 13, Batch: 300, loss: 36.8155649469042\n",
      "Epoch: 13, Batch: 400, loss: 38.3033897993873\n",
      "Epoch: 13, Batch: 500, loss: 36.61344656354103\n",
      "Epoch: 14, Batch: 0, loss: 7.084891138776679\n",
      "Epoch: 14, Batch: 100, loss: 40.910490317411615\n",
      "Epoch: 14, Batch: 200, loss: 44.152767526044386\n",
      "Epoch: 14, Batch: 300, loss: 43.27885404471312\n",
      "Epoch: 14, Batch: 400, loss: 46.88395620164672\n",
      "Epoch: 14, Batch: 500, loss: 44.38927904791927\n",
      "Epoch: 15, Batch: 0, loss: 20.45614877389572\n",
      "Epoch: 15, Batch: 100, loss: 32.40748144288569\n",
      "Epoch: 15, Batch: 200, loss: 37.07707762580113\n",
      "Epoch: 15, Batch: 300, loss: 37.09109419926531\n",
      "Epoch: 15, Batch: 400, loss: 39.30329538619549\n",
      "Epoch: 15, Batch: 500, loss: 36.578203328669986\n",
      "Epoch: 16, Batch: 0, loss: 92.38577100309116\n",
      "Epoch: 16, Batch: 100, loss: 38.66016206695904\n",
      "Epoch: 16, Batch: 200, loss: 31.916286313138308\n",
      "Epoch: 16, Batch: 300, loss: 34.41960011323012\n",
      "Epoch: 16, Batch: 400, loss: 33.85825821505797\n",
      "Epoch: 16, Batch: 500, loss: 34.78532404516187\n",
      "Epoch: 17, Batch: 0, loss: 6.889806565934152\n",
      "Epoch: 17, Batch: 100, loss: 21.95791331495036\n",
      "Epoch: 17, Batch: 200, loss: 27.29413704953488\n",
      "Epoch: 17, Batch: 300, loss: 28.412592296096975\n",
      "Epoch: 17, Batch: 400, loss: 28.729023867738768\n",
      "Epoch: 17, Batch: 500, loss: 29.226775199267674\n",
      "Epoch: 18, Batch: 0, loss: 198.27259611730167\n",
      "Epoch: 18, Batch: 100, loss: 42.10293942614401\n",
      "Epoch: 18, Batch: 200, loss: 39.8124791105493\n",
      "Epoch: 18, Batch: 300, loss: 34.54985922784335\n",
      "Epoch: 18, Batch: 400, loss: 33.20359934905601\n",
      "Epoch: 18, Batch: 500, loss: 34.0249912901313\n",
      "Epoch: 19, Batch: 0, loss: 17.98815619986454\n",
      "Epoch: 19, Batch: 100, loss: 26.076312723388213\n",
      "Epoch: 19, Batch: 200, loss: 29.222649772026145\n",
      "Epoch: 19, Batch: 300, loss: 30.624361129199805\n",
      "Epoch: 19, Batch: 400, loss: 30.218575917281\n",
      "Epoch: 19, Batch: 500, loss: 30.00436544578612\n",
      "Epoch: 20, Batch: 0, loss: 0.0015859058859536035\n",
      "Epoch: 20, Batch: 100, loss: 24.623892928988273\n",
      "Epoch: 20, Batch: 200, loss: 35.26859813481474\n",
      "Epoch: 20, Batch: 300, loss: 34.69751343874608\n",
      "Epoch: 20, Batch: 400, loss: 34.12203376947327\n",
      "Epoch: 20, Batch: 500, loss: 34.46291319407624\n",
      "Epoch: 21, Batch: 0, loss: 161.14912550890529\n",
      "Epoch: 21, Batch: 100, loss: 43.69241143537513\n",
      "Epoch: 21, Batch: 200, loss: 34.354055564250764\n",
      "Epoch: 21, Batch: 300, loss: 33.4141543870957\n",
      "Epoch: 21, Batch: 400, loss: 29.67776980159644\n",
      "Epoch: 21, Batch: 500, loss: 31.359651906740048\n",
      "Epoch: 22, Batch: 0, loss: 4.694933397995705\n",
      "Epoch: 22, Batch: 100, loss: 27.317556158556176\n",
      "Epoch: 22, Batch: 200, loss: 28.053522442427383\n",
      "Epoch: 22, Batch: 300, loss: 31.531247469511346\n",
      "Epoch: 22, Batch: 400, loss: 31.89224710598725\n",
      "Epoch: 22, Batch: 500, loss: 31.942578678990216\n",
      "Epoch: 23, Batch: 0, loss: 60.49088020425111\n",
      "Epoch: 23, Batch: 100, loss: 24.336701308769136\n",
      "Epoch: 23, Batch: 200, loss: 31.7638544445267\n",
      "Epoch: 23, Batch: 300, loss: 32.897238300733655\n",
      "Epoch: 23, Batch: 400, loss: 34.370256622575575\n",
      "Epoch: 23, Batch: 500, loss: 34.20967828301992\n",
      "Epoch: 24, Batch: 0, loss: 12.227703694585443\n",
      "Epoch: 24, Batch: 100, loss: 40.038148660323756\n",
      "Epoch: 24, Batch: 200, loss: 37.685625987092166\n",
      "Epoch: 24, Batch: 300, loss: 35.586942453758894\n",
      "Epoch: 24, Batch: 400, loss: 33.269859003856475\n",
      "Epoch: 24, Batch: 500, loss: 32.85228694694926\n",
      "Epoch: 25, Batch: 0, loss: 3.926836992766063\n",
      "Epoch: 25, Batch: 100, loss: 33.15925241452309\n",
      "Epoch: 25, Batch: 200, loss: 34.356903394375564\n",
      "Epoch: 25, Batch: 300, loss: 33.58234853599115\n",
      "Epoch: 25, Batch: 400, loss: 35.02741156475758\n",
      "Epoch: 25, Batch: 500, loss: 33.499646226388\n",
      "Epoch: 26, Batch: 0, loss: 0.8578349713062072\n",
      "Epoch: 26, Batch: 100, loss: 32.596236380035656\n",
      "Epoch: 26, Batch: 200, loss: 32.489380350880275\n",
      "Epoch: 26, Batch: 300, loss: 31.1861640307448\n",
      "Epoch: 26, Batch: 400, loss: 32.26211836114462\n",
      "Epoch: 26, Batch: 500, loss: 31.369599042609938\n",
      "Epoch: 27, Batch: 0, loss: 22.104615036401647\n",
      "Epoch: 27, Batch: 100, loss: 28.481794856334727\n",
      "Epoch: 27, Batch: 200, loss: 27.45479438330033\n",
      "Epoch: 27, Batch: 300, loss: 28.926492481023608\n",
      "Epoch: 27, Batch: 400, loss: 29.11832225082311\n",
      "Epoch: 27, Batch: 500, loss: 30.083655866017732\n",
      "Epoch: 28, Batch: 0, loss: 243.9054676188883\n",
      "Epoch: 28, Batch: 100, loss: 31.258928854990803\n",
      "Epoch: 28, Batch: 200, loss: 27.1684138839439\n",
      "Epoch: 28, Batch: 300, loss: 27.30249422801341\n",
      "Epoch: 28, Batch: 400, loss: 29.928183857148284\n",
      "Epoch: 28, Batch: 500, loss: 33.041488562238925\n",
      "Epoch: 29, Batch: 0, loss: 0.7775333426504427\n",
      "Epoch: 29, Batch: 100, loss: 38.46476642429085\n",
      "Epoch: 29, Batch: 200, loss: 35.68328200190081\n",
      "Epoch: 29, Batch: 300, loss: 34.00318422649962\n",
      "Epoch: 29, Batch: 400, loss: 30.707524154260668\n",
      "Epoch: 29, Batch: 500, loss: 32.190528443319\n",
      "Epoch: 30, Batch: 0, loss: 48.637841165298916\n",
      "Epoch: 30, Batch: 100, loss: 22.94695814802364\n",
      "Epoch: 30, Batch: 200, loss: 25.67216308285661\n",
      "Epoch: 30, Batch: 300, loss: 27.455337516276327\n",
      "Epoch: 30, Batch: 400, loss: 27.849067951681878\n",
      "Epoch: 30, Batch: 500, loss: 26.887034347906557\n",
      "Epoch: 31, Batch: 0, loss: 20.304078356280304\n",
      "Epoch: 31, Batch: 100, loss: 38.522726074437244\n",
      "Epoch: 31, Batch: 200, loss: 34.9724137530051\n",
      "Epoch: 31, Batch: 300, loss: 33.27969556826092\n",
      "Epoch: 31, Batch: 400, loss: 30.907077573856046\n",
      "Epoch: 31, Batch: 500, loss: 32.38314340701879\n",
      "Epoch: 32, Batch: 0, loss: 10.015481515053919\n",
      "Epoch: 32, Batch: 100, loss: 26.563299662973957\n",
      "Epoch: 32, Batch: 200, loss: 30.724156498987995\n",
      "Epoch: 32, Batch: 300, loss: 33.743815007070964\n",
      "Epoch: 32, Batch: 400, loss: 30.268636963866264\n",
      "Epoch: 32, Batch: 500, loss: 32.402676391411525\n",
      "Epoch: 33, Batch: 0, loss: 0.5254683355011355\n",
      "Epoch: 33, Batch: 100, loss: 35.25841782970075\n",
      "Epoch: 33, Batch: 200, loss: 28.401137696364298\n",
      "Epoch: 33, Batch: 300, loss: 29.49186240006472\n",
      "Epoch: 33, Batch: 400, loss: 29.96508705300463\n",
      "Epoch: 33, Batch: 500, loss: 30.55342166100101\n",
      "Epoch: 34, Batch: 0, loss: 2.2955256387773195\n",
      "Epoch: 34, Batch: 100, loss: 18.128325369461805\n",
      "Epoch: 34, Batch: 200, loss: 29.533707550641537\n",
      "Epoch: 34, Batch: 300, loss: 28.960121574071206\n",
      "Epoch: 34, Batch: 400, loss: 32.216607843548445\n",
      "Epoch: 34, Batch: 500, loss: 32.88118393543442\n",
      "Epoch: 35, Batch: 0, loss: 12.865802606499042\n",
      "Epoch: 35, Batch: 100, loss: 33.53305044875567\n",
      "Epoch: 35, Batch: 200, loss: 33.54673711401922\n",
      "Epoch: 35, Batch: 300, loss: 33.26120705217852\n",
      "Epoch: 35, Batch: 400, loss: 32.79340425299953\n",
      "Epoch: 35, Batch: 500, loss: 38.07164670136746\n",
      "Epoch: 36, Batch: 0, loss: 398.62390400862836\n",
      "Epoch: 36, Batch: 100, loss: 36.13101239787231\n",
      "Epoch: 36, Batch: 200, loss: 28.618909581039627\n",
      "Epoch: 36, Batch: 300, loss: 23.982691265199144\n",
      "Epoch: 36, Batch: 400, loss: 24.09533228701084\n",
      "Epoch: 36, Batch: 500, loss: 22.935853351816746\n",
      "Epoch: 37, Batch: 0, loss: 214.23728368033275\n",
      "Epoch: 37, Batch: 100, loss: 28.16159535058307\n",
      "Epoch: 37, Batch: 200, loss: 26.38081711486729\n",
      "Epoch: 37, Batch: 300, loss: 29.88253928859922\n",
      "Epoch: 37, Batch: 400, loss: 30.83522442151158\n",
      "Epoch: 37, Batch: 500, loss: 32.04091003910562\n",
      "Epoch: 38, Batch: 0, loss: 13.842287234347062\n",
      "Epoch: 38, Batch: 100, loss: 26.384582946521476\n",
      "Epoch: 38, Batch: 200, loss: 29.959006237792153\n",
      "Epoch: 38, Batch: 300, loss: 27.625150184565015\n",
      "Epoch: 38, Batch: 400, loss: 30.622622549620512\n",
      "Epoch: 38, Batch: 500, loss: 30.861543594594178\n",
      "Epoch: 39, Batch: 0, loss: 0.7557671680993573\n",
      "Epoch: 39, Batch: 100, loss: 25.466551089412796\n",
      "Epoch: 39, Batch: 200, loss: 27.4856789415227\n",
      "Epoch: 39, Batch: 300, loss: 26.573142058853207\n",
      "Epoch: 39, Batch: 400, loss: 25.7361860954227\n",
      "Epoch: 39, Batch: 500, loss: 26.634017651720708\n",
      "Epoch: 40, Batch: 0, loss: 15.012149720727257\n",
      "Epoch: 40, Batch: 100, loss: 28.193843288443166\n",
      "Epoch: 40, Batch: 200, loss: 27.82214169101274\n",
      "Epoch: 40, Batch: 300, loss: 32.42203834921894\n",
      "Epoch: 40, Batch: 400, loss: 30.136698269864144\n",
      "Epoch: 40, Batch: 500, loss: 32.43330453679556\n",
      "Epoch: 41, Batch: 0, loss: 118.78843345902989\n",
      "Epoch: 41, Batch: 100, loss: 41.41042775080013\n",
      "Epoch: 41, Batch: 200, loss: 40.429680544209646\n",
      "Epoch: 41, Batch: 300, loss: 38.929380287067985\n",
      "Epoch: 41, Batch: 400, loss: 37.49354141848373\n",
      "Epoch: 41, Batch: 500, loss: 41.268319843346205\n",
      "Epoch: 42, Batch: 0, loss: 4.068897454001062\n",
      "Epoch: 42, Batch: 100, loss: 27.55957524542181\n",
      "Epoch: 42, Batch: 200, loss: 30.590362682751405\n",
      "Epoch: 42, Batch: 300, loss: 33.07731074722544\n",
      "Epoch: 42, Batch: 400, loss: 35.42535231962564\n",
      "Epoch: 42, Batch: 500, loss: 35.3182428807358\n",
      "Epoch: 43, Batch: 0, loss: 2.173626151743135\n",
      "Epoch: 43, Batch: 100, loss: 25.62597591429642\n",
      "Epoch: 43, Batch: 200, loss: 24.344820769540966\n",
      "Epoch: 43, Batch: 300, loss: 27.08379379696445\n",
      "Epoch: 43, Batch: 400, loss: 26.182313632491283\n",
      "Epoch: 43, Batch: 500, loss: 25.76147547706503\n",
      "Epoch: 44, Batch: 0, loss: 1.0543236506099445\n",
      "Epoch: 44, Batch: 100, loss: 28.005291809908496\n",
      "Epoch: 44, Batch: 200, loss: 28.634022140881505\n",
      "Epoch: 44, Batch: 300, loss: 30.631171859496327\n",
      "Epoch: 44, Batch: 400, loss: 31.760867575697592\n",
      "Epoch: 44, Batch: 500, loss: 33.82733294838247\n",
      "Epoch: 45, Batch: 0, loss: 13.510566037436215\n",
      "Epoch: 45, Batch: 100, loss: 24.961139764541144\n",
      "Epoch: 45, Batch: 200, loss: 20.821521378900584\n",
      "Epoch: 45, Batch: 300, loss: 21.99949545190694\n",
      "Epoch: 45, Batch: 400, loss: 24.24693057579323\n",
      "Epoch: 45, Batch: 500, loss: 25.753938696000034\n",
      "Epoch: 46, Batch: 0, loss: 14.72202806931071\n",
      "Epoch: 46, Batch: 100, loss: 42.101117360517314\n",
      "Epoch: 46, Batch: 200, loss: 34.93242262987167\n",
      "Epoch: 46, Batch: 300, loss: 34.944104686674144\n",
      "Epoch: 46, Batch: 400, loss: 32.787950991621734\n",
      "Epoch: 46, Batch: 500, loss: 30.598427838384552\n",
      "Epoch: 47, Batch: 0, loss: 0.0905165483219156\n",
      "Epoch: 47, Batch: 100, loss: 52.73033108727144\n",
      "Epoch: 47, Batch: 200, loss: 40.812239471941275\n",
      "Epoch: 47, Batch: 300, loss: 35.88203310840532\n",
      "Epoch: 47, Batch: 400, loss: 35.39601954379696\n",
      "Epoch: 47, Batch: 500, loss: 35.06192472755305\n",
      "Epoch: 48, Batch: 0, loss: 0.41331500332857307\n",
      "Epoch: 48, Batch: 100, loss: 39.53511605875581\n",
      "Epoch: 48, Batch: 200, loss: 32.17648913102445\n",
      "Epoch: 48, Batch: 300, loss: 31.274276059266406\n",
      "Epoch: 48, Batch: 400, loss: 31.06141590727584\n",
      "Epoch: 48, Batch: 500, loss: 29.91555958655462\n",
      "Epoch: 49, Batch: 0, loss: 36.1340883209245\n",
      "Epoch: 49, Batch: 100, loss: 26.02133862371226\n",
      "Epoch: 49, Batch: 200, loss: 25.698756375721548\n",
      "Epoch: 49, Batch: 300, loss: 27.08756977066256\n",
      "Epoch: 49, Batch: 400, loss: 27.983550898940393\n",
      "Epoch: 49, Batch: 500, loss: 28.734677793158482\n",
      "Epoch: 50, Batch: 0, loss: 8.915098622499553\n",
      "Epoch: 50, Batch: 100, loss: 27.674222998815512\n",
      "Epoch: 50, Batch: 200, loss: 30.189970372797045\n",
      "Epoch: 50, Batch: 300, loss: 33.876596258314585\n",
      "Epoch: 50, Batch: 400, loss: 33.004765867596944\n",
      "Epoch: 50, Batch: 500, loss: 33.47469335826658\n",
      "Epoch: 51, Batch: 0, loss: 159.50930520520754\n",
      "Epoch: 51, Batch: 100, loss: 32.17631675999327\n",
      "Epoch: 51, Batch: 200, loss: 31.285823960705997\n",
      "Epoch: 51, Batch: 300, loss: 31.04698431646898\n",
      "Epoch: 51, Batch: 400, loss: 29.70239326193607\n",
      "Epoch: 51, Batch: 500, loss: 29.517623990371238\n",
      "Epoch: 52, Batch: 0, loss: 0.3379845675212036\n",
      "Epoch: 52, Batch: 100, loss: 33.76613611574095\n",
      "Epoch: 52, Batch: 200, loss: 36.54785494531031\n",
      "Epoch: 52, Batch: 300, loss: 32.1693767288305\n",
      "Epoch: 52, Batch: 400, loss: 31.59731384422743\n",
      "Epoch: 52, Batch: 500, loss: 33.86558850121941\n",
      "Epoch: 53, Batch: 0, loss: 30.710940584755257\n",
      "Epoch: 53, Batch: 100, loss: 24.26515757648127\n",
      "Epoch: 53, Batch: 200, loss: 25.462565026445503\n",
      "Epoch: 53, Batch: 300, loss: 28.071322710968257\n",
      "Epoch: 53, Batch: 400, loss: 26.806666357250666\n",
      "Epoch: 53, Batch: 500, loss: 29.86906534788889\n",
      "Epoch: 54, Batch: 0, loss: 3.251208118468873\n",
      "Epoch: 54, Batch: 100, loss: 26.72640565860997\n",
      "Epoch: 54, Batch: 200, loss: 24.540073163896103\n",
      "Epoch: 54, Batch: 300, loss: 28.65492119910187\n",
      "Epoch: 54, Batch: 400, loss: 25.617123134842277\n",
      "Epoch: 54, Batch: 500, loss: 27.05855648092723\n",
      "Epoch: 55, Batch: 0, loss: 0.3823770900253979\n",
      "Epoch: 55, Batch: 100, loss: 57.98255198154399\n",
      "Epoch: 55, Batch: 200, loss: 39.7185978832313\n",
      "Epoch: 55, Batch: 300, loss: 36.39462736082935\n",
      "Epoch: 55, Batch: 400, loss: 32.7077147214083\n",
      "Epoch: 55, Batch: 500, loss: 32.268753246925776\n",
      "Epoch: 56, Batch: 0, loss: 9.50190681155597\n",
      "Epoch: 56, Batch: 100, loss: 34.334716751575236\n",
      "Epoch: 56, Batch: 200, loss: 31.56608556109674\n",
      "Epoch: 56, Batch: 300, loss: 32.33175019994608\n",
      "Epoch: 56, Batch: 400, loss: 30.842374454947386\n",
      "Epoch: 56, Batch: 500, loss: 29.9872919135674\n",
      "Epoch: 57, Batch: 0, loss: 21.212535089908908\n",
      "Epoch: 57, Batch: 100, loss: 31.504120170261437\n",
      "Epoch: 57, Batch: 200, loss: 30.17816414808487\n",
      "Epoch: 57, Batch: 300, loss: 30.58278826299807\n",
      "Epoch: 57, Batch: 400, loss: 29.504009395186625\n",
      "Epoch: 57, Batch: 500, loss: 30.116778687315172\n",
      "Epoch: 58, Batch: 0, loss: 0.5823375144454358\n",
      "Epoch: 58, Batch: 100, loss: 30.421549366229605\n",
      "Epoch: 58, Batch: 200, loss: 34.147710802142676\n",
      "Epoch: 58, Batch: 300, loss: 35.742212194576744\n",
      "Epoch: 58, Batch: 400, loss: 34.03083636922469\n",
      "Epoch: 58, Batch: 500, loss: 31.912926444769067\n",
      "Epoch: 59, Batch: 0, loss: 1.498364506794748\n",
      "Epoch: 59, Batch: 100, loss: 25.113171115935934\n",
      "Epoch: 59, Batch: 200, loss: 31.742653993990764\n",
      "Epoch: 59, Batch: 300, loss: 32.88018362261261\n",
      "Epoch: 59, Batch: 400, loss: 34.73348567380645\n",
      "Epoch: 59, Batch: 500, loss: 35.166402543350614\n",
      "Epoch: 60, Batch: 0, loss: 58.89771516501617\n",
      "Epoch: 60, Batch: 100, loss: 44.31483073246654\n",
      "Epoch: 60, Batch: 200, loss: 38.18930108240712\n",
      "Epoch: 60, Batch: 300, loss: 37.03711120444295\n",
      "Epoch: 60, Batch: 400, loss: 35.96569891616204\n",
      "Epoch: 60, Batch: 500, loss: 34.49047978851318\n",
      "Epoch: 61, Batch: 0, loss: 15.653458266171622\n",
      "Epoch: 61, Batch: 100, loss: 30.61358978654125\n",
      "Epoch: 61, Batch: 200, loss: 27.611073648637383\n",
      "Epoch: 61, Batch: 300, loss: 33.31015695441362\n",
      "Epoch: 61, Batch: 400, loss: 33.61562964343377\n",
      "Epoch: 61, Batch: 500, loss: 32.7392434534786\n",
      "Epoch: 62, Batch: 0, loss: 3.5374909102434016\n",
      "Epoch: 62, Batch: 100, loss: 25.223080017817196\n",
      "Epoch: 62, Batch: 200, loss: 25.318297856061022\n",
      "Epoch: 62, Batch: 300, loss: 29.980016180151615\n",
      "Epoch: 62, Batch: 400, loss: 28.20780327570491\n",
      "Epoch: 62, Batch: 500, loss: 28.65620686100714\n",
      "Epoch: 63, Batch: 0, loss: 8.782388031812198\n",
      "Epoch: 63, Batch: 100, loss: 41.760476803492274\n",
      "Epoch: 63, Batch: 200, loss: 37.239657883258836\n",
      "Epoch: 63, Batch: 300, loss: 33.96675312269565\n",
      "Epoch: 63, Batch: 400, loss: 36.91796511949727\n",
      "Epoch: 63, Batch: 500, loss: 36.541487628569264\n",
      "Epoch: 64, Batch: 0, loss: 7.282500385317131\n",
      "Epoch: 64, Batch: 100, loss: 33.36578910746297\n",
      "Epoch: 64, Batch: 200, loss: 37.12876354216032\n",
      "Epoch: 64, Batch: 300, loss: 36.52640170187666\n",
      "Epoch: 64, Batch: 400, loss: 35.699576711298874\n",
      "Epoch: 64, Batch: 500, loss: 32.692721973581776\n",
      "Epoch: 65, Batch: 0, loss: 22.52103754388937\n",
      "Epoch: 65, Batch: 100, loss: 47.02809516423788\n",
      "Epoch: 65, Batch: 200, loss: 38.61208101673671\n",
      "Epoch: 65, Batch: 300, loss: 36.22418451234597\n",
      "Epoch: 65, Batch: 400, loss: 35.252876316772834\n",
      "Epoch: 65, Batch: 500, loss: 35.35232626560442\n",
      "Epoch: 66, Batch: 0, loss: 64.75033103490945\n",
      "Epoch: 66, Batch: 100, loss: 40.507250472795256\n",
      "Epoch: 66, Batch: 200, loss: 39.32120015028534\n",
      "Epoch: 66, Batch: 300, loss: 35.993703138579164\n",
      "Epoch: 66, Batch: 400, loss: 34.43458353290945\n",
      "Epoch: 66, Batch: 500, loss: 34.59135179617969\n",
      "Epoch: 67, Batch: 0, loss: 6.434877106434207\n",
      "Epoch: 67, Batch: 100, loss: 26.434394046578145\n",
      "Epoch: 67, Batch: 200, loss: 27.268025049974003\n",
      "Epoch: 67, Batch: 300, loss: 24.327803006276493\n",
      "Epoch: 67, Batch: 400, loss: 28.495852273366207\n",
      "Epoch: 67, Batch: 500, loss: 28.84909726676323\n",
      "Epoch: 68, Batch: 0, loss: 4.863210598704809\n",
      "Epoch: 68, Batch: 100, loss: 32.59408453038587\n",
      "Epoch: 68, Batch: 200, loss: 35.29543664640058\n",
      "Epoch: 68, Batch: 300, loss: 32.13697429878962\n",
      "Epoch: 68, Batch: 400, loss: 32.0188567965559\n",
      "Epoch: 68, Batch: 500, loss: 34.475404533261084\n",
      "Epoch: 69, Batch: 0, loss: 3.5129181248062027\n",
      "Epoch: 69, Batch: 100, loss: 38.81002575770595\n",
      "Epoch: 69, Batch: 200, loss: 32.65944937289356\n",
      "Epoch: 69, Batch: 300, loss: 36.25344493416537\n",
      "Epoch: 69, Batch: 400, loss: 35.301358161566384\n",
      "Epoch: 69, Batch: 500, loss: 33.65378652153365\n",
      "Epoch: 70, Batch: 0, loss: 20.062691707815123\n",
      "Epoch: 70, Batch: 100, loss: 38.29342909955808\n",
      "Epoch: 70, Batch: 200, loss: 32.684060945354986\n",
      "Epoch: 70, Batch: 300, loss: 29.865144991378585\n",
      "Epoch: 70, Batch: 400, loss: 29.859852675770906\n",
      "Epoch: 70, Batch: 500, loss: 28.714129604882874\n",
      "Epoch: 71, Batch: 0, loss: 1.4539789069163211\n",
      "Epoch: 71, Batch: 100, loss: 29.83595629825016\n",
      "Epoch: 71, Batch: 200, loss: 30.112735806912568\n",
      "Epoch: 71, Batch: 300, loss: 28.858276525086055\n",
      "Epoch: 71, Batch: 400, loss: 34.55060857995103\n",
      "Epoch: 71, Batch: 500, loss: 33.06572982732135\n",
      "Epoch: 72, Batch: 0, loss: 266.00991964753445\n",
      "Epoch: 72, Batch: 100, loss: 36.27709656843097\n",
      "Epoch: 72, Batch: 200, loss: 29.242234960592675\n",
      "Epoch: 72, Batch: 300, loss: 30.617897482473214\n",
      "Epoch: 72, Batch: 400, loss: 27.91408390159108\n",
      "Epoch: 72, Batch: 500, loss: 30.75343580045555\n",
      "Epoch: 73, Batch: 0, loss: 2.89309872471976\n",
      "Epoch: 73, Batch: 100, loss: 30.487105375582473\n",
      "Epoch: 73, Batch: 200, loss: 29.23312675665426\n",
      "Epoch: 73, Batch: 300, loss: 26.9448213370909\n",
      "Epoch: 73, Batch: 400, loss: 30.165039680813045\n",
      "Epoch: 73, Batch: 500, loss: 29.96964410623966\n",
      "Epoch: 74, Batch: 0, loss: 1.9182862582786504\n",
      "Epoch: 74, Batch: 100, loss: 29.361289853957203\n",
      "Epoch: 74, Batch: 200, loss: 33.28325411122837\n",
      "Epoch: 74, Batch: 300, loss: 32.355036031738074\n",
      "Epoch: 74, Batch: 400, loss: 33.765497928074495\n",
      "Epoch: 74, Batch: 500, loss: 31.04982015925226\n",
      "Epoch: 75, Batch: 0, loss: 5.193539460648481e-06\n",
      "Epoch: 75, Batch: 100, loss: 29.013074641075892\n",
      "Epoch: 75, Batch: 200, loss: 29.872290944564075\n",
      "Epoch: 75, Batch: 300, loss: 27.90140281564157\n",
      "Epoch: 75, Batch: 400, loss: 26.74359767474288\n",
      "Epoch: 75, Batch: 500, loss: 28.787171434560456\n",
      "Epoch: 76, Batch: 0, loss: 3.0387937840449757\n",
      "Epoch: 76, Batch: 100, loss: 28.573293115373808\n",
      "Epoch: 76, Batch: 200, loss: 36.07586231146388\n",
      "Epoch: 76, Batch: 300, loss: 33.46323128598504\n",
      "Epoch: 76, Batch: 400, loss: 34.42168308820863\n",
      "Epoch: 76, Batch: 500, loss: 33.36896856346415\n",
      "Epoch: 77, Batch: 0, loss: 47.60046349574445\n",
      "Epoch: 77, Batch: 100, loss: 40.47085858584558\n",
      "Epoch: 77, Batch: 200, loss: 35.06771150388789\n",
      "Epoch: 77, Batch: 300, loss: 36.44313769004401\n",
      "Epoch: 77, Batch: 400, loss: 34.31501414892465\n",
      "Epoch: 77, Batch: 500, loss: 33.081475016136366\n",
      "Epoch: 78, Batch: 0, loss: 3.574818638186254\n",
      "Epoch: 78, Batch: 100, loss: 29.68097735008753\n",
      "Epoch: 78, Batch: 200, loss: 26.442149206171255\n",
      "Epoch: 78, Batch: 300, loss: 28.96195192931903\n",
      "Epoch: 78, Batch: 400, loss: 29.577072621909835\n",
      "Epoch: 78, Batch: 500, loss: 30.603402771005253\n",
      "Epoch: 79, Batch: 0, loss: 176.48218996737708\n",
      "Epoch: 79, Batch: 100, loss: 33.101386230879854\n",
      "Epoch: 79, Batch: 200, loss: 32.52579561458027\n",
      "Epoch: 79, Batch: 300, loss: 33.45281089383448\n",
      "Epoch: 79, Batch: 400, loss: 31.998552811587356\n",
      "Epoch: 79, Batch: 500, loss: 30.00047672621255\n",
      "Epoch: 80, Batch: 0, loss: 106.90264836842381\n",
      "Epoch: 80, Batch: 100, loss: 36.378225701696664\n",
      "Epoch: 80, Batch: 200, loss: 35.0849459566853\n",
      "Epoch: 80, Batch: 300, loss: 34.02481289635926\n",
      "Epoch: 80, Batch: 400, loss: 31.364208641948498\n",
      "Epoch: 80, Batch: 500, loss: 31.908530169204138\n",
      "Epoch: 81, Batch: 0, loss: 77.36374781125177\n",
      "Epoch: 81, Batch: 100, loss: 20.48094954446718\n",
      "Epoch: 81, Batch: 200, loss: 26.111563975170146\n",
      "Epoch: 81, Batch: 300, loss: 25.77173334650013\n",
      "Epoch: 81, Batch: 400, loss: 27.50818681383035\n",
      "Epoch: 81, Batch: 500, loss: 27.920105981721047\n",
      "Epoch: 82, Batch: 0, loss: 2.7613042893180064\n",
      "Epoch: 82, Batch: 100, loss: 26.333110212187268\n",
      "Epoch: 82, Batch: 200, loss: 33.701805137550785\n",
      "Epoch: 82, Batch: 300, loss: 35.62865802860835\n",
      "Epoch: 82, Batch: 400, loss: 34.22618907895286\n",
      "Epoch: 82, Batch: 500, loss: 34.90431683713187\n",
      "Epoch: 83, Batch: 0, loss: 102.63763462708472\n",
      "Epoch: 83, Batch: 100, loss: 36.34445847209145\n",
      "Epoch: 83, Batch: 200, loss: 34.68975293644761\n",
      "Epoch: 83, Batch: 300, loss: 31.472308937746973\n",
      "Epoch: 83, Batch: 400, loss: 29.92566219809052\n",
      "Epoch: 83, Batch: 500, loss: 32.01873561570891\n",
      "Epoch: 84, Batch: 0, loss: 0.8520501144469809\n",
      "Epoch: 84, Batch: 100, loss: 22.632157422989135\n",
      "Epoch: 84, Batch: 200, loss: 25.926101998217696\n",
      "Epoch: 84, Batch: 300, loss: 30.79799549776256\n",
      "Epoch: 84, Batch: 400, loss: 32.921565022635036\n",
      "Epoch: 84, Batch: 500, loss: 32.802929429165545\n",
      "Epoch: 85, Batch: 0, loss: 27.96153396225017\n",
      "Epoch: 85, Batch: 100, loss: 37.98326899459553\n",
      "Epoch: 85, Batch: 200, loss: 31.02046079447852\n",
      "Epoch: 85, Batch: 300, loss: 29.170989415268995\n",
      "Epoch: 85, Batch: 400, loss: 30.177763779950716\n",
      "Epoch: 85, Batch: 500, loss: 30.581716378890178\n",
      "Epoch: 86, Batch: 0, loss: 0.17315250457320888\n",
      "Epoch: 86, Batch: 100, loss: 28.047152524194765\n",
      "Epoch: 86, Batch: 200, loss: 28.512781226332393\n",
      "Epoch: 86, Batch: 300, loss: 25.087975442891533\n",
      "Epoch: 86, Batch: 400, loss: 24.035472314243773\n",
      "Epoch: 86, Batch: 500, loss: 25.27654693024966\n",
      "Epoch: 87, Batch: 0, loss: 23.891654581892922\n",
      "Epoch: 87, Batch: 100, loss: 36.25316063794725\n",
      "Epoch: 87, Batch: 200, loss: 35.091782377435024\n",
      "Epoch: 87, Batch: 300, loss: 35.593846135051805\n",
      "Epoch: 87, Batch: 400, loss: 33.320168525277154\n",
      "Epoch: 87, Batch: 500, loss: 32.407318809348354\n",
      "Epoch: 88, Batch: 0, loss: 328.4929044983289\n",
      "Epoch: 88, Batch: 100, loss: 34.21398161375578\n",
      "Epoch: 88, Batch: 200, loss: 25.957966102852808\n",
      "Epoch: 88, Batch: 300, loss: 24.44343589522557\n",
      "Epoch: 88, Batch: 400, loss: 25.47592637188162\n",
      "Epoch: 88, Batch: 500, loss: 27.108303915010502\n",
      "Epoch: 89, Batch: 0, loss: 66.76827426734177\n",
      "Epoch: 89, Batch: 100, loss: 30.169798104627585\n",
      "Epoch: 89, Batch: 200, loss: 37.702332112926065\n",
      "Epoch: 89, Batch: 300, loss: 36.28042626391165\n",
      "Epoch: 89, Batch: 400, loss: 37.147032762115444\n",
      "Epoch: 89, Batch: 500, loss: 36.22864128796826\n",
      "Epoch: 90, Batch: 0, loss: 19.413751319639346\n",
      "Epoch: 90, Batch: 100, loss: 38.945273707431966\n",
      "Epoch: 90, Batch: 200, loss: 33.933559106425456\n",
      "Epoch: 90, Batch: 300, loss: 33.090252961885035\n",
      "Epoch: 90, Batch: 400, loss: 29.991991440881158\n",
      "Epoch: 90, Batch: 500, loss: 31.12058984914541\n",
      "Epoch: 91, Batch: 0, loss: 8.195419512202418\n",
      "Epoch: 91, Batch: 100, loss: 26.546885672700586\n",
      "Epoch: 91, Batch: 200, loss: 25.721975798815887\n",
      "Epoch: 91, Batch: 300, loss: 23.98456377285974\n",
      "Epoch: 91, Batch: 400, loss: 27.504465564493792\n",
      "Epoch: 91, Batch: 500, loss: 28.201944334429474\n",
      "Epoch: 92, Batch: 0, loss: 71.69446092132128\n",
      "Epoch: 92, Batch: 100, loss: 30.862633064204605\n",
      "Epoch: 92, Batch: 200, loss: 29.453617309713774\n",
      "Epoch: 92, Batch: 300, loss: 29.706937429782144\n",
      "Epoch: 92, Batch: 400, loss: 32.02482945322238\n",
      "Epoch: 92, Batch: 500, loss: 32.207617138742336\n",
      "Epoch: 93, Batch: 0, loss: 2.255680884769418\n",
      "Epoch: 93, Batch: 100, loss: 29.2375801868141\n",
      "Epoch: 93, Batch: 200, loss: 33.60890543241565\n",
      "Epoch: 93, Batch: 300, loss: 30.75036787083414\n",
      "Epoch: 93, Batch: 400, loss: 28.367114560127696\n",
      "Epoch: 93, Batch: 500, loss: 27.8019637725988\n",
      "Epoch: 94, Batch: 0, loss: 6.746072755495724\n",
      "Epoch: 94, Batch: 100, loss: 21.594191865604675\n",
      "Epoch: 94, Batch: 200, loss: 38.451923354109056\n",
      "Epoch: 94, Batch: 300, loss: 34.96385259801116\n",
      "Epoch: 94, Batch: 400, loss: 35.61589963515951\n",
      "Epoch: 94, Batch: 500, loss: 34.894246583857075\n",
      "Epoch: 95, Batch: 0, loss: 0.9082519163940876\n",
      "Epoch: 95, Batch: 100, loss: 23.884015694860217\n",
      "Epoch: 95, Batch: 200, loss: 31.89015678685511\n",
      "Epoch: 95, Batch: 300, loss: 28.058118181803263\n",
      "Epoch: 95, Batch: 400, loss: 28.08084277226934\n",
      "Epoch: 95, Batch: 500, loss: 26.453311380811527\n",
      "Epoch: 96, Batch: 0, loss: 69.14744461058555\n",
      "Epoch: 96, Batch: 100, loss: 26.568063391462264\n",
      "Epoch: 96, Batch: 200, loss: 29.413879635536436\n",
      "Epoch: 96, Batch: 300, loss: 27.722137763840582\n",
      "Epoch: 96, Batch: 400, loss: 30.06847575330198\n",
      "Epoch: 96, Batch: 500, loss: 29.858453693972173\n",
      "Epoch: 97, Batch: 0, loss: 6.794750365467628\n",
      "Epoch: 97, Batch: 100, loss: 47.42081139735772\n",
      "Epoch: 97, Batch: 200, loss: 44.5281346551262\n",
      "Epoch: 97, Batch: 300, loss: 36.64365220471932\n",
      "Epoch: 97, Batch: 400, loss: 33.6133466648777\n",
      "Epoch: 97, Batch: 500, loss: 34.94311635134604\n",
      "Epoch: 98, Batch: 0, loss: 36.8071938247794\n",
      "Epoch: 98, Batch: 100, loss: 22.056113224788465\n",
      "Epoch: 98, Batch: 200, loss: 24.037662031547686\n",
      "Epoch: 98, Batch: 300, loss: 26.461409379362557\n",
      "Epoch: 98, Batch: 400, loss: 27.467074734831478\n",
      "Epoch: 98, Batch: 500, loss: 29.774083764753588\n",
      "Epoch: 99, Batch: 0, loss: 6.543956008805461\n",
      "Epoch: 99, Batch: 100, loss: 32.78065572380553\n",
      "Epoch: 99, Batch: 200, loss: 32.309056595281255\n",
      "Epoch: 99, Batch: 300, loss: 33.1194067954744\n",
      "Epoch: 99, Batch: 400, loss: 31.737911478842786\n",
      "Epoch: 99, Batch: 500, loss: 30.08386260310562\n",
      "Epoch: 100, Batch: 0, loss: 18.182114776573687\n",
      "Epoch: 100, Batch: 100, loss: 44.73200273890404\n",
      "Epoch: 100, Batch: 200, loss: 41.88986775344459\n",
      "Epoch: 100, Batch: 300, loss: 36.86601654638593\n",
      "Epoch: 100, Batch: 400, loss: 35.40507503203254\n",
      "Epoch: 100, Batch: 500, loss: 34.75405867655222\n",
      "Epoch: 101, Batch: 0, loss: 13.616717325916364\n",
      "Epoch: 101, Batch: 100, loss: 19.681668589780458\n",
      "Epoch: 101, Batch: 200, loss: 28.915746733992957\n",
      "Epoch: 101, Batch: 300, loss: 32.168564531979285\n",
      "Epoch: 101, Batch: 400, loss: 30.63231763688138\n",
      "Epoch: 101, Batch: 500, loss: 33.60013870949156\n",
      "Epoch: 102, Batch: 0, loss: 20.037203897273635\n",
      "Epoch: 102, Batch: 100, loss: 28.935579240998866\n",
      "Epoch: 102, Batch: 200, loss: 28.116986970372707\n",
      "Epoch: 102, Batch: 300, loss: 28.427609149711948\n",
      "Epoch: 102, Batch: 400, loss: 27.95388611005986\n",
      "Epoch: 102, Batch: 500, loss: 27.67177605410786\n",
      "Epoch: 103, Batch: 0, loss: 308.1863174043792\n",
      "Epoch: 103, Batch: 100, loss: 28.190168702465986\n",
      "Epoch: 103, Batch: 200, loss: 31.207728297332935\n",
      "Epoch: 103, Batch: 300, loss: 29.59134212016022\n",
      "Epoch: 103, Batch: 400, loss: 32.660317166477604\n",
      "Epoch: 103, Batch: 500, loss: 34.90132068086861\n",
      "Epoch: 104, Batch: 0, loss: 45.61394151555974\n",
      "Epoch: 104, Batch: 100, loss: 20.639098156190965\n",
      "Epoch: 104, Batch: 200, loss: 28.906091200032694\n",
      "Epoch: 104, Batch: 300, loss: 29.191947875410616\n",
      "Epoch: 104, Batch: 400, loss: 28.100837357075672\n",
      "Epoch: 104, Batch: 500, loss: 28.396071516045083\n",
      "Epoch: 105, Batch: 0, loss: 1.4064437296456072\n",
      "Epoch: 105, Batch: 100, loss: 36.68972361026234\n",
      "Epoch: 105, Batch: 200, loss: 34.240957190052036\n",
      "Epoch: 105, Batch: 300, loss: 33.519234651856955\n",
      "Epoch: 105, Batch: 400, loss: 32.24805059445114\n",
      "Epoch: 105, Batch: 500, loss: 30.04093682799037\n",
      "Epoch: 106, Batch: 0, loss: 1.470457230985701\n",
      "Epoch: 106, Batch: 100, loss: 28.48601677946738\n",
      "Epoch: 106, Batch: 200, loss: 26.458528231118795\n",
      "Epoch: 106, Batch: 300, loss: 25.483881242226325\n",
      "Epoch: 106, Batch: 400, loss: 25.4990884882143\n",
      "Epoch: 106, Batch: 500, loss: 27.22849807323616\n",
      "Epoch: 107, Batch: 0, loss: 0.7177457786693007\n",
      "Epoch: 107, Batch: 100, loss: 30.09146416093049\n",
      "Epoch: 107, Batch: 200, loss: 35.651054831816715\n",
      "Epoch: 107, Batch: 300, loss: 32.97727596703362\n",
      "Epoch: 107, Batch: 400, loss: 33.50788184596364\n",
      "Epoch: 107, Batch: 500, loss: 33.18888691016782\n",
      "Epoch: 108, Batch: 0, loss: 40.67689621351244\n",
      "Epoch: 108, Batch: 100, loss: 31.781864387495382\n",
      "Epoch: 108, Batch: 200, loss: 29.438063156395767\n",
      "Epoch: 108, Batch: 300, loss: 29.29518006189607\n",
      "Epoch: 108, Batch: 400, loss: 30.052387963034317\n",
      "Epoch: 108, Batch: 500, loss: 30.553893392136803\n",
      "Epoch: 109, Batch: 0, loss: 11.528893044707356\n",
      "Epoch: 109, Batch: 100, loss: 25.96634994511592\n",
      "Epoch: 109, Batch: 200, loss: 28.41853717569715\n",
      "Epoch: 109, Batch: 300, loss: 28.46183229963974\n",
      "Epoch: 109, Batch: 400, loss: 27.699345310091307\n",
      "Epoch: 109, Batch: 500, loss: 29.509162184792597\n",
      "Epoch: 110, Batch: 0, loss: 18.131087300053768\n",
      "Epoch: 110, Batch: 100, loss: 24.71207843115476\n",
      "Epoch: 110, Batch: 200, loss: 27.437070358884263\n",
      "Epoch: 110, Batch: 300, loss: 24.648531334649416\n",
      "Epoch: 110, Batch: 400, loss: 26.800941714681386\n",
      "Epoch: 110, Batch: 500, loss: 30.296596640917652\n",
      "Epoch: 111, Batch: 0, loss: 28.25270553138759\n",
      "Epoch: 111, Batch: 100, loss: 35.227076082148905\n",
      "Epoch: 111, Batch: 200, loss: 31.961999767045807\n",
      "Epoch: 111, Batch: 300, loss: 29.033045430765924\n",
      "Epoch: 111, Batch: 400, loss: 29.420817830323116\n",
      "Epoch: 111, Batch: 500, loss: 28.842881488276976\n",
      "Epoch: 112, Batch: 0, loss: 42.735401725798134\n",
      "Epoch: 112, Batch: 100, loss: 26.86687248317398\n",
      "Epoch: 112, Batch: 200, loss: 23.165063977242074\n",
      "Epoch: 112, Batch: 300, loss: 26.219739945632984\n",
      "Epoch: 112, Batch: 400, loss: 29.345188345957066\n",
      "Epoch: 112, Batch: 500, loss: 30.277194804626582\n",
      "Epoch: 113, Batch: 0, loss: 19.164003848086256\n",
      "Epoch: 113, Batch: 100, loss: 28.79324866383348\n",
      "Epoch: 113, Batch: 200, loss: 31.852527132914744\n",
      "Epoch: 113, Batch: 300, loss: 31.684427971179776\n",
      "Epoch: 113, Batch: 400, loss: 33.393291185528085\n",
      "Epoch: 113, Batch: 500, loss: 32.95007196906398\n",
      "Epoch: 114, Batch: 0, loss: 10.592748992830824\n",
      "Epoch: 114, Batch: 100, loss: 24.42150700945942\n",
      "Epoch: 114, Batch: 200, loss: 27.802917310186057\n",
      "Epoch: 114, Batch: 300, loss: 33.57596848871008\n",
      "Epoch: 114, Batch: 400, loss: 30.64263829528857\n",
      "Epoch: 114, Batch: 500, loss: 30.680726100326936\n",
      "Epoch: 115, Batch: 0, loss: 1.4339279622471712\n",
      "Epoch: 115, Batch: 100, loss: 32.54098939233295\n",
      "Epoch: 115, Batch: 200, loss: 26.415233572154072\n",
      "Epoch: 115, Batch: 300, loss: 26.01271437067623\n",
      "Epoch: 115, Batch: 400, loss: 28.668626161413446\n",
      "Epoch: 115, Batch: 500, loss: 30.685431100593966\n",
      "Epoch: 116, Batch: 0, loss: 0.022548999525268204\n",
      "Epoch: 116, Batch: 100, loss: 27.257399359333277\n",
      "Epoch: 116, Batch: 200, loss: 24.614007323171844\n",
      "Epoch: 116, Batch: 300, loss: 26.957550155219185\n",
      "Epoch: 116, Batch: 400, loss: 26.9796181892888\n",
      "Epoch: 116, Batch: 500, loss: 27.061686443642422\n",
      "Epoch: 117, Batch: 0, loss: 19.036270138806827\n",
      "Epoch: 117, Batch: 100, loss: 29.962735902425642\n",
      "Epoch: 117, Batch: 200, loss: 32.79384154783365\n",
      "Epoch: 117, Batch: 300, loss: 30.028958811846884\n",
      "Epoch: 117, Batch: 400, loss: 32.01471543615432\n",
      "Epoch: 117, Batch: 500, loss: 31.616091736949432\n",
      "Epoch: 118, Batch: 0, loss: 100.81367688551958\n",
      "Epoch: 118, Batch: 100, loss: 24.866373443158718\n",
      "Epoch: 118, Batch: 200, loss: 27.166399845727078\n",
      "Epoch: 118, Batch: 300, loss: 26.72120728307541\n",
      "Epoch: 118, Batch: 400, loss: 27.63770543591049\n",
      "Epoch: 118, Batch: 500, loss: 28.553933478591684\n",
      "Epoch: 119, Batch: 0, loss: 2.647121962858894\n",
      "Epoch: 119, Batch: 100, loss: 35.16257309073221\n",
      "Epoch: 119, Batch: 200, loss: 36.304454663526215\n",
      "Epoch: 119, Batch: 300, loss: 31.966991418536004\n",
      "Epoch: 119, Batch: 400, loss: 30.030675530502602\n",
      "Epoch: 119, Batch: 500, loss: 32.818782019107076\n",
      "Epoch: 120, Batch: 0, loss: 28.581203026521106\n",
      "Epoch: 120, Batch: 100, loss: 30.315414513310117\n",
      "Epoch: 120, Batch: 200, loss: 34.658015287547734\n",
      "Epoch: 120, Batch: 300, loss: 35.75304426862791\n",
      "Epoch: 120, Batch: 400, loss: 34.4177417041665\n",
      "Epoch: 120, Batch: 500, loss: 33.460356628384424\n",
      "Epoch: 121, Batch: 0, loss: 71.320556486293\n",
      "Epoch: 121, Batch: 100, loss: 24.943785800437954\n",
      "Epoch: 121, Batch: 200, loss: 29.45655989823099\n",
      "Epoch: 121, Batch: 300, loss: 26.96978334278949\n",
      "Epoch: 121, Batch: 400, loss: 29.525029618700973\n",
      "Epoch: 121, Batch: 500, loss: 32.86716441480508\n",
      "Epoch: 122, Batch: 0, loss: 46.840658420003415\n",
      "Epoch: 122, Batch: 100, loss: 24.41233963219508\n",
      "Epoch: 122, Batch: 200, loss: 27.04292811799598\n",
      "Epoch: 122, Batch: 300, loss: 25.77870098558155\n",
      "Epoch: 122, Batch: 400, loss: 25.16061621727463\n",
      "Epoch: 122, Batch: 500, loss: 27.201348756140426\n",
      "Epoch: 123, Batch: 0, loss: 11.274863552822731\n",
      "Epoch: 123, Batch: 100, loss: 32.49194321147673\n",
      "Epoch: 123, Batch: 200, loss: 25.67961339273483\n",
      "Epoch: 123, Batch: 300, loss: 29.262250726550473\n",
      "Epoch: 123, Batch: 400, loss: 28.08848824589255\n",
      "Epoch: 123, Batch: 500, loss: 29.511311265731905\n",
      "Epoch: 124, Batch: 0, loss: 23.748517266068102\n",
      "Epoch: 124, Batch: 100, loss: 29.27258415162428\n",
      "Epoch: 124, Batch: 200, loss: 31.45387654994206\n",
      "Epoch: 124, Batch: 300, loss: 31.53378518174073\n",
      "Epoch: 124, Batch: 400, loss: 30.961801848830415\n",
      "Epoch: 124, Batch: 500, loss: 30.48927364110294\n",
      "Epoch: 125, Batch: 0, loss: 11.050376216233785\n",
      "Epoch: 125, Batch: 100, loss: 30.008186204517983\n",
      "Epoch: 125, Batch: 200, loss: 26.236667882761093\n",
      "Epoch: 125, Batch: 300, loss: 29.361695626937045\n",
      "Epoch: 125, Batch: 400, loss: 28.87329419285636\n",
      "Epoch: 125, Batch: 500, loss: 29.1925848014425\n",
      "Epoch: 126, Batch: 0, loss: 1.3715636023179116\n",
      "Epoch: 126, Batch: 100, loss: 25.277478739521335\n",
      "Epoch: 126, Batch: 200, loss: 31.709205669231466\n",
      "Epoch: 126, Batch: 300, loss: 30.92254335405577\n",
      "Epoch: 126, Batch: 400, loss: 30.713813094221916\n",
      "Epoch: 126, Batch: 500, loss: 30.437610624782234\n",
      "Epoch: 127, Batch: 0, loss: 1.0090123316331994\n",
      "Epoch: 127, Batch: 100, loss: 47.43135986007975\n",
      "Epoch: 127, Batch: 200, loss: 42.89113039647818\n",
      "Epoch: 127, Batch: 300, loss: 37.20803610056584\n",
      "Epoch: 127, Batch: 400, loss: 33.36200995517\n",
      "Epoch: 127, Batch: 500, loss: 30.585880949025324\n",
      "Epoch: 128, Batch: 0, loss: 2.3192360530346923\n",
      "Epoch: 128, Batch: 100, loss: 20.79003885933697\n",
      "Epoch: 128, Batch: 200, loss: 29.455542133072772\n",
      "Epoch: 128, Batch: 300, loss: 28.192970237141907\n",
      "Epoch: 128, Batch: 400, loss: 29.011199601467496\n",
      "Epoch: 128, Batch: 500, loss: 27.02659108371702\n",
      "Epoch: 129, Batch: 0, loss: 7.065630450475486\n",
      "Epoch: 129, Batch: 100, loss: 27.335765510911187\n",
      "Epoch: 129, Batch: 200, loss: 27.58776722240747\n",
      "Epoch: 129, Batch: 300, loss: 26.21900863372329\n",
      "Epoch: 129, Batch: 400, loss: 31.361892045747755\n",
      "Epoch: 129, Batch: 500, loss: 32.67653132204287\n",
      "Epoch: 130, Batch: 0, loss: 2.7751513007221758\n",
      "Epoch: 130, Batch: 100, loss: 28.52756327765455\n",
      "Epoch: 130, Batch: 200, loss: 29.360923063390562\n",
      "Epoch: 130, Batch: 300, loss: 31.098900995113148\n",
      "Epoch: 130, Batch: 400, loss: 28.83868073701426\n",
      "Epoch: 130, Batch: 500, loss: 27.413387105971864\n",
      "Epoch: 131, Batch: 0, loss: 9.44373170434905\n",
      "Epoch: 131, Batch: 100, loss: 22.617112261842014\n",
      "Epoch: 131, Batch: 200, loss: 24.381119393320663\n",
      "Epoch: 131, Batch: 300, loss: 23.511308806329467\n",
      "Epoch: 131, Batch: 400, loss: 27.854529236952786\n",
      "Epoch: 131, Batch: 500, loss: 26.30181783062332\n",
      "Epoch: 132, Batch: 0, loss: 6.111906490379427\n",
      "Epoch: 132, Batch: 100, loss: 22.23430272093315\n",
      "Epoch: 132, Batch: 200, loss: 30.131150564048934\n",
      "Epoch: 132, Batch: 300, loss: 26.933390221874223\n",
      "Epoch: 132, Batch: 400, loss: 27.322530495983287\n",
      "Epoch: 132, Batch: 500, loss: 27.361633729387687\n",
      "Epoch: 133, Batch: 0, loss: 64.54096120590916\n",
      "Epoch: 133, Batch: 100, loss: 25.136529758757913\n",
      "Epoch: 133, Batch: 200, loss: 26.967183785691468\n",
      "Epoch: 133, Batch: 300, loss: 27.022289481940998\n",
      "Epoch: 133, Batch: 400, loss: 30.77575751127846\n",
      "Epoch: 133, Batch: 500, loss: 31.69428240587877\n",
      "Epoch: 134, Batch: 0, loss: 6.196041013550289\n",
      "Epoch: 134, Batch: 100, loss: 42.250872709072716\n",
      "Epoch: 134, Batch: 200, loss: 36.80688652435294\n",
      "Epoch: 134, Batch: 300, loss: 33.4607534563941\n",
      "Epoch: 134, Batch: 400, loss: 31.798844234274082\n",
      "Epoch: 134, Batch: 500, loss: 30.60371729519629\n",
      "Epoch: 135, Batch: 0, loss: 16.288082330631003\n",
      "Epoch: 135, Batch: 100, loss: 30.79915964224075\n",
      "Epoch: 135, Batch: 200, loss: 35.3440569241475\n",
      "Epoch: 135, Batch: 300, loss: 30.717236907924388\n",
      "Epoch: 135, Batch: 400, loss: 29.89809811970573\n",
      "Epoch: 135, Batch: 500, loss: 27.548065533050785\n",
      "Epoch: 136, Batch: 0, loss: 7.562071814779283\n",
      "Epoch: 136, Batch: 100, loss: 30.769087981653282\n",
      "Epoch: 136, Batch: 200, loss: 32.329491020273224\n",
      "Epoch: 136, Batch: 300, loss: 29.20785477799403\n",
      "Epoch: 136, Batch: 400, loss: 30.867713015628876\n",
      "Epoch: 136, Batch: 500, loss: 31.905564828093233\n",
      "Epoch: 137, Batch: 0, loss: 25.62043077772103\n",
      "Epoch: 137, Batch: 100, loss: 35.200372972811394\n",
      "Epoch: 137, Batch: 200, loss: 36.598882398239724\n",
      "Epoch: 137, Batch: 300, loss: 31.543848601174314\n",
      "Epoch: 137, Batch: 400, loss: 32.880916193457935\n",
      "Epoch: 137, Batch: 500, loss: 29.823696591473468\n",
      "Epoch: 138, Batch: 0, loss: 13.804891259288345\n",
      "Epoch: 138, Batch: 100, loss: 60.25655617333571\n",
      "Epoch: 138, Batch: 200, loss: 46.53313216435886\n",
      "Epoch: 138, Batch: 300, loss: 43.33834111579405\n",
      "Epoch: 138, Batch: 400, loss: 39.27357190229447\n",
      "Epoch: 138, Batch: 500, loss: 38.81396424928409\n",
      "Epoch: 139, Batch: 0, loss: 5.93948243531948\n",
      "Epoch: 139, Batch: 100, loss: 27.12102244456354\n",
      "Epoch: 139, Batch: 200, loss: 32.49236416969308\n",
      "Epoch: 139, Batch: 300, loss: 33.80413628948424\n",
      "Epoch: 139, Batch: 400, loss: 31.549046731324445\n",
      "Epoch: 139, Batch: 500, loss: 31.198471778886894\n",
      "Epoch: 140, Batch: 0, loss: 114.10097179801099\n",
      "Epoch: 140, Batch: 100, loss: 38.10106740085979\n",
      "Epoch: 140, Batch: 200, loss: 43.3651370926174\n",
      "Epoch: 140, Batch: 300, loss: 38.115522488191665\n",
      "Epoch: 140, Batch: 400, loss: 35.560273653367986\n",
      "Epoch: 140, Batch: 500, loss: 35.33439672348925\n",
      "Epoch: 141, Batch: 0, loss: 30.696782029101932\n",
      "Epoch: 141, Batch: 100, loss: 31.879416077052767\n",
      "Epoch: 141, Batch: 200, loss: 29.202567812724\n",
      "Epoch: 141, Batch: 300, loss: 25.790117572045013\n",
      "Epoch: 141, Batch: 400, loss: 24.615916228263465\n",
      "Epoch: 141, Batch: 500, loss: 24.427399325609542\n",
      "Epoch: 142, Batch: 0, loss: 1.2544381581273556\n",
      "Epoch: 142, Batch: 100, loss: 38.93027072757935\n",
      "Epoch: 142, Batch: 200, loss: 34.47922460951225\n",
      "Epoch: 142, Batch: 300, loss: 30.691088240114233\n",
      "Epoch: 142, Batch: 400, loss: 29.384248926328866\n",
      "Epoch: 142, Batch: 500, loss: 29.15591771226257\n",
      "Epoch: 143, Batch: 0, loss: 8.082724944142644\n",
      "Epoch: 143, Batch: 100, loss: 32.61712709909028\n",
      "Epoch: 143, Batch: 200, loss: 30.910967804390104\n",
      "Epoch: 143, Batch: 300, loss: 28.28904172439088\n",
      "Epoch: 143, Batch: 400, loss: 30.5603912070184\n",
      "Epoch: 143, Batch: 500, loss: 32.232976010538174\n",
      "Epoch: 144, Batch: 0, loss: 48.31569451392679\n",
      "Epoch: 144, Batch: 100, loss: 16.2983768908494\n",
      "Epoch: 144, Batch: 200, loss: 23.106109915110192\n",
      "Epoch: 144, Batch: 300, loss: 22.91341535396332\n",
      "Epoch: 144, Batch: 400, loss: 25.656865984441648\n",
      "Epoch: 144, Batch: 500, loss: 25.00740792942851\n",
      "Epoch: 145, Batch: 0, loss: 8.397319670437216\n",
      "Epoch: 145, Batch: 100, loss: 27.93683894487995\n",
      "Epoch: 145, Batch: 200, loss: 27.037478034896374\n",
      "Epoch: 145, Batch: 300, loss: 27.088514038466958\n",
      "Epoch: 145, Batch: 400, loss: 27.78869801448748\n",
      "Epoch: 145, Batch: 500, loss: 28.677591260401208\n",
      "Epoch: 146, Batch: 0, loss: 0.4104167099663052\n",
      "Epoch: 146, Batch: 100, loss: 36.60523643428643\n",
      "Epoch: 146, Batch: 200, loss: 30.70199279145927\n",
      "Epoch: 146, Batch: 300, loss: 28.986772461976088\n",
      "Epoch: 146, Batch: 400, loss: 26.80386354593609\n",
      "Epoch: 146, Batch: 500, loss: 30.176497702607616\n",
      "Epoch: 147, Batch: 0, loss: 0.0007680478687795531\n",
      "Epoch: 147, Batch: 100, loss: 18.959666100563055\n",
      "Epoch: 147, Batch: 200, loss: 28.955782745207138\n",
      "Epoch: 147, Batch: 300, loss: 32.43019185769984\n",
      "Epoch: 147, Batch: 400, loss: 31.86799392958451\n",
      "Epoch: 147, Batch: 500, loss: 31.682708505648396\n",
      "Epoch: 148, Batch: 0, loss: 1.3270626785972135\n",
      "Epoch: 148, Batch: 100, loss: 25.82016519221566\n",
      "Epoch: 148, Batch: 200, loss: 24.991843216903213\n",
      "Epoch: 148, Batch: 300, loss: 26.00932250406105\n",
      "Epoch: 148, Batch: 400, loss: 27.383641452874453\n",
      "Epoch: 148, Batch: 500, loss: 29.743375370308957\n",
      "Epoch: 149, Batch: 0, loss: 160.50488379355414\n",
      "Epoch: 149, Batch: 100, loss: 30.79938540740844\n",
      "Epoch: 149, Batch: 200, loss: 29.06256600029835\n",
      "Epoch: 149, Batch: 300, loss: 30.01785025318209\n",
      "Epoch: 149, Batch: 400, loss: 28.929513552075345\n",
      "Epoch: 149, Batch: 500, loss: 30.46041404513863\n",
      "Epoch: 150, Batch: 0, loss: 4.173177542614161\n",
      "Epoch: 150, Batch: 100, loss: 29.137809292361098\n",
      "Epoch: 150, Batch: 200, loss: 25.286620454882936\n",
      "Epoch: 150, Batch: 300, loss: 22.73354046120439\n",
      "Epoch: 150, Batch: 400, loss: 23.79160116496326\n",
      "Epoch: 150, Batch: 500, loss: 24.100574541446434\n",
      "Epoch: 151, Batch: 0, loss: 27.431577035281926\n",
      "Epoch: 151, Batch: 100, loss: 33.72984618290818\n",
      "Epoch: 151, Batch: 200, loss: 29.600249393229088\n",
      "Epoch: 151, Batch: 300, loss: 32.61960164790755\n",
      "Epoch: 151, Batch: 400, loss: 31.357727800945955\n",
      "Epoch: 151, Batch: 500, loss: 31.60046132894617\n",
      "Epoch: 152, Batch: 0, loss: 2.869857877517061\n",
      "Epoch: 152, Batch: 100, loss: 28.78245746661597\n",
      "Epoch: 152, Batch: 200, loss: 31.840723365091996\n",
      "Epoch: 152, Batch: 300, loss: 29.459741354153458\n",
      "Epoch: 152, Batch: 400, loss: 29.41593105966386\n",
      "Epoch: 152, Batch: 500, loss: 33.299849312767094\n",
      "Epoch: 153, Batch: 0, loss: 5.609908827557937\n",
      "Epoch: 153, Batch: 100, loss: 39.294391722103136\n",
      "Epoch: 153, Batch: 200, loss: 31.720337955637383\n",
      "Epoch: 153, Batch: 300, loss: 31.385497955608663\n",
      "Epoch: 153, Batch: 400, loss: 32.403079913527435\n",
      "Epoch: 153, Batch: 500, loss: 35.21748618493375\n",
      "Epoch: 154, Batch: 0, loss: 60.16614672986076\n",
      "Epoch: 154, Batch: 100, loss: 37.68535023432286\n",
      "Epoch: 154, Batch: 200, loss: 34.779505307915315\n",
      "Epoch: 154, Batch: 300, loss: 31.985239918429954\n",
      "Epoch: 154, Batch: 400, loss: 32.25502005455947\n",
      "Epoch: 154, Batch: 500, loss: 33.79182502955712\n",
      "Epoch: 155, Batch: 0, loss: 0.25388611569823755\n",
      "Epoch: 155, Batch: 100, loss: 23.494930915894102\n",
      "Epoch: 155, Batch: 200, loss: 26.82008528607739\n",
      "Epoch: 155, Batch: 300, loss: 28.10463657622443\n",
      "Epoch: 155, Batch: 400, loss: 29.86383226429388\n",
      "Epoch: 155, Batch: 500, loss: 29.14621189298424\n",
      "Epoch: 156, Batch: 0, loss: 11.29198238328715\n",
      "Epoch: 156, Batch: 100, loss: 35.7012107209749\n",
      "Epoch: 156, Batch: 200, loss: 38.38182803704035\n",
      "Epoch: 156, Batch: 300, loss: 35.06885644616628\n",
      "Epoch: 156, Batch: 400, loss: 33.73042569220225\n",
      "Epoch: 156, Batch: 500, loss: 32.7272749596937\n",
      "Epoch: 157, Batch: 0, loss: 11.046970090390214\n",
      "Epoch: 157, Batch: 100, loss: 52.77004864548424\n",
      "Epoch: 157, Batch: 200, loss: 37.10377189571925\n",
      "Epoch: 157, Batch: 300, loss: 36.22813541729936\n",
      "Epoch: 157, Batch: 400, loss: 34.81034609089854\n",
      "Epoch: 157, Batch: 500, loss: 35.11828715215663\n",
      "Epoch: 158, Batch: 0, loss: 17.52402281055705\n",
      "Epoch: 158, Batch: 100, loss: 45.72761056250662\n",
      "Epoch: 158, Batch: 200, loss: 41.34091291120817\n",
      "Epoch: 158, Batch: 300, loss: 37.52259455051883\n",
      "Epoch: 158, Batch: 400, loss: 38.579344338263255\n",
      "Epoch: 158, Batch: 500, loss: 35.612116981944\n",
      "Epoch: 159, Batch: 0, loss: 6.33145794304291\n",
      "Epoch: 159, Batch: 100, loss: 33.72133072462247\n",
      "Epoch: 159, Batch: 200, loss: 31.05931787744691\n",
      "Epoch: 159, Batch: 300, loss: 29.54591038514986\n",
      "Epoch: 159, Batch: 400, loss: 27.494757145380355\n",
      "Epoch: 159, Batch: 500, loss: 25.709517558003537\n",
      "Epoch: 160, Batch: 0, loss: 1.4725117089204451\n",
      "Epoch: 160, Batch: 100, loss: 27.677262701752912\n",
      "Epoch: 160, Batch: 200, loss: 40.43190194455575\n",
      "Epoch: 160, Batch: 300, loss: 35.24433647346857\n",
      "Epoch: 160, Batch: 400, loss: 34.67539632770838\n",
      "Epoch: 160, Batch: 500, loss: 34.19117888049873\n",
      "Epoch: 161, Batch: 0, loss: 2.1536054651495906\n",
      "Epoch: 161, Batch: 100, loss: 28.261557286240468\n",
      "Epoch: 161, Batch: 200, loss: 30.868728829059005\n",
      "Epoch: 161, Batch: 300, loss: 32.19287322059525\n",
      "Epoch: 161, Batch: 400, loss: 28.00292222614201\n",
      "Epoch: 161, Batch: 500, loss: 27.008742669854836\n",
      "Epoch: 162, Batch: 0, loss: 8.973548569750156\n",
      "Epoch: 162, Batch: 100, loss: 22.895182154738194\n",
      "Epoch: 162, Batch: 200, loss: 23.477201432904884\n",
      "Epoch: 162, Batch: 300, loss: 23.793890083297025\n",
      "Epoch: 162, Batch: 400, loss: 27.258836090400084\n",
      "Epoch: 162, Batch: 500, loss: 29.349104613090702\n",
      "Epoch: 163, Batch: 0, loss: 0.09839856893214773\n",
      "Epoch: 163, Batch: 100, loss: 23.624356873052474\n",
      "Epoch: 163, Batch: 200, loss: 25.76325558273833\n",
      "Epoch: 163, Batch: 300, loss: 27.195758159313705\n",
      "Epoch: 163, Batch: 400, loss: 27.063433444605014\n",
      "Epoch: 163, Batch: 500, loss: 26.02194631533491\n",
      "Epoch: 164, Batch: 0, loss: 4.305399697064785\n",
      "Epoch: 164, Batch: 100, loss: 43.66120862781871\n",
      "Epoch: 164, Batch: 200, loss: 36.24523509819351\n",
      "Epoch: 164, Batch: 300, loss: 38.207567631063796\n",
      "Epoch: 164, Batch: 400, loss: 37.085967790595\n",
      "Epoch: 164, Batch: 500, loss: 36.55664834981685\n",
      "Epoch: 165, Batch: 0, loss: 0.051292643480323016\n",
      "Epoch: 165, Batch: 100, loss: 18.419025833813524\n",
      "Epoch: 165, Batch: 200, loss: 28.593135640857785\n",
      "Epoch: 165, Batch: 300, loss: 28.496527917824153\n",
      "Epoch: 165, Batch: 400, loss: 28.264848144893875\n",
      "Epoch: 165, Batch: 500, loss: 29.106227114002966\n",
      "Epoch: 166, Batch: 0, loss: 2.7230604553132\n",
      "Epoch: 166, Batch: 100, loss: 33.113523875853986\n",
      "Epoch: 166, Batch: 200, loss: 36.76231864318917\n",
      "Epoch: 166, Batch: 300, loss: 34.39993656191332\n",
      "Epoch: 166, Batch: 400, loss: 35.89239868368694\n",
      "Epoch: 166, Batch: 500, loss: 32.01222456939281\n",
      "Epoch: 167, Batch: 0, loss: 1.6285331000364793\n",
      "Epoch: 167, Batch: 100, loss: 39.017125023197345\n",
      "Epoch: 167, Batch: 200, loss: 33.21037755975817\n",
      "Epoch: 167, Batch: 300, loss: 38.43603302870609\n",
      "Epoch: 167, Batch: 400, loss: 35.85739107705674\n",
      "Epoch: 167, Batch: 500, loss: 34.04103963604393\n",
      "Epoch: 168, Batch: 0, loss: 5.946486336265674\n",
      "Epoch: 168, Batch: 100, loss: 29.792332911629472\n",
      "Epoch: 168, Batch: 200, loss: 37.55777050927183\n",
      "Epoch: 168, Batch: 300, loss: 35.34653379565213\n",
      "Epoch: 168, Batch: 400, loss: 36.3279578326597\n",
      "Epoch: 168, Batch: 500, loss: 34.403952548019845\n",
      "Epoch: 169, Batch: 0, loss: 155.56486629729986\n",
      "Epoch: 169, Batch: 100, loss: 26.26344594266635\n",
      "Epoch: 169, Batch: 200, loss: 23.654474119733234\n",
      "Epoch: 169, Batch: 300, loss: 23.465181027714596\n",
      "Epoch: 169, Batch: 400, loss: 26.51544653683481\n",
      "Epoch: 169, Batch: 500, loss: 31.184415203313186\n",
      "Epoch: 170, Batch: 0, loss: 0.2466998711538749\n",
      "Epoch: 170, Batch: 100, loss: 16.886962479633038\n",
      "Epoch: 170, Batch: 200, loss: 25.21761889686492\n",
      "Epoch: 170, Batch: 300, loss: 28.215909139340603\n",
      "Epoch: 170, Batch: 400, loss: 27.3264149666513\n",
      "Epoch: 170, Batch: 500, loss: 27.77778990413441\n",
      "Epoch: 171, Batch: 0, loss: 0.6345293011453426\n",
      "Epoch: 171, Batch: 100, loss: 20.287012176987957\n",
      "Epoch: 171, Batch: 200, loss: 26.99172089169566\n",
      "Epoch: 171, Batch: 300, loss: 30.559519463585694\n",
      "Epoch: 171, Batch: 400, loss: 33.49935536323421\n",
      "Epoch: 171, Batch: 500, loss: 33.34943863256058\n",
      "Epoch: 172, Batch: 0, loss: 6.413519544874998\n",
      "Epoch: 172, Batch: 100, loss: 29.655272033032798\n",
      "Epoch: 172, Batch: 200, loss: 23.896073297660234\n",
      "Epoch: 172, Batch: 300, loss: 22.167625974997584\n",
      "Epoch: 172, Batch: 400, loss: 22.32747201443876\n",
      "Epoch: 172, Batch: 500, loss: 22.9618968653144\n",
      "Epoch: 173, Batch: 0, loss: 4.775359315562435\n",
      "Epoch: 173, Batch: 100, loss: 39.095013204949545\n",
      "Epoch: 173, Batch: 200, loss: 35.58535345821083\n",
      "Epoch: 173, Batch: 300, loss: 34.27205953766677\n",
      "Epoch: 173, Batch: 400, loss: 35.21507859812548\n",
      "Epoch: 173, Batch: 500, loss: 32.14742085175198\n",
      "Epoch: 174, Batch: 0, loss: 161.89400685367872\n",
      "Epoch: 174, Batch: 100, loss: 33.14203095430157\n",
      "Epoch: 174, Batch: 200, loss: 29.25868537366464\n",
      "Epoch: 174, Batch: 300, loss: 28.229977246110415\n",
      "Epoch: 174, Batch: 400, loss: 28.29104591623995\n",
      "Epoch: 174, Batch: 500, loss: 26.980036575016612\n",
      "Epoch: 175, Batch: 0, loss: 22.955039659196263\n",
      "Epoch: 175, Batch: 100, loss: 26.95721070899796\n",
      "Epoch: 175, Batch: 200, loss: 27.858039402770107\n",
      "Epoch: 175, Batch: 300, loss: 30.48183340696708\n",
      "Epoch: 175, Batch: 400, loss: 29.420553238205404\n",
      "Epoch: 175, Batch: 500, loss: 29.85010765438402\n",
      "Epoch: 176, Batch: 0, loss: 2.2544335378589984\n",
      "Epoch: 176, Batch: 100, loss: 31.18472602478389\n",
      "Epoch: 176, Batch: 200, loss: 24.90125409695074\n",
      "Epoch: 176, Batch: 300, loss: 24.832420802854955\n",
      "Epoch: 176, Batch: 400, loss: 23.92694888022272\n",
      "Epoch: 176, Batch: 500, loss: 24.65323931827008\n",
      "Epoch: 177, Batch: 0, loss: 0.8386132988453372\n",
      "Epoch: 177, Batch: 100, loss: 15.430471357388353\n",
      "Epoch: 177, Batch: 200, loss: 17.98527493259464\n",
      "Epoch: 177, Batch: 300, loss: 20.844065873440368\n",
      "Epoch: 177, Batch: 400, loss: 22.304183223026058\n",
      "Epoch: 177, Batch: 500, loss: 22.699872865480533\n",
      "Epoch: 178, Batch: 0, loss: 3.466250615538483\n",
      "Epoch: 178, Batch: 100, loss: 42.82772951087713\n",
      "Epoch: 178, Batch: 200, loss: 28.588881119165016\n",
      "Epoch: 178, Batch: 300, loss: 27.88791441694881\n",
      "Epoch: 178, Batch: 400, loss: 30.521779631591382\n",
      "Epoch: 178, Batch: 500, loss: 33.4287856682203\n",
      "Epoch: 179, Batch: 0, loss: 25.604842087282986\n",
      "Epoch: 179, Batch: 100, loss: 17.408807443372872\n",
      "Epoch: 179, Batch: 200, loss: 28.105238073441555\n",
      "Epoch: 179, Batch: 300, loss: 30.797665932757095\n",
      "Epoch: 179, Batch: 400, loss: 31.914681133164223\n",
      "Epoch: 179, Batch: 500, loss: 30.426904249804103\n",
      "Epoch: 180, Batch: 0, loss: 2.9824232743185815\n",
      "Epoch: 180, Batch: 100, loss: 29.41352749366555\n",
      "Epoch: 180, Batch: 200, loss: 35.84300223630624\n",
      "Epoch: 180, Batch: 300, loss: 32.9054436318123\n",
      "Epoch: 180, Batch: 400, loss: 33.885473962553\n",
      "Epoch: 180, Batch: 500, loss: 33.06651968357459\n",
      "Epoch: 181, Batch: 0, loss: 1.083035590498323\n",
      "Epoch: 181, Batch: 100, loss: 28.54406785749762\n",
      "Epoch: 181, Batch: 200, loss: 29.600499396089678\n",
      "Epoch: 181, Batch: 300, loss: 27.73110425148796\n",
      "Epoch: 181, Batch: 400, loss: 30.871938001979583\n",
      "Epoch: 181, Batch: 500, loss: 30.83643136286935\n",
      "Epoch: 182, Batch: 0, loss: 21.848852345415896\n",
      "Epoch: 182, Batch: 100, loss: 23.690011822935436\n",
      "Epoch: 182, Batch: 200, loss: 24.705230663936163\n",
      "Epoch: 182, Batch: 300, loss: 24.693819677154263\n",
      "Epoch: 182, Batch: 400, loss: 26.130751008951226\n",
      "Epoch: 182, Batch: 500, loss: 29.131841081875116\n",
      "Epoch: 183, Batch: 0, loss: 39.50169899128609\n",
      "Epoch: 183, Batch: 100, loss: 37.71340578242291\n",
      "Epoch: 183, Batch: 200, loss: 36.44082139255571\n",
      "Epoch: 183, Batch: 300, loss: 32.92637743635792\n",
      "Epoch: 183, Batch: 400, loss: 29.27573204610807\n",
      "Epoch: 183, Batch: 500, loss: 32.060208918548746\n",
      "Epoch: 184, Batch: 0, loss: 8.880119877997217\n",
      "Epoch: 184, Batch: 100, loss: 26.452139249200034\n",
      "Epoch: 184, Batch: 200, loss: 28.845668487931807\n",
      "Epoch: 184, Batch: 300, loss: 29.39679060167411\n",
      "Epoch: 184, Batch: 400, loss: 33.14996112409656\n",
      "Epoch: 184, Batch: 500, loss: 32.63132942596668\n",
      "Epoch: 185, Batch: 0, loss: 0.0723171821315014\n",
      "Epoch: 185, Batch: 100, loss: 34.90619615383259\n",
      "Epoch: 185, Batch: 200, loss: 33.8407577105348\n",
      "Epoch: 185, Batch: 300, loss: 32.390994940982516\n",
      "Epoch: 185, Batch: 400, loss: 34.32353543232528\n",
      "Epoch: 185, Batch: 500, loss: 32.92413909357088\n",
      "Epoch: 186, Batch: 0, loss: 1.9138172182758113\n",
      "Epoch: 186, Batch: 100, loss: 28.960410047660226\n",
      "Epoch: 186, Batch: 200, loss: 33.03479486559903\n",
      "Epoch: 186, Batch: 300, loss: 30.72474899458671\n",
      "Epoch: 186, Batch: 400, loss: 30.317516014461695\n",
      "Epoch: 186, Batch: 500, loss: 32.42739704499818\n",
      "Epoch: 187, Batch: 0, loss: 0.14351916273918408\n",
      "Epoch: 187, Batch: 100, loss: 34.48476247688065\n",
      "Epoch: 187, Batch: 200, loss: 31.21238488872172\n",
      "Epoch: 187, Batch: 300, loss: 29.577008469147312\n",
      "Epoch: 187, Batch: 400, loss: 29.566045080374685\n",
      "Epoch: 187, Batch: 500, loss: 30.345855857268546\n",
      "Epoch: 188, Batch: 0, loss: 0.12101626291379454\n",
      "Epoch: 188, Batch: 100, loss: 24.04117413408914\n",
      "Epoch: 188, Batch: 200, loss: 21.385268837548164\n",
      "Epoch: 188, Batch: 300, loss: 24.257605787207638\n",
      "Epoch: 188, Batch: 400, loss: 25.904233062800603\n",
      "Epoch: 188, Batch: 500, loss: 29.953223747305437\n",
      "Epoch: 189, Batch: 0, loss: 0.3340276202985021\n",
      "Epoch: 189, Batch: 100, loss: 46.58332976381042\n",
      "Epoch: 189, Batch: 200, loss: 36.105492222790396\n",
      "Epoch: 189, Batch: 300, loss: 35.94793398967093\n",
      "Epoch: 189, Batch: 400, loss: 36.45810334565314\n",
      "Epoch: 189, Batch: 500, loss: 34.0386515744814\n",
      "Epoch: 190, Batch: 0, loss: 1.124495084232466\n",
      "Epoch: 190, Batch: 100, loss: 48.90626266014668\n",
      "Epoch: 190, Batch: 200, loss: 45.690913549242126\n",
      "Epoch: 190, Batch: 300, loss: 38.36127784815562\n",
      "Epoch: 190, Batch: 400, loss: 37.34904272232163\n",
      "Epoch: 190, Batch: 500, loss: 37.596428447648584\n",
      "Epoch: 191, Batch: 0, loss: 26.988997327213628\n",
      "Epoch: 191, Batch: 100, loss: 39.82123543113601\n",
      "Epoch: 191, Batch: 200, loss: 37.8374797516211\n",
      "Epoch: 191, Batch: 300, loss: 34.73099267826081\n",
      "Epoch: 191, Batch: 400, loss: 38.71378010714644\n",
      "Epoch: 191, Batch: 500, loss: 37.36571637289588\n",
      "Epoch: 192, Batch: 0, loss: 32.21371417901871\n",
      "Epoch: 192, Batch: 100, loss: 27.3599787904492\n",
      "Epoch: 192, Batch: 200, loss: 30.33143952985761\n",
      "Epoch: 192, Batch: 300, loss: 29.406268160780755\n",
      "Epoch: 192, Batch: 400, loss: 30.425817701565293\n",
      "Epoch: 192, Batch: 500, loss: 28.613827678541313\n",
      "Epoch: 193, Batch: 0, loss: 8.177937961476065\n",
      "Epoch: 193, Batch: 100, loss: 20.349060836719215\n",
      "Epoch: 193, Batch: 200, loss: 19.057145235922395\n",
      "Epoch: 193, Batch: 300, loss: 22.591593154782018\n",
      "Epoch: 193, Batch: 400, loss: 24.947233657948125\n",
      "Epoch: 193, Batch: 500, loss: 26.347464559271707\n",
      "Epoch: 194, Batch: 0, loss: 728.6835488382704\n",
      "Epoch: 194, Batch: 100, loss: 45.3879539157251\n",
      "Epoch: 194, Batch: 200, loss: 35.29696786453344\n",
      "Epoch: 194, Batch: 300, loss: 32.81853013546823\n",
      "Epoch: 194, Batch: 400, loss: 31.446178674960233\n",
      "Epoch: 194, Batch: 500, loss: 31.324717390360597\n",
      "Epoch: 195, Batch: 0, loss: 6.893620313305624\n",
      "Epoch: 195, Batch: 100, loss: 25.546069995916312\n",
      "Epoch: 195, Batch: 200, loss: 26.072983023954222\n",
      "Epoch: 195, Batch: 300, loss: 27.10791115287152\n",
      "Epoch: 195, Batch: 400, loss: 27.390211965927314\n",
      "Epoch: 195, Batch: 500, loss: 28.523186118301332\n",
      "Epoch: 196, Batch: 0, loss: 14.545424143422226\n",
      "Epoch: 196, Batch: 100, loss: 29.34187685140932\n",
      "Epoch: 196, Batch: 200, loss: 24.84592838464649\n",
      "Epoch: 196, Batch: 300, loss: 25.969725480599376\n",
      "Epoch: 196, Batch: 400, loss: 27.191564737199663\n",
      "Epoch: 196, Batch: 500, loss: 30.78975578312957\n",
      "Epoch: 197, Batch: 0, loss: 6.356829918244008\n",
      "Epoch: 197, Batch: 100, loss: 35.74811208600449\n",
      "Epoch: 197, Batch: 200, loss: 40.90232566572839\n",
      "Epoch: 197, Batch: 300, loss: 37.17200213449241\n",
      "Epoch: 197, Batch: 400, loss: 36.327318952487914\n",
      "Epoch: 197, Batch: 500, loss: 33.285047535005745\n",
      "Epoch: 198, Batch: 0, loss: 13.300701466483051\n",
      "Epoch: 198, Batch: 100, loss: 27.958811442855637\n",
      "Epoch: 198, Batch: 200, loss: 32.00088345706831\n",
      "Epoch: 198, Batch: 300, loss: 33.9996001350261\n",
      "Epoch: 198, Batch: 400, loss: 31.897549760187793\n",
      "Epoch: 198, Batch: 500, loss: 31.39613092434797\n",
      "Epoch: 199, Batch: 0, loss: 20.0478160639273\n",
      "Epoch: 199, Batch: 100, loss: 27.963210991965667\n",
      "Epoch: 199, Batch: 200, loss: 25.609516581094436\n",
      "Epoch: 199, Batch: 300, loss: 25.601720995889803\n",
      "Epoch: 199, Batch: 400, loss: 29.689633120581632\n",
      "Epoch: 199, Batch: 500, loss: 28.308274447364248\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Logstic Regression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\n",
    "housing_price = load_boston()\n",
    "dataframe = pd.DataFrame(housing_price['data'])\n",
    "dataframe.columns = housing_price['feature_names']\n",
    "dataframe['price'] = housing_price['target']\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lst = dataframe['LSTAT']\n",
    "price = dataframe['price']\n",
    "print(np.percentile(price, 66))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23.53\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# plt.hist(target)\n",
    "# plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > np.percentile(price, 66)))\n",
    "expensive = dataframe['expensive']\n",
    "\n",
    "# print(dataframe.head())\n",
    "print(dataframe['expensive'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "501    0\n",
      "502    0\n",
      "503    1\n",
      "504    0\n",
      "505    0\n",
      "Name: expensive, Length: 506, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def model(x, w, b):\n",
    "    return logistic(np.dot(x, w.T) + b)\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -1 * np.sum(y*np.log(yhat) + (1 - y) * np.log(1 - yhat))\n",
    "\n",
    "\n",
    "def partial_w(x1, x2, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x1), np.sum((yhat - y) * x2)])\n",
    "\n",
    "\n",
    "def partial_b(x1, x2, y, yhat):\n",
    "    return np.sum(yhat - y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "w = np.random.random_sample((1, 2))\n",
    "print(w)\n",
    "b = 0\n",
    "alpha = 1e-5\n",
    "\n",
    "epoch = 200\n",
    "history = []\n",
    "\n",
    "history_k_b_loss = []"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.69565948 0.90768813]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for e in range(epoch):\n",
    "    losses = []\n",
    "    for batch in range(len(rm)):\n",
    "        random_index = random.choice(range(len(rm)))\n",
    "\n",
    "        x1, x2 = rm[random_index], lst[random_index]\n",
    "        y = expensive[random_index]\n",
    "\n",
    "        yhat = model(np.array([x1, x2]), w, b)\n",
    "        loss_v = loss(yhat, y)\n",
    "\n",
    "        w = w - partial_w(x1, x2, y, yhat) * alpha\n",
    "        b = b - partial_b(x1, x2, y, yhat) * alpha\n",
    "\n",
    "        losses.append(loss_v)\n",
    "\n",
    "        history_k_b_loss.append((w, b, loss_v))\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch: {}, Batch: {}, loss: {}'.format(e, batch, np.mean(losses)))\n",
    "\n",
    "    history.append(np.mean(losses))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Batch: 0, loss: 3.14765267665445e-06\n",
      "Epoch: 0, Batch: 100, loss: 13.555508645878497\n",
      "Epoch: 0, Batch: 200, loss: 11.83709021684691\n",
      "Epoch: 0, Batch: 300, loss: 11.738465997702518\n",
      "Epoch: 0, Batch: 400, loss: 11.935773254362111\n",
      "Epoch: 0, Batch: 500, loss: 11.920971659114693\n",
      "Epoch: 1, Batch: 0, loss: 9.491595103632969\n",
      "Epoch: 1, Batch: 100, loss: 11.607244608288832\n",
      "Epoch: 1, Batch: 200, loss: 12.0667577594433\n",
      "Epoch: 1, Batch: 300, loss: 11.572571737367278\n",
      "Epoch: 1, Batch: 400, loss: 11.579775065015916\n",
      "Epoch: 1, Batch: 500, loss: 11.692493156104222\n",
      "Epoch: 2, Batch: 0, loss: 0.0002565112564880696\n",
      "Epoch: 2, Batch: 100, loss: 10.82601935494795\n",
      "Epoch: 2, Batch: 200, loss: 10.288777212104227\n",
      "Epoch: 2, Batch: 300, loss: 10.525115134161169\n",
      "Epoch: 2, Batch: 400, loss: 10.478520186471238\n",
      "Epoch: 2, Batch: 500, loss: 10.468264440938869\n",
      "Epoch: 3, Batch: 0, loss: 16.033642480271318\n",
      "Epoch: 3, Batch: 100, loss: 9.955363813982737\n",
      "Epoch: 3, Batch: 200, loss: 9.979613145136888\n",
      "Epoch: 3, Batch: 300, loss: 10.190590626068161\n",
      "Epoch: 3, Batch: 400, loss: 9.935536599426165\n",
      "Epoch: 3, Batch: 500, loss: 9.545042899637076\n",
      "Epoch: 4, Batch: 0, loss: 0.0007426862001544194\n",
      "Epoch: 4, Batch: 100, loss: 9.499301919017062\n",
      "Epoch: 4, Batch: 200, loss: 9.762504456989697\n",
      "Epoch: 4, Batch: 300, loss: 9.655555976193227\n",
      "Epoch: 4, Batch: 400, loss: 9.50459480806719\n",
      "Epoch: 4, Batch: 500, loss: 9.29964827018245\n",
      "Epoch: 5, Batch: 0, loss: 20.678771958512968\n",
      "Epoch: 5, Batch: 100, loss: 9.10610166811353\n",
      "Epoch: 5, Batch: 200, loss: 8.977382737508686\n",
      "Epoch: 5, Batch: 300, loss: 8.471843598149709\n",
      "Epoch: 5, Batch: 400, loss: 8.706170363053298\n",
      "Epoch: 5, Batch: 500, loss: 8.809281597195271\n",
      "Epoch: 6, Batch: 0, loss: 0.0027339795537887576\n",
      "Epoch: 6, Batch: 100, loss: 8.11212562154213\n",
      "Epoch: 6, Batch: 200, loss: 8.519645793442484\n",
      "Epoch: 6, Batch: 300, loss: 8.698641023814641\n",
      "Epoch: 6, Batch: 400, loss: 8.424904396155252\n",
      "Epoch: 6, Batch: 500, loss: 8.31729090998737\n",
      "Epoch: 7, Batch: 0, loss: 19.489431393641848\n",
      "Epoch: 7, Batch: 100, loss: 9.07806029003255\n",
      "Epoch: 7, Batch: 200, loss: 8.729912582283394\n",
      "Epoch: 7, Batch: 300, loss: 8.42719949342613\n",
      "Epoch: 7, Batch: 400, loss: 8.03311740427043\n",
      "Epoch: 7, Batch: 500, loss: 7.781196871334401\n",
      "Epoch: 8, Batch: 0, loss: 10.13031895671362\n",
      "Epoch: 8, Batch: 100, loss: 7.49309580801646\n",
      "Epoch: 8, Batch: 200, loss: 7.267597184491184\n",
      "Epoch: 8, Batch: 300, loss: 7.1039561225026375\n",
      "Epoch: 8, Batch: 400, loss: 6.827936602584884\n",
      "Epoch: 8, Batch: 500, loss: 6.815624055986337\n",
      "Epoch: 9, Batch: 0, loss: 11.61611425474074\n",
      "Epoch: 9, Batch: 100, loss: 5.670427075702777\n",
      "Epoch: 9, Batch: 200, loss: 5.9996166705363345\n",
      "Epoch: 9, Batch: 300, loss: 6.023472281802251\n",
      "Epoch: 9, Batch: 400, loss: 6.167433909200858\n",
      "Epoch: 9, Batch: 500, loss: 5.996928464056135\n",
      "Epoch: 10, Batch: 0, loss: 0.0017196970888846141\n",
      "Epoch: 10, Batch: 100, loss: 5.838223689842674\n",
      "Epoch: 10, Batch: 200, loss: 5.83905234541126\n",
      "Epoch: 10, Batch: 300, loss: 5.751836693615192\n",
      "Epoch: 10, Batch: 400, loss: 5.723965754195509\n",
      "Epoch: 10, Batch: 500, loss: 5.698505111094065\n",
      "Epoch: 11, Batch: 0, loss: 5.577100684548692\n",
      "Epoch: 11, Batch: 100, loss: 5.717186616672811\n",
      "Epoch: 11, Batch: 200, loss: 5.244595844490303\n",
      "Epoch: 11, Batch: 300, loss: 5.10612536579018\n",
      "Epoch: 11, Batch: 400, loss: 4.888944824875722\n",
      "Epoch: 11, Batch: 500, loss: 4.8273713039524635\n",
      "Epoch: 12, Batch: 0, loss: 9.214952523623731\n",
      "Epoch: 12, Batch: 100, loss: 4.469209490247028\n",
      "Epoch: 12, Batch: 200, loss: 4.351726951795307\n",
      "Epoch: 12, Batch: 300, loss: 4.35315858835264\n",
      "Epoch: 12, Batch: 400, loss: 4.347157063136533\n",
      "Epoch: 12, Batch: 500, loss: 4.239012480456293\n",
      "Epoch: 13, Batch: 0, loss: 6.735828525509854\n",
      "Epoch: 13, Batch: 100, loss: 4.587863754679346\n",
      "Epoch: 13, Batch: 200, loss: 4.242675820072107\n",
      "Epoch: 13, Batch: 300, loss: 4.098805701392385\n",
      "Epoch: 13, Batch: 400, loss: 4.072690809341422\n",
      "Epoch: 13, Batch: 500, loss: 3.982821966650162\n",
      "Epoch: 14, Batch: 0, loss: 5.24564980503872\n",
      "Epoch: 14, Batch: 100, loss: 3.438242102891212\n",
      "Epoch: 14, Batch: 200, loss: 3.3963836507916656\n",
      "Epoch: 14, Batch: 300, loss: 3.28168225674437\n",
      "Epoch: 14, Batch: 400, loss: 3.2233319664038094\n",
      "Epoch: 14, Batch: 500, loss: 3.1078073330882514\n",
      "Epoch: 15, Batch: 0, loss: 3.903647659415151\n",
      "Epoch: 15, Batch: 100, loss: 2.6833754272093633\n",
      "Epoch: 15, Batch: 200, loss: 2.6946106111223136\n",
      "Epoch: 15, Batch: 300, loss: 2.6750369484685512\n",
      "Epoch: 15, Batch: 400, loss: 2.653592688868063\n",
      "Epoch: 15, Batch: 500, loss: 2.538394619275435\n",
      "Epoch: 16, Batch: 0, loss: 3.2824274986286466\n",
      "Epoch: 16, Batch: 100, loss: 2.1188567514513648\n",
      "Epoch: 16, Batch: 200, loss: 2.1046502722656895\n",
      "Epoch: 16, Batch: 300, loss: 1.9735195039322275\n",
      "Epoch: 16, Batch: 400, loss: 1.9363019346581491\n",
      "Epoch: 16, Batch: 500, loss: 1.8902149370697388\n",
      "Epoch: 17, Batch: 0, loss: 0.08262120392271291\n",
      "Epoch: 17, Batch: 100, loss: 1.4882781667055298\n",
      "Epoch: 17, Batch: 200, loss: 1.489505068465795\n",
      "Epoch: 17, Batch: 300, loss: 1.5166318928929914\n",
      "Epoch: 17, Batch: 400, loss: 1.4402552180907495\n",
      "Epoch: 17, Batch: 500, loss: 1.3942609069334526\n",
      "Epoch: 18, Batch: 0, loss: 0.09749712148680584\n",
      "Epoch: 18, Batch: 100, loss: 1.0894825666724546\n",
      "Epoch: 18, Batch: 200, loss: 1.1072307016965606\n",
      "Epoch: 18, Batch: 300, loss: 1.0745699715028618\n",
      "Epoch: 18, Batch: 400, loss: 1.0614523420498148\n",
      "Epoch: 18, Batch: 500, loss: 1.0315648717478738\n",
      "Epoch: 19, Batch: 0, loss: 0.9430326815006719\n",
      "Epoch: 19, Batch: 100, loss: 0.9477508620974635\n",
      "Epoch: 19, Batch: 200, loss: 0.8888095687596799\n",
      "Epoch: 19, Batch: 300, loss: 0.8813698348232321\n",
      "Epoch: 19, Batch: 400, loss: 0.8351036819760943\n",
      "Epoch: 19, Batch: 500, loss: 0.8121953159383404\n",
      "Epoch: 20, Batch: 0, loss: 1.401260726809097\n",
      "Epoch: 20, Batch: 100, loss: 0.7300589773795719\n",
      "Epoch: 20, Batch: 200, loss: 0.6850514091435136\n",
      "Epoch: 20, Batch: 300, loss: 0.6551792846543912\n",
      "Epoch: 20, Batch: 400, loss: 0.6387397090320784\n",
      "Epoch: 20, Batch: 500, loss: 0.6379920925152132\n",
      "Epoch: 21, Batch: 0, loss: 0.19254188604969505\n",
      "Epoch: 21, Batch: 100, loss: 0.652813536630543\n",
      "Epoch: 21, Batch: 200, loss: 0.6002544931060352\n",
      "Epoch: 21, Batch: 300, loss: 0.5882609274501747\n",
      "Epoch: 21, Batch: 400, loss: 0.5704231363282594\n",
      "Epoch: 21, Batch: 500, loss: 0.5507003667878918\n",
      "Epoch: 22, Batch: 0, loss: 0.06324263992349295\n",
      "Epoch: 22, Batch: 100, loss: 0.4567579586779523\n",
      "Epoch: 22, Batch: 200, loss: 0.48670862595413533\n",
      "Epoch: 22, Batch: 300, loss: 0.4776353428891178\n",
      "Epoch: 22, Batch: 400, loss: 0.4866087873495464\n",
      "Epoch: 22, Batch: 500, loss: 0.47513731168166967\n",
      "Epoch: 23, Batch: 0, loss: 0.6830419687800493\n",
      "Epoch: 23, Batch: 100, loss: 0.4927469160485665\n",
      "Epoch: 23, Batch: 200, loss: 0.48632155035537816\n",
      "Epoch: 23, Batch: 300, loss: 0.4747584924487487\n",
      "Epoch: 23, Batch: 400, loss: 0.4670318212464176\n",
      "Epoch: 23, Batch: 500, loss: 0.4601618611047766\n",
      "Epoch: 24, Batch: 0, loss: 0.804916231067148\n",
      "Epoch: 24, Batch: 100, loss: 0.4265911008730877\n",
      "Epoch: 24, Batch: 200, loss: 0.43908228916715625\n",
      "Epoch: 24, Batch: 300, loss: 0.44620479134603297\n",
      "Epoch: 24, Batch: 400, loss: 0.4351523734453799\n",
      "Epoch: 24, Batch: 500, loss: 0.4330707314658382\n",
      "Epoch: 25, Batch: 0, loss: 0.5207162989881753\n",
      "Epoch: 25, Batch: 100, loss: 0.42083218062163485\n",
      "Epoch: 25, Batch: 200, loss: 0.435229926250124\n",
      "Epoch: 25, Batch: 300, loss: 0.4221237066892708\n",
      "Epoch: 25, Batch: 400, loss: 0.4185285787199979\n",
      "Epoch: 25, Batch: 500, loss: 0.4137330026703081\n",
      "Epoch: 26, Batch: 0, loss: 0.2731345520500898\n",
      "Epoch: 26, Batch: 100, loss: 0.44144888555516376\n",
      "Epoch: 26, Batch: 200, loss: 0.4380765995135119\n",
      "Epoch: 26, Batch: 300, loss: 0.42379871527828394\n",
      "Epoch: 26, Batch: 400, loss: 0.40869279716802537\n",
      "Epoch: 26, Batch: 500, loss: 0.4122583239849339\n",
      "Epoch: 27, Batch: 0, loss: 0.3776542757024841\n",
      "Epoch: 27, Batch: 100, loss: 0.4050122303078685\n",
      "Epoch: 27, Batch: 200, loss: 0.3970969115751853\n",
      "Epoch: 27, Batch: 300, loss: 0.3956660522269356\n",
      "Epoch: 27, Batch: 400, loss: 0.40080101696310727\n",
      "Epoch: 27, Batch: 500, loss: 0.39939438068881744\n",
      "Epoch: 28, Batch: 0, loss: 0.014666914807304575\n",
      "Epoch: 28, Batch: 100, loss: 0.38567505629304655\n",
      "Epoch: 28, Batch: 200, loss: 0.37572686480844425\n",
      "Epoch: 28, Batch: 300, loss: 0.39079251178889096\n",
      "Epoch: 28, Batch: 400, loss: 0.3856455994401439\n",
      "Epoch: 28, Batch: 500, loss: 0.3890640380518216\n",
      "Epoch: 29, Batch: 0, loss: 0.2006364897717914\n",
      "Epoch: 29, Batch: 100, loss: 0.3669655444077861\n",
      "Epoch: 29, Batch: 200, loss: 0.37862792881711044\n",
      "Epoch: 29, Batch: 300, loss: 0.3850038365885416\n",
      "Epoch: 29, Batch: 400, loss: 0.38046831367417777\n",
      "Epoch: 29, Batch: 500, loss: 0.38952337628902717\n",
      "Epoch: 30, Batch: 0, loss: 0.5814393875840224\n",
      "Epoch: 30, Batch: 100, loss: 0.4284489000822605\n",
      "Epoch: 30, Batch: 200, loss: 0.41514344065737424\n",
      "Epoch: 30, Batch: 300, loss: 0.4238963374793159\n",
      "Epoch: 30, Batch: 400, loss: 0.4278266991085186\n",
      "Epoch: 30, Batch: 500, loss: 0.4089074749586395\n",
      "Epoch: 31, Batch: 0, loss: 0.34908974752219407\n",
      "Epoch: 31, Batch: 100, loss: 0.3617933890565428\n",
      "Epoch: 31, Batch: 200, loss: 0.36088888690763954\n",
      "Epoch: 31, Batch: 300, loss: 0.36664855705227933\n",
      "Epoch: 31, Batch: 400, loss: 0.3679499960391727\n",
      "Epoch: 31, Batch: 500, loss: 0.3626449368117172\n",
      "Epoch: 32, Batch: 0, loss: 0.75436374458742\n",
      "Epoch: 32, Batch: 100, loss: 0.5341431264029662\n",
      "Epoch: 32, Batch: 200, loss: 0.4497693706773352\n",
      "Epoch: 32, Batch: 300, loss: 0.41983856892193205\n",
      "Epoch: 32, Batch: 400, loss: 0.4166814562354669\n",
      "Epoch: 32, Batch: 500, loss: 0.4054162577350849\n",
      "Epoch: 33, Batch: 0, loss: 0.028784839985964723\n",
      "Epoch: 33, Batch: 100, loss: 0.40426810443184935\n",
      "Epoch: 33, Batch: 200, loss: 0.37879453545554653\n",
      "Epoch: 33, Batch: 300, loss: 0.3961062747609882\n",
      "Epoch: 33, Batch: 400, loss: 0.38206202839513614\n",
      "Epoch: 33, Batch: 500, loss: 0.38486039122080645\n",
      "Epoch: 34, Batch: 0, loss: 0.9877628406761233\n",
      "Epoch: 34, Batch: 100, loss: 0.37478925050453443\n",
      "Epoch: 34, Batch: 200, loss: 0.3628933230584226\n",
      "Epoch: 34, Batch: 300, loss: 0.38040607324743675\n",
      "Epoch: 34, Batch: 400, loss: 0.38552215358069936\n",
      "Epoch: 34, Batch: 500, loss: 0.38325099302325905\n",
      "Epoch: 35, Batch: 0, loss: 0.39048069088496146\n",
      "Epoch: 35, Batch: 100, loss: 0.4197296123033089\n",
      "Epoch: 35, Batch: 200, loss: 0.41990326875724465\n",
      "Epoch: 35, Batch: 300, loss: 0.39389213943227097\n",
      "Epoch: 35, Batch: 400, loss: 0.4006282575148747\n",
      "Epoch: 35, Batch: 500, loss: 0.39776086501221003\n",
      "Epoch: 36, Batch: 0, loss: 0.3214854041205176\n",
      "Epoch: 36, Batch: 100, loss: 0.319632900500218\n",
      "Epoch: 36, Batch: 200, loss: 0.42013375763773714\n",
      "Epoch: 36, Batch: 300, loss: 0.41843222654258505\n",
      "Epoch: 36, Batch: 400, loss: 0.4114400146440446\n",
      "Epoch: 36, Batch: 500, loss: 0.4097668226181082\n",
      "Epoch: 37, Batch: 0, loss: 0.14665630599233942\n",
      "Epoch: 37, Batch: 100, loss: 0.3451863099232358\n",
      "Epoch: 37, Batch: 200, loss: 0.3803565259000018\n",
      "Epoch: 37, Batch: 300, loss: 0.38257526223190774\n",
      "Epoch: 37, Batch: 400, loss: 0.41085986246044887\n",
      "Epoch: 37, Batch: 500, loss: 0.4085120646350882\n",
      "Epoch: 38, Batch: 0, loss: 0.4675067521005516\n",
      "Epoch: 38, Batch: 100, loss: 0.3601334462195033\n",
      "Epoch: 38, Batch: 200, loss: 0.36037331344463147\n",
      "Epoch: 38, Batch: 300, loss: 0.35825689271406463\n",
      "Epoch: 38, Batch: 400, loss: 0.3675346287120655\n",
      "Epoch: 38, Batch: 500, loss: 0.3646374835946025\n",
      "Epoch: 39, Batch: 0, loss: 0.1870225383394169\n",
      "Epoch: 39, Batch: 100, loss: 0.37121321513501543\n",
      "Epoch: 39, Batch: 200, loss: 0.40034507125400426\n",
      "Epoch: 39, Batch: 300, loss: 0.43754014071130615\n",
      "Epoch: 39, Batch: 400, loss: 0.43958425518581773\n",
      "Epoch: 39, Batch: 500, loss: 0.4246167918765587\n",
      "Epoch: 40, Batch: 0, loss: 0.4222548958506989\n",
      "Epoch: 40, Batch: 100, loss: 0.3363637318880987\n",
      "Epoch: 40, Batch: 200, loss: 0.3485873385155695\n",
      "Epoch: 40, Batch: 300, loss: 0.36316945455115873\n",
      "Epoch: 40, Batch: 400, loss: 0.3554660241271766\n",
      "Epoch: 40, Batch: 500, loss: 0.35477444368968697\n",
      "Epoch: 41, Batch: 0, loss: 0.21898560877678086\n",
      "Epoch: 41, Batch: 100, loss: 0.3937645533163161\n",
      "Epoch: 41, Batch: 200, loss: 0.3960641589136199\n",
      "Epoch: 41, Batch: 300, loss: 0.41904215113020826\n",
      "Epoch: 41, Batch: 400, loss: 0.4051420331212033\n",
      "Epoch: 41, Batch: 500, loss: 0.3919363490008537\n",
      "Epoch: 42, Batch: 0, loss: 0.5489431845770095\n",
      "Epoch: 42, Batch: 100, loss: 0.3796950670383557\n",
      "Epoch: 42, Batch: 200, loss: 0.36014975382585274\n",
      "Epoch: 42, Batch: 300, loss: 0.397751343560506\n",
      "Epoch: 42, Batch: 400, loss: 0.38665240003996915\n",
      "Epoch: 42, Batch: 500, loss: 0.38634811262184693\n",
      "Epoch: 43, Batch: 0, loss: 0.29071024624530883\n",
      "Epoch: 43, Batch: 100, loss: 0.3864894133330684\n",
      "Epoch: 43, Batch: 200, loss: 0.3841356919902139\n",
      "Epoch: 43, Batch: 300, loss: 0.37184916779455157\n",
      "Epoch: 43, Batch: 400, loss: 0.3941398552071453\n",
      "Epoch: 43, Batch: 500, loss: 0.3901775080959068\n",
      "Epoch: 44, Batch: 0, loss: 0.0379148324477801\n",
      "Epoch: 44, Batch: 100, loss: 0.31328144140320585\n",
      "Epoch: 44, Batch: 200, loss: 0.2993580485418905\n",
      "Epoch: 44, Batch: 300, loss: 0.3207173040997675\n",
      "Epoch: 44, Batch: 400, loss: 0.32285936572123547\n",
      "Epoch: 44, Batch: 500, loss: 0.35027699912413285\n",
      "Epoch: 45, Batch: 0, loss: 0.19078760288631566\n",
      "Epoch: 45, Batch: 100, loss: 0.31540931605361155\n",
      "Epoch: 45, Batch: 200, loss: 0.34308458799973046\n",
      "Epoch: 45, Batch: 300, loss: 0.33426992366752334\n",
      "Epoch: 45, Batch: 400, loss: 0.3469258925272644\n",
      "Epoch: 45, Batch: 500, loss: 0.3507983148397282\n",
      "Epoch: 46, Batch: 0, loss: 0.36094269499376225\n",
      "Epoch: 46, Batch: 100, loss: 0.4353088216928332\n",
      "Epoch: 46, Batch: 200, loss: 0.393995489609285\n",
      "Epoch: 46, Batch: 300, loss: 0.4045864172469238\n",
      "Epoch: 46, Batch: 400, loss: 0.409408150598935\n",
      "Epoch: 46, Batch: 500, loss: 0.4014019452481424\n",
      "Epoch: 47, Batch: 0, loss: 0.004025683299185029\n",
      "Epoch: 47, Batch: 100, loss: 0.35916113222703994\n",
      "Epoch: 47, Batch: 200, loss: 0.35615441869235215\n",
      "Epoch: 47, Batch: 300, loss: 0.36539432255265325\n",
      "Epoch: 47, Batch: 400, loss: 0.3769958024929084\n",
      "Epoch: 47, Batch: 500, loss: 0.37668809784178076\n",
      "Epoch: 48, Batch: 0, loss: 0.01638994329802984\n",
      "Epoch: 48, Batch: 100, loss: 0.3662340225906791\n",
      "Epoch: 48, Batch: 200, loss: 0.3861445134521634\n",
      "Epoch: 48, Batch: 300, loss: 0.3839949908837247\n",
      "Epoch: 48, Batch: 400, loss: 0.38706575414925215\n",
      "Epoch: 48, Batch: 500, loss: 0.3851079292445232\n",
      "Epoch: 49, Batch: 0, loss: 0.2395243432121101\n",
      "Epoch: 49, Batch: 100, loss: 0.38233305153739894\n",
      "Epoch: 49, Batch: 200, loss: 0.3810181299881789\n",
      "Epoch: 49, Batch: 300, loss: 0.3835526445738088\n",
      "Epoch: 49, Batch: 400, loss: 0.3778759591432203\n",
      "Epoch: 49, Batch: 500, loss: 0.37732896779507447\n",
      "Epoch: 50, Batch: 0, loss: 0.42599685898733325\n",
      "Epoch: 50, Batch: 100, loss: 0.3507274330345537\n",
      "Epoch: 50, Batch: 200, loss: 0.3541553520048753\n",
      "Epoch: 50, Batch: 300, loss: 0.3366982485772419\n",
      "Epoch: 50, Batch: 400, loss: 0.3379793599469216\n",
      "Epoch: 50, Batch: 500, loss: 0.36204457739044404\n",
      "Epoch: 51, Batch: 0, loss: 0.2292548218331222\n",
      "Epoch: 51, Batch: 100, loss: 0.32343218910950494\n",
      "Epoch: 51, Batch: 200, loss: 0.3851599633782171\n",
      "Epoch: 51, Batch: 300, loss: 0.36858857790619626\n",
      "Epoch: 51, Batch: 400, loss: 0.3637807754532306\n",
      "Epoch: 51, Batch: 500, loss: 0.3614736242260204\n",
      "Epoch: 52, Batch: 0, loss: 0.04269578758457169\n",
      "Epoch: 52, Batch: 100, loss: 0.3692407393071208\n",
      "Epoch: 52, Batch: 200, loss: 0.3571004403925276\n",
      "Epoch: 52, Batch: 300, loss: 0.3643480964944667\n",
      "Epoch: 52, Batch: 400, loss: 0.35599835033465377\n",
      "Epoch: 52, Batch: 500, loss: 0.342470933402974\n",
      "Epoch: 53, Batch: 0, loss: 0.28019473608208917\n",
      "Epoch: 53, Batch: 100, loss: 0.3056213506167034\n",
      "Epoch: 53, Batch: 200, loss: 0.3376357954035372\n",
      "Epoch: 53, Batch: 300, loss: 0.3438114584111549\n",
      "Epoch: 53, Batch: 400, loss: 0.37355431468607064\n",
      "Epoch: 53, Batch: 500, loss: 0.3653940594589642\n",
      "Epoch: 54, Batch: 0, loss: 0.05468758523018133\n",
      "Epoch: 54, Batch: 100, loss: 0.4114539649002977\n",
      "Epoch: 54, Batch: 200, loss: 0.3832995268219341\n",
      "Epoch: 54, Batch: 300, loss: 0.3739218916275682\n",
      "Epoch: 54, Batch: 400, loss: 0.38927859919563235\n",
      "Epoch: 54, Batch: 500, loss: 0.37527558334197103\n",
      "Epoch: 55, Batch: 0, loss: 0.329781151085327\n",
      "Epoch: 55, Batch: 100, loss: 0.4509947679316677\n",
      "Epoch: 55, Batch: 200, loss: 0.39807051356598383\n",
      "Epoch: 55, Batch: 300, loss: 0.3777246509820699\n",
      "Epoch: 55, Batch: 400, loss: 0.35754139800553775\n",
      "Epoch: 55, Batch: 500, loss: 0.35097366395472956\n",
      "Epoch: 56, Batch: 0, loss: 0.6218228789527387\n",
      "Epoch: 56, Batch: 100, loss: 0.3707106873554314\n",
      "Epoch: 56, Batch: 200, loss: 0.3772208219108079\n",
      "Epoch: 56, Batch: 300, loss: 0.3446407352568494\n",
      "Epoch: 56, Batch: 400, loss: 0.3687747261941301\n",
      "Epoch: 56, Batch: 500, loss: 0.36795090454613016\n",
      "Epoch: 57, Batch: 0, loss: 0.41798517965970977\n",
      "Epoch: 57, Batch: 100, loss: 0.3513162633882212\n",
      "Epoch: 57, Batch: 200, loss: 0.34636057065148423\n",
      "Epoch: 57, Batch: 300, loss: 0.3520956011916675\n",
      "Epoch: 57, Batch: 400, loss: 0.3555448113730974\n",
      "Epoch: 57, Batch: 500, loss: 0.3639332521947186\n",
      "Epoch: 58, Batch: 0, loss: 0.44968988095034373\n",
      "Epoch: 58, Batch: 100, loss: 0.3862842453974732\n",
      "Epoch: 58, Batch: 200, loss: 0.3902046339699057\n",
      "Epoch: 58, Batch: 300, loss: 0.3864593988551849\n",
      "Epoch: 58, Batch: 400, loss: 0.3878588292361057\n",
      "Epoch: 58, Batch: 500, loss: 0.3689223363816391\n",
      "Epoch: 59, Batch: 0, loss: 0.13708649164708203\n",
      "Epoch: 59, Batch: 100, loss: 0.32833592703977726\n",
      "Epoch: 59, Batch: 200, loss: 0.3133346296914441\n",
      "Epoch: 59, Batch: 300, loss: 0.3318985327346329\n",
      "Epoch: 59, Batch: 400, loss: 0.3399590671060992\n",
      "Epoch: 59, Batch: 500, loss: 0.3408107680036652\n",
      "Epoch: 60, Batch: 0, loss: 0.5139419362492222\n",
      "Epoch: 60, Batch: 100, loss: 0.34716747987097335\n",
      "Epoch: 60, Batch: 200, loss: 0.38837591297578233\n",
      "Epoch: 60, Batch: 300, loss: 0.38255104830005016\n",
      "Epoch: 60, Batch: 400, loss: 0.3864238585881993\n",
      "Epoch: 60, Batch: 500, loss: 0.3823761554673443\n",
      "Epoch: 61, Batch: 0, loss: 0.6388250889111485\n",
      "Epoch: 61, Batch: 100, loss: 0.34636563636430273\n",
      "Epoch: 61, Batch: 200, loss: 0.4050652385525868\n",
      "Epoch: 61, Batch: 300, loss: 0.3758158237869213\n",
      "Epoch: 61, Batch: 400, loss: 0.36895743645827384\n",
      "Epoch: 61, Batch: 500, loss: 0.39053510993705154\n",
      "Epoch: 62, Batch: 0, loss: 0.37723978656274587\n",
      "Epoch: 62, Batch: 100, loss: 0.37232320855362866\n",
      "Epoch: 62, Batch: 200, loss: 0.3849363592141259\n",
      "Epoch: 62, Batch: 300, loss: 0.38353347680818695\n",
      "Epoch: 62, Batch: 400, loss: 0.38641093679950206\n",
      "Epoch: 62, Batch: 500, loss: 0.3946164952542147\n",
      "Epoch: 63, Batch: 0, loss: 0.1645222286539486\n",
      "Epoch: 63, Batch: 100, loss: 0.3545175837313702\n",
      "Epoch: 63, Batch: 200, loss: 0.3582250096584595\n",
      "Epoch: 63, Batch: 300, loss: 0.3642188311347561\n",
      "Epoch: 63, Batch: 400, loss: 0.36733887902072737\n",
      "Epoch: 63, Batch: 500, loss: 0.3664799448847808\n",
      "Epoch: 64, Batch: 0, loss: 0.05319589546037314\n",
      "Epoch: 64, Batch: 100, loss: 0.4132261134645021\n",
      "Epoch: 64, Batch: 200, loss: 0.37743498483716403\n",
      "Epoch: 64, Batch: 300, loss: 0.3971643930519308\n",
      "Epoch: 64, Batch: 400, loss: 0.4098789925054204\n",
      "Epoch: 64, Batch: 500, loss: 0.3935567902417436\n",
      "Epoch: 65, Batch: 0, loss: 0.18659383399076437\n",
      "Epoch: 65, Batch: 100, loss: 0.36611618722713\n",
      "Epoch: 65, Batch: 200, loss: 0.3369475591889261\n",
      "Epoch: 65, Batch: 300, loss: 0.3344442602544169\n",
      "Epoch: 65, Batch: 400, loss: 0.3525593807189224\n",
      "Epoch: 65, Batch: 500, loss: 0.3588532363240663\n",
      "Epoch: 66, Batch: 0, loss: 0.7747721655253973\n",
      "Epoch: 66, Batch: 100, loss: 0.3492423577873785\n",
      "Epoch: 66, Batch: 200, loss: 0.33299089583271996\n",
      "Epoch: 66, Batch: 300, loss: 0.3288566066102367\n",
      "Epoch: 66, Batch: 400, loss: 0.3292301904042727\n",
      "Epoch: 66, Batch: 500, loss: 0.33917313572844765\n",
      "Epoch: 67, Batch: 0, loss: 0.6111236407862141\n",
      "Epoch: 67, Batch: 100, loss: 0.3100859057619945\n",
      "Epoch: 67, Batch: 200, loss: 0.3580245104995177\n",
      "Epoch: 67, Batch: 300, loss: 0.3477370113561839\n",
      "Epoch: 67, Batch: 400, loss: 0.3415133250073521\n",
      "Epoch: 67, Batch: 500, loss: 0.3484591927655442\n",
      "Epoch: 68, Batch: 0, loss: 0.28279152710726996\n",
      "Epoch: 68, Batch: 100, loss: 0.37573586707341694\n",
      "Epoch: 68, Batch: 200, loss: 0.402460713400797\n",
      "Epoch: 68, Batch: 300, loss: 0.36772726547848106\n",
      "Epoch: 68, Batch: 400, loss: 0.3715460922277249\n",
      "Epoch: 68, Batch: 500, loss: 0.3745457851672106\n",
      "Epoch: 69, Batch: 0, loss: 0.19151479381483547\n",
      "Epoch: 69, Batch: 100, loss: 0.3238091583966655\n",
      "Epoch: 69, Batch: 200, loss: 0.32964381394858583\n",
      "Epoch: 69, Batch: 300, loss: 0.3583636691863548\n",
      "Epoch: 69, Batch: 400, loss: 0.3512169887094559\n",
      "Epoch: 69, Batch: 500, loss: 0.3607439603744203\n",
      "Epoch: 70, Batch: 0, loss: 0.0013217901641698515\n",
      "Epoch: 70, Batch: 100, loss: 0.2625637839588166\n",
      "Epoch: 70, Batch: 200, loss: 0.3378271357570913\n",
      "Epoch: 70, Batch: 300, loss: 0.33216998351366506\n",
      "Epoch: 70, Batch: 400, loss: 0.3451613388277334\n",
      "Epoch: 70, Batch: 500, loss: 0.34617897199562986\n",
      "Epoch: 71, Batch: 0, loss: 0.5246733238374937\n",
      "Epoch: 71, Batch: 100, loss: 0.3992132042809657\n",
      "Epoch: 71, Batch: 200, loss: 0.3913303193441119\n",
      "Epoch: 71, Batch: 300, loss: 0.36621063573383705\n",
      "Epoch: 71, Batch: 400, loss: 0.36411234518024194\n",
      "Epoch: 71, Batch: 500, loss: 0.35231172188824844\n",
      "Epoch: 72, Batch: 0, loss: 0.23868102143250883\n",
      "Epoch: 72, Batch: 100, loss: 0.5078046434918742\n",
      "Epoch: 72, Batch: 200, loss: 0.44553271003396183\n",
      "Epoch: 72, Batch: 300, loss: 0.44555584508243884\n",
      "Epoch: 72, Batch: 400, loss: 0.4301593207225956\n",
      "Epoch: 72, Batch: 500, loss: 0.4260346050797436\n",
      "Epoch: 73, Batch: 0, loss: 0.6528528610287871\n",
      "Epoch: 73, Batch: 100, loss: 0.34373828115882993\n",
      "Epoch: 73, Batch: 200, loss: 0.31891919762160864\n",
      "Epoch: 73, Batch: 300, loss: 0.3177023423852712\n",
      "Epoch: 73, Batch: 400, loss: 0.34559883565734617\n",
      "Epoch: 73, Batch: 500, loss: 0.3443322835736065\n",
      "Epoch: 74, Batch: 0, loss: 0.3739243036536537\n",
      "Epoch: 74, Batch: 100, loss: 0.317144533824137\n",
      "Epoch: 74, Batch: 200, loss: 0.3441561402963888\n",
      "Epoch: 74, Batch: 300, loss: 0.3490524419589368\n",
      "Epoch: 74, Batch: 400, loss: 0.3492779778856781\n",
      "Epoch: 74, Batch: 500, loss: 0.3423569286084432\n",
      "Epoch: 75, Batch: 0, loss: 0.674185900790458\n",
      "Epoch: 75, Batch: 100, loss: 0.41946122526553026\n",
      "Epoch: 75, Batch: 200, loss: 0.4064642581268046\n",
      "Epoch: 75, Batch: 300, loss: 0.40533187874492416\n",
      "Epoch: 75, Batch: 400, loss: 0.3783429483504655\n",
      "Epoch: 75, Batch: 500, loss: 0.37141022992102607\n",
      "Epoch: 76, Batch: 0, loss: 0.2972932355095097\n",
      "Epoch: 76, Batch: 100, loss: 0.3638497447000189\n",
      "Epoch: 76, Batch: 200, loss: 0.3336414039869941\n",
      "Epoch: 76, Batch: 300, loss: 0.36617410703520625\n",
      "Epoch: 76, Batch: 400, loss: 0.3795662793684856\n",
      "Epoch: 76, Batch: 500, loss: 0.37596172392263116\n",
      "Epoch: 77, Batch: 0, loss: 0.2738633706103201\n",
      "Epoch: 77, Batch: 100, loss: 0.39150468614017847\n",
      "Epoch: 77, Batch: 200, loss: 0.3694688599909346\n",
      "Epoch: 77, Batch: 300, loss: 0.35795593745239246\n",
      "Epoch: 77, Batch: 400, loss: 0.35891050278563114\n",
      "Epoch: 77, Batch: 500, loss: 0.35270801100284543\n",
      "Epoch: 78, Batch: 0, loss: 0.04789090722049878\n",
      "Epoch: 78, Batch: 100, loss: 0.39123980813739706\n",
      "Epoch: 78, Batch: 200, loss: 0.33056253375900485\n",
      "Epoch: 78, Batch: 300, loss: 0.3705480407176402\n",
      "Epoch: 78, Batch: 400, loss: 0.38082132573101135\n",
      "Epoch: 78, Batch: 500, loss: 0.367996741570961\n",
      "Epoch: 79, Batch: 0, loss: 0.5443427688959969\n",
      "Epoch: 79, Batch: 100, loss: 0.3849904906596412\n",
      "Epoch: 79, Batch: 200, loss: 0.3342779627228057\n",
      "Epoch: 79, Batch: 300, loss: 0.36712494149696\n",
      "Epoch: 79, Batch: 400, loss: 0.37601087111166465\n",
      "Epoch: 79, Batch: 500, loss: 0.37021991672796145\n",
      "Epoch: 80, Batch: 0, loss: 0.18805116668381128\n",
      "Epoch: 80, Batch: 100, loss: 0.42325833877604035\n",
      "Epoch: 80, Batch: 200, loss: 0.37448275585286095\n",
      "Epoch: 80, Batch: 300, loss: 0.3666224353714851\n",
      "Epoch: 80, Batch: 400, loss: 0.36073352159304745\n",
      "Epoch: 80, Batch: 500, loss: 0.36444899174294587\n",
      "Epoch: 81, Batch: 0, loss: 0.9628619761914926\n",
      "Epoch: 81, Batch: 100, loss: 0.40929426931470264\n",
      "Epoch: 81, Batch: 200, loss: 0.37243959305093777\n",
      "Epoch: 81, Batch: 300, loss: 0.36582585080130015\n",
      "Epoch: 81, Batch: 400, loss: 0.345228087294018\n",
      "Epoch: 81, Batch: 500, loss: 0.33970230912824595\n",
      "Epoch: 82, Batch: 0, loss: 0.8898108840045703\n",
      "Epoch: 82, Batch: 100, loss: 0.4751553233827103\n",
      "Epoch: 82, Batch: 200, loss: 0.4098301009035262\n",
      "Epoch: 82, Batch: 300, loss: 0.3807276074257609\n",
      "Epoch: 82, Batch: 400, loss: 0.3842058805951037\n",
      "Epoch: 82, Batch: 500, loss: 0.3728957619044845\n",
      "Epoch: 83, Batch: 0, loss: 0.4300286363340826\n",
      "Epoch: 83, Batch: 100, loss: 0.35393314847445245\n",
      "Epoch: 83, Batch: 200, loss: 0.3635681251052545\n",
      "Epoch: 83, Batch: 300, loss: 0.3464272152804923\n",
      "Epoch: 83, Batch: 400, loss: 0.36050034162168676\n",
      "Epoch: 83, Batch: 500, loss: 0.36602300287365447\n",
      "Epoch: 84, Batch: 0, loss: 0.09923105131789832\n",
      "Epoch: 84, Batch: 100, loss: 0.32634758822138976\n",
      "Epoch: 84, Batch: 200, loss: 0.35136109706956437\n",
      "Epoch: 84, Batch: 300, loss: 0.37810663187428223\n",
      "Epoch: 84, Batch: 400, loss: 0.3747951883879494\n",
      "Epoch: 84, Batch: 500, loss: 0.38403905914229824\n",
      "Epoch: 85, Batch: 0, loss: 0.8815727918166542\n",
      "Epoch: 85, Batch: 100, loss: 0.3797561986156313\n",
      "Epoch: 85, Batch: 200, loss: 0.34161192852367317\n",
      "Epoch: 85, Batch: 300, loss: 0.34277675532643304\n",
      "Epoch: 85, Batch: 400, loss: 0.34969701067446113\n",
      "Epoch: 85, Batch: 500, loss: 0.3511847172256963\n",
      "Epoch: 86, Batch: 0, loss: 0.3083272986749524\n",
      "Epoch: 86, Batch: 100, loss: 0.33806119929674694\n",
      "Epoch: 86, Batch: 200, loss: 0.3317321730897529\n",
      "Epoch: 86, Batch: 300, loss: 0.3623113887294182\n",
      "Epoch: 86, Batch: 400, loss: 0.36494041809017025\n",
      "Epoch: 86, Batch: 500, loss: 0.3592629921507592\n",
      "Epoch: 87, Batch: 0, loss: 0.16542995572412675\n",
      "Epoch: 87, Batch: 100, loss: 0.31570786412758295\n",
      "Epoch: 87, Batch: 200, loss: 0.3234829530177504\n",
      "Epoch: 87, Batch: 300, loss: 0.337285809126347\n",
      "Epoch: 87, Batch: 400, loss: 0.35775611932062296\n",
      "Epoch: 87, Batch: 500, loss: 0.3494983420959012\n",
      "Epoch: 88, Batch: 0, loss: 0.047617728895580046\n",
      "Epoch: 88, Batch: 100, loss: 0.32604533762553156\n",
      "Epoch: 88, Batch: 200, loss: 0.35510676481354647\n",
      "Epoch: 88, Batch: 300, loss: 0.3399192325051455\n",
      "Epoch: 88, Batch: 400, loss: 0.3460157332356194\n",
      "Epoch: 88, Batch: 500, loss: 0.34872880320063054\n",
      "Epoch: 89, Batch: 0, loss: 0.02236344435783708\n",
      "Epoch: 89, Batch: 100, loss: 0.40203028041289096\n",
      "Epoch: 89, Batch: 200, loss: 0.3606572300073003\n",
      "Epoch: 89, Batch: 300, loss: 0.3460577582141527\n",
      "Epoch: 89, Batch: 400, loss: 0.34096771671626425\n",
      "Epoch: 89, Batch: 500, loss: 0.3398558130217474\n",
      "Epoch: 90, Batch: 0, loss: 1.6518402308848634\n",
      "Epoch: 90, Batch: 100, loss: 0.3392493174538213\n",
      "Epoch: 90, Batch: 200, loss: 0.3512513342117654\n",
      "Epoch: 90, Batch: 300, loss: 0.3468361371192971\n",
      "Epoch: 90, Batch: 400, loss: 0.35533209938377947\n",
      "Epoch: 90, Batch: 500, loss: 0.3466534541288516\n",
      "Epoch: 91, Batch: 0, loss: 0.23341637447411306\n",
      "Epoch: 91, Batch: 100, loss: 0.4554085609668746\n",
      "Epoch: 91, Batch: 200, loss: 0.38367437503298196\n",
      "Epoch: 91, Batch: 300, loss: 0.3594495276284472\n",
      "Epoch: 91, Batch: 400, loss: 0.3491225362686715\n",
      "Epoch: 91, Batch: 500, loss: 0.35794252383177405\n",
      "Epoch: 92, Batch: 0, loss: 0.06489497159817965\n",
      "Epoch: 92, Batch: 100, loss: 0.3201195152259629\n",
      "Epoch: 92, Batch: 200, loss: 0.34416875729866886\n",
      "Epoch: 92, Batch: 300, loss: 0.34429204677664255\n",
      "Epoch: 92, Batch: 400, loss: 0.36495334643547056\n",
      "Epoch: 92, Batch: 500, loss: 0.3664458730086908\n",
      "Epoch: 93, Batch: 0, loss: 0.5131414512248742\n",
      "Epoch: 93, Batch: 100, loss: 0.4210041445562106\n",
      "Epoch: 93, Batch: 200, loss: 0.40010846628521257\n",
      "Epoch: 93, Batch: 300, loss: 0.4131483092322527\n",
      "Epoch: 93, Batch: 400, loss: 0.4085038112894051\n",
      "Epoch: 93, Batch: 500, loss: 0.3994831352264347\n",
      "Epoch: 94, Batch: 0, loss: 0.5268633996344968\n",
      "Epoch: 94, Batch: 100, loss: 0.2920885677599094\n",
      "Epoch: 94, Batch: 200, loss: 0.30800949151759666\n",
      "Epoch: 94, Batch: 300, loss: 0.3255002282745069\n",
      "Epoch: 94, Batch: 400, loss: 0.33990683174069153\n",
      "Epoch: 94, Batch: 500, loss: 0.3497771077457597\n",
      "Epoch: 95, Batch: 0, loss: 0.137768111101441\n",
      "Epoch: 95, Batch: 100, loss: 0.35509756105721013\n",
      "Epoch: 95, Batch: 200, loss: 0.3757046606475691\n",
      "Epoch: 95, Batch: 300, loss: 0.3951139425069646\n",
      "Epoch: 95, Batch: 400, loss: 0.36729260900696353\n",
      "Epoch: 95, Batch: 500, loss: 0.3558769175463025\n",
      "Epoch: 96, Batch: 0, loss: 0.23919085135694995\n",
      "Epoch: 96, Batch: 100, loss: 0.3745116001030365\n",
      "Epoch: 96, Batch: 200, loss: 0.36264327055299783\n",
      "Epoch: 96, Batch: 300, loss: 0.37661561321031406\n",
      "Epoch: 96, Batch: 400, loss: 0.3825003888740089\n",
      "Epoch: 96, Batch: 500, loss: 0.39849828081163824\n",
      "Epoch: 97, Batch: 0, loss: 0.3409064828613538\n",
      "Epoch: 97, Batch: 100, loss: 0.3092400534160085\n",
      "Epoch: 97, Batch: 200, loss: 0.2992706262573731\n",
      "Epoch: 97, Batch: 300, loss: 0.3316997192753966\n",
      "Epoch: 97, Batch: 400, loss: 0.34236665481604117\n",
      "Epoch: 97, Batch: 500, loss: 0.3400739666915302\n",
      "Epoch: 98, Batch: 0, loss: 1.6986735300016769\n",
      "Epoch: 98, Batch: 100, loss: 0.37015430967743507\n",
      "Epoch: 98, Batch: 200, loss: 0.3475333062474605\n",
      "Epoch: 98, Batch: 300, loss: 0.35097797004265185\n",
      "Epoch: 98, Batch: 400, loss: 0.34571525986343443\n",
      "Epoch: 98, Batch: 500, loss: 0.340448610441537\n",
      "Epoch: 99, Batch: 0, loss: 0.06590614250822732\n",
      "Epoch: 99, Batch: 100, loss: 0.41107029830640274\n",
      "Epoch: 99, Batch: 200, loss: 0.36987776040529946\n",
      "Epoch: 99, Batch: 300, loss: 0.3778009901461423\n",
      "Epoch: 99, Batch: 400, loss: 0.37274391637756454\n",
      "Epoch: 99, Batch: 500, loss: 0.3728174848448816\n",
      "Epoch: 100, Batch: 0, loss: 0.13823374871948932\n",
      "Epoch: 100, Batch: 100, loss: 0.3250692159229471\n",
      "Epoch: 100, Batch: 200, loss: 0.30406359018817597\n",
      "Epoch: 100, Batch: 300, loss: 0.3073313363299955\n",
      "Epoch: 100, Batch: 400, loss: 0.320402608623231\n",
      "Epoch: 100, Batch: 500, loss: 0.34035683162874414\n",
      "Epoch: 101, Batch: 0, loss: 0.2815939732121173\n",
      "Epoch: 101, Batch: 100, loss: 0.3617982376044725\n",
      "Epoch: 101, Batch: 200, loss: 0.38482027825349835\n",
      "Epoch: 101, Batch: 300, loss: 0.3726067961316711\n",
      "Epoch: 101, Batch: 400, loss: 0.37473070408490805\n",
      "Epoch: 101, Batch: 500, loss: 0.37250358393413774\n",
      "Epoch: 102, Batch: 0, loss: 0.08487129010426311\n",
      "Epoch: 102, Batch: 100, loss: 0.34483759256299373\n",
      "Epoch: 102, Batch: 200, loss: 0.3281280739718952\n",
      "Epoch: 102, Batch: 300, loss: 0.3697055439090266\n",
      "Epoch: 102, Batch: 400, loss: 0.3757601006235774\n",
      "Epoch: 102, Batch: 500, loss: 0.389317246731845\n",
      "Epoch: 103, Batch: 0, loss: 0.2916870627192509\n",
      "Epoch: 103, Batch: 100, loss: 0.3710077123240164\n",
      "Epoch: 103, Batch: 200, loss: 0.40440436150063264\n",
      "Epoch: 103, Batch: 300, loss: 0.37734904766143185\n",
      "Epoch: 103, Batch: 400, loss: 0.3779387528441801\n",
      "Epoch: 103, Batch: 500, loss: 0.39112427500122604\n",
      "Epoch: 104, Batch: 0, loss: 0.3960631531702792\n",
      "Epoch: 104, Batch: 100, loss: 0.35083362771697685\n",
      "Epoch: 104, Batch: 200, loss: 0.3548060844520525\n",
      "Epoch: 104, Batch: 300, loss: 0.35120687589914934\n",
      "Epoch: 104, Batch: 400, loss: 0.3443240810310702\n",
      "Epoch: 104, Batch: 500, loss: 0.3654474280651013\n",
      "Epoch: 105, Batch: 0, loss: 0.32464243689470496\n",
      "Epoch: 105, Batch: 100, loss: 0.28988650475995786\n",
      "Epoch: 105, Batch: 200, loss: 0.2923171567358507\n",
      "Epoch: 105, Batch: 300, loss: 0.3344070011177796\n",
      "Epoch: 105, Batch: 400, loss: 0.32887621717054133\n",
      "Epoch: 105, Batch: 500, loss: 0.3434798464940156\n",
      "Epoch: 106, Batch: 0, loss: 0.9535059061957916\n",
      "Epoch: 106, Batch: 100, loss: 0.356446115386627\n",
      "Epoch: 106, Batch: 200, loss: 0.33168286117304274\n",
      "Epoch: 106, Batch: 300, loss: 0.33121964853838\n",
      "Epoch: 106, Batch: 400, loss: 0.32659444234856233\n",
      "Epoch: 106, Batch: 500, loss: 0.3362951255347055\n",
      "Epoch: 107, Batch: 0, loss: 0.1489933909011002\n",
      "Epoch: 107, Batch: 100, loss: 0.28909317980723176\n",
      "Epoch: 107, Batch: 200, loss: 0.3321226085003918\n",
      "Epoch: 107, Batch: 300, loss: 0.33557638180500504\n",
      "Epoch: 107, Batch: 400, loss: 0.3249282317028858\n",
      "Epoch: 107, Batch: 500, loss: 0.3315853143350789\n",
      "Epoch: 108, Batch: 0, loss: 0.043560651343528066\n",
      "Epoch: 108, Batch: 100, loss: 0.4069525891477458\n",
      "Epoch: 108, Batch: 200, loss: 0.3817930318000872\n",
      "Epoch: 108, Batch: 300, loss: 0.3723060568076949\n",
      "Epoch: 108, Batch: 400, loss: 0.393105424351665\n",
      "Epoch: 108, Batch: 500, loss: 0.3780361929003635\n",
      "Epoch: 109, Batch: 0, loss: 0.1980635974945959\n",
      "Epoch: 109, Batch: 100, loss: 0.3655409939372058\n",
      "Epoch: 109, Batch: 200, loss: 0.37903422588708957\n",
      "Epoch: 109, Batch: 300, loss: 0.37627179434921043\n",
      "Epoch: 109, Batch: 400, loss: 0.3592344946909526\n",
      "Epoch: 109, Batch: 500, loss: 0.3546263052076247\n",
      "Epoch: 110, Batch: 0, loss: 0.11470482792775893\n",
      "Epoch: 110, Batch: 100, loss: 0.44344512114896795\n",
      "Epoch: 110, Batch: 200, loss: 0.40155318032372905\n",
      "Epoch: 110, Batch: 300, loss: 0.3863600832984452\n",
      "Epoch: 110, Batch: 400, loss: 0.3810224215604567\n",
      "Epoch: 110, Batch: 500, loss: 0.38444119457290965\n",
      "Epoch: 111, Batch: 0, loss: 0.1947032904432213\n",
      "Epoch: 111, Batch: 100, loss: 0.2888909465741642\n",
      "Epoch: 111, Batch: 200, loss: 0.3315933078303575\n",
      "Epoch: 111, Batch: 300, loss: 0.3501034556146282\n",
      "Epoch: 111, Batch: 400, loss: 0.34288084677339153\n",
      "Epoch: 111, Batch: 500, loss: 0.3442538331244102\n",
      "Epoch: 112, Batch: 0, loss: 0.0006569187524150766\n",
      "Epoch: 112, Batch: 100, loss: 0.3849068482399598\n",
      "Epoch: 112, Batch: 200, loss: 0.3474627552011184\n",
      "Epoch: 112, Batch: 300, loss: 0.36194196098027953\n",
      "Epoch: 112, Batch: 400, loss: 0.35485863278094926\n",
      "Epoch: 112, Batch: 500, loss: 0.36010772169343963\n",
      "Epoch: 113, Batch: 0, loss: 0.915438577556795\n",
      "Epoch: 113, Batch: 100, loss: 0.34174330105951\n",
      "Epoch: 113, Batch: 200, loss: 0.3507668463061463\n",
      "Epoch: 113, Batch: 300, loss: 0.34225735396785983\n",
      "Epoch: 113, Batch: 400, loss: 0.34635139286765065\n",
      "Epoch: 113, Batch: 500, loss: 0.3417926968714147\n",
      "Epoch: 114, Batch: 0, loss: 1.0089799944091253\n",
      "Epoch: 114, Batch: 100, loss: 0.33232787072400904\n",
      "Epoch: 114, Batch: 200, loss: 0.34597088728977643\n",
      "Epoch: 114, Batch: 300, loss: 0.38825858330778173\n",
      "Epoch: 114, Batch: 400, loss: 0.3767708362163557\n",
      "Epoch: 114, Batch: 500, loss: 0.3644520041698285\n",
      "Epoch: 115, Batch: 0, loss: 0.5444764190803802\n",
      "Epoch: 115, Batch: 100, loss: 0.3648444929955378\n",
      "Epoch: 115, Batch: 200, loss: 0.353621641412528\n",
      "Epoch: 115, Batch: 300, loss: 0.3599871933958825\n",
      "Epoch: 115, Batch: 400, loss: 0.35079590485703854\n",
      "Epoch: 115, Batch: 500, loss: 0.3563988291955745\n",
      "Epoch: 116, Batch: 0, loss: 0.45759047969446875\n",
      "Epoch: 116, Batch: 100, loss: 0.38581975392553497\n",
      "Epoch: 116, Batch: 200, loss: 0.3785556923785121\n",
      "Epoch: 116, Batch: 300, loss: 0.36497308888884933\n",
      "Epoch: 116, Batch: 400, loss: 0.36926232000211395\n",
      "Epoch: 116, Batch: 500, loss: 0.3563966610658721\n",
      "Epoch: 117, Batch: 0, loss: 0.048381129903556884\n",
      "Epoch: 117, Batch: 100, loss: 0.35054707684184133\n",
      "Epoch: 117, Batch: 200, loss: 0.3556664279465031\n",
      "Epoch: 117, Batch: 300, loss: 0.389191001318035\n",
      "Epoch: 117, Batch: 400, loss: 0.3892492332676255\n",
      "Epoch: 117, Batch: 500, loss: 0.38465617664475577\n",
      "Epoch: 118, Batch: 0, loss: 0.6341962622373659\n",
      "Epoch: 118, Batch: 100, loss: 0.3892581371641175\n",
      "Epoch: 118, Batch: 200, loss: 0.3869013788011832\n",
      "Epoch: 118, Batch: 300, loss: 0.37043415451065437\n",
      "Epoch: 118, Batch: 400, loss: 0.35898153753261725\n",
      "Epoch: 118, Batch: 500, loss: 0.36755642142459694\n",
      "Epoch: 119, Batch: 0, loss: 0.3255359639201257\n",
      "Epoch: 119, Batch: 100, loss: 0.4845164305015207\n",
      "Epoch: 119, Batch: 200, loss: 0.39593893882999354\n",
      "Epoch: 119, Batch: 300, loss: 0.37390777554051796\n",
      "Epoch: 119, Batch: 400, loss: 0.36579926021566367\n",
      "Epoch: 119, Batch: 500, loss: 0.36453575325339194\n",
      "Epoch: 120, Batch: 0, loss: 0.005840476829192959\n",
      "Epoch: 120, Batch: 100, loss: 0.3909408947728782\n",
      "Epoch: 120, Batch: 200, loss: 0.37896176319728425\n",
      "Epoch: 120, Batch: 300, loss: 0.3649970402310088\n",
      "Epoch: 120, Batch: 400, loss: 0.3639885914211766\n",
      "Epoch: 120, Batch: 500, loss: 0.3707344455067753\n",
      "Epoch: 121, Batch: 0, loss: 0.03692358418353774\n",
      "Epoch: 121, Batch: 100, loss: 0.3872238689114066\n",
      "Epoch: 121, Batch: 200, loss: 0.37476113621584795\n",
      "Epoch: 121, Batch: 300, loss: 0.3635637083732848\n",
      "Epoch: 121, Batch: 400, loss: 0.3592312693179785\n",
      "Epoch: 121, Batch: 500, loss: 0.3509325234180293\n",
      "Epoch: 122, Batch: 0, loss: 0.48506360186327613\n",
      "Epoch: 122, Batch: 100, loss: 0.33107838703597253\n",
      "Epoch: 122, Batch: 200, loss: 0.36585201939817397\n",
      "Epoch: 122, Batch: 300, loss: 0.33221407893919375\n",
      "Epoch: 122, Batch: 400, loss: 0.34074302695810615\n",
      "Epoch: 122, Batch: 500, loss: 0.33348461430661697\n",
      "Epoch: 123, Batch: 0, loss: 0.9937938007626832\n",
      "Epoch: 123, Batch: 100, loss: 0.33131806208916925\n",
      "Epoch: 123, Batch: 200, loss: 0.32420159802737647\n",
      "Epoch: 123, Batch: 300, loss: 0.33876600501514653\n",
      "Epoch: 123, Batch: 400, loss: 0.33841267349073684\n",
      "Epoch: 123, Batch: 500, loss: 0.350983016325222\n",
      "Epoch: 124, Batch: 0, loss: 0.37009636384698974\n",
      "Epoch: 124, Batch: 100, loss: 0.38214847153267484\n",
      "Epoch: 124, Batch: 200, loss: 0.3925551595950231\n",
      "Epoch: 124, Batch: 300, loss: 0.3429132203264778\n",
      "Epoch: 124, Batch: 400, loss: 0.3241580083629738\n",
      "Epoch: 124, Batch: 500, loss: 0.3300495004836694\n",
      "Epoch: 125, Batch: 0, loss: 0.3889005850481957\n",
      "Epoch: 125, Batch: 100, loss: 0.3019455034617914\n",
      "Epoch: 125, Batch: 200, loss: 0.3252356272070027\n",
      "Epoch: 125, Batch: 300, loss: 0.32638509692365664\n",
      "Epoch: 125, Batch: 400, loss: 0.3299614963327657\n",
      "Epoch: 125, Batch: 500, loss: 0.3300785553454712\n",
      "Epoch: 126, Batch: 0, loss: 0.8267400186019845\n",
      "Epoch: 126, Batch: 100, loss: 0.3239605365874022\n",
      "Epoch: 126, Batch: 200, loss: 0.3294257531880726\n",
      "Epoch: 126, Batch: 300, loss: 0.3210299030341574\n",
      "Epoch: 126, Batch: 400, loss: 0.32203012464921466\n",
      "Epoch: 126, Batch: 500, loss: 0.3267378361993762\n",
      "Epoch: 127, Batch: 0, loss: 0.016782804029295478\n",
      "Epoch: 127, Batch: 100, loss: 0.37392006479574386\n",
      "Epoch: 127, Batch: 200, loss: 0.32242830769346636\n",
      "Epoch: 127, Batch: 300, loss: 0.32585969176401375\n",
      "Epoch: 127, Batch: 400, loss: 0.3345671183565081\n",
      "Epoch: 127, Batch: 500, loss: 0.3251645024151408\n",
      "Epoch: 128, Batch: 0, loss: 0.012743319462716337\n",
      "Epoch: 128, Batch: 100, loss: 0.3331879707057929\n",
      "Epoch: 128, Batch: 200, loss: 0.3322786012119024\n",
      "Epoch: 128, Batch: 300, loss: 0.36210013608670144\n",
      "Epoch: 128, Batch: 400, loss: 0.368226001254395\n",
      "Epoch: 128, Batch: 500, loss: 0.36583271506149767\n",
      "Epoch: 129, Batch: 0, loss: 0.38155338310977555\n",
      "Epoch: 129, Batch: 100, loss: 0.3424116304061112\n",
      "Epoch: 129, Batch: 200, loss: 0.35094778771145446\n",
      "Epoch: 129, Batch: 300, loss: 0.3456704514583809\n",
      "Epoch: 129, Batch: 400, loss: 0.3340299560151654\n",
      "Epoch: 129, Batch: 500, loss: 0.335735330997331\n",
      "Epoch: 130, Batch: 0, loss: 0.045476010779321244\n",
      "Epoch: 130, Batch: 100, loss: 0.33475098183490976\n",
      "Epoch: 130, Batch: 200, loss: 0.3146766251937772\n",
      "Epoch: 130, Batch: 300, loss: 0.3199472138566239\n",
      "Epoch: 130, Batch: 400, loss: 0.34716017419483347\n",
      "Epoch: 130, Batch: 500, loss: 0.34492285863896444\n",
      "Epoch: 131, Batch: 0, loss: 0.7827948726227368\n",
      "Epoch: 131, Batch: 100, loss: 0.43232724505004105\n",
      "Epoch: 131, Batch: 200, loss: 0.39354933167524464\n",
      "Epoch: 131, Batch: 300, loss: 0.3809811452243549\n",
      "Epoch: 131, Batch: 400, loss: 0.3638880087257562\n",
      "Epoch: 131, Batch: 500, loss: 0.34804962970475284\n",
      "Epoch: 132, Batch: 0, loss: 0.0005642685511151774\n",
      "Epoch: 132, Batch: 100, loss: 0.31365597519124017\n",
      "Epoch: 132, Batch: 200, loss: 0.29977997277049456\n",
      "Epoch: 132, Batch: 300, loss: 0.3282471811552037\n",
      "Epoch: 132, Batch: 400, loss: 0.3340023375742299\n",
      "Epoch: 132, Batch: 500, loss: 0.3234766371046501\n",
      "Epoch: 133, Batch: 0, loss: 0.9799265076021653\n",
      "Epoch: 133, Batch: 100, loss: 0.32749613988547066\n",
      "Epoch: 133, Batch: 200, loss: 0.3495887767887392\n",
      "Epoch: 133, Batch: 300, loss: 0.34055410544261194\n",
      "Epoch: 133, Batch: 400, loss: 0.37508805129266165\n",
      "Epoch: 133, Batch: 500, loss: 0.37077824452875896\n",
      "Epoch: 134, Batch: 0, loss: 0.6940838430275936\n",
      "Epoch: 134, Batch: 100, loss: 0.3520950781409858\n",
      "Epoch: 134, Batch: 200, loss: 0.33669206049232636\n",
      "Epoch: 134, Batch: 300, loss: 0.34496245100119494\n",
      "Epoch: 134, Batch: 400, loss: 0.3371239329677349\n",
      "Epoch: 134, Batch: 500, loss: 0.33858882533836204\n",
      "Epoch: 135, Batch: 0, loss: 0.04412157333906439\n",
      "Epoch: 135, Batch: 100, loss: 0.28784789623647117\n",
      "Epoch: 135, Batch: 200, loss: 0.3044609249547829\n",
      "Epoch: 135, Batch: 300, loss: 0.3030647314041818\n",
      "Epoch: 135, Batch: 400, loss: 0.3295788866476187\n",
      "Epoch: 135, Batch: 500, loss: 0.33003889907634953\n",
      "Epoch: 136, Batch: 0, loss: 0.28459825715421644\n",
      "Epoch: 136, Batch: 100, loss: 0.4064298197264799\n",
      "Epoch: 136, Batch: 200, loss: 0.36400783335951165\n",
      "Epoch: 136, Batch: 300, loss: 0.35501532736595837\n",
      "Epoch: 136, Batch: 400, loss: 0.36084697509752595\n",
      "Epoch: 136, Batch: 500, loss: 0.35999995777808275\n",
      "Epoch: 137, Batch: 0, loss: 0.1834119458335954\n",
      "Epoch: 137, Batch: 100, loss: 0.35841597550807386\n",
      "Epoch: 137, Batch: 200, loss: 0.37615398875207334\n",
      "Epoch: 137, Batch: 300, loss: 0.3739173271587621\n",
      "Epoch: 137, Batch: 400, loss: 0.37597876646842665\n",
      "Epoch: 137, Batch: 500, loss: 0.37143576992341976\n",
      "Epoch: 138, Batch: 0, loss: 0.10052783040213076\n",
      "Epoch: 138, Batch: 100, loss: 0.37670135415447964\n",
      "Epoch: 138, Batch: 200, loss: 0.3412065055611652\n",
      "Epoch: 138, Batch: 300, loss: 0.3381679777008196\n",
      "Epoch: 138, Batch: 400, loss: 0.33030503105482156\n",
      "Epoch: 138, Batch: 500, loss: 0.3328127546726583\n",
      "Epoch: 139, Batch: 0, loss: 1.0129494083508164\n",
      "Epoch: 139, Batch: 100, loss: 0.31887443865216336\n",
      "Epoch: 139, Batch: 200, loss: 0.34960520293561165\n",
      "Epoch: 139, Batch: 300, loss: 0.37271164196522494\n",
      "Epoch: 139, Batch: 400, loss: 0.35881369836732296\n",
      "Epoch: 139, Batch: 500, loss: 0.3343931347498187\n",
      "Epoch: 140, Batch: 0, loss: 0.3582906954405706\n",
      "Epoch: 140, Batch: 100, loss: 0.3899339488699109\n",
      "Epoch: 140, Batch: 200, loss: 0.4132564665236722\n",
      "Epoch: 140, Batch: 300, loss: 0.39245761708995675\n",
      "Epoch: 140, Batch: 400, loss: 0.3844855257398942\n",
      "Epoch: 140, Batch: 500, loss: 0.37362650911843454\n",
      "Epoch: 141, Batch: 0, loss: 0.4410970485786136\n",
      "Epoch: 141, Batch: 100, loss: 0.36748340390576195\n",
      "Epoch: 141, Batch: 200, loss: 0.39437936005312646\n",
      "Epoch: 141, Batch: 300, loss: 0.3761154209281692\n",
      "Epoch: 141, Batch: 400, loss: 0.351214931458849\n",
      "Epoch: 141, Batch: 500, loss: 0.34906645950805737\n",
      "Epoch: 142, Batch: 0, loss: 1.0368015342656927\n",
      "Epoch: 142, Batch: 100, loss: 0.3440870432007619\n",
      "Epoch: 142, Batch: 200, loss: 0.3419283631147618\n",
      "Epoch: 142, Batch: 300, loss: 0.34682332777363284\n",
      "Epoch: 142, Batch: 400, loss: 0.34760978051745045\n",
      "Epoch: 142, Batch: 500, loss: 0.3528565693884406\n",
      "Epoch: 143, Batch: 0, loss: 0.4141188881813337\n",
      "Epoch: 143, Batch: 100, loss: 0.28004820196909436\n",
      "Epoch: 143, Batch: 200, loss: 0.2591770310083441\n",
      "Epoch: 143, Batch: 300, loss: 0.2985641402724063\n",
      "Epoch: 143, Batch: 400, loss: 0.3138530059112131\n",
      "Epoch: 143, Batch: 500, loss: 0.31544881371439\n",
      "Epoch: 144, Batch: 0, loss: 0.28649496456457485\n",
      "Epoch: 144, Batch: 100, loss: 0.38489240427488675\n",
      "Epoch: 144, Batch: 200, loss: 0.36962673554461656\n",
      "Epoch: 144, Batch: 300, loss: 0.34964831902105353\n",
      "Epoch: 144, Batch: 400, loss: 0.3441999456095031\n",
      "Epoch: 144, Batch: 500, loss: 0.33788316347666353\n",
      "Epoch: 145, Batch: 0, loss: 0.5707608774412941\n",
      "Epoch: 145, Batch: 100, loss: 0.3200901672711015\n",
      "Epoch: 145, Batch: 200, loss: 0.3412808787562521\n",
      "Epoch: 145, Batch: 300, loss: 0.34021572272692124\n",
      "Epoch: 145, Batch: 400, loss: 0.33158805446545836\n",
      "Epoch: 145, Batch: 500, loss: 0.34675771670466654\n",
      "Epoch: 146, Batch: 0, loss: 0.3852462583658891\n",
      "Epoch: 146, Batch: 100, loss: 0.3022084384722422\n",
      "Epoch: 146, Batch: 200, loss: 0.2939481884326577\n",
      "Epoch: 146, Batch: 300, loss: 0.2976640201988294\n",
      "Epoch: 146, Batch: 400, loss: 0.3020240420953999\n",
      "Epoch: 146, Batch: 500, loss: 0.3097954392515188\n",
      "Epoch: 147, Batch: 0, loss: 0.902908048390786\n",
      "Epoch: 147, Batch: 100, loss: 0.3517986291421247\n",
      "Epoch: 147, Batch: 200, loss: 0.3277787217389544\n",
      "Epoch: 147, Batch: 300, loss: 0.3611558343813402\n",
      "Epoch: 147, Batch: 400, loss: 0.3525727953037555\n",
      "Epoch: 147, Batch: 500, loss: 0.37324210295074617\n",
      "Epoch: 148, Batch: 0, loss: 0.00027025197783412313\n",
      "Epoch: 148, Batch: 100, loss: 0.3491961760156725\n",
      "Epoch: 148, Batch: 200, loss: 0.34562019716733305\n",
      "Epoch: 148, Batch: 300, loss: 0.3421866313781988\n",
      "Epoch: 148, Batch: 400, loss: 0.34099642274197955\n",
      "Epoch: 148, Batch: 500, loss: 0.3436771959076176\n",
      "Epoch: 149, Batch: 0, loss: 0.4480095869936912\n",
      "Epoch: 149, Batch: 100, loss: 0.4417119745673356\n",
      "Epoch: 149, Batch: 200, loss: 0.33003926063009764\n",
      "Epoch: 149, Batch: 300, loss: 0.3429066983168374\n",
      "Epoch: 149, Batch: 400, loss: 0.3297999255292898\n",
      "Epoch: 149, Batch: 500, loss: 0.32050917036007165\n",
      "Epoch: 150, Batch: 0, loss: 0.262347696611872\n",
      "Epoch: 150, Batch: 100, loss: 0.384867549792949\n",
      "Epoch: 150, Batch: 200, loss: 0.3423099451834422\n",
      "Epoch: 150, Batch: 300, loss: 0.34897100192388514\n",
      "Epoch: 150, Batch: 400, loss: 0.35997752007407935\n",
      "Epoch: 150, Batch: 500, loss: 0.3659250252931405\n",
      "Epoch: 151, Batch: 0, loss: 0.023306228167996518\n",
      "Epoch: 151, Batch: 100, loss: 0.36717740376075697\n",
      "Epoch: 151, Batch: 200, loss: 0.32969722532278906\n",
      "Epoch: 151, Batch: 300, loss: 0.32629176601686777\n",
      "Epoch: 151, Batch: 400, loss: 0.3425718404834382\n",
      "Epoch: 151, Batch: 500, loss: 0.33494610406349645\n",
      "Epoch: 152, Batch: 0, loss: 0.04235589057673664\n",
      "Epoch: 152, Batch: 100, loss: 0.40220355351080084\n",
      "Epoch: 152, Batch: 200, loss: 0.4077091642496308\n",
      "Epoch: 152, Batch: 300, loss: 0.39937286900298485\n",
      "Epoch: 152, Batch: 400, loss: 0.39247227785671307\n",
      "Epoch: 152, Batch: 500, loss: 0.3777273197652445\n",
      "Epoch: 153, Batch: 0, loss: 1.6500059171437111\n",
      "Epoch: 153, Batch: 100, loss: 0.34972695380698\n",
      "Epoch: 153, Batch: 200, loss: 0.33137046255641067\n",
      "Epoch: 153, Batch: 300, loss: 0.38445024493182306\n",
      "Epoch: 153, Batch: 400, loss: 0.3625169784905088\n",
      "Epoch: 153, Batch: 500, loss: 0.374174694348694\n",
      "Epoch: 154, Batch: 0, loss: 0.2402618075456801\n",
      "Epoch: 154, Batch: 100, loss: 0.39961467383522953\n",
      "Epoch: 154, Batch: 200, loss: 0.33761135354530414\n",
      "Epoch: 154, Batch: 300, loss: 0.32031642365510943\n",
      "Epoch: 154, Batch: 400, loss: 0.33095099959355917\n",
      "Epoch: 154, Batch: 500, loss: 0.316565572949434\n",
      "Epoch: 155, Batch: 0, loss: 0.13324689218018335\n",
      "Epoch: 155, Batch: 100, loss: 0.38499085694060864\n",
      "Epoch: 155, Batch: 200, loss: 0.36074742865648035\n",
      "Epoch: 155, Batch: 300, loss: 0.35122004579171723\n",
      "Epoch: 155, Batch: 400, loss: 0.34733392791768647\n",
      "Epoch: 155, Batch: 500, loss: 0.33528665997422735\n",
      "Epoch: 156, Batch: 0, loss: 0.3679010365128372\n",
      "Epoch: 156, Batch: 100, loss: 0.36739004383590956\n",
      "Epoch: 156, Batch: 200, loss: 0.3188337716374719\n",
      "Epoch: 156, Batch: 300, loss: 0.3268900536844996\n",
      "Epoch: 156, Batch: 400, loss: 0.32776944288071774\n",
      "Epoch: 156, Batch: 500, loss: 0.3226801383779117\n",
      "Epoch: 157, Batch: 0, loss: 0.24426139987332543\n",
      "Epoch: 157, Batch: 100, loss: 0.32405302809762243\n",
      "Epoch: 157, Batch: 200, loss: 0.3981957953361949\n",
      "Epoch: 157, Batch: 300, loss: 0.3728866676085451\n",
      "Epoch: 157, Batch: 400, loss: 0.3634178651954795\n",
      "Epoch: 157, Batch: 500, loss: 0.35690112278377906\n",
      "Epoch: 158, Batch: 0, loss: 0.06747683961812737\n",
      "Epoch: 158, Batch: 100, loss: 0.4431443878590061\n",
      "Epoch: 158, Batch: 200, loss: 0.37000734942433494\n",
      "Epoch: 158, Batch: 300, loss: 0.35966441547702327\n",
      "Epoch: 158, Batch: 400, loss: 0.34301132971631676\n",
      "Epoch: 158, Batch: 500, loss: 0.33686748324129023\n",
      "Epoch: 159, Batch: 0, loss: 0.17057130301408907\n",
      "Epoch: 159, Batch: 100, loss: 0.3912084231621804\n",
      "Epoch: 159, Batch: 200, loss: 0.37225930257640055\n",
      "Epoch: 159, Batch: 300, loss: 0.3490318589625182\n",
      "Epoch: 159, Batch: 400, loss: 0.342254833557102\n",
      "Epoch: 159, Batch: 500, loss: 0.33167834451362926\n",
      "Epoch: 160, Batch: 0, loss: 0.12314642165781332\n",
      "Epoch: 160, Batch: 100, loss: 0.3682939910016043\n",
      "Epoch: 160, Batch: 200, loss: 0.34690344284203106\n",
      "Epoch: 160, Batch: 300, loss: 0.3742914644912232\n",
      "Epoch: 160, Batch: 400, loss: 0.3606032952804502\n",
      "Epoch: 160, Batch: 500, loss: 0.3618573487158982\n",
      "Epoch: 161, Batch: 0, loss: 0.04022739616783976\n",
      "Epoch: 161, Batch: 100, loss: 0.3830654022028171\n",
      "Epoch: 161, Batch: 200, loss: 0.3686272866704061\n",
      "Epoch: 161, Batch: 300, loss: 0.3833923868919495\n",
      "Epoch: 161, Batch: 400, loss: 0.3639950175658433\n",
      "Epoch: 161, Batch: 500, loss: 0.35773586867071694\n",
      "Epoch: 162, Batch: 0, loss: 0.3702442141547535\n",
      "Epoch: 162, Batch: 100, loss: 0.33745745835760066\n",
      "Epoch: 162, Batch: 200, loss: 0.31349582254417313\n",
      "Epoch: 162, Batch: 300, loss: 0.3287551094314463\n",
      "Epoch: 162, Batch: 400, loss: 0.33444781694001174\n",
      "Epoch: 162, Batch: 500, loss: 0.3369403259828178\n",
      "Epoch: 163, Batch: 0, loss: 0.09726057121227678\n",
      "Epoch: 163, Batch: 100, loss: 0.406039440450245\n",
      "Epoch: 163, Batch: 200, loss: 0.36636175013248234\n",
      "Epoch: 163, Batch: 300, loss: 0.3481762245108303\n",
      "Epoch: 163, Batch: 400, loss: 0.34109144304394695\n",
      "Epoch: 163, Batch: 500, loss: 0.33629250758886126\n",
      "Epoch: 164, Batch: 0, loss: 0.2739455773462604\n",
      "Epoch: 164, Batch: 100, loss: 0.3142972613908014\n",
      "Epoch: 164, Batch: 200, loss: 0.38021538416281286\n",
      "Epoch: 164, Batch: 300, loss: 0.36531480314580056\n",
      "Epoch: 164, Batch: 400, loss: 0.375158176723653\n",
      "Epoch: 164, Batch: 500, loss: 0.3672088067737364\n",
      "Epoch: 165, Batch: 0, loss: 0.3837710019329745\n",
      "Epoch: 165, Batch: 100, loss: 0.3746900863740828\n",
      "Epoch: 165, Batch: 200, loss: 0.35443580095327004\n",
      "Epoch: 165, Batch: 300, loss: 0.353296595229847\n",
      "Epoch: 165, Batch: 400, loss: 0.37739120061382486\n",
      "Epoch: 165, Batch: 500, loss: 0.3832549690840705\n",
      "Epoch: 166, Batch: 0, loss: 0.2483570230996296\n",
      "Epoch: 166, Batch: 100, loss: 0.31846143315181247\n",
      "Epoch: 166, Batch: 200, loss: 0.34750569079454857\n",
      "Epoch: 166, Batch: 300, loss: 0.34817091905490555\n",
      "Epoch: 166, Batch: 400, loss: 0.3520726836606468\n",
      "Epoch: 166, Batch: 500, loss: 0.3412303914251093\n",
      "Epoch: 167, Batch: 0, loss: 0.002210768705370444\n",
      "Epoch: 167, Batch: 100, loss: 0.35757351851389496\n",
      "Epoch: 167, Batch: 200, loss: 0.33934511730784767\n",
      "Epoch: 167, Batch: 300, loss: 0.32433905297965776\n",
      "Epoch: 167, Batch: 400, loss: 0.3171800843175273\n",
      "Epoch: 167, Batch: 500, loss: 0.32705860317682545\n",
      "Epoch: 168, Batch: 0, loss: 0.5165820402480038\n",
      "Epoch: 168, Batch: 100, loss: 0.2895364836267542\n",
      "Epoch: 168, Batch: 200, loss: 0.346936400715007\n",
      "Epoch: 168, Batch: 300, loss: 0.3339955086836833\n",
      "Epoch: 168, Batch: 400, loss: 0.3495122295702488\n",
      "Epoch: 168, Batch: 500, loss: 0.3593009538661086\n",
      "Epoch: 169, Batch: 0, loss: 0.13994051499048513\n",
      "Epoch: 169, Batch: 100, loss: 0.4047791867289258\n",
      "Epoch: 169, Batch: 200, loss: 0.3694740459804543\n",
      "Epoch: 169, Batch: 300, loss: 0.37272021106660014\n",
      "Epoch: 169, Batch: 400, loss: 0.36001509027293216\n",
      "Epoch: 169, Batch: 500, loss: 0.35061407241024023\n",
      "Epoch: 170, Batch: 0, loss: 0.21109568900117714\n",
      "Epoch: 170, Batch: 100, loss: 0.36775515005826004\n",
      "Epoch: 170, Batch: 200, loss: 0.33239341600689987\n",
      "Epoch: 170, Batch: 300, loss: 0.34667180701395905\n",
      "Epoch: 170, Batch: 400, loss: 0.3753106677227157\n",
      "Epoch: 170, Batch: 500, loss: 0.373494628662464\n",
      "Epoch: 171, Batch: 0, loss: 0.21571461644892348\n",
      "Epoch: 171, Batch: 100, loss: 0.361042198691726\n",
      "Epoch: 171, Batch: 200, loss: 0.3736649106366454\n",
      "Epoch: 171, Batch: 300, loss: 0.35948958273249776\n",
      "Epoch: 171, Batch: 400, loss: 0.3553893870927376\n",
      "Epoch: 171, Batch: 500, loss: 0.34697729943161176\n",
      "Epoch: 172, Batch: 0, loss: 0.11202406722902858\n",
      "Epoch: 172, Batch: 100, loss: 0.3622157158435909\n",
      "Epoch: 172, Batch: 200, loss: 0.34916321382502885\n",
      "Epoch: 172, Batch: 300, loss: 0.3532400666165737\n",
      "Epoch: 172, Batch: 400, loss: 0.3593625156752097\n",
      "Epoch: 172, Batch: 500, loss: 0.3435397813072951\n",
      "Epoch: 173, Batch: 0, loss: 0.09543967147932406\n",
      "Epoch: 173, Batch: 100, loss: 0.291704040365051\n",
      "Epoch: 173, Batch: 200, loss: 0.3133378809668271\n",
      "Epoch: 173, Batch: 300, loss: 0.38077997935560715\n",
      "Epoch: 173, Batch: 400, loss: 0.3629183968691967\n",
      "Epoch: 173, Batch: 500, loss: 0.3699604342954369\n",
      "Epoch: 174, Batch: 0, loss: 0.25549596083501724\n",
      "Epoch: 174, Batch: 100, loss: 0.27960416676682714\n",
      "Epoch: 174, Batch: 200, loss: 0.31052145148436533\n",
      "Epoch: 174, Batch: 300, loss: 0.31321827972006205\n",
      "Epoch: 174, Batch: 400, loss: 0.33535751555410975\n",
      "Epoch: 174, Batch: 500, loss: 0.3497336564398194\n",
      "Epoch: 175, Batch: 0, loss: 0.4510993942884949\n",
      "Epoch: 175, Batch: 100, loss: 0.2915910527992291\n",
      "Epoch: 175, Batch: 200, loss: 0.31008065552883085\n",
      "Epoch: 175, Batch: 300, loss: 0.31270466068523495\n",
      "Epoch: 175, Batch: 400, loss: 0.34582602362485776\n",
      "Epoch: 175, Batch: 500, loss: 0.35773910142730503\n",
      "Epoch: 176, Batch: 0, loss: 0.05668078949587625\n",
      "Epoch: 176, Batch: 100, loss: 0.28367107356584453\n",
      "Epoch: 176, Batch: 200, loss: 0.27033364165975043\n",
      "Epoch: 176, Batch: 300, loss: 0.3027067168500242\n",
      "Epoch: 176, Batch: 400, loss: 0.31894985611870336\n",
      "Epoch: 176, Batch: 500, loss: 0.30846416995919035\n",
      "Epoch: 177, Batch: 0, loss: 0.2735632042574739\n",
      "Epoch: 177, Batch: 100, loss: 0.3004900434660102\n",
      "Epoch: 177, Batch: 200, loss: 0.32800172509911674\n",
      "Epoch: 177, Batch: 300, loss: 0.3339900392756229\n",
      "Epoch: 177, Batch: 400, loss: 0.3620238860661921\n",
      "Epoch: 177, Batch: 500, loss: 0.34673436982031614\n",
      "Epoch: 178, Batch: 0, loss: 0.06855656921374301\n",
      "Epoch: 178, Batch: 100, loss: 0.30424365233628803\n",
      "Epoch: 178, Batch: 200, loss: 0.3486465895300939\n",
      "Epoch: 178, Batch: 300, loss: 0.35440732553754906\n",
      "Epoch: 178, Batch: 400, loss: 0.34125620407979895\n",
      "Epoch: 178, Batch: 500, loss: 0.3451633501756882\n",
      "Epoch: 179, Batch: 0, loss: 0.00038994522909671046\n",
      "Epoch: 179, Batch: 100, loss: 0.4022673262678256\n",
      "Epoch: 179, Batch: 200, loss: 0.376812906779626\n",
      "Epoch: 179, Batch: 300, loss: 0.37664363776366483\n",
      "Epoch: 179, Batch: 400, loss: 0.3640450456420359\n",
      "Epoch: 179, Batch: 500, loss: 0.35385869364160244\n",
      "Epoch: 180, Batch: 0, loss: 0.12685361973989656\n",
      "Epoch: 180, Batch: 100, loss: 0.303143710670832\n",
      "Epoch: 180, Batch: 200, loss: 0.27897191688256484\n",
      "Epoch: 180, Batch: 300, loss: 0.3012746070622678\n",
      "Epoch: 180, Batch: 400, loss: 0.30198974798966094\n",
      "Epoch: 180, Batch: 500, loss: 0.3165556723792496\n",
      "Epoch: 181, Batch: 0, loss: 0.00015596639035360732\n",
      "Epoch: 181, Batch: 100, loss: 0.3532177076176701\n",
      "Epoch: 181, Batch: 200, loss: 0.332292712095861\n",
      "Epoch: 181, Batch: 300, loss: 0.36278780739702327\n",
      "Epoch: 181, Batch: 400, loss: 0.3714758605534071\n",
      "Epoch: 181, Batch: 500, loss: 0.3565244296742196\n",
      "Epoch: 182, Batch: 0, loss: 0.45399229633203725\n",
      "Epoch: 182, Batch: 100, loss: 0.2656125715480132\n",
      "Epoch: 182, Batch: 200, loss: 0.28478462063118826\n",
      "Epoch: 182, Batch: 300, loss: 0.33300145551319704\n",
      "Epoch: 182, Batch: 400, loss: 0.3115074399615808\n",
      "Epoch: 182, Batch: 500, loss: 0.3102692849143172\n",
      "Epoch: 183, Batch: 0, loss: 0.12815523974938076\n",
      "Epoch: 183, Batch: 100, loss: 0.35894002659604185\n",
      "Epoch: 183, Batch: 200, loss: 0.3506363000138952\n",
      "Epoch: 183, Batch: 300, loss: 0.340756044415854\n",
      "Epoch: 183, Batch: 400, loss: 0.32607472451604075\n",
      "Epoch: 183, Batch: 500, loss: 0.3271922664225699\n",
      "Epoch: 184, Batch: 0, loss: 0.014211412515535937\n",
      "Epoch: 184, Batch: 100, loss: 0.3586582109232381\n",
      "Epoch: 184, Batch: 200, loss: 0.38632055435237034\n",
      "Epoch: 184, Batch: 300, loss: 0.37373808304947165\n",
      "Epoch: 184, Batch: 400, loss: 0.3531929379799708\n",
      "Epoch: 184, Batch: 500, loss: 0.355455290218245\n",
      "Epoch: 185, Batch: 0, loss: 0.6343499285799472\n",
      "Epoch: 185, Batch: 100, loss: 0.317981740346985\n",
      "Epoch: 185, Batch: 200, loss: 0.4136099089372889\n",
      "Epoch: 185, Batch: 300, loss: 0.3872092981784017\n",
      "Epoch: 185, Batch: 400, loss: 0.3773282346189678\n",
      "Epoch: 185, Batch: 500, loss: 0.4011381267493783\n",
      "Epoch: 186, Batch: 0, loss: 0.1537334035821551\n",
      "Epoch: 186, Batch: 100, loss: 0.34040667373354516\n",
      "Epoch: 186, Batch: 200, loss: 0.33116723142381843\n",
      "Epoch: 186, Batch: 300, loss: 0.32475982634846506\n",
      "Epoch: 186, Batch: 400, loss: 0.37470414997348467\n",
      "Epoch: 186, Batch: 500, loss: 0.3544116310752427\n",
      "Epoch: 187, Batch: 0, loss: 0.30088465135413756\n",
      "Epoch: 187, Batch: 100, loss: 0.33619492478306245\n",
      "Epoch: 187, Batch: 200, loss: 0.30756838432129063\n",
      "Epoch: 187, Batch: 300, loss: 0.3364666567814176\n",
      "Epoch: 187, Batch: 400, loss: 0.3451711128155618\n",
      "Epoch: 187, Batch: 500, loss: 0.3599663928707198\n",
      "Epoch: 188, Batch: 0, loss: 0.3652905179620396\n",
      "Epoch: 188, Batch: 100, loss: 0.3135729035712665\n",
      "Epoch: 188, Batch: 200, loss: 0.364408542747741\n",
      "Epoch: 188, Batch: 300, loss: 0.35668421429953057\n",
      "Epoch: 188, Batch: 400, loss: 0.3428147558107326\n",
      "Epoch: 188, Batch: 500, loss: 0.34607677511071894\n",
      "Epoch: 189, Batch: 0, loss: 3.397821071142762\n",
      "Epoch: 189, Batch: 100, loss: 0.31412546341624337\n",
      "Epoch: 189, Batch: 200, loss: 0.42110569455117497\n",
      "Epoch: 189, Batch: 300, loss: 0.4004421761069436\n",
      "Epoch: 189, Batch: 400, loss: 0.4039641473470258\n",
      "Epoch: 189, Batch: 500, loss: 0.4097620955635833\n",
      "Epoch: 190, Batch: 0, loss: 0.007022868324527684\n",
      "Epoch: 190, Batch: 100, loss: 0.3048714741899727\n",
      "Epoch: 190, Batch: 200, loss: 0.3210389222568686\n",
      "Epoch: 190, Batch: 300, loss: 0.3458489085032204\n",
      "Epoch: 190, Batch: 400, loss: 0.33269885334074717\n",
      "Epoch: 190, Batch: 500, loss: 0.34084534278278983\n",
      "Epoch: 191, Batch: 0, loss: 0.3767467541287988\n",
      "Epoch: 191, Batch: 100, loss: 0.2768416900849256\n",
      "Epoch: 191, Batch: 200, loss: 0.3276395857236261\n",
      "Epoch: 191, Batch: 300, loss: 0.32950488270505457\n",
      "Epoch: 191, Batch: 400, loss: 0.33136561522831287\n",
      "Epoch: 191, Batch: 500, loss: 0.3233922903333546\n",
      "Epoch: 192, Batch: 0, loss: 0.05491987669257723\n",
      "Epoch: 192, Batch: 100, loss: 0.3331504308849331\n",
      "Epoch: 192, Batch: 200, loss: 0.3294573953745472\n",
      "Epoch: 192, Batch: 300, loss: 0.33890956544977474\n",
      "Epoch: 192, Batch: 400, loss: 0.3258165378589342\n",
      "Epoch: 192, Batch: 500, loss: 0.32109402418194827\n",
      "Epoch: 193, Batch: 0, loss: 0.0027435762127709313\n",
      "Epoch: 193, Batch: 100, loss: 0.3316095990036245\n",
      "Epoch: 193, Batch: 200, loss: 0.3382794139722142\n",
      "Epoch: 193, Batch: 300, loss: 0.32222077299286817\n",
      "Epoch: 193, Batch: 400, loss: 0.33910755096796286\n",
      "Epoch: 193, Batch: 500, loss: 0.3383078941752493\n",
      "Epoch: 194, Batch: 0, loss: 0.20990392103809166\n",
      "Epoch: 194, Batch: 100, loss: 0.35647618199346504\n",
      "Epoch: 194, Batch: 200, loss: 0.3532635749443715\n",
      "Epoch: 194, Batch: 300, loss: 0.3363959027496885\n",
      "Epoch: 194, Batch: 400, loss: 0.33519039714440557\n",
      "Epoch: 194, Batch: 500, loss: 0.3713120429243987\n",
      "Epoch: 195, Batch: 0, loss: 0.4689895315457185\n",
      "Epoch: 195, Batch: 100, loss: 0.39051247553009616\n",
      "Epoch: 195, Batch: 200, loss: 0.39349104470282115\n",
      "Epoch: 195, Batch: 300, loss: 0.36221948500337986\n",
      "Epoch: 195, Batch: 400, loss: 0.37029828624705935\n",
      "Epoch: 195, Batch: 500, loss: 0.3707552734606088\n",
      "Epoch: 196, Batch: 0, loss: 0.00378847431051497\n",
      "Epoch: 196, Batch: 100, loss: 0.39561376988652114\n",
      "Epoch: 196, Batch: 200, loss: 0.37679737641420097\n",
      "Epoch: 196, Batch: 300, loss: 0.3683827481228577\n",
      "Epoch: 196, Batch: 400, loss: 0.3533680332341169\n",
      "Epoch: 196, Batch: 500, loss: 0.37173950339009393\n",
      "Epoch: 197, Batch: 0, loss: 0.0032733190803960147\n",
      "Epoch: 197, Batch: 100, loss: 0.33782710353809964\n",
      "Epoch: 197, Batch: 200, loss: 0.3235087197292492\n",
      "Epoch: 197, Batch: 300, loss: 0.324824643278912\n",
      "Epoch: 197, Batch: 400, loss: 0.3075589889754877\n",
      "Epoch: 197, Batch: 500, loss: 0.30808282274648224\n",
      "Epoch: 198, Batch: 0, loss: 1.7441778599084414\n",
      "Epoch: 198, Batch: 100, loss: 0.3811253011850946\n",
      "Epoch: 198, Batch: 200, loss: 0.3859946501466621\n",
      "Epoch: 198, Batch: 300, loss: 0.3604643545407777\n",
      "Epoch: 198, Batch: 400, loss: 0.3508670883706978\n",
      "Epoch: 198, Batch: 500, loss: 0.348287959105961\n",
      "Epoch: 199, Batch: 0, loss: 0.030530630659723244\n",
      "Epoch: 199, Batch: 100, loss: 0.270325035822589\n",
      "Epoch: 199, Batch: 200, loss: 0.3014006118714678\n",
      "Epoch: 199, Batch: 300, loss: 0.30491648705797303\n",
      "Epoch: 199, Batch: 400, loss: 0.312474789256759\n",
      "Epoch: 199, Batch: 500, loss: 0.31372698791846687\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "predicated = [model(np.array([x1, x2]), w, b) for x1, x2 in zip(rm, lst)]\n",
    "true = expensive"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def accuracy(y, yhat):\n",
    "    return sum(1 if i == j else 0 for i, j in zip(y, yhat)) / len(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(accuracy(true, predicated))\n",
    "\n",
    "# decision boundary"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\"\"\"\n",
    "Linear Regression: 实现了回归，其中包括线性函数的定义，为什么要用线性函数，loss的意义，梯度下降的意义，stochastic gradient descent\n",
    "Use Boston house price dataset.\n",
    "北京2020年房价的数据集，为什么我没有用北京房价的数据集呢？\n",
    "Boston: room size, subway, highway, crime rate 有一个比较明显的关系，所以就观察关系比较容易\n",
    "北京的房价：！远近，！房况 ==》 学区！！！！ => 非常贵 海淀区\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nLinear Regression: 实现了回归，其中包括线性函数的定义，为什么要用线性函数，loss的意义，梯度下降的意义，stochastic gradient descent\\nUse Boston house price dataset.\\n北京2020年房价的数据集，为什么我没有用北京房价的数据集呢？\\nBoston: room size, subway, highway, crime rate 有一个比较明显的关系，所以就观察关系比较容易\\n北京的房价：！远近，！房况 ==》 学区！！！！ => 非常贵 海淀区\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\"\"\"\n",
    "为什么我没有一行一行解释代码\n",
    "为什么我没有注释\n",
    "\n",
    "==> 好的Python代码 一定是\"自解释(self description)\"\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n为什么我没有一行一行解释代码\\n为什么我没有注释\\n\\n==> 好的Python代码 一定是\"自解释(self description)\"\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "dataset = load_boston()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# print(dataframe.corr()) # show the correlation of dataframe variables\n",
    "# correlation => 如果一个值的增大，会引起另外一个值一定增大，而且是定比例增大 相关系数就越接近于1\n",
    "# correlation => 0 就是两者之间没有任何关系\n",
    "# correlation => -1 一个值增大 另外一个值一定减小 而且减小是成相等比例的\n",
    "\n",
    "# sns.heatmap(dataframe.corr())\n",
    "# plt.show()\n",
    "\n",
    "# RM：小区平均的卧室个数\n",
    "# LSTAT: 低收入人群在周围的比例\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def linear(x, w, b):\n",
    "    # vectorized model\n",
    "    return np.dot(x, w.T) + b\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    # numpy broadcast numpy广播方法\n",
    "    return np.mean( (yhat - y) ** 2)\n",
    "\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([2 * np.mean((yhat - y) * x[0]), 2 * np.mean((yhat - y) * x[1])])\n",
    "\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return 2 * np.mean((yhat - y))\n",
    "\n",
    "\n",
    "def optimize(w, b, x, y, yhat, pw, pb, learning_rate):\n",
    "    w = w + -1 * pw(x, y, yhat) * learning_rate\n",
    "    b = b + -1 * pb(x, y, yhat) * learning_rate\n",
    "\n",
    "    return w, b"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def train(model_to_be_train, target, loss, pw, pb):\n",
    "\n",
    "    w = np.random.random_sample((1, 2)) # w normal\n",
    "    b = np.random.random() # 0 深度学习的时候会和大家详细解释\n",
    "    learning_rate = 1e-5\n",
    "    epoch = 200\n",
    "    losses = []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        batch_loss = []\n",
    "        for batch in range(len(rm)):\n",
    "            # batch training\n",
    "            index = random.choice(range(len(rm)))\n",
    "            rm_x, lstat_x = rm[index], lstat[index]\n",
    "            x = np.array([rm_x, lstat_x])\n",
    "            y = target[index]\n",
    "\n",
    "            yhat = model_to_be_train(x, w, b)\n",
    "            loss_v = loss(yhat, y)\n",
    "\n",
    "            batch_loss.append(loss_v)\n",
    "\n",
    "            w, b = optimize(w, b, x, y, yhat, pw, pb, learning_rate)\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch: {} Batch: {}, loss: {}'.format(i, batch, loss_v))\n",
    "        losses.append(np.mean(batch_loss))\n",
    "\n",
    "    return model_to_be_train, w, b, losses"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    target = dataframe['price']\n",
    "\n",
    "    model, w, b, losses = train(linear, target, loss, partial_w, partial_b)\n",
    "    plt.plot(losses)\n",
    "    predicate = model(np.array([19, 7]), w, b)\n",
    "    print(predicate)\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Batch: 0, loss: 165.0318036522631\n",
      "Epoch: 0 Batch: 100, loss: 1936.2111196826459\n",
      "Epoch: 0 Batch: 200, loss: 87.98685416771973\n",
      "Epoch: 0 Batch: 300, loss: 30.661954019864307\n",
      "Epoch: 0 Batch: 400, loss: 202.03139655964674\n",
      "Epoch: 0 Batch: 500, loss: 17.580267736634838\n",
      "Epoch: 1 Batch: 0, loss: 1446.1253865700296\n",
      "Epoch: 1 Batch: 100, loss: 1.5047965030815005\n",
      "Epoch: 1 Batch: 200, loss: 154.92310608521424\n",
      "Epoch: 1 Batch: 300, loss: 31.418267059890848\n",
      "Epoch: 1 Batch: 400, loss: 60.12302874669766\n",
      "Epoch: 1 Batch: 500, loss: 0.017649206948686953\n",
      "Epoch: 2 Batch: 0, loss: 1042.8976252299444\n",
      "Epoch: 2 Batch: 100, loss: 22.805604762686905\n",
      "Epoch: 2 Batch: 200, loss: 17.571935057777385\n",
      "Epoch: 2 Batch: 300, loss: 24.85551059275261\n",
      "Epoch: 2 Batch: 400, loss: 59.53967707873719\n",
      "Epoch: 2 Batch: 500, loss: 5.696399894817007\n",
      "Epoch: 3 Batch: 0, loss: 8.513585740753195\n",
      "Epoch: 3 Batch: 100, loss: 398.7638929121661\n",
      "Epoch: 3 Batch: 200, loss: 200.7024045227773\n",
      "Epoch: 3 Batch: 300, loss: 33.54234520380767\n",
      "Epoch: 3 Batch: 400, loss: 30.5864091533695\n",
      "Epoch: 3 Batch: 500, loss: 10.031957272145894\n",
      "Epoch: 4 Batch: 0, loss: 19.654707060739792\n",
      "Epoch: 4 Batch: 100, loss: 45.5164034991163\n",
      "Epoch: 4 Batch: 200, loss: 9.038107415763728\n",
      "Epoch: 4 Batch: 300, loss: 183.3663381478182\n",
      "Epoch: 4 Batch: 400, loss: 17.363954853228233\n",
      "Epoch: 4 Batch: 500, loss: 249.20646044455594\n",
      "Epoch: 5 Batch: 0, loss: 10.792854963458819\n",
      "Epoch: 5 Batch: 100, loss: 4.156551692733539\n",
      "Epoch: 5 Batch: 200, loss: 202.0715916566896\n",
      "Epoch: 5 Batch: 300, loss: 34.58785385061545\n",
      "Epoch: 5 Batch: 400, loss: 106.46286716528596\n",
      "Epoch: 5 Batch: 500, loss: 56.976274287033796\n",
      "Epoch: 6 Batch: 0, loss: 2.217680230467319\n",
      "Epoch: 6 Batch: 100, loss: 6.1836167999472025\n",
      "Epoch: 6 Batch: 200, loss: 71.37480543753581\n",
      "Epoch: 6 Batch: 300, loss: 152.67484167021598\n",
      "Epoch: 6 Batch: 400, loss: 39.05339465541599\n",
      "Epoch: 6 Batch: 500, loss: 140.67451039955805\n",
      "Epoch: 7 Batch: 0, loss: 0.05915866351480416\n",
      "Epoch: 7 Batch: 100, loss: 32.63274530993421\n",
      "Epoch: 7 Batch: 200, loss: 0.17223810693136235\n",
      "Epoch: 7 Batch: 300, loss: 0.17212490910792555\n",
      "Epoch: 7 Batch: 400, loss: 241.9009568750074\n",
      "Epoch: 7 Batch: 500, loss: 11.707222946021083\n",
      "Epoch: 8 Batch: 0, loss: 8.655895222743153\n",
      "Epoch: 8 Batch: 100, loss: 1.212181792184858\n",
      "Epoch: 8 Batch: 200, loss: 26.136435754633325\n",
      "Epoch: 8 Batch: 300, loss: 81.00207822318826\n",
      "Epoch: 8 Batch: 400, loss: 68.29900510310422\n",
      "Epoch: 8 Batch: 500, loss: 5.747259314829293\n",
      "Epoch: 9 Batch: 0, loss: 2.6651013836235915\n",
      "Epoch: 9 Batch: 100, loss: 362.2317427820767\n",
      "Epoch: 9 Batch: 200, loss: 100.07274906498411\n",
      "Epoch: 9 Batch: 300, loss: 15.825191705985443\n",
      "Epoch: 9 Batch: 400, loss: 0.8398965553366324\n",
      "Epoch: 9 Batch: 500, loss: 471.5900101540311\n",
      "Epoch: 10 Batch: 0, loss: 26.268822449250365\n",
      "Epoch: 10 Batch: 100, loss: 4.679414380221198\n",
      "Epoch: 10 Batch: 200, loss: 698.0138925394014\n",
      "Epoch: 10 Batch: 300, loss: 38.76722664716321\n",
      "Epoch: 10 Batch: 400, loss: 0.03332684596755375\n",
      "Epoch: 10 Batch: 500, loss: 50.714039295965854\n",
      "Epoch: 11 Batch: 0, loss: 0.3039491429757925\n",
      "Epoch: 11 Batch: 100, loss: 67.19473827534117\n",
      "Epoch: 11 Batch: 200, loss: 25.504671211710534\n",
      "Epoch: 11 Batch: 300, loss: 0.05036268863616471\n",
      "Epoch: 11 Batch: 400, loss: 0.07754097400431365\n",
      "Epoch: 11 Batch: 500, loss: 0.8528869200134028\n",
      "Epoch: 12 Batch: 0, loss: 0.40200207459616394\n",
      "Epoch: 12 Batch: 100, loss: 2.61718973741836\n",
      "Epoch: 12 Batch: 200, loss: 8.596689283595591\n",
      "Epoch: 12 Batch: 300, loss: 26.771352598428198\n",
      "Epoch: 12 Batch: 400, loss: 48.373366002564424\n",
      "Epoch: 12 Batch: 500, loss: 6.070005072923548\n",
      "Epoch: 13 Batch: 0, loss: 3.286614939639981\n",
      "Epoch: 13 Batch: 100, loss: 11.763801991085419\n",
      "Epoch: 13 Batch: 200, loss: 90.30834556305608\n",
      "Epoch: 13 Batch: 300, loss: 16.144758986001378\n",
      "Epoch: 13 Batch: 400, loss: 23.543149206648486\n",
      "Epoch: 13 Batch: 500, loss: 1.1574214878041154\n",
      "Epoch: 14 Batch: 0, loss: 0.3958046641630613\n",
      "Epoch: 14 Batch: 100, loss: 5.078035088228379\n",
      "Epoch: 14 Batch: 200, loss: 6.219477038815754\n",
      "Epoch: 14 Batch: 300, loss: 21.630029874844794\n",
      "Epoch: 14 Batch: 400, loss: 9.67195486022411\n",
      "Epoch: 14 Batch: 500, loss: 4.011025056276207\n",
      "Epoch: 15 Batch: 0, loss: 1.924446498627239\n",
      "Epoch: 15 Batch: 100, loss: 34.54863680525634\n",
      "Epoch: 15 Batch: 200, loss: 0.029074873210084944\n",
      "Epoch: 15 Batch: 300, loss: 54.15426867277343\n",
      "Epoch: 15 Batch: 400, loss: 6.836989142664036\n",
      "Epoch: 15 Batch: 500, loss: 62.679386077994785\n",
      "Epoch: 16 Batch: 0, loss: 69.49623625410233\n",
      "Epoch: 16 Batch: 100, loss: 80.70448024122521\n",
      "Epoch: 16 Batch: 200, loss: 103.86176920969835\n",
      "Epoch: 16 Batch: 300, loss: 0.40738559273890174\n",
      "Epoch: 16 Batch: 400, loss: 1.6124561311385797\n",
      "Epoch: 16 Batch: 500, loss: 18.394068189112904\n",
      "Epoch: 17 Batch: 0, loss: 2.2678593493490418\n",
      "Epoch: 17 Batch: 100, loss: 2.4631271537377954\n",
      "Epoch: 17 Batch: 200, loss: 2.5206990417473714\n",
      "Epoch: 17 Batch: 300, loss: 0.19389510877395968\n",
      "Epoch: 17 Batch: 400, loss: 18.303526912809367\n",
      "Epoch: 17 Batch: 500, loss: 84.0421789297173\n",
      "Epoch: 18 Batch: 0, loss: 32.73269933906996\n",
      "Epoch: 18 Batch: 100, loss: 39.64923755680796\n",
      "Epoch: 18 Batch: 200, loss: 15.134020735637561\n",
      "Epoch: 18 Batch: 300, loss: 22.493606087920806\n",
      "Epoch: 18 Batch: 400, loss: 0.001750896579869041\n",
      "Epoch: 18 Batch: 500, loss: 0.03858485654849556\n",
      "Epoch: 19 Batch: 0, loss: 39.94764651258677\n",
      "Epoch: 19 Batch: 100, loss: 1.2697278517111859\n",
      "Epoch: 19 Batch: 200, loss: 50.33129095532308\n",
      "Epoch: 19 Batch: 300, loss: 52.015249709542005\n",
      "Epoch: 19 Batch: 400, loss: 39.229729673774756\n",
      "Epoch: 19 Batch: 500, loss: 9.978781263740256\n",
      "Epoch: 20 Batch: 0, loss: 48.289695886851575\n",
      "Epoch: 20 Batch: 100, loss: 1.4857094765189491\n",
      "Epoch: 20 Batch: 200, loss: 5.927732408156\n",
      "Epoch: 20 Batch: 300, loss: 226.07998280246633\n",
      "Epoch: 20 Batch: 400, loss: 2.4085319179565885\n",
      "Epoch: 20 Batch: 500, loss: 1.199092729124266\n",
      "Epoch: 21 Batch: 0, loss: 0.3119895202366102\n",
      "Epoch: 21 Batch: 100, loss: 1.437301159079638\n",
      "Epoch: 21 Batch: 200, loss: 79.15553671040692\n",
      "Epoch: 21 Batch: 300, loss: 54.78500185166148\n",
      "Epoch: 21 Batch: 400, loss: 10.535337916211178\n",
      "Epoch: 21 Batch: 500, loss: 67.12484270579513\n",
      "Epoch: 22 Batch: 0, loss: 247.97735835324184\n",
      "Epoch: 22 Batch: 100, loss: 3.4869808899192245\n",
      "Epoch: 22 Batch: 200, loss: 264.7560886075215\n",
      "Epoch: 22 Batch: 300, loss: 9.118776068344735\n",
      "Epoch: 22 Batch: 400, loss: 6.84718084376927\n",
      "Epoch: 22 Batch: 500, loss: 46.172555593560794\n",
      "Epoch: 23 Batch: 0, loss: 5.196281037334641\n",
      "Epoch: 23 Batch: 100, loss: 17.376446714303206\n",
      "Epoch: 23 Batch: 200, loss: 134.00507165592336\n",
      "Epoch: 23 Batch: 300, loss: 0.041496988173208946\n",
      "Epoch: 23 Batch: 400, loss: 87.61932686836292\n",
      "Epoch: 23 Batch: 500, loss: 0.04464096187546659\n",
      "Epoch: 24 Batch: 0, loss: 37.746962407651225\n",
      "Epoch: 24 Batch: 100, loss: 4.033069283032188\n",
      "Epoch: 24 Batch: 200, loss: 31.81174674153305\n",
      "Epoch: 24 Batch: 300, loss: 140.2624496558734\n",
      "Epoch: 24 Batch: 400, loss: 8.153406846163055\n",
      "Epoch: 24 Batch: 500, loss: 0.8047630182195467\n",
      "Epoch: 25 Batch: 0, loss: 27.204976207926762\n",
      "Epoch: 25 Batch: 100, loss: 117.6537724795352\n",
      "Epoch: 25 Batch: 200, loss: 1.6851085863204065\n",
      "Epoch: 25 Batch: 300, loss: 6.599790940336662\n",
      "Epoch: 25 Batch: 400, loss: 0.6795521636405824\n",
      "Epoch: 25 Batch: 500, loss: 16.93129670219463\n",
      "Epoch: 26 Batch: 0, loss: 0.07905157903603928\n",
      "Epoch: 26 Batch: 100, loss: 2.5744229972614865\n",
      "Epoch: 26 Batch: 200, loss: 15.031509429020172\n",
      "Epoch: 26 Batch: 300, loss: 3.5277251136581764\n",
      "Epoch: 26 Batch: 400, loss: 18.134863650547793\n",
      "Epoch: 26 Batch: 500, loss: 1.2790929679584548\n",
      "Epoch: 27 Batch: 0, loss: 12.291384910522492\n",
      "Epoch: 27 Batch: 100, loss: 5.960474488501353\n",
      "Epoch: 27 Batch: 200, loss: 6.536657561037847\n",
      "Epoch: 27 Batch: 300, loss: 0.2550204794680412\n",
      "Epoch: 27 Batch: 400, loss: 4.165136826489474\n",
      "Epoch: 27 Batch: 500, loss: 1.192978738532072\n",
      "Epoch: 28 Batch: 0, loss: 7.395044561633403\n",
      "Epoch: 28 Batch: 100, loss: 14.072789797916323\n",
      "Epoch: 28 Batch: 200, loss: 0.6860265052623135\n",
      "Epoch: 28 Batch: 300, loss: 0.27691112194323503\n",
      "Epoch: 28 Batch: 400, loss: 5.667108536605594\n",
      "Epoch: 28 Batch: 500, loss: 12.088320968466174\n",
      "Epoch: 29 Batch: 0, loss: 3.459403759270398\n",
      "Epoch: 29 Batch: 100, loss: 5.124393691510977\n",
      "Epoch: 29 Batch: 200, loss: 9.039092362616383\n",
      "Epoch: 29 Batch: 300, loss: 51.85277615535911\n",
      "Epoch: 29 Batch: 400, loss: 741.224169328346\n",
      "Epoch: 29 Batch: 500, loss: 1.1455258091421103\n",
      "Epoch: 30 Batch: 0, loss: 5.732128176584093\n",
      "Epoch: 30 Batch: 100, loss: 12.150304772473723\n",
      "Epoch: 30 Batch: 200, loss: 6.804615045022966\n",
      "Epoch: 30 Batch: 300, loss: 3.99891609073822\n",
      "Epoch: 30 Batch: 400, loss: 42.738980236458964\n",
      "Epoch: 30 Batch: 500, loss: 3.8295237664093236\n",
      "Epoch: 31 Batch: 0, loss: 1.7624379226977576\n",
      "Epoch: 31 Batch: 100, loss: 1.8587391231361003\n",
      "Epoch: 31 Batch: 200, loss: 16.0902582425194\n",
      "Epoch: 31 Batch: 300, loss: 5.882467815244907\n",
      "Epoch: 31 Batch: 400, loss: 2.414199044481208\n",
      "Epoch: 31 Batch: 500, loss: 44.869068287196015\n",
      "Epoch: 32 Batch: 0, loss: 0.8494773010234854\n",
      "Epoch: 32 Batch: 100, loss: 31.288627861522787\n",
      "Epoch: 32 Batch: 200, loss: 7.284451455222004\n",
      "Epoch: 32 Batch: 300, loss: 17.72676018572161\n",
      "Epoch: 32 Batch: 400, loss: 0.06019171486804546\n",
      "Epoch: 32 Batch: 500, loss: 11.614521616920008\n",
      "Epoch: 33 Batch: 0, loss: 1.3363125017796114\n",
      "Epoch: 33 Batch: 100, loss: 0.05636671067489283\n",
      "Epoch: 33 Batch: 200, loss: 159.81451201991075\n",
      "Epoch: 33 Batch: 300, loss: 90.49976318300837\n",
      "Epoch: 33 Batch: 400, loss: 4.665419102626213\n",
      "Epoch: 33 Batch: 500, loss: 0.20165599865946954\n",
      "Epoch: 34 Batch: 0, loss: 5.664608387237534\n",
      "Epoch: 34 Batch: 100, loss: 5.994131762981918\n",
      "Epoch: 34 Batch: 200, loss: 104.77771585041538\n",
      "Epoch: 34 Batch: 300, loss: 0.3089858084311\n",
      "Epoch: 34 Batch: 400, loss: 9.565393314781216\n",
      "Epoch: 34 Batch: 500, loss: 6.551056165332506\n",
      "Epoch: 35 Batch: 0, loss: 11.0913503003926\n",
      "Epoch: 35 Batch: 100, loss: 30.25832099299688\n",
      "Epoch: 35 Batch: 200, loss: 0.6020307538645945\n",
      "Epoch: 35 Batch: 300, loss: 151.01156859648734\n",
      "Epoch: 35 Batch: 400, loss: 15.76257646907016\n",
      "Epoch: 35 Batch: 500, loss: 108.8726425014698\n",
      "Epoch: 36 Batch: 0, loss: 268.9286005372283\n",
      "Epoch: 36 Batch: 100, loss: 3.6489718442997905\n",
      "Epoch: 36 Batch: 200, loss: 1.1537930716481275\n",
      "Epoch: 36 Batch: 300, loss: 34.712872986205454\n",
      "Epoch: 36 Batch: 400, loss: 22.85294591784073\n",
      "Epoch: 36 Batch: 500, loss: 50.67763255656671\n",
      "Epoch: 37 Batch: 0, loss: 1.5457209526993485\n",
      "Epoch: 37 Batch: 100, loss: 13.111474380367978\n",
      "Epoch: 37 Batch: 200, loss: 1.388765123403642\n",
      "Epoch: 37 Batch: 300, loss: 253.58675953900172\n",
      "Epoch: 37 Batch: 400, loss: 177.62604331619767\n",
      "Epoch: 37 Batch: 500, loss: 1.8873522615741332\n",
      "Epoch: 38 Batch: 0, loss: 1.9390526719480892\n",
      "Epoch: 38 Batch: 100, loss: 2.593208210931778\n",
      "Epoch: 38 Batch: 200, loss: 8.940263413722558\n",
      "Epoch: 38 Batch: 300, loss: 0.008293320841878664\n",
      "Epoch: 38 Batch: 400, loss: 1.155640144894236\n",
      "Epoch: 38 Batch: 500, loss: 28.172519614634687\n",
      "Epoch: 39 Batch: 0, loss: 31.430387623860195\n",
      "Epoch: 39 Batch: 100, loss: 33.76884002887041\n",
      "Epoch: 39 Batch: 200, loss: 27.481851388546357\n",
      "Epoch: 39 Batch: 300, loss: 0.004129570956710169\n",
      "Epoch: 39 Batch: 400, loss: 2.0151435378813574\n",
      "Epoch: 39 Batch: 500, loss: 1.8123607474473304\n",
      "Epoch: 40 Batch: 0, loss: 0.44646492104196095\n",
      "Epoch: 40 Batch: 100, loss: 0.478558697192745\n",
      "Epoch: 40 Batch: 200, loss: 20.774756334364636\n",
      "Epoch: 40 Batch: 300, loss: 0.9286976834935952\n",
      "Epoch: 40 Batch: 400, loss: 61.101650615604385\n",
      "Epoch: 40 Batch: 500, loss: 2.056905683041531\n",
      "Epoch: 41 Batch: 0, loss: 77.15871224872197\n",
      "Epoch: 41 Batch: 100, loss: 0.4791882237922514\n",
      "Epoch: 41 Batch: 200, loss: 8.835161214168377\n",
      "Epoch: 41 Batch: 300, loss: 1.4287557588302362\n",
      "Epoch: 41 Batch: 400, loss: 2.25772007451599\n",
      "Epoch: 41 Batch: 500, loss: 0.12842694283603778\n",
      "Epoch: 42 Batch: 0, loss: 2.8123526164924266\n",
      "Epoch: 42 Batch: 100, loss: 7.23226317104346\n",
      "Epoch: 42 Batch: 200, loss: 0.8942664129829295\n",
      "Epoch: 42 Batch: 300, loss: 76.21308896102383\n",
      "Epoch: 42 Batch: 400, loss: 27.43595397587573\n",
      "Epoch: 42 Batch: 500, loss: 19.85620006669176\n",
      "Epoch: 43 Batch: 0, loss: 0.29986940040234517\n",
      "Epoch: 43 Batch: 100, loss: 6.6593503139746355\n",
      "Epoch: 43 Batch: 200, loss: 5.755092078531094\n",
      "Epoch: 43 Batch: 300, loss: 2.9186259107088635\n",
      "Epoch: 43 Batch: 400, loss: 19.157485884923357\n",
      "Epoch: 43 Batch: 500, loss: 1.335777446498188\n",
      "Epoch: 44 Batch: 0, loss: 215.63216994420628\n",
      "Epoch: 44 Batch: 100, loss: 0.033903442345497074\n",
      "Epoch: 44 Batch: 200, loss: 99.49815278188493\n",
      "Epoch: 44 Batch: 300, loss: 47.51926086645387\n",
      "Epoch: 44 Batch: 400, loss: 81.75502237327804\n",
      "Epoch: 44 Batch: 500, loss: 2.3980199157557225\n",
      "Epoch: 45 Batch: 0, loss: 6.368337824014247\n",
      "Epoch: 45 Batch: 100, loss: 3.6638054047011197\n",
      "Epoch: 45 Batch: 200, loss: 1.0621278784856942\n",
      "Epoch: 45 Batch: 300, loss: 1.930491235653956\n",
      "Epoch: 45 Batch: 400, loss: 3.5793685801285053\n",
      "Epoch: 45 Batch: 500, loss: 22.045838347055447\n",
      "Epoch: 46 Batch: 0, loss: 14.294858693159483\n",
      "Epoch: 46 Batch: 100, loss: 1.2638871450032145\n",
      "Epoch: 46 Batch: 200, loss: 54.44107296533436\n",
      "Epoch: 46 Batch: 300, loss: 31.298298397453014\n",
      "Epoch: 46 Batch: 400, loss: 0.11393552907337323\n",
      "Epoch: 46 Batch: 500, loss: 11.762934227458311\n",
      "Epoch: 47 Batch: 0, loss: 12.004246740472496\n",
      "Epoch: 47 Batch: 100, loss: 4.460659001422086\n",
      "Epoch: 47 Batch: 200, loss: 3.196154226595056\n",
      "Epoch: 47 Batch: 300, loss: 1.0389905343998849\n",
      "Epoch: 47 Batch: 400, loss: 0.5506385190145662\n",
      "Epoch: 47 Batch: 500, loss: 0.20083946688416254\n",
      "Epoch: 48 Batch: 0, loss: 7.194313793164096\n",
      "Epoch: 48 Batch: 100, loss: 38.43371917075666\n",
      "Epoch: 48 Batch: 200, loss: 42.61738863849939\n",
      "Epoch: 48 Batch: 300, loss: 0.39830007874892237\n",
      "Epoch: 48 Batch: 400, loss: 14.368211362397972\n",
      "Epoch: 48 Batch: 500, loss: 12.963883725649346\n",
      "Epoch: 49 Batch: 0, loss: 6.63619537554392\n",
      "Epoch: 49 Batch: 100, loss: 160.95248399279586\n",
      "Epoch: 49 Batch: 200, loss: 26.830772786826053\n",
      "Epoch: 49 Batch: 300, loss: 1.174794991103814\n",
      "Epoch: 49 Batch: 400, loss: 2.2911007872114473\n",
      "Epoch: 49 Batch: 500, loss: 5.302054341162025\n",
      "Epoch: 50 Batch: 0, loss: 13.098201813703895\n",
      "Epoch: 50 Batch: 100, loss: 23.784363676068615\n",
      "Epoch: 50 Batch: 200, loss: 0.5143204577138467\n",
      "Epoch: 50 Batch: 300, loss: 7.693275403867133\n",
      "Epoch: 50 Batch: 400, loss: 0.8279359661593008\n",
      "Epoch: 50 Batch: 500, loss: 0.2254142468812555\n",
      "Epoch: 51 Batch: 0, loss: 0.8421438941540111\n",
      "Epoch: 51 Batch: 100, loss: 0.1559028709066014\n",
      "Epoch: 51 Batch: 200, loss: 0.3525963102954398\n",
      "Epoch: 51 Batch: 300, loss: 12.804009341433167\n",
      "Epoch: 51 Batch: 400, loss: 9.342423181367499\n",
      "Epoch: 51 Batch: 500, loss: 46.74881643160353\n",
      "Epoch: 52 Batch: 0, loss: 28.869335202347877\n",
      "Epoch: 52 Batch: 100, loss: 6.527888632268584\n",
      "Epoch: 52 Batch: 200, loss: 20.063423208738463\n",
      "Epoch: 52 Batch: 300, loss: 1.901449466957149\n",
      "Epoch: 52 Batch: 400, loss: 0.9027214523873779\n",
      "Epoch: 52 Batch: 500, loss: 5.954686764180242\n",
      "Epoch: 53 Batch: 0, loss: 0.3873629379933664\n",
      "Epoch: 53 Batch: 100, loss: 20.60485016122946\n",
      "Epoch: 53 Batch: 200, loss: 3.434827695287965\n",
      "Epoch: 53 Batch: 300, loss: 25.549159683284948\n",
      "Epoch: 53 Batch: 400, loss: 9.879984938392944\n",
      "Epoch: 53 Batch: 500, loss: 0.32126841419648855\n",
      "Epoch: 54 Batch: 0, loss: 0.23452870771662032\n",
      "Epoch: 54 Batch: 100, loss: 12.589050671560885\n",
      "Epoch: 54 Batch: 200, loss: 76.45503831728035\n",
      "Epoch: 54 Batch: 300, loss: 0.7382294565356798\n",
      "Epoch: 54 Batch: 400, loss: 3.6428786787892258\n",
      "Epoch: 54 Batch: 500, loss: 25.917802144470635\n",
      "Epoch: 55 Batch: 0, loss: 15.363586323374474\n",
      "Epoch: 55 Batch: 100, loss: 13.779938918825769\n",
      "Epoch: 55 Batch: 200, loss: 12.609830375502776\n",
      "Epoch: 55 Batch: 300, loss: 0.9756770172730345\n",
      "Epoch: 55 Batch: 400, loss: 10.522639868084392\n",
      "Epoch: 55 Batch: 500, loss: 6.861368935577149\n",
      "Epoch: 56 Batch: 0, loss: 4.380806661375096\n",
      "Epoch: 56 Batch: 100, loss: 2.1687799497198648\n",
      "Epoch: 56 Batch: 200, loss: 63.46231078145867\n",
      "Epoch: 56 Batch: 300, loss: 4.705800173094941\n",
      "Epoch: 56 Batch: 400, loss: 9.487823014582004\n",
      "Epoch: 56 Batch: 500, loss: 0.5145313867606305\n",
      "Epoch: 57 Batch: 0, loss: 10.328900864502197\n",
      "Epoch: 57 Batch: 100, loss: 0.09914589875857455\n",
      "Epoch: 57 Batch: 200, loss: 16.512324370815065\n",
      "Epoch: 57 Batch: 300, loss: 7.010587766465191\n",
      "Epoch: 57 Batch: 400, loss: 4.641398382387823\n",
      "Epoch: 57 Batch: 500, loss: 45.317901592704374\n",
      "Epoch: 58 Batch: 0, loss: 1.1642419242697943\n",
      "Epoch: 58 Batch: 100, loss: 1.9039917165193796\n",
      "Epoch: 58 Batch: 200, loss: 2.260311656719671\n",
      "Epoch: 58 Batch: 300, loss: 0.0920412069125764\n",
      "Epoch: 58 Batch: 400, loss: 43.46682378502337\n",
      "Epoch: 58 Batch: 500, loss: 757.318588123008\n",
      "Epoch: 59 Batch: 0, loss: 6.145372318560688\n",
      "Epoch: 59 Batch: 100, loss: 14.161940736306237\n",
      "Epoch: 59 Batch: 200, loss: 7.174173264522584\n",
      "Epoch: 59 Batch: 300, loss: 22.857164609358133\n",
      "Epoch: 59 Batch: 400, loss: 342.6636152996125\n",
      "Epoch: 59 Batch: 500, loss: 5.395793014248272\n",
      "Epoch: 60 Batch: 0, loss: 41.49115716283433\n",
      "Epoch: 60 Batch: 100, loss: 10.928681684696425\n",
      "Epoch: 60 Batch: 200, loss: 4.806050518163034\n",
      "Epoch: 60 Batch: 300, loss: 19.380297400348827\n",
      "Epoch: 60 Batch: 400, loss: 44.74135573448658\n",
      "Epoch: 60 Batch: 500, loss: 252.9285194795551\n",
      "Epoch: 61 Batch: 0, loss: 31.51883035757275\n",
      "Epoch: 61 Batch: 100, loss: 5.9884948351917995\n",
      "Epoch: 61 Batch: 200, loss: 15.684573188195703\n",
      "Epoch: 61 Batch: 300, loss: 51.75921580683779\n",
      "Epoch: 61 Batch: 400, loss: 4.212894685260564\n",
      "Epoch: 61 Batch: 500, loss: 9.913545377852254\n",
      "Epoch: 62 Batch: 0, loss: 4.0697291736215995\n",
      "Epoch: 62 Batch: 100, loss: 0.03750263294424988\n",
      "Epoch: 62 Batch: 200, loss: 1.6740977439106655\n",
      "Epoch: 62 Batch: 300, loss: 5.140388876944154\n",
      "Epoch: 62 Batch: 400, loss: 27.707900489189242\n",
      "Epoch: 62 Batch: 500, loss: 47.87196673306302\n",
      "Epoch: 63 Batch: 0, loss: 9.965290118955656\n",
      "Epoch: 63 Batch: 100, loss: 7.70772082527878\n",
      "Epoch: 63 Batch: 200, loss: 2.1071322173428446\n",
      "Epoch: 63 Batch: 300, loss: 32.811919555570185\n",
      "Epoch: 63 Batch: 400, loss: 28.945151377696526\n",
      "Epoch: 63 Batch: 500, loss: 5.910042311433142\n",
      "Epoch: 64 Batch: 0, loss: 5.360642980674029\n",
      "Epoch: 64 Batch: 100, loss: 19.920491262443708\n",
      "Epoch: 64 Batch: 200, loss: 52.5928584029251\n",
      "Epoch: 64 Batch: 300, loss: 14.825613807912502\n",
      "Epoch: 64 Batch: 400, loss: 98.57972181776337\n",
      "Epoch: 64 Batch: 500, loss: 36.77839446925471\n",
      "Epoch: 65 Batch: 0, loss: 5.910799216652379\n",
      "Epoch: 65 Batch: 100, loss: 156.2334012955465\n",
      "Epoch: 65 Batch: 200, loss: 5.006152557953337\n",
      "Epoch: 65 Batch: 300, loss: 18.636332102698276\n",
      "Epoch: 65 Batch: 400, loss: 0.02264318680362086\n",
      "Epoch: 65 Batch: 500, loss: 8.188789250068604\n",
      "Epoch: 66 Batch: 0, loss: 8.34519146303316\n",
      "Epoch: 66 Batch: 100, loss: 3.5520297040885414\n",
      "Epoch: 66 Batch: 200, loss: 20.305167238166916\n",
      "Epoch: 66 Batch: 300, loss: 111.4030664022114\n",
      "Epoch: 66 Batch: 400, loss: 8.613262940218357\n",
      "Epoch: 66 Batch: 500, loss: 0.5449007235956788\n",
      "Epoch: 67 Batch: 0, loss: 18.483316492664795\n",
      "Epoch: 67 Batch: 100, loss: 31.39739631702137\n",
      "Epoch: 67 Batch: 200, loss: 57.69983199886647\n",
      "Epoch: 67 Batch: 300, loss: 6.384939766544626\n",
      "Epoch: 67 Batch: 400, loss: 5.032475910212011\n",
      "Epoch: 67 Batch: 500, loss: 1.7255220382542713\n",
      "Epoch: 68 Batch: 0, loss: 1.6533650958980608\n",
      "Epoch: 68 Batch: 100, loss: 10.150980317515275\n",
      "Epoch: 68 Batch: 200, loss: 209.26473143447842\n",
      "Epoch: 68 Batch: 300, loss: 15.358600631559101\n",
      "Epoch: 68 Batch: 400, loss: 212.93876908456218\n",
      "Epoch: 68 Batch: 500, loss: 2.2409678464734175\n",
      "Epoch: 69 Batch: 0, loss: 5.380452428486298\n",
      "Epoch: 69 Batch: 100, loss: 7.294931559994829\n",
      "Epoch: 69 Batch: 200, loss: 6.663861827079337\n",
      "Epoch: 69 Batch: 300, loss: 105.43304787538571\n",
      "Epoch: 69 Batch: 400, loss: 0.09043844920650657\n",
      "Epoch: 69 Batch: 500, loss: 32.5401490398383\n",
      "Epoch: 70 Batch: 0, loss: 7.005751210206881\n",
      "Epoch: 70 Batch: 100, loss: 17.39201405942735\n",
      "Epoch: 70 Batch: 200, loss: 39.69538707042665\n",
      "Epoch: 70 Batch: 300, loss: 0.03070678460743966\n",
      "Epoch: 70 Batch: 400, loss: 39.83658654462256\n",
      "Epoch: 70 Batch: 500, loss: 5.856413649835348\n",
      "Epoch: 71 Batch: 0, loss: 42.35416714803099\n",
      "Epoch: 71 Batch: 100, loss: 3.097531595081898\n",
      "Epoch: 71 Batch: 200, loss: 0.008152260965572679\n",
      "Epoch: 71 Batch: 300, loss: 0.1520054557085163\n",
      "Epoch: 71 Batch: 400, loss: 30.610380374129328\n",
      "Epoch: 71 Batch: 500, loss: 351.99857219943\n",
      "Epoch: 72 Batch: 0, loss: 5.894663243962327\n",
      "Epoch: 72 Batch: 100, loss: 21.862503160874063\n",
      "Epoch: 72 Batch: 200, loss: 0.5676268398609032\n",
      "Epoch: 72 Batch: 300, loss: 0.14673794689408287\n",
      "Epoch: 72 Batch: 400, loss: 309.2480882585131\n",
      "Epoch: 72 Batch: 500, loss: 1.523848936129672\n",
      "Epoch: 73 Batch: 0, loss: 1.0431719396370314\n",
      "Epoch: 73 Batch: 100, loss: 28.630377789203866\n",
      "Epoch: 73 Batch: 200, loss: 36.670390300355294\n",
      "Epoch: 73 Batch: 300, loss: 16.91429359844125\n",
      "Epoch: 73 Batch: 400, loss: 10.110035017369066\n",
      "Epoch: 73 Batch: 500, loss: 106.56672422965697\n",
      "Epoch: 74 Batch: 0, loss: 46.77491248245363\n",
      "Epoch: 74 Batch: 100, loss: 203.27597665004987\n",
      "Epoch: 74 Batch: 200, loss: 7.23405620722111\n",
      "Epoch: 74 Batch: 300, loss: 0.08248179548483388\n",
      "Epoch: 74 Batch: 400, loss: 1.217270959408689\n",
      "Epoch: 74 Batch: 500, loss: 9.043791557459832\n",
      "Epoch: 75 Batch: 0, loss: 7.048919666659428\n",
      "Epoch: 75 Batch: 100, loss: 0.0006951973565818533\n",
      "Epoch: 75 Batch: 200, loss: 0.8265965177445516\n",
      "Epoch: 75 Batch: 300, loss: 3.5151422826639718\n",
      "Epoch: 75 Batch: 400, loss: 24.591957619405292\n",
      "Epoch: 75 Batch: 500, loss: 0.1930906181891331\n",
      "Epoch: 76 Batch: 0, loss: 0.49299511183621797\n",
      "Epoch: 76 Batch: 100, loss: 0.5153112041706057\n",
      "Epoch: 76 Batch: 200, loss: 0.00016699326590815343\n",
      "Epoch: 76 Batch: 300, loss: 13.2699443069611\n",
      "Epoch: 76 Batch: 400, loss: 0.5757174004545162\n",
      "Epoch: 76 Batch: 500, loss: 11.941128436045428\n",
      "Epoch: 77 Batch: 0, loss: 154.8684376568468\n",
      "Epoch: 77 Batch: 100, loss: 31.141276485456512\n",
      "Epoch: 77 Batch: 200, loss: 11.052760824892426\n",
      "Epoch: 77 Batch: 300, loss: 0.8325863062014653\n",
      "Epoch: 77 Batch: 400, loss: 13.461333384902439\n",
      "Epoch: 77 Batch: 500, loss: 135.69479495708876\n",
      "Epoch: 78 Batch: 0, loss: 6.738647079083224\n",
      "Epoch: 78 Batch: 100, loss: 5.298439511562226\n",
      "Epoch: 78 Batch: 200, loss: 2.294328990516225\n",
      "Epoch: 78 Batch: 300, loss: 20.71421926119909\n",
      "Epoch: 78 Batch: 400, loss: 7.465601219723193\n",
      "Epoch: 78 Batch: 500, loss: 121.29325435922414\n",
      "Epoch: 79 Batch: 0, loss: 0.40964688362405344\n",
      "Epoch: 79 Batch: 100, loss: 2.096957152312635\n",
      "Epoch: 79 Batch: 200, loss: 12.663272626027535\n",
      "Epoch: 79 Batch: 300, loss: 2.2477199144435134\n",
      "Epoch: 79 Batch: 400, loss: 34.143360407930324\n",
      "Epoch: 79 Batch: 500, loss: 17.85759180792839\n",
      "Epoch: 80 Batch: 0, loss: 49.462026428815975\n",
      "Epoch: 80 Batch: 100, loss: 164.9935334215838\n",
      "Epoch: 80 Batch: 200, loss: 5.7017784471292225\n",
      "Epoch: 80 Batch: 300, loss: 4.059946504063874\n",
      "Epoch: 80 Batch: 400, loss: 36.5314640144044\n",
      "Epoch: 80 Batch: 500, loss: 11.945939667277942\n",
      "Epoch: 81 Batch: 0, loss: 12.295886966573772\n",
      "Epoch: 81 Batch: 100, loss: 5.603155601142583\n",
      "Epoch: 81 Batch: 200, loss: 59.670246771773655\n",
      "Epoch: 81 Batch: 300, loss: 1.7917355799088983\n",
      "Epoch: 81 Batch: 400, loss: 41.282187114656566\n",
      "Epoch: 81 Batch: 500, loss: 11.950711443116646\n",
      "Epoch: 82 Batch: 0, loss: 0.14310289464967627\n",
      "Epoch: 82 Batch: 100, loss: 29.854084035982577\n",
      "Epoch: 82 Batch: 200, loss: 2.728750577721406\n",
      "Epoch: 82 Batch: 300, loss: 20.384813763034867\n",
      "Epoch: 82 Batch: 400, loss: 3.08573349926514\n",
      "Epoch: 82 Batch: 500, loss: 0.4988139164958844\n",
      "Epoch: 83 Batch: 0, loss: 174.7054471473609\n",
      "Epoch: 83 Batch: 100, loss: 27.604076729330078\n",
      "Epoch: 83 Batch: 200, loss: 4.868483107241284\n",
      "Epoch: 83 Batch: 300, loss: 0.5510429151829142\n",
      "Epoch: 83 Batch: 400, loss: 103.36647420412164\n",
      "Epoch: 83 Batch: 500, loss: 12.495851207848554\n",
      "Epoch: 84 Batch: 0, loss: 14.840679546554197\n",
      "Epoch: 84 Batch: 100, loss: 8.448201471472721\n",
      "Epoch: 84 Batch: 200, loss: 32.294709463831815\n",
      "Epoch: 84 Batch: 300, loss: 47.99263015323456\n",
      "Epoch: 84 Batch: 400, loss: 7.330059892366107\n",
      "Epoch: 84 Batch: 500, loss: 37.05951506037859\n",
      "Epoch: 85 Batch: 0, loss: 2.4161566682839863\n",
      "Epoch: 85 Batch: 100, loss: 10.919522377333328\n",
      "Epoch: 85 Batch: 200, loss: 26.71676935385484\n",
      "Epoch: 85 Batch: 300, loss: 102.61456759354368\n",
      "Epoch: 85 Batch: 400, loss: 21.99451530071888\n",
      "Epoch: 85 Batch: 500, loss: 0.18710240825645302\n",
      "Epoch: 86 Batch: 0, loss: 0.4638750630634232\n",
      "Epoch: 86 Batch: 100, loss: 24.05492470567029\n",
      "Epoch: 86 Batch: 200, loss: 1.7494976790280063\n",
      "Epoch: 86 Batch: 300, loss: 12.12367733425698\n",
      "Epoch: 86 Batch: 400, loss: 4.947180550048447\n",
      "Epoch: 86 Batch: 500, loss: 15.044163701469435\n",
      "Epoch: 87 Batch: 0, loss: 22.650292520304905\n",
      "Epoch: 87 Batch: 100, loss: 1.9118496297704721\n",
      "Epoch: 87 Batch: 200, loss: 39.28658172467348\n",
      "Epoch: 87 Batch: 300, loss: 5.83386931080753\n",
      "Epoch: 87 Batch: 400, loss: 280.4944867198505\n",
      "Epoch: 87 Batch: 500, loss: 23.768514436726758\n",
      "Epoch: 88 Batch: 0, loss: 48.525479910777335\n",
      "Epoch: 88 Batch: 100, loss: 9.888457213703616\n",
      "Epoch: 88 Batch: 200, loss: 28.102262530003998\n",
      "Epoch: 88 Batch: 300, loss: 92.3327751502764\n",
      "Epoch: 88 Batch: 400, loss: 22.55606700357476\n",
      "Epoch: 88 Batch: 500, loss: 30.96884167874805\n",
      "Epoch: 89 Batch: 0, loss: 41.9159339675599\n",
      "Epoch: 89 Batch: 100, loss: 25.882632839115505\n",
      "Epoch: 89 Batch: 200, loss: 5.989100870863046\n",
      "Epoch: 89 Batch: 300, loss: 168.96025360197757\n",
      "Epoch: 89 Batch: 400, loss: 9.386494997845784\n",
      "Epoch: 89 Batch: 500, loss: 7.185093552993682\n",
      "Epoch: 90 Batch: 0, loss: 0.7508844492729004\n",
      "Epoch: 90 Batch: 100, loss: 22.934446703663\n",
      "Epoch: 90 Batch: 200, loss: 13.523054198492956\n",
      "Epoch: 90 Batch: 300, loss: 1.7032794304758134\n",
      "Epoch: 90 Batch: 400, loss: 2.9017461587958\n",
      "Epoch: 90 Batch: 500, loss: 5.3802677631236175\n",
      "Epoch: 91 Batch: 0, loss: 21.210847975474017\n",
      "Epoch: 91 Batch: 100, loss: 20.87568887927794\n",
      "Epoch: 91 Batch: 200, loss: 116.94970666890345\n",
      "Epoch: 91 Batch: 300, loss: 0.2281739164166518\n",
      "Epoch: 91 Batch: 400, loss: 16.015016384931723\n",
      "Epoch: 91 Batch: 500, loss: 1.5116127699490418\n",
      "Epoch: 92 Batch: 0, loss: 110.56817527925072\n",
      "Epoch: 92 Batch: 100, loss: 46.09925678531282\n",
      "Epoch: 92 Batch: 200, loss: 71.59325873679614\n",
      "Epoch: 92 Batch: 300, loss: 1.9647318643343439\n",
      "Epoch: 92 Batch: 400, loss: 12.218322724230909\n",
      "Epoch: 92 Batch: 500, loss: 2.330391739496686\n",
      "Epoch: 93 Batch: 0, loss: 0.0007386652596184504\n",
      "Epoch: 93 Batch: 100, loss: 14.779356859283428\n",
      "Epoch: 93 Batch: 200, loss: 22.486112181270865\n",
      "Epoch: 93 Batch: 300, loss: 2.739005308236884\n",
      "Epoch: 93 Batch: 400, loss: 1.5607176658562663\n",
      "Epoch: 93 Batch: 500, loss: 1.4870523512587561\n",
      "Epoch: 94 Batch: 0, loss: 100.61306728042406\n",
      "Epoch: 94 Batch: 100, loss: 3.662413319245064\n",
      "Epoch: 94 Batch: 200, loss: 0.023992457950572168\n",
      "Epoch: 94 Batch: 300, loss: 89.73104272074755\n",
      "Epoch: 94 Batch: 400, loss: 13.073552946202685\n",
      "Epoch: 94 Batch: 500, loss: 30.407658857499914\n",
      "Epoch: 95 Batch: 0, loss: 21.94990846218933\n",
      "Epoch: 95 Batch: 100, loss: 3.1387802693788456\n",
      "Epoch: 95 Batch: 200, loss: 3.6673160109401963\n",
      "Epoch: 95 Batch: 300, loss: 0.032648190724344085\n",
      "Epoch: 95 Batch: 400, loss: 0.15767802710817788\n",
      "Epoch: 95 Batch: 500, loss: 300.9444704182488\n",
      "Epoch: 96 Batch: 0, loss: 26.340954286177546\n",
      "Epoch: 96 Batch: 100, loss: 13.421404838197645\n",
      "Epoch: 96 Batch: 200, loss: 269.14345191944705\n",
      "Epoch: 96 Batch: 300, loss: 9.55083006403811\n",
      "Epoch: 96 Batch: 400, loss: 7.363271788314592\n",
      "Epoch: 96 Batch: 500, loss: 0.047051322394801\n",
      "Epoch: 97 Batch: 0, loss: 26.35041440579207\n",
      "Epoch: 97 Batch: 100, loss: 0.026552052879295126\n",
      "Epoch: 97 Batch: 200, loss: 0.023468441377907493\n",
      "Epoch: 97 Batch: 300, loss: 44.23955218238816\n",
      "Epoch: 97 Batch: 400, loss: 0.3464677977817086\n",
      "Epoch: 97 Batch: 500, loss: 23.254209268333277\n",
      "Epoch: 98 Batch: 0, loss: 2.338311453550716\n",
      "Epoch: 98 Batch: 100, loss: 0.6991925962511251\n",
      "Epoch: 98 Batch: 200, loss: 118.75859683681215\n",
      "Epoch: 98 Batch: 300, loss: 12.23788925653202\n",
      "Epoch: 98 Batch: 400, loss: 1.362206705158875\n",
      "Epoch: 98 Batch: 500, loss: 106.89438300985478\n",
      "Epoch: 99 Batch: 0, loss: 1.659962564333348\n",
      "Epoch: 99 Batch: 100, loss: 22.66444031809457\n",
      "Epoch: 99 Batch: 200, loss: 102.827336980086\n",
      "Epoch: 99 Batch: 300, loss: 5.957203675605563\n",
      "Epoch: 99 Batch: 400, loss: 18.86753008166191\n",
      "Epoch: 99 Batch: 500, loss: 0.5929399871859196\n",
      "Epoch: 100 Batch: 0, loss: 137.4877762445533\n",
      "Epoch: 100 Batch: 100, loss: 2.9150953771081816\n",
      "Epoch: 100 Batch: 200, loss: 25.410678256106515\n",
      "Epoch: 100 Batch: 300, loss: 41.42334205452084\n",
      "Epoch: 100 Batch: 400, loss: 213.32441913870397\n",
      "Epoch: 100 Batch: 500, loss: 5.941600623361769\n",
      "Epoch: 101 Batch: 0, loss: 1.9370253310672338\n",
      "Epoch: 101 Batch: 100, loss: 0.6959525067244399\n",
      "Epoch: 101 Batch: 200, loss: 4.265013587940076\n",
      "Epoch: 101 Batch: 300, loss: 2.7877201347804172\n",
      "Epoch: 101 Batch: 400, loss: 24.031383969829086\n",
      "Epoch: 101 Batch: 500, loss: 159.4043531516391\n",
      "Epoch: 102 Batch: 0, loss: 12.175256980658537\n",
      "Epoch: 102 Batch: 100, loss: 105.7937865730941\n",
      "Epoch: 102 Batch: 200, loss: 14.041652623525303\n",
      "Epoch: 102 Batch: 300, loss: 49.41137062032899\n",
      "Epoch: 102 Batch: 400, loss: 21.021777705605693\n",
      "Epoch: 102 Batch: 500, loss: 10.563929205311357\n",
      "Epoch: 103 Batch: 0, loss: 8.432448640697883\n",
      "Epoch: 103 Batch: 100, loss: 1.1629298259220264\n",
      "Epoch: 103 Batch: 200, loss: 3.217517368189617\n",
      "Epoch: 103 Batch: 300, loss: 1.7142285227664533\n",
      "Epoch: 103 Batch: 400, loss: 66.00993748547663\n",
      "Epoch: 103 Batch: 500, loss: 0.572488175603719\n",
      "Epoch: 104 Batch: 0, loss: 9.097354326785275\n",
      "Epoch: 104 Batch: 100, loss: 2.36234851774665\n",
      "Epoch: 104 Batch: 200, loss: 12.53292401326402\n",
      "Epoch: 104 Batch: 300, loss: 21.896489805365796\n",
      "Epoch: 104 Batch: 400, loss: 8.037358253983413\n",
      "Epoch: 104 Batch: 500, loss: 28.483052864173537\n",
      "Epoch: 105 Batch: 0, loss: 1.1075724460433514\n",
      "Epoch: 105 Batch: 100, loss: 4.514027960505325\n",
      "Epoch: 105 Batch: 200, loss: 111.33443410894665\n",
      "Epoch: 105 Batch: 300, loss: 18.38978758025968\n",
      "Epoch: 105 Batch: 400, loss: 4.523904632210316\n",
      "Epoch: 105 Batch: 500, loss: 3.1244097720608317\n",
      "Epoch: 106 Batch: 0, loss: 1.0337717233098165\n",
      "Epoch: 106 Batch: 100, loss: 0.2866162893884368\n",
      "Epoch: 106 Batch: 200, loss: 18.097293885177383\n",
      "Epoch: 106 Batch: 300, loss: 10.151991870666539\n",
      "Epoch: 106 Batch: 400, loss: 171.75049535478036\n",
      "Epoch: 106 Batch: 500, loss: 2.2300881274793296\n",
      "Epoch: 107 Batch: 0, loss: 2.8175237833694866\n",
      "Epoch: 107 Batch: 100, loss: 1.0063274008196792\n",
      "Epoch: 107 Batch: 200, loss: 323.7363314537811\n",
      "Epoch: 107 Batch: 300, loss: 0.11966287700478317\n",
      "Epoch: 107 Batch: 400, loss: 0.12370507730289275\n",
      "Epoch: 107 Batch: 500, loss: 60.38715097120618\n",
      "Epoch: 108 Batch: 0, loss: 1.527387638437787\n",
      "Epoch: 108 Batch: 100, loss: 0.03593396996317102\n",
      "Epoch: 108 Batch: 200, loss: 35.609757949104505\n",
      "Epoch: 108 Batch: 300, loss: 1.9983744917359882\n",
      "Epoch: 108 Batch: 400, loss: 3.9925594775267603\n",
      "Epoch: 108 Batch: 500, loss: 1.433597760329723\n",
      "Epoch: 109 Batch: 0, loss: 26.417696293803427\n",
      "Epoch: 109 Batch: 100, loss: 74.96791008422004\n",
      "Epoch: 109 Batch: 200, loss: 14.884516373946324\n",
      "Epoch: 109 Batch: 300, loss: 27.787767114003245\n",
      "Epoch: 109 Batch: 400, loss: 0.0040970175254825165\n",
      "Epoch: 109 Batch: 500, loss: 1.252273536150809\n",
      "Epoch: 110 Batch: 0, loss: 22.642384689076295\n",
      "Epoch: 110 Batch: 100, loss: 1.6198572121384869\n",
      "Epoch: 110 Batch: 200, loss: 13.301625552746312\n",
      "Epoch: 110 Batch: 300, loss: 0.39154534711682787\n",
      "Epoch: 110 Batch: 400, loss: 0.6231618581871932\n",
      "Epoch: 110 Batch: 500, loss: 0.01025991351426524\n",
      "Epoch: 111 Batch: 0, loss: 3.5362669127985735\n",
      "Epoch: 111 Batch: 100, loss: 1.9876380212781015\n",
      "Epoch: 111 Batch: 200, loss: 26.73980724260786\n",
      "Epoch: 111 Batch: 300, loss: 21.225354464278663\n",
      "Epoch: 111 Batch: 400, loss: 1.995342369431627\n",
      "Epoch: 111 Batch: 500, loss: 0.00034249716223727617\n",
      "Epoch: 112 Batch: 0, loss: 28.235526230122662\n",
      "Epoch: 112 Batch: 100, loss: 26.12474067797898\n",
      "Epoch: 112 Batch: 200, loss: 61.38520512256984\n",
      "Epoch: 112 Batch: 300, loss: 0.8392773671710748\n",
      "Epoch: 112 Batch: 400, loss: 1.530878220087621\n",
      "Epoch: 112 Batch: 500, loss: 10.705742307879598\n",
      "Epoch: 113 Batch: 0, loss: 15.003239150284134\n",
      "Epoch: 113 Batch: 100, loss: 18.794502897975164\n",
      "Epoch: 113 Batch: 200, loss: 12.047291532899417\n",
      "Epoch: 113 Batch: 300, loss: 2.8391387335220397\n",
      "Epoch: 113 Batch: 400, loss: 5.716143400178361\n",
      "Epoch: 113 Batch: 500, loss: 25.148299140399875\n",
      "Epoch: 114 Batch: 0, loss: 0.6497171338529788\n",
      "Epoch: 114 Batch: 100, loss: 33.52792771847514\n",
      "Epoch: 114 Batch: 200, loss: 4.441944377221081\n",
      "Epoch: 114 Batch: 300, loss: 0.3084704820935972\n",
      "Epoch: 114 Batch: 400, loss: 6.5015469576503335\n",
      "Epoch: 114 Batch: 500, loss: 0.016614451849581408\n",
      "Epoch: 115 Batch: 0, loss: 14.420688158712043\n",
      "Epoch: 115 Batch: 100, loss: 20.46391104107944\n",
      "Epoch: 115 Batch: 200, loss: 27.74665603154558\n",
      "Epoch: 115 Batch: 300, loss: 2.7821017688534364\n",
      "Epoch: 115 Batch: 400, loss: 24.524151040447816\n",
      "Epoch: 115 Batch: 500, loss: 5.220421512508674\n",
      "Epoch: 116 Batch: 0, loss: 1.695544634108097\n",
      "Epoch: 116 Batch: 100, loss: 5.419432059094484\n",
      "Epoch: 116 Batch: 200, loss: 1.2804342637474402\n",
      "Epoch: 116 Batch: 300, loss: 2.7713562070467104\n",
      "Epoch: 116 Batch: 400, loss: 29.56323299477552\n",
      "Epoch: 116 Batch: 500, loss: 6.913885447020697\n",
      "Epoch: 117 Batch: 0, loss: 24.469550411166697\n",
      "Epoch: 117 Batch: 100, loss: 27.00190086438412\n",
      "Epoch: 117 Batch: 200, loss: 4.16352267425801\n",
      "Epoch: 117 Batch: 300, loss: 1.0150244296692847\n",
      "Epoch: 117 Batch: 400, loss: 141.8378319335724\n",
      "Epoch: 117 Batch: 500, loss: 17.978999997952464\n",
      "Epoch: 118 Batch: 0, loss: 0.8796627960572168\n",
      "Epoch: 118 Batch: 100, loss: 186.3343541248634\n",
      "Epoch: 118 Batch: 200, loss: 0.09198001678736942\n",
      "Epoch: 118 Batch: 300, loss: 12.098250656367021\n",
      "Epoch: 118 Batch: 400, loss: 23.408874219469965\n",
      "Epoch: 118 Batch: 500, loss: 1.3074052968568612\n",
      "Epoch: 119 Batch: 0, loss: 1.8254568589160591\n",
      "Epoch: 119 Batch: 100, loss: 14.50047006804542\n",
      "Epoch: 119 Batch: 200, loss: 35.340004504482536\n",
      "Epoch: 119 Batch: 300, loss: 4.060321095533662\n",
      "Epoch: 119 Batch: 400, loss: 27.085479221922064\n",
      "Epoch: 119 Batch: 500, loss: 8.519249265463758\n",
      "Epoch: 120 Batch: 0, loss: 66.02557953018768\n",
      "Epoch: 120 Batch: 100, loss: 28.276914428038946\n",
      "Epoch: 120 Batch: 200, loss: 0.22072768387453434\n",
      "Epoch: 120 Batch: 300, loss: 1.9722195874552582\n",
      "Epoch: 120 Batch: 400, loss: 0.8888706023610896\n",
      "Epoch: 120 Batch: 500, loss: 0.5701362583400847\n",
      "Epoch: 121 Batch: 0, loss: 14.558119621537429\n",
      "Epoch: 121 Batch: 100, loss: 64.57461347685391\n",
      "Epoch: 121 Batch: 200, loss: 4.577135749840314\n",
      "Epoch: 121 Batch: 300, loss: 11.721037986848696\n",
      "Epoch: 121 Batch: 400, loss: 53.71054926081822\n",
      "Epoch: 121 Batch: 500, loss: 48.65665909138121\n",
      "Epoch: 122 Batch: 0, loss: 0.34370449184313506\n",
      "Epoch: 122 Batch: 100, loss: 6.944789883748849\n",
      "Epoch: 122 Batch: 200, loss: 11.323469092593\n",
      "Epoch: 122 Batch: 300, loss: 100.57266797848615\n",
      "Epoch: 122 Batch: 400, loss: 14.052109387617111\n",
      "Epoch: 122 Batch: 500, loss: 20.920553148419145\n",
      "Epoch: 123 Batch: 0, loss: 1.4827354950457379\n",
      "Epoch: 123 Batch: 100, loss: 7.60802323566888\n",
      "Epoch: 123 Batch: 200, loss: 2.737382630620973e-06\n",
      "Epoch: 123 Batch: 300, loss: 5.260057116622584\n",
      "Epoch: 123 Batch: 400, loss: 0.001253425110184698\n",
      "Epoch: 123 Batch: 500, loss: 1.2019756211009913\n",
      "Epoch: 124 Batch: 0, loss: 88.78472199194844\n",
      "Epoch: 124 Batch: 100, loss: 2.004739175393255\n",
      "Epoch: 124 Batch: 200, loss: 73.37678498182134\n",
      "Epoch: 124 Batch: 300, loss: 3.0343668198776\n",
      "Epoch: 124 Batch: 400, loss: 11.963562993637497\n",
      "Epoch: 124 Batch: 500, loss: 6.872908300552626\n",
      "Epoch: 125 Batch: 0, loss: 141.04628567831205\n",
      "Epoch: 125 Batch: 100, loss: 43.17410445756678\n",
      "Epoch: 125 Batch: 200, loss: 1.406768390026523\n",
      "Epoch: 125 Batch: 300, loss: 1.3592607780070098\n",
      "Epoch: 125 Batch: 400, loss: 0.003884517493729336\n",
      "Epoch: 125 Batch: 500, loss: 227.5404431049921\n",
      "Epoch: 126 Batch: 0, loss: 20.688648904243767\n",
      "Epoch: 126 Batch: 100, loss: 66.53737428451241\n",
      "Epoch: 126 Batch: 200, loss: 7.092504653534527\n",
      "Epoch: 126 Batch: 300, loss: 8.798622037601158\n",
      "Epoch: 126 Batch: 400, loss: 93.52826378118519\n",
      "Epoch: 126 Batch: 500, loss: 38.911508738837625\n",
      "Epoch: 127 Batch: 0, loss: 0.38535995536376166\n",
      "Epoch: 127 Batch: 100, loss: 1.4074761641319604\n",
      "Epoch: 127 Batch: 200, loss: 14.190877906991558\n",
      "Epoch: 127 Batch: 300, loss: 0.18180800499026706\n",
      "Epoch: 127 Batch: 400, loss: 82.20886807810368\n",
      "Epoch: 127 Batch: 500, loss: 15.56786948904368\n",
      "Epoch: 128 Batch: 0, loss: 4.196883277129068\n",
      "Epoch: 128 Batch: 100, loss: 18.144852557589786\n",
      "Epoch: 128 Batch: 200, loss: 5.910404763410882\n",
      "Epoch: 128 Batch: 300, loss: 33.52580428480226\n",
      "Epoch: 128 Batch: 400, loss: 25.342811012243224\n",
      "Epoch: 128 Batch: 500, loss: 42.88458325020498\n",
      "Epoch: 129 Batch: 0, loss: 159.1330297720742\n",
      "Epoch: 129 Batch: 100, loss: 36.59227863598366\n",
      "Epoch: 129 Batch: 200, loss: 24.337505544234883\n",
      "Epoch: 129 Batch: 300, loss: 3.4648413626132237\n",
      "Epoch: 129 Batch: 400, loss: 2.4368250253127464\n",
      "Epoch: 129 Batch: 500, loss: 3.8583053099571956\n",
      "Epoch: 130 Batch: 0, loss: 33.7825468667852\n",
      "Epoch: 130 Batch: 100, loss: 3.137011501340448\n",
      "Epoch: 130 Batch: 200, loss: 3.9783496413490393\n",
      "Epoch: 130 Batch: 300, loss: 47.7965892633299\n",
      "Epoch: 130 Batch: 400, loss: 0.0011716503458040416\n",
      "Epoch: 130 Batch: 500, loss: 16.86661571343345\n",
      "Epoch: 131 Batch: 0, loss: 0.017234303618885293\n",
      "Epoch: 131 Batch: 100, loss: 12.076802002692204\n",
      "Epoch: 131 Batch: 200, loss: 17.065415729645224\n",
      "Epoch: 131 Batch: 300, loss: 36.70290081082252\n",
      "Epoch: 131 Batch: 400, loss: 49.63971159227737\n",
      "Epoch: 131 Batch: 500, loss: 56.675102759323664\n",
      "Epoch: 132 Batch: 0, loss: 55.21726441270094\n",
      "Epoch: 132 Batch: 100, loss: 2.841766734459291\n",
      "Epoch: 132 Batch: 200, loss: 24.159000064179196\n",
      "Epoch: 132 Batch: 300, loss: 103.1694388061354\n",
      "Epoch: 132 Batch: 400, loss: 0.08356519837034646\n",
      "Epoch: 132 Batch: 500, loss: 2.2128938473787443\n",
      "Epoch: 133 Batch: 0, loss: 13.93454169562667\n",
      "Epoch: 133 Batch: 100, loss: 0.4077528879383518\n",
      "Epoch: 133 Batch: 200, loss: 37.29540895126822\n",
      "Epoch: 133 Batch: 300, loss: 2.6929841790858653\n",
      "Epoch: 133 Batch: 400, loss: 157.11581235854715\n",
      "Epoch: 133 Batch: 500, loss: 1.9528309964341688\n",
      "Epoch: 134 Batch: 0, loss: 133.85707326563693\n",
      "Epoch: 134 Batch: 100, loss: 0.6171311014004028\n",
      "Epoch: 134 Batch: 200, loss: 14.451797797685234\n",
      "Epoch: 134 Batch: 300, loss: 22.64174663996787\n",
      "Epoch: 134 Batch: 400, loss: 18.4263739229889\n",
      "Epoch: 134 Batch: 500, loss: 17.84138665672612\n",
      "Epoch: 135 Batch: 0, loss: 1.4955536783628007\n",
      "Epoch: 135 Batch: 100, loss: 33.90240985131003\n",
      "Epoch: 135 Batch: 200, loss: 142.86517305212237\n",
      "Epoch: 135 Batch: 300, loss: 14.64630320593115\n",
      "Epoch: 135 Batch: 400, loss: 2.819962620673635\n",
      "Epoch: 135 Batch: 500, loss: 13.002299587025774\n",
      "Epoch: 136 Batch: 0, loss: 1.1013096298617826\n",
      "Epoch: 136 Batch: 100, loss: 1.7556054523103528\n",
      "Epoch: 136 Batch: 200, loss: 12.66131225220712\n",
      "Epoch: 136 Batch: 300, loss: 50.82714956316176\n",
      "Epoch: 136 Batch: 400, loss: 5.852913483024977\n",
      "Epoch: 136 Batch: 500, loss: 0.06495320943574162\n",
      "Epoch: 137 Batch: 0, loss: 0.4258412198332114\n",
      "Epoch: 137 Batch: 100, loss: 1.2372239826256541\n",
      "Epoch: 137 Batch: 200, loss: 0.00032688661124836326\n",
      "Epoch: 137 Batch: 300, loss: 4.783423309031295\n",
      "Epoch: 137 Batch: 400, loss: 12.587444160498743\n",
      "Epoch: 137 Batch: 500, loss: 15.656174079322323\n",
      "Epoch: 138 Batch: 0, loss: 5.161767090475353\n",
      "Epoch: 138 Batch: 100, loss: 4.870575370532015\n",
      "Epoch: 138 Batch: 200, loss: 8.743074799517101\n",
      "Epoch: 138 Batch: 300, loss: 6.15089269553023\n",
      "Epoch: 138 Batch: 400, loss: 96.8092528785824\n",
      "Epoch: 138 Batch: 500, loss: 0.29894187669106465\n",
      "Epoch: 139 Batch: 0, loss: 5.451112141509288\n",
      "Epoch: 139 Batch: 100, loss: 87.86364357009316\n",
      "Epoch: 139 Batch: 200, loss: 0.0006501514382950775\n",
      "Epoch: 139 Batch: 300, loss: 323.7159812797508\n",
      "Epoch: 139 Batch: 400, loss: 6.882151232434704\n",
      "Epoch: 139 Batch: 500, loss: 64.85884088255581\n",
      "Epoch: 140 Batch: 0, loss: 148.3228410076355\n",
      "Epoch: 140 Batch: 100, loss: 0.8232195917366291\n",
      "Epoch: 140 Batch: 200, loss: 1.8714622877937857\n",
      "Epoch: 140 Batch: 300, loss: 19.715420403165563\n",
      "Epoch: 140 Batch: 400, loss: 0.7317763450094408\n",
      "Epoch: 140 Batch: 500, loss: 0.01338446630508375\n",
      "Epoch: 141 Batch: 0, loss: 12.462077185839586\n",
      "Epoch: 141 Batch: 100, loss: 11.274577105681072\n",
      "Epoch: 141 Batch: 200, loss: 20.92803444504483\n",
      "Epoch: 141 Batch: 300, loss: 10.636187502488589\n",
      "Epoch: 141 Batch: 400, loss: 8.230530433026859\n",
      "Epoch: 141 Batch: 500, loss: 1.0504694417844846\n",
      "Epoch: 142 Batch: 0, loss: 88.87440675308747\n",
      "Epoch: 142 Batch: 100, loss: 35.97432686032299\n",
      "Epoch: 142 Batch: 200, loss: 115.12391310755656\n",
      "Epoch: 142 Batch: 300, loss: 1.5074944794844323\n",
      "Epoch: 142 Batch: 400, loss: 0.1084387088175503\n",
      "Epoch: 142 Batch: 500, loss: 26.345460919110277\n",
      "Epoch: 143 Batch: 0, loss: 8.664687162343517\n",
      "Epoch: 143 Batch: 100, loss: 1.4543417555221032\n",
      "Epoch: 143 Batch: 200, loss: 4.006396785837513\n",
      "Epoch: 143 Batch: 300, loss: 19.311741668368114\n",
      "Epoch: 143 Batch: 400, loss: 8.201105636156043\n",
      "Epoch: 143 Batch: 500, loss: 2.702794304129836\n",
      "Epoch: 144 Batch: 0, loss: 0.0025935876461266635\n",
      "Epoch: 144 Batch: 100, loss: 0.17638480074834292\n",
      "Epoch: 144 Batch: 200, loss: 24.960658123495183\n",
      "Epoch: 144 Batch: 300, loss: 5.310455834108428\n",
      "Epoch: 144 Batch: 400, loss: 5.1513214359725525\n",
      "Epoch: 144 Batch: 500, loss: 33.5342141628043\n",
      "Epoch: 145 Batch: 0, loss: 3.9807155811441644\n",
      "Epoch: 145 Batch: 100, loss: 31.354193793751552\n",
      "Epoch: 145 Batch: 200, loss: 25.567118965491193\n",
      "Epoch: 145 Batch: 300, loss: 0.9359699796491295\n",
      "Epoch: 145 Batch: 400, loss: 0.009748222165527681\n",
      "Epoch: 145 Batch: 500, loss: 28.989109555520418\n",
      "Epoch: 146 Batch: 0, loss: 0.6191804442943556\n",
      "Epoch: 146 Batch: 100, loss: 3.1536266365102206\n",
      "Epoch: 146 Batch: 200, loss: 308.2011296846404\n",
      "Epoch: 146 Batch: 300, loss: 4.85170780790006\n",
      "Epoch: 146 Batch: 400, loss: 33.74010656916709\n",
      "Epoch: 146 Batch: 500, loss: 38.03510158975928\n",
      "Epoch: 147 Batch: 0, loss: 25.692112766360953\n",
      "Epoch: 147 Batch: 100, loss: 202.5108540861047\n",
      "Epoch: 147 Batch: 200, loss: 309.2094882324612\n",
      "Epoch: 147 Batch: 300, loss: 16.574582832571174\n",
      "Epoch: 147 Batch: 400, loss: 5.235840532253194\n",
      "Epoch: 147 Batch: 500, loss: 0.16621237995038263\n",
      "Epoch: 148 Batch: 0, loss: 1.9380984241702326\n",
      "Epoch: 148 Batch: 100, loss: 2.7629904993596206\n",
      "Epoch: 148 Batch: 200, loss: 2.6533124322384287\n",
      "Epoch: 148 Batch: 300, loss: 100.08528113012638\n",
      "Epoch: 148 Batch: 400, loss: 14.443022680478146\n",
      "Epoch: 148 Batch: 500, loss: 1.1523305369698298\n",
      "Epoch: 149 Batch: 0, loss: 17.83148739491679\n",
      "Epoch: 149 Batch: 100, loss: 51.754410540532476\n",
      "Epoch: 149 Batch: 200, loss: 16.061760525086616\n",
      "Epoch: 149 Batch: 300, loss: 1.9176375448840932\n",
      "Epoch: 149 Batch: 400, loss: 0.04159775381880124\n",
      "Epoch: 149 Batch: 500, loss: 27.506211394025993\n",
      "Epoch: 150 Batch: 0, loss: 0.01489689699213349\n",
      "Epoch: 150 Batch: 100, loss: 7.516995815772518\n",
      "Epoch: 150 Batch: 200, loss: 0.004525191860003455\n",
      "Epoch: 150 Batch: 300, loss: 94.88752406783922\n",
      "Epoch: 150 Batch: 400, loss: 0.7871826812576888\n",
      "Epoch: 150 Batch: 500, loss: 16.50863391429218\n",
      "Epoch: 151 Batch: 0, loss: 18.0284321455677\n",
      "Epoch: 151 Batch: 100, loss: 0.19978235086910967\n",
      "Epoch: 151 Batch: 200, loss: 3.562636728399108\n",
      "Epoch: 151 Batch: 300, loss: 44.3368309713363\n",
      "Epoch: 151 Batch: 400, loss: 73.71170560293329\n",
      "Epoch: 151 Batch: 500, loss: 10.265748760929975\n",
      "Epoch: 152 Batch: 0, loss: 109.43750108808433\n",
      "Epoch: 152 Batch: 100, loss: 11.79923743854702\n",
      "Epoch: 152 Batch: 200, loss: 1.6258537404738278\n",
      "Epoch: 152 Batch: 300, loss: 16.41981254072967\n",
      "Epoch: 152 Batch: 400, loss: 0.5691247949700963\n",
      "Epoch: 152 Batch: 500, loss: 80.14625820241743\n",
      "Epoch: 153 Batch: 0, loss: 18.495310100836527\n",
      "Epoch: 153 Batch: 100, loss: 15.778799974679233\n",
      "Epoch: 153 Batch: 200, loss: 5.300820759733161\n",
      "Epoch: 153 Batch: 300, loss: 0.48888581188340124\n",
      "Epoch: 153 Batch: 400, loss: 189.41724199516898\n",
      "Epoch: 153 Batch: 500, loss: 34.042151668433526\n",
      "Epoch: 154 Batch: 0, loss: 6.64999300626414\n",
      "Epoch: 154 Batch: 100, loss: 17.801123478999855\n",
      "Epoch: 154 Batch: 200, loss: 19.73801106518594\n",
      "Epoch: 154 Batch: 300, loss: 0.0035594330132468336\n",
      "Epoch: 154 Batch: 400, loss: 47.37183361134851\n",
      "Epoch: 154 Batch: 500, loss: 2.9273583849266775\n",
      "Epoch: 155 Batch: 0, loss: 0.4229817846739218\n",
      "Epoch: 155 Batch: 100, loss: 10.436723787997453\n",
      "Epoch: 155 Batch: 200, loss: 112.5277212128693\n",
      "Epoch: 155 Batch: 300, loss: 14.852315349954749\n",
      "Epoch: 155 Batch: 400, loss: 46.70497823631061\n",
      "Epoch: 155 Batch: 500, loss: 3.4232049838050367\n",
      "Epoch: 156 Batch: 0, loss: 15.903746913391743\n",
      "Epoch: 156 Batch: 100, loss: 93.43036155830245\n",
      "Epoch: 156 Batch: 200, loss: 37.51948317274823\n",
      "Epoch: 156 Batch: 300, loss: 3.201955135729124\n",
      "Epoch: 156 Batch: 400, loss: 10.11623394131514\n",
      "Epoch: 156 Batch: 500, loss: 9.782306970408914\n",
      "Epoch: 157 Batch: 0, loss: 0.5774343385719878\n",
      "Epoch: 157 Batch: 100, loss: 1.0319369991422072\n",
      "Epoch: 157 Batch: 200, loss: 1.8140018029303617\n",
      "Epoch: 157 Batch: 300, loss: 0.02322999099208866\n",
      "Epoch: 157 Batch: 400, loss: 19.009804297573773\n",
      "Epoch: 157 Batch: 500, loss: 5.907643280999064\n",
      "Epoch: 158 Batch: 0, loss: 7.745947818924366\n",
      "Epoch: 158 Batch: 100, loss: 1.2073451472694348\n",
      "Epoch: 158 Batch: 200, loss: 3.274963226767069\n",
      "Epoch: 158 Batch: 300, loss: 11.109077847162755\n",
      "Epoch: 158 Batch: 400, loss: 6.795524772484771\n",
      "Epoch: 158 Batch: 500, loss: 1.3317627435788395\n",
      "Epoch: 159 Batch: 0, loss: 11.07216331349817\n",
      "Epoch: 159 Batch: 100, loss: 0.39630663574850894\n",
      "Epoch: 159 Batch: 200, loss: 0.0009453940715982666\n",
      "Epoch: 159 Batch: 300, loss: 11.823100009477436\n",
      "Epoch: 159 Batch: 400, loss: 22.06004314696247\n",
      "Epoch: 159 Batch: 500, loss: 67.4198566865126\n",
      "Epoch: 160 Batch: 0, loss: 0.1375782835574988\n",
      "Epoch: 160 Batch: 100, loss: 1.1013679012844406\n",
      "Epoch: 160 Batch: 200, loss: 49.166364760034995\n",
      "Epoch: 160 Batch: 300, loss: 1.6138602225693528\n",
      "Epoch: 160 Batch: 400, loss: 6.984896717915386\n",
      "Epoch: 160 Batch: 500, loss: 26.125700874786904\n",
      "Epoch: 161 Batch: 0, loss: 21.01191107342665\n",
      "Epoch: 161 Batch: 100, loss: 18.19709062745143\n",
      "Epoch: 161 Batch: 200, loss: 13.402005285124536\n",
      "Epoch: 161 Batch: 300, loss: 0.32055874277526747\n",
      "Epoch: 161 Batch: 400, loss: 0.0503638452470101\n",
      "Epoch: 161 Batch: 500, loss: 66.05760487719743\n",
      "Epoch: 162 Batch: 0, loss: 0.12412584191487104\n",
      "Epoch: 162 Batch: 100, loss: 62.81230174460983\n",
      "Epoch: 162 Batch: 200, loss: 11.086098507975517\n",
      "Epoch: 162 Batch: 300, loss: 23.890580934715498\n",
      "Epoch: 162 Batch: 400, loss: 10.120287472880374\n",
      "Epoch: 162 Batch: 500, loss: 0.3017934257260004\n",
      "Epoch: 163 Batch: 0, loss: 6.412291438841723\n",
      "Epoch: 163 Batch: 100, loss: 20.73416853791106\n",
      "Epoch: 163 Batch: 200, loss: 3.5059367247752404\n",
      "Epoch: 163 Batch: 300, loss: 6.554621478414524\n",
      "Epoch: 163 Batch: 400, loss: 11.627972222017155\n",
      "Epoch: 163 Batch: 500, loss: 316.3767282614374\n",
      "Epoch: 164 Batch: 0, loss: 61.35789044697806\n",
      "Epoch: 164 Batch: 100, loss: 3.8888908530245754\n",
      "Epoch: 164 Batch: 200, loss: 14.961997202024875\n",
      "Epoch: 164 Batch: 300, loss: 10.616004928864307\n",
      "Epoch: 164 Batch: 400, loss: 122.74212734040879\n",
      "Epoch: 164 Batch: 500, loss: 1.7102453798890096\n",
      "Epoch: 165 Batch: 0, loss: 33.22110564235398\n",
      "Epoch: 165 Batch: 100, loss: 12.66192085169836\n",
      "Epoch: 165 Batch: 200, loss: 15.679210139485761\n",
      "Epoch: 165 Batch: 300, loss: 0.9664362971287634\n",
      "Epoch: 165 Batch: 400, loss: 0.00039884918069442297\n",
      "Epoch: 165 Batch: 500, loss: 11.450102790062193\n",
      "Epoch: 166 Batch: 0, loss: 2.8317936953199268\n",
      "Epoch: 166 Batch: 100, loss: 13.36581280003438\n",
      "Epoch: 166 Batch: 200, loss: 22.661319319383118\n",
      "Epoch: 166 Batch: 300, loss: 2.629038528248296\n",
      "Epoch: 166 Batch: 400, loss: 9.442875683964784\n",
      "Epoch: 166 Batch: 500, loss: 13.246855387193145\n",
      "Epoch: 167 Batch: 0, loss: 2.9362115065918855\n",
      "Epoch: 167 Batch: 100, loss: 14.995215983467336\n",
      "Epoch: 167 Batch: 200, loss: 37.63793810436882\n",
      "Epoch: 167 Batch: 300, loss: 17.25660364808192\n",
      "Epoch: 167 Batch: 400, loss: 6.373157594328219\n",
      "Epoch: 167 Batch: 500, loss: 19.925696091947827\n",
      "Epoch: 168 Batch: 0, loss: 0.5846669952516926\n",
      "Epoch: 168 Batch: 100, loss: 91.90165739911924\n",
      "Epoch: 168 Batch: 200, loss: 10.55155602860288\n",
      "Epoch: 168 Batch: 300, loss: 1.9854348102778085\n",
      "Epoch: 168 Batch: 400, loss: 18.655995048679273\n",
      "Epoch: 168 Batch: 500, loss: 36.09907560239375\n",
      "Epoch: 169 Batch: 0, loss: 0.3758107458758244\n",
      "Epoch: 169 Batch: 100, loss: 12.496976128860794\n",
      "Epoch: 169 Batch: 200, loss: 0.21384705409868807\n",
      "Epoch: 169 Batch: 300, loss: 9.009755311438429\n",
      "Epoch: 169 Batch: 400, loss: 3.913954430965708\n",
      "Epoch: 169 Batch: 500, loss: 7.659087277512257\n",
      "Epoch: 170 Batch: 0, loss: 1.0094778597836833\n",
      "Epoch: 170 Batch: 100, loss: 6.466248560758383\n",
      "Epoch: 170 Batch: 200, loss: 30.796757216758493\n",
      "Epoch: 170 Batch: 300, loss: 0.028686707650763255\n",
      "Epoch: 170 Batch: 400, loss: 2.0212158135118568\n",
      "Epoch: 170 Batch: 500, loss: 7.605308724645735\n",
      "Epoch: 171 Batch: 0, loss: 4.970051141221537\n",
      "Epoch: 171 Batch: 100, loss: 5.420286278023082\n",
      "Epoch: 171 Batch: 200, loss: 151.93856389472273\n",
      "Epoch: 171 Batch: 300, loss: 3.5481375562707194\n",
      "Epoch: 171 Batch: 400, loss: 22.828472632363614\n",
      "Epoch: 171 Batch: 500, loss: 11.66766631987363\n",
      "Epoch: 172 Batch: 0, loss: 0.1061194671153476\n",
      "Epoch: 172 Batch: 100, loss: 14.700787741945483\n",
      "Epoch: 172 Batch: 200, loss: 16.15372320596665\n",
      "Epoch: 172 Batch: 300, loss: 26.059138997260174\n",
      "Epoch: 172 Batch: 400, loss: 72.75684143673644\n",
      "Epoch: 172 Batch: 500, loss: 0.20855216617062952\n",
      "Epoch: 173 Batch: 0, loss: 12.052000515181803\n",
      "Epoch: 173 Batch: 100, loss: 35.50774072183716\n",
      "Epoch: 173 Batch: 200, loss: 3.3384527325141016\n",
      "Epoch: 173 Batch: 300, loss: 0.4305008111712829\n",
      "Epoch: 173 Batch: 400, loss: 0.04533049713773724\n",
      "Epoch: 173 Batch: 500, loss: 1.3100235515579177\n",
      "Epoch: 174 Batch: 0, loss: 0.10218895952289964\n",
      "Epoch: 174 Batch: 100, loss: 14.827977634898135\n",
      "Epoch: 174 Batch: 200, loss: 25.43872157924075\n",
      "Epoch: 174 Batch: 300, loss: 0.027104353130055606\n",
      "Epoch: 174 Batch: 400, loss: 3.226277536201381\n",
      "Epoch: 174 Batch: 500, loss: 4.4144106988237475\n",
      "Epoch: 175 Batch: 0, loss: 1.0272889951214845\n",
      "Epoch: 175 Batch: 100, loss: 264.07866961563644\n",
      "Epoch: 175 Batch: 200, loss: 2.528694308746077\n",
      "Epoch: 175 Batch: 300, loss: 15.355818509314394\n",
      "Epoch: 175 Batch: 400, loss: 4.407698755498284\n",
      "Epoch: 175 Batch: 500, loss: 11.712037757704325\n",
      "Epoch: 176 Batch: 0, loss: 2.199392723852683\n",
      "Epoch: 176 Batch: 100, loss: 20.845438756409756\n",
      "Epoch: 176 Batch: 200, loss: 11.042742365208142\n",
      "Epoch: 176 Batch: 300, loss: 12.787989794811347\n",
      "Epoch: 176 Batch: 400, loss: 11.58845246184218\n",
      "Epoch: 176 Batch: 500, loss: 8.635569774242265\n",
      "Epoch: 177 Batch: 0, loss: 152.18052234412076\n",
      "Epoch: 177 Batch: 100, loss: 44.45724431392282\n",
      "Epoch: 177 Batch: 200, loss: 27.181789636437326\n",
      "Epoch: 177 Batch: 300, loss: 149.54760915283026\n",
      "Epoch: 177 Batch: 400, loss: 20.455393318424036\n",
      "Epoch: 177 Batch: 500, loss: 12.235714638523012\n",
      "Epoch: 178 Batch: 0, loss: 0.8064996145413469\n",
      "Epoch: 178 Batch: 100, loss: 12.697260507224874\n",
      "Epoch: 178 Batch: 200, loss: 2.432458587775159\n",
      "Epoch: 178 Batch: 300, loss: 67.02213306571959\n",
      "Epoch: 178 Batch: 400, loss: 6.28222090201551e-06\n",
      "Epoch: 178 Batch: 500, loss: 18.95505997386354\n",
      "Epoch: 179 Batch: 0, loss: 5.350807720615372\n",
      "Epoch: 179 Batch: 100, loss: 3.068277157853443\n",
      "Epoch: 179 Batch: 200, loss: 33.751292717011445\n",
      "Epoch: 179 Batch: 300, loss: 6.46240407834986\n",
      "Epoch: 179 Batch: 400, loss: 1.919114321171796\n",
      "Epoch: 179 Batch: 500, loss: 0.2329530416072651\n",
      "Epoch: 180 Batch: 0, loss: 25.902736063167477\n",
      "Epoch: 180 Batch: 100, loss: 20.371584182604405\n",
      "Epoch: 180 Batch: 200, loss: 3.2266083505453116\n",
      "Epoch: 180 Batch: 300, loss: 137.48774415817326\n",
      "Epoch: 180 Batch: 400, loss: 45.4842072149202\n",
      "Epoch: 180 Batch: 500, loss: 10.986687156502693\n",
      "Epoch: 181 Batch: 0, loss: 2.2163262807341626\n",
      "Epoch: 181 Batch: 100, loss: 6.9403852541299385\n",
      "Epoch: 181 Batch: 200, loss: 16.007369244868684\n",
      "Epoch: 181 Batch: 300, loss: 5.010419059494419\n",
      "Epoch: 181 Batch: 400, loss: 60.70479247761172\n",
      "Epoch: 181 Batch: 500, loss: 11.277221443319268\n",
      "Epoch: 182 Batch: 0, loss: 0.2549717808029019\n",
      "Epoch: 182 Batch: 100, loss: 20.2009143450835\n",
      "Epoch: 182 Batch: 200, loss: 2.287766786532198\n",
      "Epoch: 182 Batch: 300, loss: 0.965666579579603\n",
      "Epoch: 182 Batch: 400, loss: 23.510964230282895\n",
      "Epoch: 182 Batch: 500, loss: 3.853921752483931\n",
      "Epoch: 183 Batch: 0, loss: 314.28426199125107\n",
      "Epoch: 183 Batch: 100, loss: 1.5718225721765111\n",
      "Epoch: 183 Batch: 200, loss: 19.81055090546446\n",
      "Epoch: 183 Batch: 300, loss: 1.4046381320537078\n",
      "Epoch: 183 Batch: 400, loss: 0.25293408449315385\n",
      "Epoch: 183 Batch: 500, loss: 12.728677701995421\n",
      "Epoch: 184 Batch: 0, loss: 34.08589508069873\n",
      "Epoch: 184 Batch: 100, loss: 46.40011203857629\n",
      "Epoch: 184 Batch: 200, loss: 746.9924553324886\n",
      "Epoch: 184 Batch: 300, loss: 2.9840520445808427\n",
      "Epoch: 184 Batch: 400, loss: 0.47589937292604656\n",
      "Epoch: 184 Batch: 500, loss: 23.529522856959513\n",
      "Epoch: 185 Batch: 0, loss: 4.967196895390183\n",
      "Epoch: 185 Batch: 100, loss: 12.903874686647272\n",
      "Epoch: 185 Batch: 200, loss: 96.94548419306074\n",
      "Epoch: 185 Batch: 300, loss: 0.7288424200572556\n",
      "Epoch: 185 Batch: 400, loss: 0.5281355228765179\n",
      "Epoch: 185 Batch: 500, loss: 1.0458583337136382\n",
      "Epoch: 186 Batch: 0, loss: 27.675773463378665\n",
      "Epoch: 186 Batch: 100, loss: 147.5429654715169\n",
      "Epoch: 186 Batch: 200, loss: 25.37590838317151\n",
      "Epoch: 186 Batch: 300, loss: 83.13867931179355\n",
      "Epoch: 186 Batch: 400, loss: 58.446825187556186\n",
      "Epoch: 186 Batch: 500, loss: 149.55844930691956\n",
      "Epoch: 187 Batch: 0, loss: 15.276055014597999\n",
      "Epoch: 187 Batch: 100, loss: 2.2872789911491687\n",
      "Epoch: 187 Batch: 200, loss: 0.855761110373845\n",
      "Epoch: 187 Batch: 300, loss: 13.84944275205439\n",
      "Epoch: 187 Batch: 400, loss: 46.88317901604233\n",
      "Epoch: 187 Batch: 500, loss: 2.428799055551439\n",
      "Epoch: 188 Batch: 0, loss: 1.1889156631336795\n",
      "Epoch: 188 Batch: 100, loss: 0.14394121586804823\n",
      "Epoch: 188 Batch: 200, loss: 2.500203204245454\n",
      "Epoch: 188 Batch: 300, loss: 3.861859960380629\n",
      "Epoch: 188 Batch: 400, loss: 7.0505721051328365\n",
      "Epoch: 188 Batch: 500, loss: 99.66803865711029\n",
      "Epoch: 189 Batch: 0, loss: 27.65755854218119\n",
      "Epoch: 189 Batch: 100, loss: 1.8913456938409738\n",
      "Epoch: 189 Batch: 200, loss: 12.081032732225577\n",
      "Epoch: 189 Batch: 300, loss: 2.612053436030584\n",
      "Epoch: 189 Batch: 400, loss: 25.955043417706303\n",
      "Epoch: 189 Batch: 500, loss: 0.4728421299130743\n",
      "Epoch: 190 Batch: 0, loss: 58.50928714766278\n",
      "Epoch: 190 Batch: 100, loss: 3.2054517810499163\n",
      "Epoch: 190 Batch: 200, loss: 2.9799325225477493\n",
      "Epoch: 190 Batch: 300, loss: 1.9633315862480245\n",
      "Epoch: 190 Batch: 400, loss: 0.00857601521563803\n",
      "Epoch: 190 Batch: 500, loss: 2.577409503068409\n",
      "Epoch: 191 Batch: 0, loss: 6.736387710790487\n",
      "Epoch: 191 Batch: 100, loss: 0.31456339447496656\n",
      "Epoch: 191 Batch: 200, loss: 24.599163162251454\n",
      "Epoch: 191 Batch: 300, loss: 106.26959468021546\n",
      "Epoch: 191 Batch: 400, loss: 0.2902753718939026\n",
      "Epoch: 191 Batch: 500, loss: 29.23316598595646\n",
      "Epoch: 192 Batch: 0, loss: 0.147488768237518\n",
      "Epoch: 192 Batch: 100, loss: 1.748224539396072\n",
      "Epoch: 192 Batch: 200, loss: 3.9363791176855627\n",
      "Epoch: 192 Batch: 300, loss: 1.9927433740485148\n",
      "Epoch: 192 Batch: 400, loss: 21.007876794770155\n",
      "Epoch: 192 Batch: 500, loss: 1.9098604702903308\n",
      "Epoch: 193 Batch: 0, loss: 0.9606776192296417\n",
      "Epoch: 193 Batch: 100, loss: 31.99373800378345\n",
      "Epoch: 193 Batch: 200, loss: 22.5176566730506\n",
      "Epoch: 193 Batch: 300, loss: 1.136003208162874\n",
      "Epoch: 193 Batch: 400, loss: 14.041981231968009\n",
      "Epoch: 193 Batch: 500, loss: 11.280967886602147\n",
      "Epoch: 194 Batch: 0, loss: 3.9833362846889186\n",
      "Epoch: 194 Batch: 100, loss: 46.01007434551232\n",
      "Epoch: 194 Batch: 200, loss: 32.909458968262555\n",
      "Epoch: 194 Batch: 300, loss: 35.95506123579278\n",
      "Epoch: 194 Batch: 400, loss: 4.393605208792919\n",
      "Epoch: 194 Batch: 500, loss: 7.166557630499504\n",
      "Epoch: 195 Batch: 0, loss: 746.5373454742056\n",
      "Epoch: 195 Batch: 100, loss: 141.45695292009876\n",
      "Epoch: 195 Batch: 200, loss: 2.6639856112400455\n",
      "Epoch: 195 Batch: 300, loss: 0.12984100322340947\n",
      "Epoch: 195 Batch: 400, loss: 20.380001039012697\n",
      "Epoch: 195 Batch: 500, loss: 0.6036559135288762\n",
      "Epoch: 196 Batch: 0, loss: 0.26528078895884827\n",
      "Epoch: 196 Batch: 100, loss: 0.5790795891392856\n",
      "Epoch: 196 Batch: 200, loss: 5.779961286673177\n",
      "Epoch: 196 Batch: 300, loss: 3.9670207819903385\n",
      "Epoch: 196 Batch: 400, loss: 11.024222574764508\n",
      "Epoch: 196 Batch: 500, loss: 15.189789976640402\n",
      "Epoch: 197 Batch: 0, loss: 10.311701589392941\n",
      "Epoch: 197 Batch: 100, loss: 0.7655491483872181\n",
      "Epoch: 197 Batch: 200, loss: 102.56874240849953\n",
      "Epoch: 197 Batch: 300, loss: 1.2107344579494346\n",
      "Epoch: 197 Batch: 400, loss: 0.38823013452069866\n",
      "Epoch: 197 Batch: 500, loss: 2.4370192153340366\n",
      "Epoch: 198 Batch: 0, loss: 0.9560274460342474\n",
      "Epoch: 198 Batch: 100, loss: 18.45485356088647\n",
      "Epoch: 198 Batch: 200, loss: 1.910258362108452\n",
      "Epoch: 198 Batch: 300, loss: 35.57836658033716\n",
      "Epoch: 198 Batch: 400, loss: 1.1939476120051238\n",
      "Epoch: 198 Batch: 500, loss: 2.5164300745471277\n",
      "Epoch: 199 Batch: 0, loss: 7.187000800949054\n",
      "Epoch: 199 Batch: 100, loss: 88.49549590940043\n",
      "Epoch: 199 Batch: 200, loss: 17.273158888252738\n",
      "Epoch: 199 Batch: 300, loss: 0.474136869747376\n",
      "Epoch: 199 Batch: 400, loss: 52.63952070507809\n",
      "Epoch: 199 Batch: 500, loss: 0.024829543832110872\n",
      "[88.74340551]\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"297.190125pt\" version=\"1.1\" viewBox=\"0 0 397.6075 297.190125\" width=\"397.6075pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-31T10:22:51.128617</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 297.190125 \nL 397.6075 297.190125 \nL 397.6075 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 273.312 \nL 390.4075 273.312 \nL 390.4075 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mdc6b4e19fc\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.520227\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(46.338977 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"90.305974\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(83.943474 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"131.091721\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(124.729221 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.877468\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(165.514968 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"212.663215\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(203.119465 287.910437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"253.448962\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(243.905212 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.234709\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(284.690959 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"335.020456\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(325.476706 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.806203\" xlink:href=\"#mdc6b4e19fc\" y=\"273.312\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(366.262453 287.910437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m90691706d2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m90691706d2\" y=\"228.867547\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 232.666766)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m90691706d2\" y=\"172.63864\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 176.437858)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m90691706d2\" y=\"116.409732\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 120.208951)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m90691706d2\" y=\"60.180824\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 63.980043)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p11ec2e63db)\" d=\"M 49.520227 19.296 \nL 51.151657 53.687695 \nL 52.783087 121.134871 \nL 54.414517 124.400116 \nL 56.045947 162.601828 \nL 57.677377 164.86283 \nL 59.308807 193.92136 \nL 60.940236 201.168724 \nL 62.571666 220.578634 \nL 64.203096 222.045233 \nL 65.834526 221.677968 \nL 67.465956 229.651753 \nL 69.097386 232.232702 \nL 70.728816 238.276436 \nL 72.360246 248.240875 \nL 73.991675 243.155822 \nL 75.623105 241.902548 \nL 77.254535 241.301262 \nL 78.885965 250.504708 \nL 80.517395 252.135653 \nL 82.148825 250.704173 \nL 83.780255 243.328162 \nL 85.411685 248.670204 \nL 87.043114 251.94322 \nL 88.674544 252.0451 \nL 90.305974 245.739579 \nL 91.937404 261.216 \nL 93.568834 249.393728 \nL 95.200264 243.19426 \nL 96.831694 251.601489 \nL 98.463124 255.469404 \nL 100.094553 251.569266 \nL 101.725983 253.74341 \nL 103.357413 244.991208 \nL 104.988843 250.960657 \nL 106.620273 250.184554 \nL 108.251703 246.333121 \nL 109.883133 249.79731 \nL 111.514563 249.562664 \nL 113.145992 250.833917 \nL 114.777422 247.752808 \nL 116.408852 248.904596 \nL 118.040282 249.764233 \nL 119.671712 246.746006 \nL 121.303142 248.10964 \nL 122.934572 246.36653 \nL 124.566002 247.377652 \nL 126.197431 246.945132 \nL 127.828861 250.313394 \nL 129.460291 248.746025 \nL 131.091721 250.820008 \nL 132.723151 245.230965 \nL 134.354581 251.200358 \nL 135.986011 250.171046 \nL 137.617441 247.53517 \nL 139.24887 248.691531 \nL 140.8803 253.257428 \nL 142.51173 251.32122 \nL 144.14316 243.615443 \nL 145.77459 254.466785 \nL 147.40602 244.363124 \nL 149.03745 247.842232 \nL 150.66888 242.685021 \nL 152.30031 250.458918 \nL 153.931739 249.076816 \nL 155.563169 251.246237 \nL 157.194599 244.964188 \nL 158.826029 248.865978 \nL 160.457459 250.962481 \nL 162.088889 250.912176 \nL 163.720319 245.933633 \nL 165.351749 248.57475 \nL 166.983178 246.989645 \nL 168.614608 250.233073 \nL 170.246038 255.598329 \nL 171.877468 251.158935 \nL 173.508898 248.998935 \nL 175.140328 252.842143 \nL 176.771758 248.216059 \nL 178.403188 250.560663 \nL 180.034617 251.48312 \nL 181.666047 250.330394 \nL 183.297477 252.990687 \nL 184.928907 244.021067 \nL 188.191767 246.726061 \nL 189.823197 254.296307 \nL 191.454627 249.926329 \nL 193.086056 252.927885 \nL 194.717486 249.431954 \nL 196.348916 252.854756 \nL 197.980346 241.89348 \nL 199.611776 244.25427 \nL 201.243206 252.433981 \nL 202.874636 251.245199 \nL 204.506066 250.509692 \nL 207.768925 242.108272 \nL 209.400355 252.389513 \nL 211.031785 249.757383 \nL 212.663215 249.443813 \nL 214.294645 256.600789 \nL 215.926075 248.419208 \nL 217.557505 250.047668 \nL 219.188934 245.0878 \nL 220.820364 249.881413 \nL 222.451794 245.102747 \nL 224.083224 250.360658 \nL 225.714654 250.269349 \nL 227.346084 252.67628 \nL 228.977514 250.863053 \nL 230.608944 253.531578 \nL 232.240373 247.692446 \nL 233.871803 255.674477 \nL 235.503233 244.98513 \nL 237.134663 254.659845 \nL 238.766093 248.785234 \nL 240.397523 246.3821 \nL 242.028953 256.375164 \nL 243.660383 247.373874 \nL 245.291812 248.480095 \nL 246.923242 248.090235 \nL 248.554672 248.901523 \nL 250.186102 253.671962 \nL 251.817532 252.312975 \nL 253.448962 254.183231 \nL 255.080392 253.195096 \nL 256.711822 251.327489 \nL 258.343251 248.370396 \nL 259.974681 254.754742 \nL 261.606111 254.635976 \nL 263.237541 255.498355 \nL 264.868971 246.205234 \nL 266.500401 249.273799 \nL 268.131831 257.865028 \nL 269.763261 250.939041 \nL 271.39469 254.60786 \nL 273.02612 256.673879 \nL 274.65755 259.48753 \nL 276.28898 249.479835 \nL 277.92041 251.335804 \nL 279.55184 253.686789 \nL 281.18327 253.797168 \nL 282.8147 245.13326 \nL 284.44613 254.453345 \nL 286.077559 253.228269 \nL 287.708989 250.323664 \nL 289.340419 247.058008 \nL 290.971849 246.817129 \nL 292.603279 255.627289 \nL 294.234709 250.663272 \nL 295.866139 243.414359 \nL 297.497569 255.234764 \nL 299.128998 252.047789 \nL 300.760428 256.06457 \nL 302.391858 245.226557 \nL 304.023288 248.733006 \nL 305.654718 246.295473 \nL 307.286148 257.008713 \nL 308.917578 254.787339 \nL 312.180437 251.328712 \nL 313.811867 251.043801 \nL 315.443297 252.126194 \nL 317.074727 250.43698 \nL 318.706157 252.993038 \nL 320.337587 252.124861 \nL 321.969017 249.620349 \nL 323.600447 242.814652 \nL 325.231876 245.003273 \nL 326.863306 253.047793 \nL 328.494736 253.267165 \nL 330.126166 250.902377 \nL 331.757596 254.634417 \nL 333.389026 254.39613 \nL 335.020456 252.975131 \nL 336.651886 252.531596 \nL 338.283315 250.878489 \nL 339.914745 250.242923 \nL 341.546175 251.02274 \nL 343.177605 252.021787 \nL 344.809035 250.91496 \nL 346.440465 253.115153 \nL 348.071895 252.912529 \nL 349.703325 252.934925 \nL 351.334754 254.904697 \nL 352.966184 250.52063 \nL 354.597614 249.541086 \nL 356.229044 246.793309 \nL 357.860474 247.530039 \nL 359.491904 246.863057 \nL 361.123334 257.959243 \nL 362.754764 245.578673 \nL 364.386193 250.257363 \nL 366.017623 248.83647 \nL 367.649053 249.499678 \nL 369.280483 248.973319 \nL 370.911913 242.660134 \nL 372.543343 255.5856 \nL 374.174773 246.622573 \nL 374.174773 246.622573 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.2875 273.312 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 390.4075 273.312 \nL 390.4075 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.2875 273.312 \nL 390.4075 273.312 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.2875 7.2 \nL 390.4075 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p11ec2e63db\">\n   <rect height=\"266.112\" width=\"357.12\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Logstic Regression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "\"\"\"\n",
    "Linear Regression: 实现了回归，其中包括线性函数的定义，为什么要用线性函数，loss的意义，梯度下降的意义，stochastic gradient descent\n",
    "Use Boston house price dataset.\n",
    "北京2020年房价的数据集，为什么我没有用北京房价的数据集呢？\n",
    "Boston: room size, subway, highway, crime rate 有一个比较明显的关系，所以就观察关系比较容易\n",
    "北京的房价：！远近，！房况 ==》 学区！！！！ => 非常贵 海淀区\n",
    "Harder than deep learning:\n",
    "    1. compiler\n",
    "    2. programming language & automata\n",
    "    3. computer graphic\n",
    "    4. complexity system\n",
    "    5. computing complexity\n",
    "    6. operating system\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nLinear Regression: 实现了回归，其中包括线性函数的定义，为什么要用线性函数，loss的意义，梯度下降的意义，stochastic gradient descent\\nUse Boston house price dataset.\\n北京2020年房价的数据集，为什么我没有用北京房价的数据集呢？\\nBoston: room size, subway, highway, crime rate 有一个比较明显的关系，所以就观察关系比较容易\\n北京的房价：！远近，！房况 ==》 学区！！！！ => 非常贵 海淀区\\nHarder than deep learning:\\n    1. compiler\\n    2. programming language & automata\\n    3. computer graphic\\n    4. complexity system\\n    5. computing complexity\\n    6. operating system\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "dataset = load_boston()\n",
    "data = dataset['data']\n",
    "target = dataset['target']\n",
    "columns = dataset['feature_names']\n",
    "\n",
    "dataframe = pd.DataFrame(data)\n",
    "dataframe.columns = columns\n",
    "dataframe['price'] = target\n",
    "\n",
    "# print(dataframe.corr()) # show the correlation of dataframe variables\n",
    "# correlation => 如果一个值的增大，会引起另外一个值一定增大，而且是定比例增大 相关系数就越接近于1\n",
    "# correlation => 0 就是两者之间没有任何关系\n",
    "# correlation => -1 一个值增大 另外一个值一定减小 而且减小是成相等比例的\n",
    "\n",
    "# sns.heatmap(dataframe.corr())\n",
    "# plt.show()\n",
    "\n",
    "# RM：小区平均的卧室个数\n",
    "# LSTAT: 低收入人群在周围的比例\n",
    "\n",
    "rm = dataframe['RM']\n",
    "lstat = dataframe['LSTAT']\n",
    "price = dataframe['price']\n",
    "greater_then_most = np.percentile(price, 66)\n",
    "dataframe['expensive'] = dataframe['price'].apply(lambda p: int(p > greater_then_most))\n",
    "target = dataframe['expensive']\n",
    "\n",
    "print(dataframe[:20])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
      "0   0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
      "1   0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
      "2   0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
      "3   0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
      "4   0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
      "5   0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
      "6   0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
      "7   0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
      "8   0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
      "9   0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
      "10  0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467  5.0  311.0   \n",
      "11  0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267  5.0  311.0   \n",
      "12  0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509  5.0  311.0   \n",
      "13  0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075  4.0  307.0   \n",
      "14  0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619  4.0  307.0   \n",
      "15  0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986  4.0  307.0   \n",
      "16  1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986  4.0  307.0   \n",
      "17  0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579  4.0  307.0   \n",
      "18  0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965  4.0  307.0   \n",
      "19  0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965  4.0  307.0   \n",
      "\n",
      "    PTRATIO       B  LSTAT  price  expensive  \n",
      "0      15.3  396.90   4.98   24.0          1  \n",
      "1      17.8  396.90   9.14   21.6          0  \n",
      "2      17.8  392.83   4.03   34.7          1  \n",
      "3      18.7  394.63   2.94   33.4          1  \n",
      "4      18.7  396.90   5.33   36.2          1  \n",
      "5      18.7  394.12   5.21   28.7          1  \n",
      "6      15.2  395.60  12.43   22.9          0  \n",
      "7      15.2  396.90  19.15   27.1          1  \n",
      "8      15.2  386.63  29.93   16.5          0  \n",
      "9      15.2  386.71  17.10   18.9          0  \n",
      "10     15.2  392.52  20.45   15.0          0  \n",
      "11     15.2  396.90  13.27   18.9          0  \n",
      "12     15.2  390.50  15.71   21.7          0  \n",
      "13     21.0  396.90   8.26   20.4          0  \n",
      "14     21.0  380.02  10.26   18.2          0  \n",
      "15     21.0  395.62   8.47   19.9          0  \n",
      "16     21.0  386.85   6.58   23.1          0  \n",
      "17     21.0  386.75  14.67   17.5          0  \n",
      "18     21.0  288.99  11.69   20.2          0  \n",
      "19     21.0  390.95  11.28   18.2          0  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def model(x, w, b):\n",
    "    return sigmoid(np.dot(x, w.T) + b)\n",
    "\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return -np.sum(y*np.log(yhat) + (1 - y)*np.log(1 - yhat))\n",
    "\n",
    "\n",
    "def partial_w(x, y, yhat):\n",
    "    return np.array([np.sum((yhat - y) * x[0]), np.sum((yhat - y) * x[1])])\n",
    "\n",
    "\n",
    "def partial_b(x, y, yhat):\n",
    "    return np.sum((yhat - y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "\n",
    "model, w, b, losses = train(model, target,loss, partial_w, partial_b)\n",
    "\n",
    "random_test_indices = np.random.choice(range(len(rm)), size=100)\n",
    "decision_boundary = 0.5"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 Batch: 0, loss: 5.380792320433632\n",
      "Epoch: 0 Batch: 100, loss: 4.821708458450062\n",
      "Epoch: 0 Batch: 200, loss: 0.009970051372436815\n",
      "Epoch: 0 Batch: 300, loss: 0.007276578288854888\n",
      "Epoch: 0 Batch: 400, loss: 0.008371349455533252\n",
      "Epoch: 0 Batch: 500, loss: 4.439392817690861\n",
      "Epoch: 1 Batch: 0, loss: 0.0057417844585807625\n",
      "Epoch: 1 Batch: 100, loss: 4.0672693147995975\n",
      "Epoch: 1 Batch: 200, loss: 4.3388231170015805\n",
      "Epoch: 1 Batch: 300, loss: 3.9678430939219997\n",
      "Epoch: 1 Batch: 400, loss: 3.8457306703880336\n",
      "Epoch: 1 Batch: 500, loss: 0.018338303952971355\n",
      "Epoch: 2 Batch: 0, loss: 3.420840235954716\n",
      "Epoch: 2 Batch: 100, loss: 0.03059785100883833\n",
      "Epoch: 2 Batch: 200, loss: 0.01311801914872309\n",
      "Epoch: 2 Batch: 300, loss: 3.20868533902604\n",
      "Epoch: 2 Batch: 400, loss: 0.01855035024291908\n",
      "Epoch: 2 Batch: 500, loss: 0.028177909778007017\n",
      "Epoch: 3 Batch: 0, loss: 3.5804308101600375\n",
      "Epoch: 3 Batch: 100, loss: 2.708057456536129\n",
      "Epoch: 3 Batch: 200, loss: 3.0363565059324196\n",
      "Epoch: 3 Batch: 300, loss: 1.866795909184806\n",
      "Epoch: 3 Batch: 400, loss: 1.0278640227571683\n",
      "Epoch: 3 Batch: 500, loss: 2.0265007514813385\n",
      "Epoch: 4 Batch: 0, loss: 0.030447845698670515\n",
      "Epoch: 4 Batch: 100, loss: 2.7344749278036633\n",
      "Epoch: 4 Batch: 200, loss: 0.03895850225016091\n",
      "Epoch: 4 Batch: 300, loss: 0.036368943928910366\n",
      "Epoch: 4 Batch: 400, loss: 2.069721603442639\n",
      "Epoch: 4 Batch: 500, loss: 2.497187814677821\n",
      "Epoch: 5 Batch: 0, loss: 2.2136688140002176\n",
      "Epoch: 5 Batch: 100, loss: 0.03318203866766176\n",
      "Epoch: 5 Batch: 200, loss: 1.642885193462861\n",
      "Epoch: 5 Batch: 300, loss: 1.4585656759624122\n",
      "Epoch: 5 Batch: 400, loss: 0.0714424541683665\n",
      "Epoch: 5 Batch: 500, loss: 0.035133709726208946\n",
      "Epoch: 6 Batch: 0, loss: 0.09205770009720385\n",
      "Epoch: 6 Batch: 100, loss: 0.032356528684140524\n",
      "Epoch: 6 Batch: 200, loss: 1.8143331032534296\n",
      "Epoch: 6 Batch: 300, loss: 0.6626717694983573\n",
      "Epoch: 6 Batch: 400, loss: 1.4186235052663205\n",
      "Epoch: 6 Batch: 500, loss: 0.02413806956328395\n",
      "Epoch: 7 Batch: 0, loss: 1.0275720406929458\n",
      "Epoch: 7 Batch: 100, loss: 1.0083770457017576\n",
      "Epoch: 7 Batch: 200, loss: 0.15391802921611594\n",
      "Epoch: 7 Batch: 300, loss: 0.01577627267065096\n",
      "Epoch: 7 Batch: 400, loss: 1.6040958705362491\n",
      "Epoch: 7 Batch: 500, loss: 0.6927445037327032\n",
      "Epoch: 8 Batch: 0, loss: 0.02776882015079546\n",
      "Epoch: 8 Batch: 100, loss: 0.8754746353236733\n",
      "Epoch: 8 Batch: 200, loss: 0.009296903476775838\n",
      "Epoch: 8 Batch: 300, loss: 0.03266595362288707\n",
      "Epoch: 8 Batch: 400, loss: 0.4033590221093798\n",
      "Epoch: 8 Batch: 500, loss: 1.7697523246827371\n",
      "Epoch: 9 Batch: 0, loss: 0.09631158788609226\n",
      "Epoch: 9 Batch: 100, loss: 1.156479527081582\n",
      "Epoch: 9 Batch: 200, loss: 2.087331538008202\n",
      "Epoch: 9 Batch: 300, loss: 0.07064875972106865\n",
      "Epoch: 9 Batch: 400, loss: 0.098260836860656\n",
      "Epoch: 9 Batch: 500, loss: 2.414391642621165\n",
      "Epoch: 10 Batch: 0, loss: 1.9465375348445775\n",
      "Epoch: 10 Batch: 100, loss: 0.07224351520452191\n",
      "Epoch: 10 Batch: 200, loss: 0.06316855345374921\n",
      "Epoch: 10 Batch: 300, loss: 0.07925923796698316\n",
      "Epoch: 10 Batch: 400, loss: 0.13837769670564937\n",
      "Epoch: 10 Batch: 500, loss: 0.07379928764271589\n",
      "Epoch: 11 Batch: 0, loss: 0.232784172392302\n",
      "Epoch: 11 Batch: 100, loss: 0.20090682898428694\n",
      "Epoch: 11 Batch: 200, loss: 0.051173010030841605\n",
      "Epoch: 11 Batch: 300, loss: 0.0008708399663208575\n",
      "Epoch: 11 Batch: 400, loss: 0.33321527557782127\n",
      "Epoch: 11 Batch: 500, loss: 0.10696250123002608\n",
      "Epoch: 12 Batch: 0, loss: 0.8727761023045538\n",
      "Epoch: 12 Batch: 100, loss: 0.06119314961094128\n",
      "Epoch: 12 Batch: 200, loss: 0.7521748971966725\n",
      "Epoch: 12 Batch: 300, loss: 1.0478149193641821\n",
      "Epoch: 12 Batch: 400, loss: 0.02075665545021403\n",
      "Epoch: 12 Batch: 500, loss: 0.03962548009023739\n",
      "Epoch: 13 Batch: 0, loss: 0.21924641200819875\n",
      "Epoch: 13 Batch: 100, loss: 0.2889368476553469\n",
      "Epoch: 13 Batch: 200, loss: 0.568203057503268\n",
      "Epoch: 13 Batch: 300, loss: 1.4212063898141871\n",
      "Epoch: 13 Batch: 400, loss: 0.3451420224463932\n",
      "Epoch: 13 Batch: 500, loss: 0.10007573734603599\n",
      "Epoch: 14 Batch: 0, loss: 0.1359898523248599\n",
      "Epoch: 14 Batch: 100, loss: 1.1949388694950585\n",
      "Epoch: 14 Batch: 200, loss: 0.03553296257637123\n",
      "Epoch: 14 Batch: 300, loss: 0.7073782487482271\n",
      "Epoch: 14 Batch: 400, loss: 1.1091371151391702\n",
      "Epoch: 14 Batch: 500, loss: 0.17982998283657411\n",
      "Epoch: 15 Batch: 0, loss: 0.12991626656483163\n",
      "Epoch: 15 Batch: 100, loss: 0.7388569467743201\n",
      "Epoch: 15 Batch: 200, loss: 0.028419163037624113\n",
      "Epoch: 15 Batch: 300, loss: 0.426246275029529\n",
      "Epoch: 15 Batch: 400, loss: 2.58202625264882\n",
      "Epoch: 15 Batch: 500, loss: 0.07418922198070305\n",
      "Epoch: 16 Batch: 0, loss: 0.9092124958859726\n",
      "Epoch: 16 Batch: 100, loss: 0.06637470102098776\n",
      "Epoch: 16 Batch: 200, loss: 0.14842987514954617\n",
      "Epoch: 16 Batch: 300, loss: 0.08770534738609649\n",
      "Epoch: 16 Batch: 400, loss: 0.8770542467230436\n",
      "Epoch: 16 Batch: 500, loss: 0.049150579169326844\n",
      "Epoch: 17 Batch: 0, loss: 0.8240133178618176\n",
      "Epoch: 17 Batch: 100, loss: 0.0536109270607212\n",
      "Epoch: 17 Batch: 200, loss: 0.4292530958792331\n",
      "Epoch: 17 Batch: 300, loss: 0.07401808757788984\n",
      "Epoch: 17 Batch: 400, loss: 0.4035446451645505\n",
      "Epoch: 17 Batch: 500, loss: 0.000993276495402985\n",
      "Epoch: 18 Batch: 0, loss: 0.08596377536701236\n",
      "Epoch: 18 Batch: 100, loss: 0.9296692453742578\n",
      "Epoch: 18 Batch: 200, loss: 0.056125587886364445\n",
      "Epoch: 18 Batch: 300, loss: 0.16519511261990744\n",
      "Epoch: 18 Batch: 400, loss: 0.6498145892004564\n",
      "Epoch: 18 Batch: 500, loss: 0.6337788228290931\n",
      "Epoch: 19 Batch: 0, loss: 0.3873952572619042\n",
      "Epoch: 19 Batch: 100, loss: 1.4370397668714199\n",
      "Epoch: 19 Batch: 200, loss: 0.398032165555517\n",
      "Epoch: 19 Batch: 300, loss: 1.276432096582268\n",
      "Epoch: 19 Batch: 400, loss: 0.3065446308624019\n",
      "Epoch: 19 Batch: 500, loss: 0.06817115704708787\n",
      "Epoch: 20 Batch: 0, loss: 0.373063907435357\n",
      "Epoch: 20 Batch: 100, loss: 0.029054789232553738\n",
      "Epoch: 20 Batch: 200, loss: 0.00370084971367833\n",
      "Epoch: 20 Batch: 300, loss: 0.12027008482472462\n",
      "Epoch: 20 Batch: 400, loss: 0.05107814303310267\n",
      "Epoch: 20 Batch: 500, loss: 1.5098616840236487\n",
      "Epoch: 21 Batch: 0, loss: 0.24563600438505243\n",
      "Epoch: 21 Batch: 100, loss: 0.01644693294337069\n",
      "Epoch: 21 Batch: 200, loss: 0.22317381341594078\n",
      "Epoch: 21 Batch: 300, loss: 0.5001362427826384\n",
      "Epoch: 21 Batch: 400, loss: 0.06480818802599922\n",
      "Epoch: 21 Batch: 500, loss: 0.7422613501729928\n",
      "Epoch: 22 Batch: 0, loss: 0.24475908679772557\n",
      "Epoch: 22 Batch: 100, loss: 0.13272501329007813\n",
      "Epoch: 22 Batch: 200, loss: 0.005972692706830083\n",
      "Epoch: 22 Batch: 300, loss: 0.22855372338211205\n",
      "Epoch: 22 Batch: 400, loss: 0.13334006858863373\n",
      "Epoch: 22 Batch: 500, loss: 0.000239998817884512\n",
      "Epoch: 23 Batch: 0, loss: 0.11752592993542688\n",
      "Epoch: 23 Batch: 100, loss: 0.13606094136008087\n",
      "Epoch: 23 Batch: 200, loss: 0.00536480795142386\n",
      "Epoch: 23 Batch: 300, loss: 0.03708978346420309\n",
      "Epoch: 23 Batch: 400, loss: 0.76244183246656\n",
      "Epoch: 23 Batch: 500, loss: 0.15783921113445118\n",
      "Epoch: 24 Batch: 0, loss: 0.3349537667183777\n",
      "Epoch: 24 Batch: 100, loss: 0.890120373266175\n",
      "Epoch: 24 Batch: 200, loss: 0.11450832994807382\n",
      "Epoch: 24 Batch: 300, loss: 0.03402784363077725\n",
      "Epoch: 24 Batch: 400, loss: 0.07568625655498395\n",
      "Epoch: 24 Batch: 500, loss: 0.22628202251795929\n",
      "Epoch: 25 Batch: 0, loss: 1.0801466452899198\n",
      "Epoch: 25 Batch: 100, loss: 0.049052842981610736\n",
      "Epoch: 25 Batch: 200, loss: 0.12306907458384234\n",
      "Epoch: 25 Batch: 300, loss: 0.43230597324169573\n",
      "Epoch: 25 Batch: 400, loss: 0.004607513133209891\n",
      "Epoch: 25 Batch: 500, loss: 0.01906157182585967\n",
      "Epoch: 26 Batch: 0, loss: 0.1586670893742628\n",
      "Epoch: 26 Batch: 100, loss: 0.4435564579721588\n",
      "Epoch: 26 Batch: 200, loss: 0.04808203891845973\n",
      "Epoch: 26 Batch: 300, loss: 0.0013964875231573574\n",
      "Epoch: 26 Batch: 400, loss: 1.1038873712217971\n",
      "Epoch: 26 Batch: 500, loss: 0.008595282378324258\n",
      "Epoch: 27 Batch: 0, loss: 0.11327990470298213\n",
      "Epoch: 27 Batch: 100, loss: 0.024554282846741615\n",
      "Epoch: 27 Batch: 200, loss: 0.10246433270678641\n",
      "Epoch: 27 Batch: 300, loss: 0.8934171484181477\n",
      "Epoch: 27 Batch: 400, loss: 0.04330263472447696\n",
      "Epoch: 27 Batch: 500, loss: 0.12896234357264966\n",
      "Epoch: 28 Batch: 0, loss: 0.15160640187022967\n",
      "Epoch: 28 Batch: 100, loss: 0.7523133402488935\n",
      "Epoch: 28 Batch: 200, loss: 0.6335566040330416\n",
      "Epoch: 28 Batch: 300, loss: 0.37566281840844445\n",
      "Epoch: 28 Batch: 400, loss: 0.09099841655472346\n",
      "Epoch: 28 Batch: 500, loss: 1.15894447533203\n",
      "Epoch: 29 Batch: 0, loss: 0.00010285661972349887\n",
      "Epoch: 29 Batch: 100, loss: 0.48737912137932\n",
      "Epoch: 29 Batch: 200, loss: 0.1093564553646189\n",
      "Epoch: 29 Batch: 300, loss: 0.34160730046217763\n",
      "Epoch: 29 Batch: 400, loss: 0.3751450195645035\n",
      "Epoch: 29 Batch: 500, loss: 0.568621845355148\n",
      "Epoch: 30 Batch: 0, loss: 0.2382797580808784\n",
      "Epoch: 30 Batch: 100, loss: 0.03404554244704742\n",
      "Epoch: 30 Batch: 200, loss: 0.5582632838636892\n",
      "Epoch: 30 Batch: 300, loss: 0.140393818501955\n",
      "Epoch: 30 Batch: 400, loss: 0.022664094195223188\n",
      "Epoch: 30 Batch: 500, loss: 0.8340329418994238\n",
      "Epoch: 31 Batch: 0, loss: 0.6120551443508871\n",
      "Epoch: 31 Batch: 100, loss: 0.02357221566945815\n",
      "Epoch: 31 Batch: 200, loss: 0.1049981723840866\n",
      "Epoch: 31 Batch: 300, loss: 0.043256077684848356\n",
      "Epoch: 31 Batch: 400, loss: 0.060601757327674394\n",
      "Epoch: 31 Batch: 500, loss: 0.037485050652102614\n",
      "Epoch: 32 Batch: 0, loss: 0.15586141123703914\n",
      "Epoch: 32 Batch: 100, loss: 1.4216453299519873\n",
      "Epoch: 32 Batch: 200, loss: 0.006219954547916304\n",
      "Epoch: 32 Batch: 300, loss: 0.16007129034665812\n",
      "Epoch: 32 Batch: 400, loss: 0.31265408791350574\n",
      "Epoch: 32 Batch: 500, loss: 0.3754883844481008\n",
      "Epoch: 33 Batch: 0, loss: 0.0877495252222309\n",
      "Epoch: 33 Batch: 100, loss: 0.4105045295604948\n",
      "Epoch: 33 Batch: 200, loss: 0.0856444832803707\n",
      "Epoch: 33 Batch: 300, loss: 0.420501741847677\n",
      "Epoch: 33 Batch: 400, loss: 0.8208493304491838\n",
      "Epoch: 33 Batch: 500, loss: 0.46776386094543154\n",
      "Epoch: 34 Batch: 0, loss: 0.0006428002612593602\n",
      "Epoch: 34 Batch: 100, loss: 0.10967624397286177\n",
      "Epoch: 34 Batch: 200, loss: 0.30940069735953335\n",
      "Epoch: 34 Batch: 300, loss: 0.03802045436693299\n",
      "Epoch: 34 Batch: 400, loss: 0.03101465810956315\n",
      "Epoch: 34 Batch: 500, loss: 0.4317427793919286\n",
      "Epoch: 35 Batch: 0, loss: 0.07740682474451789\n",
      "Epoch: 35 Batch: 100, loss: 0.00860881849047615\n",
      "Epoch: 35 Batch: 200, loss: 0.13100288582280242\n",
      "Epoch: 35 Batch: 300, loss: 0.08243288634313986\n",
      "Epoch: 35 Batch: 400, loss: 0.581494555792847\n",
      "Epoch: 35 Batch: 500, loss: 0.03679635985894317\n",
      "Epoch: 36 Batch: 0, loss: 0.004134967458239972\n",
      "Epoch: 36 Batch: 100, loss: 0.8960933052432662\n",
      "Epoch: 36 Batch: 200, loss: 0.17009359034408422\n",
      "Epoch: 36 Batch: 300, loss: 0.39875008433183184\n",
      "Epoch: 36 Batch: 400, loss: 0.6691650142437764\n",
      "Epoch: 36 Batch: 500, loss: 0.058511590487068874\n",
      "Epoch: 37 Batch: 0, loss: 0.792952390064864\n",
      "Epoch: 37 Batch: 100, loss: 0.008161495191235359\n",
      "Epoch: 37 Batch: 200, loss: 0.0001465199655606639\n",
      "Epoch: 37 Batch: 300, loss: 0.028880884316987338\n",
      "Epoch: 37 Batch: 400, loss: 0.05465542491697647\n",
      "Epoch: 37 Batch: 500, loss: 1.8197405134237792\n",
      "Epoch: 38 Batch: 0, loss: 0.39820703714933053\n",
      "Epoch: 38 Batch: 100, loss: 0.011643573863595852\n",
      "Epoch: 38 Batch: 200, loss: 0.0021097135455813406\n",
      "Epoch: 38 Batch: 300, loss: 0.32970403901433526\n",
      "Epoch: 38 Batch: 400, loss: 0.0007247044127706879\n",
      "Epoch: 38 Batch: 500, loss: 0.11153319104972974\n",
      "Epoch: 39 Batch: 0, loss: 0.28196727728932436\n",
      "Epoch: 39 Batch: 100, loss: 0.140363231954698\n",
      "Epoch: 39 Batch: 200, loss: 0.0034857342436920677\n",
      "Epoch: 39 Batch: 300, loss: 0.00028774109069589014\n",
      "Epoch: 39 Batch: 400, loss: 0.4202102722785765\n",
      "Epoch: 39 Batch: 500, loss: 0.06901424770833518\n",
      "Epoch: 40 Batch: 0, loss: 0.0721541752715178\n",
      "Epoch: 40 Batch: 100, loss: 1.2355458470488674\n",
      "Epoch: 40 Batch: 200, loss: 2.878862306167949e-05\n",
      "Epoch: 40 Batch: 300, loss: 0.2210442976179973\n",
      "Epoch: 40 Batch: 400, loss: 0.4427002274406925\n",
      "Epoch: 40 Batch: 500, loss: 0.0008254838292630266\n",
      "Epoch: 41 Batch: 0, loss: 0.018472999077047036\n",
      "Epoch: 41 Batch: 100, loss: 0.04445054401301446\n",
      "Epoch: 41 Batch: 200, loss: 0.05068203907529665\n",
      "Epoch: 41 Batch: 300, loss: 0.010933267798149442\n",
      "Epoch: 41 Batch: 400, loss: 0.04579123144729709\n",
      "Epoch: 41 Batch: 500, loss: 0.10522141230797098\n",
      "Epoch: 42 Batch: 0, loss: 1.3393113622364354\n",
      "Epoch: 42 Batch: 100, loss: 0.28787963326211313\n",
      "Epoch: 42 Batch: 200, loss: 0.23835024977452082\n",
      "Epoch: 42 Batch: 300, loss: 0.03787898075757065\n",
      "Epoch: 42 Batch: 400, loss: 0.2654644005146695\n",
      "Epoch: 42 Batch: 500, loss: 0.891557564727534\n",
      "Epoch: 43 Batch: 0, loss: 0.07724479758298793\n",
      "Epoch: 43 Batch: 100, loss: 2.4662332572489536\n",
      "Epoch: 43 Batch: 200, loss: 0.0825994685138938\n",
      "Epoch: 43 Batch: 300, loss: 0.08897621904327974\n",
      "Epoch: 43 Batch: 400, loss: 0.02441919123187305\n",
      "Epoch: 43 Batch: 500, loss: 0.16662364227221768\n",
      "Epoch: 44 Batch: 0, loss: 0.42089955118600847\n",
      "Epoch: 44 Batch: 100, loss: 0.0016485007630003287\n",
      "Epoch: 44 Batch: 200, loss: 5.460617633361888e-06\n",
      "Epoch: 44 Batch: 300, loss: 0.04306481200588759\n",
      "Epoch: 44 Batch: 400, loss: 0.22782358082066412\n",
      "Epoch: 44 Batch: 500, loss: 0.332830643422904\n",
      "Epoch: 45 Batch: 0, loss: 0.9431762924826259\n",
      "Epoch: 45 Batch: 100, loss: 0.04032930630478969\n",
      "Epoch: 45 Batch: 200, loss: 0.0872422594101995\n",
      "Epoch: 45 Batch: 300, loss: 0.2708511285090915\n",
      "Epoch: 45 Batch: 400, loss: 9.412507246707485e-05\n",
      "Epoch: 45 Batch: 500, loss: 0.07392269707794603\n",
      "Epoch: 46 Batch: 0, loss: 0.05965725729149934\n",
      "Epoch: 46 Batch: 100, loss: 0.18076000979964038\n",
      "Epoch: 46 Batch: 200, loss: 0.48574434767050734\n",
      "Epoch: 46 Batch: 300, loss: 0.011735853904358362\n",
      "Epoch: 46 Batch: 400, loss: 0.3840265582545035\n",
      "Epoch: 46 Batch: 500, loss: 0.05578523506430665\n",
      "Epoch: 47 Batch: 0, loss: 0.017728916149623568\n",
      "Epoch: 47 Batch: 100, loss: 0.026768782555280167\n",
      "Epoch: 47 Batch: 200, loss: 0.8904562543970188\n",
      "Epoch: 47 Batch: 300, loss: 0.0002439021725958037\n",
      "Epoch: 47 Batch: 400, loss: 0.04792852962924521\n",
      "Epoch: 47 Batch: 500, loss: 0.685518962640891\n",
      "Epoch: 48 Batch: 0, loss: 0.01625591171904248\n",
      "Epoch: 48 Batch: 100, loss: 0.37333512421224874\n",
      "Epoch: 48 Batch: 200, loss: 0.0012568311085292424\n",
      "Epoch: 48 Batch: 300, loss: 1.0094409114951708\n",
      "Epoch: 48 Batch: 400, loss: 0.9435825812586521\n",
      "Epoch: 48 Batch: 500, loss: 0.20948924008973938\n",
      "Epoch: 49 Batch: 0, loss: 0.2740870054279454\n",
      "Epoch: 49 Batch: 100, loss: 2.5100186516494588e-05\n",
      "Epoch: 49 Batch: 200, loss: 0.27058935567750814\n",
      "Epoch: 49 Batch: 300, loss: 0.03254751793683135\n",
      "Epoch: 49 Batch: 400, loss: 0.034228957252145996\n",
      "Epoch: 49 Batch: 500, loss: 0.21538521888070725\n",
      "Epoch: 50 Batch: 0, loss: 9.07957889365642e-05\n",
      "Epoch: 50 Batch: 100, loss: 0.6146201541187455\n",
      "Epoch: 50 Batch: 200, loss: 2.484501113499272\n",
      "Epoch: 50 Batch: 300, loss: 0.6482505098002599\n",
      "Epoch: 50 Batch: 400, loss: 0.2133941298728278\n",
      "Epoch: 50 Batch: 500, loss: 0.07173944753672105\n",
      "Epoch: 51 Batch: 0, loss: 0.009868610193835224\n",
      "Epoch: 51 Batch: 100, loss: 0.05066813088500331\n",
      "Epoch: 51 Batch: 200, loss: 0.0017900877826589852\n",
      "Epoch: 51 Batch: 300, loss: 1.1959100565592704\n",
      "Epoch: 51 Batch: 400, loss: 0.30315282888945094\n",
      "Epoch: 51 Batch: 500, loss: 0.02662845139676996\n",
      "Epoch: 52 Batch: 0, loss: 0.47733389168661344\n",
      "Epoch: 52 Batch: 100, loss: 0.5349082606267264\n",
      "Epoch: 52 Batch: 200, loss: 1.1936422313170394\n",
      "Epoch: 52 Batch: 300, loss: 0.24303180467891938\n",
      "Epoch: 52 Batch: 400, loss: 0.47739117303240347\n",
      "Epoch: 52 Batch: 500, loss: 0.171845803093811\n",
      "Epoch: 53 Batch: 0, loss: 0.4685951711011135\n",
      "Epoch: 53 Batch: 100, loss: 2.2576019354661074\n",
      "Epoch: 53 Batch: 200, loss: 0.03280859508799478\n",
      "Epoch: 53 Batch: 300, loss: 0.5374926030975564\n",
      "Epoch: 53 Batch: 400, loss: 0.024572613896610584\n",
      "Epoch: 53 Batch: 500, loss: 0.22408380162760677\n",
      "Epoch: 54 Batch: 0, loss: 0.06989446571330898\n",
      "Epoch: 54 Batch: 100, loss: 1.3221118924427528\n",
      "Epoch: 54 Batch: 200, loss: 0.37328878050488706\n",
      "Epoch: 54 Batch: 300, loss: 0.07651044347086329\n",
      "Epoch: 54 Batch: 400, loss: 0.7697060091788817\n",
      "Epoch: 54 Batch: 500, loss: 0.4356915777715353\n",
      "Epoch: 55 Batch: 0, loss: 0.0733834274979157\n",
      "Epoch: 55 Batch: 100, loss: 0.0726044254232529\n",
      "Epoch: 55 Batch: 200, loss: 0.030647269119359208\n",
      "Epoch: 55 Batch: 300, loss: 0.2704857865377588\n",
      "Epoch: 55 Batch: 400, loss: 0.8990030748912436\n",
      "Epoch: 55 Batch: 500, loss: 0.048626023554987144\n",
      "Epoch: 56 Batch: 0, loss: 0.949159637155119\n",
      "Epoch: 56 Batch: 100, loss: 0.023912894838504457\n",
      "Epoch: 56 Batch: 200, loss: 0.4943292185269025\n",
      "Epoch: 56 Batch: 300, loss: 0.29040938283405254\n",
      "Epoch: 56 Batch: 400, loss: 0.034003311529781595\n",
      "Epoch: 56 Batch: 500, loss: 0.5386705628265993\n",
      "Epoch: 57 Batch: 0, loss: 1.0595405537728793\n",
      "Epoch: 57 Batch: 100, loss: 0.1574848223108336\n",
      "Epoch: 57 Batch: 200, loss: 0.5366969639682759\n",
      "Epoch: 57 Batch: 300, loss: 0.1404940939506804\n",
      "Epoch: 57 Batch: 400, loss: 0.10888892390642038\n",
      "Epoch: 57 Batch: 500, loss: 0.16561748879174323\n",
      "Epoch: 58 Batch: 0, loss: 2.5562305887847767\n",
      "Epoch: 58 Batch: 100, loss: 0.025223616436498255\n",
      "Epoch: 58 Batch: 200, loss: 0.18840283698386803\n",
      "Epoch: 58 Batch: 300, loss: 0.7721019533054588\n",
      "Epoch: 58 Batch: 400, loss: 0.467827238961135\n",
      "Epoch: 58 Batch: 500, loss: 0.07340671254356645\n",
      "Epoch: 59 Batch: 0, loss: 0.022818142144838297\n",
      "Epoch: 59 Batch: 100, loss: 0.3586353096506263\n",
      "Epoch: 59 Batch: 200, loss: 0.22407921229676864\n",
      "Epoch: 59 Batch: 300, loss: 0.00017143951762647874\n",
      "Epoch: 59 Batch: 400, loss: 0.4890583076413412\n",
      "Epoch: 59 Batch: 500, loss: 0.21103606463603442\n",
      "Epoch: 60 Batch: 0, loss: 0.05266802532645287\n",
      "Epoch: 60 Batch: 100, loss: 0.04513810762757452\n",
      "Epoch: 60 Batch: 200, loss: 0.3921951891231102\n",
      "Epoch: 60 Batch: 300, loss: 0.023994859778518493\n",
      "Epoch: 60 Batch: 400, loss: 0.1397888598807058\n",
      "Epoch: 60 Batch: 500, loss: 0.22714956977675568\n",
      "Epoch: 61 Batch: 0, loss: 0.47636927772535786\n",
      "Epoch: 61 Batch: 100, loss: 0.05975617130139858\n",
      "Epoch: 61 Batch: 200, loss: 0.005602601888598654\n",
      "Epoch: 61 Batch: 300, loss: 0.2072488915211618\n",
      "Epoch: 61 Batch: 400, loss: 0.25152134122334746\n",
      "Epoch: 61 Batch: 500, loss: 0.8576040175527554\n",
      "Epoch: 62 Batch: 0, loss: 0.18849393358483482\n",
      "Epoch: 62 Batch: 100, loss: 0.2153176246060633\n",
      "Epoch: 62 Batch: 200, loss: 0.24713681635205617\n",
      "Epoch: 62 Batch: 300, loss: 7.758849977710802e-06\n",
      "Epoch: 62 Batch: 400, loss: 0.033033431747746686\n",
      "Epoch: 62 Batch: 500, loss: 0.40485176635207526\n",
      "Epoch: 63 Batch: 0, loss: 0.00017636457005928857\n",
      "Epoch: 63 Batch: 100, loss: 0.026471974736746725\n",
      "Epoch: 63 Batch: 200, loss: 0.46863383572287526\n",
      "Epoch: 63 Batch: 300, loss: 0.09819794300082389\n",
      "Epoch: 63 Batch: 400, loss: 1.1806841706744386\n",
      "Epoch: 63 Batch: 500, loss: 0.015288964089271254\n",
      "Epoch: 64 Batch: 0, loss: 0.0005161138493534802\n",
      "Epoch: 64 Batch: 100, loss: 0.023836402119392586\n",
      "Epoch: 64 Batch: 200, loss: 0.8011724059636642\n",
      "Epoch: 64 Batch: 300, loss: 0.16941839514583154\n",
      "Epoch: 64 Batch: 400, loss: 0.02244113244009576\n",
      "Epoch: 64 Batch: 500, loss: 0.004069763516754793\n",
      "Epoch: 65 Batch: 0, loss: 0.9105487244266549\n",
      "Epoch: 65 Batch: 100, loss: 0.0022888676632394672\n",
      "Epoch: 65 Batch: 200, loss: 0.07765036064481483\n",
      "Epoch: 65 Batch: 300, loss: 0.12618416987204464\n",
      "Epoch: 65 Batch: 400, loss: 0.08244838084618825\n",
      "Epoch: 65 Batch: 500, loss: 1.2072874351529301\n",
      "Epoch: 66 Batch: 0, loss: 0.047283722738875766\n",
      "Epoch: 66 Batch: 100, loss: 0.0032833728165514654\n",
      "Epoch: 66 Batch: 200, loss: 0.9958438129215792\n",
      "Epoch: 66 Batch: 300, loss: 0.5815176769141056\n",
      "Epoch: 66 Batch: 400, loss: 0.00015996638078900815\n",
      "Epoch: 66 Batch: 500, loss: 0.09364869466328116\n",
      "Epoch: 67 Batch: 0, loss: 0.06879191349737983\n",
      "Epoch: 67 Batch: 100, loss: 0.4548362642901734\n",
      "Epoch: 67 Batch: 200, loss: 0.5231764821069986\n",
      "Epoch: 67 Batch: 300, loss: 0.015117019130554766\n",
      "Epoch: 67 Batch: 400, loss: 0.24871675969674203\n",
      "Epoch: 67 Batch: 500, loss: 0.32761056908588326\n",
      "Epoch: 68 Batch: 0, loss: 0.05974378818949501\n",
      "Epoch: 68 Batch: 100, loss: 0.34484119636502025\n",
      "Epoch: 68 Batch: 200, loss: 0.8535986133465048\n",
      "Epoch: 68 Batch: 300, loss: 0.2264711701312955\n",
      "Epoch: 68 Batch: 400, loss: 0.6362686188518364\n",
      "Epoch: 68 Batch: 500, loss: 0.18555958272551998\n",
      "Epoch: 69 Batch: 0, loss: 0.3323992819557445\n",
      "Epoch: 69 Batch: 100, loss: 1.2316405301051436\n",
      "Epoch: 69 Batch: 200, loss: 0.5829138145427055\n",
      "Epoch: 69 Batch: 300, loss: 0.14432674708419943\n",
      "Epoch: 69 Batch: 400, loss: 0.3560485035060301\n",
      "Epoch: 69 Batch: 500, loss: 0.140467878816806\n",
      "Epoch: 70 Batch: 0, loss: 4.125133632066496\n",
      "Epoch: 70 Batch: 100, loss: 0.14656464527023133\n",
      "Epoch: 70 Batch: 200, loss: 0.04824709917674391\n",
      "Epoch: 70 Batch: 300, loss: 0.08519030565602559\n",
      "Epoch: 70 Batch: 400, loss: 0.8647959139700144\n",
      "Epoch: 70 Batch: 500, loss: 0.01659732464544071\n",
      "Epoch: 71 Batch: 0, loss: 0.5712071485355814\n",
      "Epoch: 71 Batch: 100, loss: 0.47386406286223487\n",
      "Epoch: 71 Batch: 200, loss: 0.015478900041556658\n",
      "Epoch: 71 Batch: 300, loss: 0.3826556055664277\n",
      "Epoch: 71 Batch: 400, loss: 0.23798016068664093\n",
      "Epoch: 71 Batch: 500, loss: 0.30201059975825206\n",
      "Epoch: 72 Batch: 0, loss: 0.045902387325322806\n",
      "Epoch: 72 Batch: 100, loss: 0.9355228437900779\n",
      "Epoch: 72 Batch: 200, loss: 0.9870264608520202\n",
      "Epoch: 72 Batch: 300, loss: 0.8160610576244041\n",
      "Epoch: 72 Batch: 400, loss: 0.030861269398402863\n",
      "Epoch: 72 Batch: 500, loss: 0.035936331862811706\n",
      "Epoch: 73 Batch: 0, loss: 0.16425556505589983\n",
      "Epoch: 73 Batch: 100, loss: 0.0005278830492036781\n",
      "Epoch: 73 Batch: 200, loss: 0.0681180203088126\n",
      "Epoch: 73 Batch: 300, loss: 0.24270336671837625\n",
      "Epoch: 73 Batch: 400, loss: 0.0005197343536928865\n",
      "Epoch: 73 Batch: 500, loss: 0.1389940933187892\n",
      "Epoch: 74 Batch: 0, loss: 0.04297420974264769\n",
      "Epoch: 74 Batch: 100, loss: 0.3029920230892228\n",
      "Epoch: 74 Batch: 200, loss: 0.15779778524765337\n",
      "Epoch: 74 Batch: 300, loss: 0.08608250443572098\n",
      "Epoch: 74 Batch: 400, loss: 2.2816714630140833e-05\n",
      "Epoch: 74 Batch: 500, loss: 0.0004792497109764001\n",
      "Epoch: 75 Batch: 0, loss: 0.9858074248653382\n",
      "Epoch: 75 Batch: 100, loss: 0.5923433920243827\n",
      "Epoch: 75 Batch: 200, loss: 0.2980058515499525\n",
      "Epoch: 75 Batch: 300, loss: 0.014557992178465403\n",
      "Epoch: 75 Batch: 400, loss: 0.6913205265585447\n",
      "Epoch: 75 Batch: 500, loss: 0.0001476195771774048\n",
      "Epoch: 76 Batch: 0, loss: 0.030331760406415116\n",
      "Epoch: 76 Batch: 100, loss: 4.24904918846267\n",
      "Epoch: 76 Batch: 200, loss: 0.23791705569690366\n",
      "Epoch: 76 Batch: 300, loss: 0.07926151606746387\n",
      "Epoch: 76 Batch: 400, loss: 0.0008788747562614856\n",
      "Epoch: 76 Batch: 500, loss: 0.04702852014881013\n",
      "Epoch: 77 Batch: 0, loss: 0.15871373033955466\n",
      "Epoch: 77 Batch: 100, loss: 0.33213108107304135\n",
      "Epoch: 77 Batch: 200, loss: 0.4195340845916014\n",
      "Epoch: 77 Batch: 300, loss: 0.37568934824246664\n",
      "Epoch: 77 Batch: 400, loss: 0.05895599844803391\n",
      "Epoch: 77 Batch: 500, loss: 0.2192891122228296\n",
      "Epoch: 78 Batch: 0, loss: 0.023112891381534464\n",
      "Epoch: 78 Batch: 100, loss: 1.625481137060642\n",
      "Epoch: 78 Batch: 200, loss: 0.19051706172034025\n",
      "Epoch: 78 Batch: 300, loss: 0.029097215823218402\n",
      "Epoch: 78 Batch: 400, loss: 2.490274146377274\n",
      "Epoch: 78 Batch: 500, loss: 0.07740185553662597\n",
      "Epoch: 79 Batch: 0, loss: 0.08851576049126318\n",
      "Epoch: 79 Batch: 100, loss: 0.08457142066789952\n",
      "Epoch: 79 Batch: 200, loss: 0.9105174292918692\n",
      "Epoch: 79 Batch: 300, loss: 0.17604848726957809\n",
      "Epoch: 79 Batch: 400, loss: 3.986928988878928e-06\n",
      "Epoch: 79 Batch: 500, loss: 0.24573018625381068\n",
      "Epoch: 80 Batch: 0, loss: 0.2217056365666356\n",
      "Epoch: 80 Batch: 100, loss: 0.08035862346103677\n",
      "Epoch: 80 Batch: 200, loss: 0.20316811277962374\n",
      "Epoch: 80 Batch: 300, loss: 0.005920406118607875\n",
      "Epoch: 80 Batch: 400, loss: 0.029670585174834258\n",
      "Epoch: 80 Batch: 500, loss: 0.0583324524246471\n",
      "Epoch: 81 Batch: 0, loss: 0.02103214921413666\n",
      "Epoch: 81 Batch: 100, loss: 0.02440079158928069\n",
      "Epoch: 81 Batch: 200, loss: 0.7559620351328664\n",
      "Epoch: 81 Batch: 300, loss: 0.0005467278048156335\n",
      "Epoch: 81 Batch: 400, loss: 0.32183564241964774\n",
      "Epoch: 81 Batch: 500, loss: 0.10250459837516454\n",
      "Epoch: 82 Batch: 0, loss: 0.47706764462902596\n",
      "Epoch: 82 Batch: 100, loss: 0.79322044679957\n",
      "Epoch: 82 Batch: 200, loss: 0.20888342439373403\n",
      "Epoch: 82 Batch: 300, loss: 0.11056689586539638\n",
      "Epoch: 82 Batch: 400, loss: 0.09011326676517598\n",
      "Epoch: 82 Batch: 500, loss: 0.7266348442077261\n",
      "Epoch: 83 Batch: 0, loss: 0.5373145325463656\n",
      "Epoch: 83 Batch: 100, loss: 0.010910853797811444\n",
      "Epoch: 83 Batch: 200, loss: 0.5929186108931067\n",
      "Epoch: 83 Batch: 300, loss: 0.06459967680917456\n",
      "Epoch: 83 Batch: 400, loss: 0.217800915012276\n",
      "Epoch: 83 Batch: 500, loss: 0.31512439291527056\n",
      "Epoch: 84 Batch: 0, loss: 0.030924190164670705\n",
      "Epoch: 84 Batch: 100, loss: 0.4547229922353077\n",
      "Epoch: 84 Batch: 200, loss: 0.13052725139786925\n",
      "Epoch: 84 Batch: 300, loss: 0.00014878130229185969\n",
      "Epoch: 84 Batch: 400, loss: 0.8663198132270584\n",
      "Epoch: 84 Batch: 500, loss: 0.008995682905677645\n",
      "Epoch: 85 Batch: 0, loss: 0.04204781701735163\n",
      "Epoch: 85 Batch: 100, loss: 0.00011353015246763721\n",
      "Epoch: 85 Batch: 200, loss: 0.2211153792003256\n",
      "Epoch: 85 Batch: 300, loss: 0.35346784971821377\n",
      "Epoch: 85 Batch: 400, loss: 0.07716674972119308\n",
      "Epoch: 85 Batch: 500, loss: 0.8636063895656246\n",
      "Epoch: 86 Batch: 0, loss: 0.42301638173851847\n",
      "Epoch: 86 Batch: 100, loss: 0.21300606419647627\n",
      "Epoch: 86 Batch: 200, loss: 0.015445681377859146\n",
      "Epoch: 86 Batch: 300, loss: 0.1664713799453987\n",
      "Epoch: 86 Batch: 400, loss: 0.0006866090817842764\n",
      "Epoch: 86 Batch: 500, loss: 0.34646049607345997\n",
      "Epoch: 87 Batch: 0, loss: 1.2270688439847344\n",
      "Epoch: 87 Batch: 100, loss: 0.22644991920903168\n",
      "Epoch: 87 Batch: 200, loss: 0.6115521207648971\n",
      "Epoch: 87 Batch: 300, loss: 0.010441901953141122\n",
      "Epoch: 87 Batch: 400, loss: 0.6095765483972877\n",
      "Epoch: 87 Batch: 500, loss: 0.47775108654412124\n",
      "Epoch: 88 Batch: 0, loss: 0.07555383459464073\n",
      "Epoch: 88 Batch: 100, loss: 0.04720524879722347\n",
      "Epoch: 88 Batch: 200, loss: 0.00020258394858676005\n",
      "Epoch: 88 Batch: 300, loss: 9.063412571774851e-05\n",
      "Epoch: 88 Batch: 400, loss: 1.2880584712343845\n",
      "Epoch: 88 Batch: 500, loss: 0.030654694833033957\n",
      "Epoch: 89 Batch: 0, loss: 0.2178026490420842\n",
      "Epoch: 89 Batch: 100, loss: 1.2381541067080648\n",
      "Epoch: 89 Batch: 200, loss: 0.0013243307964685156\n",
      "Epoch: 89 Batch: 300, loss: 0.18686828659969065\n",
      "Epoch: 89 Batch: 400, loss: 1.2570969505313663\n",
      "Epoch: 89 Batch: 500, loss: 0.008858203451250475\n",
      "Epoch: 90 Batch: 0, loss: 0.023161698149972817\n",
      "Epoch: 90 Batch: 100, loss: 0.15680461447202604\n",
      "Epoch: 90 Batch: 200, loss: 0.6941514301502492\n",
      "Epoch: 90 Batch: 300, loss: 0.30326445284853054\n",
      "Epoch: 90 Batch: 400, loss: 0.07503630253154808\n",
      "Epoch: 90 Batch: 500, loss: 0.005150949885551612\n",
      "Epoch: 91 Batch: 0, loss: 0.10910426017290019\n",
      "Epoch: 91 Batch: 100, loss: 0.09492255549907137\n",
      "Epoch: 91 Batch: 200, loss: 0.29748292327288145\n",
      "Epoch: 91 Batch: 300, loss: 1.6438694685946758\n",
      "Epoch: 91 Batch: 400, loss: 0.0001013483275451077\n",
      "Epoch: 91 Batch: 500, loss: 0.16452430464534384\n",
      "Epoch: 92 Batch: 0, loss: 0.0023154818193667505\n",
      "Epoch: 92 Batch: 100, loss: 0.02046308424570042\n",
      "Epoch: 92 Batch: 200, loss: 0.2420380597946344\n",
      "Epoch: 92 Batch: 300, loss: 0.00035629123493652727\n",
      "Epoch: 92 Batch: 400, loss: 0.4570673495949295\n",
      "Epoch: 92 Batch: 500, loss: 0.26895405654578347\n",
      "Epoch: 93 Batch: 0, loss: 0.07678011563998952\n",
      "Epoch: 93 Batch: 100, loss: 0.5280154625494555\n",
      "Epoch: 93 Batch: 200, loss: 0.11426852243654563\n",
      "Epoch: 93 Batch: 300, loss: 0.11132673389306146\n",
      "Epoch: 93 Batch: 400, loss: 0.47377203846059873\n",
      "Epoch: 93 Batch: 500, loss: 0.00035288070754971616\n",
      "Epoch: 94 Batch: 0, loss: 0.08356265266998734\n",
      "Epoch: 94 Batch: 100, loss: 0.08692764640559877\n",
      "Epoch: 94 Batch: 200, loss: 0.527371835617326\n",
      "Epoch: 94 Batch: 300, loss: 0.06796367249723553\n",
      "Epoch: 94 Batch: 400, loss: 0.09079870556636205\n",
      "Epoch: 94 Batch: 500, loss: 1.0787120219747879\n",
      "Epoch: 95 Batch: 0, loss: 0.05817167524918913\n",
      "Epoch: 95 Batch: 100, loss: 0.0466486947312358\n",
      "Epoch: 95 Batch: 200, loss: 0.5588447674572967\n",
      "Epoch: 95 Batch: 300, loss: 0.12846826723600904\n",
      "Epoch: 95 Batch: 400, loss: 0.005981279167926852\n",
      "Epoch: 95 Batch: 500, loss: 0.049411519392477274\n",
      "Epoch: 96 Batch: 0, loss: 0.022614910247076084\n",
      "Epoch: 96 Batch: 100, loss: 0.25758932199344525\n",
      "Epoch: 96 Batch: 200, loss: 0.028128369134355687\n",
      "Epoch: 96 Batch: 300, loss: 0.005935275981249384\n",
      "Epoch: 96 Batch: 400, loss: 0.09453149846325061\n",
      "Epoch: 96 Batch: 500, loss: 0.0025575594022890697\n",
      "Epoch: 97 Batch: 0, loss: 0.013928386955789948\n",
      "Epoch: 97 Batch: 100, loss: 0.40644542743428946\n",
      "Epoch: 97 Batch: 200, loss: 0.056970363890155896\n",
      "Epoch: 97 Batch: 300, loss: 0.0939906880512442\n",
      "Epoch: 97 Batch: 400, loss: 0.3019327059066138\n",
      "Epoch: 97 Batch: 500, loss: 0.9431046311641471\n",
      "Epoch: 98 Batch: 0, loss: 0.0001366695948605296\n",
      "Epoch: 98 Batch: 100, loss: 0.8766356384172864\n",
      "Epoch: 98 Batch: 200, loss: 0.09463168271481048\n",
      "Epoch: 98 Batch: 300, loss: 0.4225327099224844\n",
      "Epoch: 98 Batch: 400, loss: 0.002809770992095718\n",
      "Epoch: 98 Batch: 500, loss: 0.06386728872474731\n",
      "Epoch: 99 Batch: 0, loss: 0.7665659935948356\n",
      "Epoch: 99 Batch: 100, loss: 0.334833084215747\n",
      "Epoch: 99 Batch: 200, loss: 0.6337223904461621\n",
      "Epoch: 99 Batch: 300, loss: 0.0006697904438080526\n",
      "Epoch: 99 Batch: 400, loss: 0.2253669168277892\n",
      "Epoch: 99 Batch: 500, loss: 0.015688615949728018\n",
      "Epoch: 100 Batch: 0, loss: 0.9299739067778922\n",
      "Epoch: 100 Batch: 100, loss: 0.7924041325274866\n",
      "Epoch: 100 Batch: 200, loss: 0.10822735282214264\n",
      "Epoch: 100 Batch: 300, loss: 0.054077230684545105\n",
      "Epoch: 100 Batch: 400, loss: 0.22017102631775942\n",
      "Epoch: 100 Batch: 500, loss: 0.15449848410929323\n",
      "Epoch: 101 Batch: 0, loss: 0.11264406831887579\n",
      "Epoch: 101 Batch: 100, loss: 0.35864195504106333\n",
      "Epoch: 101 Batch: 200, loss: 0.1933500357986467\n",
      "Epoch: 101 Batch: 300, loss: 1.0399613151003795\n",
      "Epoch: 101 Batch: 400, loss: 1.3764418694098635\n",
      "Epoch: 101 Batch: 500, loss: 0.02817100666222444\n",
      "Epoch: 102 Batch: 0, loss: 0.01700694729097206\n",
      "Epoch: 102 Batch: 100, loss: 1.352053470311897\n",
      "Epoch: 102 Batch: 200, loss: 0.34287971507298154\n",
      "Epoch: 102 Batch: 300, loss: 0.5468585218845284\n",
      "Epoch: 102 Batch: 400, loss: 0.06800772022688276\n",
      "Epoch: 102 Batch: 500, loss: 0.21879029046426451\n",
      "Epoch: 103 Batch: 0, loss: 0.01519964951360463\n",
      "Epoch: 103 Batch: 100, loss: 0.06570787541766782\n",
      "Epoch: 103 Batch: 200, loss: 0.4645235010672874\n",
      "Epoch: 103 Batch: 300, loss: 0.001232739862476397\n",
      "Epoch: 103 Batch: 400, loss: 0.3457015322111836\n",
      "Epoch: 103 Batch: 500, loss: 0.049090943800487716\n",
      "Epoch: 104 Batch: 0, loss: 0.14300410344490552\n",
      "Epoch: 104 Batch: 100, loss: 0.0006594571472774855\n",
      "Epoch: 104 Batch: 200, loss: 0.004432813982002221\n",
      "Epoch: 104 Batch: 300, loss: 0.024807039204804544\n",
      "Epoch: 104 Batch: 400, loss: 0.10715254842874161\n",
      "Epoch: 104 Batch: 500, loss: 0.014307430878256594\n",
      "Epoch: 105 Batch: 0, loss: 0.017566254695261435\n",
      "Epoch: 105 Batch: 100, loss: 1.2310393593324258\n",
      "Epoch: 105 Batch: 200, loss: 0.1809785032985844\n",
      "Epoch: 105 Batch: 300, loss: 0.22576436825989743\n",
      "Epoch: 105 Batch: 400, loss: 0.5652695538280684\n",
      "Epoch: 105 Batch: 500, loss: 0.12359813287713559\n",
      "Epoch: 106 Batch: 0, loss: 0.1714587302833681\n",
      "Epoch: 106 Batch: 100, loss: 0.22486227250472293\n",
      "Epoch: 106 Batch: 200, loss: 0.36605595062461116\n",
      "Epoch: 106 Batch: 300, loss: 2.514300999701313\n",
      "Epoch: 106 Batch: 400, loss: 0.000136906642470752\n",
      "Epoch: 106 Batch: 500, loss: 0.9663092070536765\n",
      "Epoch: 107 Batch: 0, loss: 0.12809096083942823\n",
      "Epoch: 107 Batch: 100, loss: 0.08040411806198777\n",
      "Epoch: 107 Batch: 200, loss: 0.07740356951764021\n",
      "Epoch: 107 Batch: 300, loss: 0.017592564614006757\n",
      "Epoch: 107 Batch: 400, loss: 0.09401374130166791\n",
      "Epoch: 107 Batch: 500, loss: 0.34440250367043834\n",
      "Epoch: 108 Batch: 0, loss: 0.06621409793136501\n",
      "Epoch: 108 Batch: 100, loss: 0.16636949022909303\n",
      "Epoch: 108 Batch: 200, loss: 0.007258384277941798\n",
      "Epoch: 108 Batch: 300, loss: 0.1865075392037371\n",
      "Epoch: 108 Batch: 400, loss: 0.8033079902070787\n",
      "Epoch: 108 Batch: 500, loss: 0.02694519622308901\n",
      "Epoch: 109 Batch: 0, loss: 0.04430152961552291\n",
      "Epoch: 109 Batch: 100, loss: 0.5266780191325178\n",
      "Epoch: 109 Batch: 200, loss: 0.2659921917705715\n",
      "Epoch: 109 Batch: 300, loss: 0.00722528955630081\n",
      "Epoch: 109 Batch: 400, loss: 0.07065593077640143\n",
      "Epoch: 109 Batch: 500, loss: 9.98695743709837e-05\n",
      "Epoch: 110 Batch: 0, loss: 0.2833741817052431\n",
      "Epoch: 110 Batch: 100, loss: 0.3859869107895557\n",
      "Epoch: 110 Batch: 200, loss: 0.00043107580079623526\n",
      "Epoch: 110 Batch: 300, loss: 0.05495863616070103\n",
      "Epoch: 110 Batch: 400, loss: 0.8398468488678765\n",
      "Epoch: 110 Batch: 500, loss: 1.2947552728545773\n",
      "Epoch: 111 Batch: 0, loss: 0.00023403563560299542\n",
      "Epoch: 111 Batch: 100, loss: 0.021677549240329066\n",
      "Epoch: 111 Batch: 200, loss: 0.029189504588341\n",
      "Epoch: 111 Batch: 300, loss: 0.027406900515799165\n",
      "Epoch: 111 Batch: 400, loss: 0.160662772063601\n",
      "Epoch: 111 Batch: 500, loss: 0.2259998191386041\n",
      "Epoch: 112 Batch: 0, loss: 0.46236686607948824\n",
      "Epoch: 112 Batch: 100, loss: 0.025117731921670716\n",
      "Epoch: 112 Batch: 200, loss: 9.636577531091408e-05\n",
      "Epoch: 112 Batch: 300, loss: 0.686345587185462\n",
      "Epoch: 112 Batch: 400, loss: 0.7220560647287381\n",
      "Epoch: 112 Batch: 500, loss: 0.18088934978929647\n",
      "Epoch: 113 Batch: 0, loss: 0.1388764868600618\n",
      "Epoch: 113 Batch: 100, loss: 0.005454402948287044\n",
      "Epoch: 113 Batch: 200, loss: 0.11788221414135615\n",
      "Epoch: 113 Batch: 300, loss: 0.014796113293127841\n",
      "Epoch: 113 Batch: 400, loss: 0.07155085109696392\n",
      "Epoch: 113 Batch: 500, loss: 0.04096795025894862\n",
      "Epoch: 114 Batch: 0, loss: 0.02797542075176963\n",
      "Epoch: 114 Batch: 100, loss: 0.10268206220398264\n",
      "Epoch: 114 Batch: 200, loss: 1.0330677374677393\n",
      "Epoch: 114 Batch: 300, loss: 0.00012887933468686108\n",
      "Epoch: 114 Batch: 400, loss: 0.28740278405245984\n",
      "Epoch: 114 Batch: 500, loss: 0.026481743368378392\n",
      "Epoch: 115 Batch: 0, loss: 0.46866844972713173\n",
      "Epoch: 115 Batch: 100, loss: 0.713359855933411\n",
      "Epoch: 115 Batch: 200, loss: 0.0009398317942281214\n",
      "Epoch: 115 Batch: 300, loss: 0.17962336333192652\n",
      "Epoch: 115 Batch: 400, loss: 0.22552913374224537\n",
      "Epoch: 115 Batch: 500, loss: 0.014922955281602182\n",
      "Epoch: 116 Batch: 0, loss: 0.16496122916543227\n",
      "Epoch: 116 Batch: 100, loss: 0.4190770016952114\n",
      "Epoch: 116 Batch: 200, loss: 0.0820465644227955\n",
      "Epoch: 116 Batch: 300, loss: 0.023189489174593243\n",
      "Epoch: 116 Batch: 400, loss: 0.028284751396832186\n",
      "Epoch: 116 Batch: 500, loss: 1.2697983187384547\n",
      "Epoch: 117 Batch: 0, loss: 1.115103542041269\n",
      "Epoch: 117 Batch: 100, loss: 0.007460749710655738\n",
      "Epoch: 117 Batch: 200, loss: 0.18284027783265455\n",
      "Epoch: 117 Batch: 300, loss: 0.05276855373368422\n",
      "Epoch: 117 Batch: 400, loss: 0.27010767252487844\n",
      "Epoch: 117 Batch: 500, loss: 0.025645936837524596\n",
      "Epoch: 118 Batch: 0, loss: 0.10862095710178594\n",
      "Epoch: 118 Batch: 100, loss: 0.0037203120468333826\n",
      "Epoch: 118 Batch: 200, loss: 1.6508318267060504\n",
      "Epoch: 118 Batch: 300, loss: 0.16459367968615157\n",
      "Epoch: 118 Batch: 400, loss: 0.0007834888213190928\n",
      "Epoch: 118 Batch: 500, loss: 8.219368538413769e-05\n",
      "Epoch: 119 Batch: 0, loss: 0.9242593889539529\n",
      "Epoch: 119 Batch: 100, loss: 0.21698836547307745\n",
      "Epoch: 119 Batch: 200, loss: 0.04123170555163132\n",
      "Epoch: 119 Batch: 300, loss: 0.02148535576582127\n",
      "Epoch: 119 Batch: 400, loss: 0.0011984232977803478\n",
      "Epoch: 119 Batch: 500, loss: 0.33947279276213765\n",
      "Epoch: 120 Batch: 0, loss: 0.7562047469775941\n",
      "Epoch: 120 Batch: 100, loss: 0.18617211191021968\n",
      "Epoch: 120 Batch: 200, loss: 0.0019268095781830876\n",
      "Epoch: 120 Batch: 300, loss: 0.23781209770243772\n",
      "Epoch: 120 Batch: 400, loss: 0.03700422025538596\n",
      "Epoch: 120 Batch: 500, loss: 0.08924178665408063\n",
      "Epoch: 121 Batch: 0, loss: 0.5953973666435388\n",
      "Epoch: 121 Batch: 100, loss: 0.6255553066898739\n",
      "Epoch: 121 Batch: 200, loss: 0.3469242067045043\n",
      "Epoch: 121 Batch: 300, loss: 0.12080182241299538\n",
      "Epoch: 121 Batch: 400, loss: 0.15455155227788706\n",
      "Epoch: 121 Batch: 500, loss: 0.082044908039043\n",
      "Epoch: 122 Batch: 0, loss: 1.1143385481494181\n",
      "Epoch: 122 Batch: 100, loss: 0.12098634831713614\n",
      "Epoch: 122 Batch: 200, loss: 0.15554527972680987\n",
      "Epoch: 122 Batch: 300, loss: 0.13671509855517866\n",
      "Epoch: 122 Batch: 400, loss: 0.05770135698504722\n",
      "Epoch: 122 Batch: 500, loss: 0.015193457113274193\n",
      "Epoch: 123 Batch: 0, loss: 0.07894690645750224\n",
      "Epoch: 123 Batch: 100, loss: 0.9065343356204326\n",
      "Epoch: 123 Batch: 200, loss: 0.05859738327470143\n",
      "Epoch: 123 Batch: 300, loss: 0.10740486470346049\n",
      "Epoch: 123 Batch: 400, loss: 0.15038717305430357\n",
      "Epoch: 123 Batch: 500, loss: 0.058183500314081454\n",
      "Epoch: 124 Batch: 0, loss: 0.7181444110742912\n",
      "Epoch: 124 Batch: 100, loss: 0.05179179913444948\n",
      "Epoch: 124 Batch: 200, loss: 0.02920785048677804\n",
      "Epoch: 124 Batch: 300, loss: 0.9157136196037806\n",
      "Epoch: 124 Batch: 400, loss: 0.7908189387128848\n",
      "Epoch: 124 Batch: 500, loss: 0.2374844428139175\n",
      "Epoch: 125 Batch: 0, loss: 0.04555833845470274\n",
      "Epoch: 125 Batch: 100, loss: 0.43192921617023167\n",
      "Epoch: 125 Batch: 200, loss: 1.233500327743255\n",
      "Epoch: 125 Batch: 300, loss: 0.06696163654209662\n",
      "Epoch: 125 Batch: 400, loss: 0.9970216642663748\n",
      "Epoch: 125 Batch: 500, loss: 0.5921966783011575\n",
      "Epoch: 126 Batch: 0, loss: 0.7811760000375839\n",
      "Epoch: 126 Batch: 100, loss: 0.06363972259287105\n",
      "Epoch: 126 Batch: 200, loss: 0.0028375269033924446\n",
      "Epoch: 126 Batch: 300, loss: 0.3699449660565361\n",
      "Epoch: 126 Batch: 400, loss: 0.0025780898536134967\n",
      "Epoch: 126 Batch: 500, loss: 2.6087001892258206\n",
      "Epoch: 127 Batch: 0, loss: 0.47846707373493236\n",
      "Epoch: 127 Batch: 100, loss: 0.3061766771367805\n",
      "Epoch: 127 Batch: 200, loss: 0.4052962557311451\n",
      "Epoch: 127 Batch: 300, loss: 0.0006124040022222428\n",
      "Epoch: 127 Batch: 400, loss: 0.08829939049948636\n",
      "Epoch: 127 Batch: 500, loss: 0.13755639200292097\n",
      "Epoch: 128 Batch: 0, loss: 0.029763961905712892\n",
      "Epoch: 128 Batch: 100, loss: 0.22488617390596258\n",
      "Epoch: 128 Batch: 200, loss: 0.409247343463962\n",
      "Epoch: 128 Batch: 300, loss: 0.04554977451114335\n",
      "Epoch: 128 Batch: 400, loss: 9.813124061393457e-05\n",
      "Epoch: 128 Batch: 500, loss: 0.017938441155970205\n",
      "Epoch: 129 Batch: 0, loss: 2.3045983634257365\n",
      "Epoch: 129 Batch: 100, loss: 0.0006377101482457012\n",
      "Epoch: 129 Batch: 200, loss: 0.11182345268674605\n",
      "Epoch: 129 Batch: 300, loss: 0.15278945030718022\n",
      "Epoch: 129 Batch: 400, loss: 0.3302479981134186\n",
      "Epoch: 129 Batch: 500, loss: 0.057957871023231085\n",
      "Epoch: 130 Batch: 0, loss: 0.04636655133549257\n",
      "Epoch: 130 Batch: 100, loss: 0.01586680166531596\n",
      "Epoch: 130 Batch: 200, loss: 0.10509291172141126\n",
      "Epoch: 130 Batch: 300, loss: 0.0991820378634892\n",
      "Epoch: 130 Batch: 400, loss: 0.05696361359816936\n",
      "Epoch: 130 Batch: 500, loss: 0.362428712635639\n",
      "Epoch: 131 Batch: 0, loss: 0.0567240006140489\n",
      "Epoch: 131 Batch: 100, loss: 0.20274776729404106\n",
      "Epoch: 131 Batch: 200, loss: 0.1790459205879231\n",
      "Epoch: 131 Batch: 300, loss: 0.8978728056391154\n",
      "Epoch: 131 Batch: 400, loss: 0.0009392162900664014\n",
      "Epoch: 131 Batch: 500, loss: 1.6349014525166242e-05\n",
      "Epoch: 132 Batch: 0, loss: 0.0345500744688598\n",
      "Epoch: 132 Batch: 100, loss: 0.1815281403071618\n",
      "Epoch: 132 Batch: 200, loss: 0.12445412835794242\n",
      "Epoch: 132 Batch: 300, loss: 0.056606090565812166\n",
      "Epoch: 132 Batch: 400, loss: 0.7011721206515005\n",
      "Epoch: 132 Batch: 500, loss: 0.03513484731898405\n",
      "Epoch: 133 Batch: 0, loss: 0.09135643418199503\n",
      "Epoch: 133 Batch: 100, loss: 0.1438995283036709\n",
      "Epoch: 133 Batch: 200, loss: 2.626818278269797\n",
      "Epoch: 133 Batch: 300, loss: 1.9606473824774018e-05\n",
      "Epoch: 133 Batch: 400, loss: 0.06359400481147205\n",
      "Epoch: 133 Batch: 500, loss: 8.106806263037058e-05\n",
      "Epoch: 134 Batch: 0, loss: 9.207595504473203e-05\n",
      "Epoch: 134 Batch: 100, loss: 0.6397418375088808\n",
      "Epoch: 134 Batch: 200, loss: 0.2968711338015878\n",
      "Epoch: 134 Batch: 300, loss: 0.055947747650411196\n",
      "Epoch: 134 Batch: 400, loss: 0.06978080295177048\n",
      "Epoch: 134 Batch: 500, loss: 0.12809282029191654\n",
      "Epoch: 135 Batch: 0, loss: 0.013924880264533474\n",
      "Epoch: 135 Batch: 100, loss: 0.3000982881639101\n",
      "Epoch: 135 Batch: 200, loss: 0.34987150588100224\n",
      "Epoch: 135 Batch: 300, loss: 0.050002921945371426\n",
      "Epoch: 135 Batch: 400, loss: 0.2893049164390197\n",
      "Epoch: 135 Batch: 500, loss: 0.032181256622119424\n",
      "Epoch: 136 Batch: 0, loss: 9.302542739657372e-05\n",
      "Epoch: 136 Batch: 100, loss: 0.0881179620694879\n",
      "Epoch: 136 Batch: 200, loss: 0.014724660962135178\n",
      "Epoch: 136 Batch: 300, loss: 3.049595420143613e-06\n",
      "Epoch: 136 Batch: 400, loss: 0.021323010291499273\n",
      "Epoch: 136 Batch: 500, loss: 0.26490995486674895\n",
      "Epoch: 137 Batch: 0, loss: 0.053275861535701526\n",
      "Epoch: 137 Batch: 100, loss: 0.0001257180468174116\n",
      "Epoch: 137 Batch: 200, loss: 0.06988384059496854\n",
      "Epoch: 137 Batch: 300, loss: 1.2783699350942175\n",
      "Epoch: 137 Batch: 400, loss: 0.09467942138890224\n",
      "Epoch: 137 Batch: 500, loss: 0.007198715433379665\n",
      "Epoch: 138 Batch: 0, loss: 0.6998531785144814\n",
      "Epoch: 138 Batch: 100, loss: 0.11988680991005611\n",
      "Epoch: 138 Batch: 200, loss: 0.07648207861407577\n",
      "Epoch: 138 Batch: 300, loss: 0.18034148851309192\n",
      "Epoch: 138 Batch: 400, loss: 0.5279876435384048\n",
      "Epoch: 138 Batch: 500, loss: 1.647870219164124\n",
      "Epoch: 139 Batch: 0, loss: 0.0024737978708572056\n",
      "Epoch: 139 Batch: 100, loss: 0.003463356405503085\n",
      "Epoch: 139 Batch: 200, loss: 0.014002788312674751\n",
      "Epoch: 139 Batch: 300, loss: 0.3591557027276723\n",
      "Epoch: 139 Batch: 400, loss: 0.3243312255373074\n",
      "Epoch: 139 Batch: 500, loss: 0.8577682663984497\n",
      "Epoch: 140 Batch: 0, loss: 0.020207386323917408\n",
      "Epoch: 140 Batch: 100, loss: 0.009585704613595092\n",
      "Epoch: 140 Batch: 200, loss: 0.08349611829054944\n",
      "Epoch: 140 Batch: 300, loss: 0.4248296114150006\n",
      "Epoch: 140 Batch: 400, loss: 1.3827931290264788\n",
      "Epoch: 140 Batch: 500, loss: 0.43434868377914104\n",
      "Epoch: 141 Batch: 0, loss: 4.304263975316081\n",
      "Epoch: 141 Batch: 100, loss: 0.14084193560070674\n",
      "Epoch: 141 Batch: 200, loss: 0.005643931528148002\n",
      "Epoch: 141 Batch: 300, loss: 0.24245673809326834\n",
      "Epoch: 141 Batch: 400, loss: 0.0655662728228907\n",
      "Epoch: 141 Batch: 500, loss: 0.24210596851207544\n",
      "Epoch: 142 Batch: 0, loss: 0.38710770353575413\n",
      "Epoch: 142 Batch: 100, loss: 0.03660706065663905\n",
      "Epoch: 142 Batch: 200, loss: 0.3636512944650518\n",
      "Epoch: 142 Batch: 300, loss: 0.21505010904192956\n",
      "Epoch: 142 Batch: 400, loss: 6.188484731021222e-05\n",
      "Epoch: 142 Batch: 500, loss: 0.13026623054525135\n",
      "Epoch: 143 Batch: 0, loss: 0.3671748095031353\n",
      "Epoch: 143 Batch: 100, loss: 0.4796967589547131\n",
      "Epoch: 143 Batch: 200, loss: 0.32194235336603366\n",
      "Epoch: 143 Batch: 300, loss: 1.0537407405233232\n",
      "Epoch: 143 Batch: 400, loss: 0.02357074730619528\n",
      "Epoch: 143 Batch: 500, loss: 0.42938416962316267\n",
      "Epoch: 144 Batch: 0, loss: 0.15297139037923094\n",
      "Epoch: 144 Batch: 100, loss: 0.00835061158586879\n",
      "Epoch: 144 Batch: 200, loss: 2.601370895910076\n",
      "Epoch: 144 Batch: 300, loss: 0.10864454016664\n",
      "Epoch: 144 Batch: 400, loss: 0.7329329482655941\n",
      "Epoch: 144 Batch: 500, loss: 0.18023598394061094\n",
      "Epoch: 145 Batch: 0, loss: 0.14572038496654724\n",
      "Epoch: 145 Batch: 100, loss: 0.0660099860601135\n",
      "Epoch: 145 Batch: 200, loss: 1.3478273698259091\n",
      "Epoch: 145 Batch: 300, loss: 0.43156676565742397\n",
      "Epoch: 145 Batch: 400, loss: 0.008286266262218086\n",
      "Epoch: 145 Batch: 500, loss: 0.2600736681774173\n",
      "Epoch: 146 Batch: 0, loss: 0.01441346416902991\n",
      "Epoch: 146 Batch: 100, loss: 0.2356275462496478\n",
      "Epoch: 146 Batch: 200, loss: 0.0006270126538450614\n",
      "Epoch: 146 Batch: 300, loss: 0.0719342986945669\n",
      "Epoch: 146 Batch: 400, loss: 0.866587875530553\n",
      "Epoch: 146 Batch: 500, loss: 0.01852375366294895\n",
      "Epoch: 147 Batch: 0, loss: 0.23769312717271643\n",
      "Epoch: 147 Batch: 100, loss: 0.6444246156625563\n",
      "Epoch: 147 Batch: 200, loss: 4.285808081252468\n",
      "Epoch: 147 Batch: 300, loss: 0.06749814166915401\n",
      "Epoch: 147 Batch: 400, loss: 0.06392249759669222\n",
      "Epoch: 147 Batch: 500, loss: 0.3179911073378987\n",
      "Epoch: 148 Batch: 0, loss: 0.6974009374137057\n",
      "Epoch: 148 Batch: 100, loss: 0.7160854111851914\n",
      "Epoch: 148 Batch: 200, loss: 0.00015308372862471475\n",
      "Epoch: 148 Batch: 300, loss: 0.10930994454801651\n",
      "Epoch: 148 Batch: 400, loss: 0.026487846954875348\n",
      "Epoch: 148 Batch: 500, loss: 0.08153852618904195\n",
      "Epoch: 149 Batch: 0, loss: 1.347530620018351\n",
      "Epoch: 149 Batch: 100, loss: 0.0962624634126584\n",
      "Epoch: 149 Batch: 200, loss: 0.04096255243924441\n",
      "Epoch: 149 Batch: 300, loss: 0.07890328051865259\n",
      "Epoch: 149 Batch: 400, loss: 0.0023813246993447928\n",
      "Epoch: 149 Batch: 500, loss: 0.3625089280650819\n",
      "Epoch: 150 Batch: 0, loss: 0.15700195999434818\n",
      "Epoch: 150 Batch: 100, loss: 0.022263610328551564\n",
      "Epoch: 150 Batch: 200, loss: 3.3856406303484315e-05\n",
      "Epoch: 150 Batch: 300, loss: 0.06317377662235062\n",
      "Epoch: 150 Batch: 400, loss: 0.42493182159927906\n",
      "Epoch: 150 Batch: 500, loss: 0.036497701001689815\n",
      "Epoch: 151 Batch: 0, loss: 0.004388393310139402\n",
      "Epoch: 151 Batch: 100, loss: 0.2893321620608096\n",
      "Epoch: 151 Batch: 200, loss: 0.23102343472826234\n",
      "Epoch: 151 Batch: 300, loss: 0.825472169842295\n",
      "Epoch: 151 Batch: 400, loss: 0.20924703309259787\n",
      "Epoch: 151 Batch: 500, loss: 0.0806678432777469\n",
      "Epoch: 152 Batch: 0, loss: 0.7409580906741373\n",
      "Epoch: 152 Batch: 100, loss: 0.9565164557695403\n",
      "Epoch: 152 Batch: 200, loss: 0.0017790730589778993\n",
      "Epoch: 152 Batch: 300, loss: 0.021477441774604485\n",
      "Epoch: 152 Batch: 400, loss: 0.0005655203108170525\n",
      "Epoch: 152 Batch: 500, loss: 0.13815025005052498\n",
      "Epoch: 153 Batch: 0, loss: 0.1825135162012208\n",
      "Epoch: 153 Batch: 100, loss: 0.8120572833615517\n",
      "Epoch: 153 Batch: 200, loss: 0.08812618713597795\n",
      "Epoch: 153 Batch: 300, loss: 0.9738636570463902\n",
      "Epoch: 153 Batch: 400, loss: 1.0993115213188038\n",
      "Epoch: 153 Batch: 500, loss: 0.4566814097144327\n",
      "Epoch: 154 Batch: 0, loss: 0.4253929071799318\n",
      "Epoch: 154 Batch: 100, loss: 1.3519319666505902\n",
      "Epoch: 154 Batch: 200, loss: 0.03811040281805724\n",
      "Epoch: 154 Batch: 300, loss: 0.18307962124763594\n",
      "Epoch: 154 Batch: 400, loss: 0.2611742550789839\n",
      "Epoch: 154 Batch: 500, loss: 0.925335106871993\n",
      "Epoch: 155 Batch: 0, loss: 0.09047561120068578\n",
      "Epoch: 155 Batch: 100, loss: 0.0017258278440125479\n",
      "Epoch: 155 Batch: 200, loss: 0.07388609392207493\n",
      "Epoch: 155 Batch: 300, loss: 0.2784638326216792\n",
      "Epoch: 155 Batch: 400, loss: 0.00011225882761153163\n",
      "Epoch: 155 Batch: 500, loss: 0.24048661272705218\n",
      "Epoch: 156 Batch: 0, loss: 0.28571181108611\n",
      "Epoch: 156 Batch: 100, loss: 0.31771952899576666\n",
      "Epoch: 156 Batch: 200, loss: 0.0002876850540275269\n",
      "Epoch: 156 Batch: 300, loss: 0.06797085378446904\n",
      "Epoch: 156 Batch: 400, loss: 0.3521965324662236\n",
      "Epoch: 156 Batch: 500, loss: 0.00039203786617539603\n",
      "Epoch: 157 Batch: 0, loss: 0.004350621628020885\n",
      "Epoch: 157 Batch: 100, loss: 0.925709324660209\n",
      "Epoch: 157 Batch: 200, loss: 1.2395025029443194\n",
      "Epoch: 157 Batch: 300, loss: 0.086962611910034\n",
      "Epoch: 157 Batch: 400, loss: 0.024178735993637856\n",
      "Epoch: 157 Batch: 500, loss: 0.0013587748856850892\n",
      "Epoch: 158 Batch: 0, loss: 0.01867269634779413\n",
      "Epoch: 158 Batch: 100, loss: 0.09045227917870251\n",
      "Epoch: 158 Batch: 200, loss: 0.32692378128777105\n",
      "Epoch: 158 Batch: 300, loss: 1.8554639313258767\n",
      "Epoch: 158 Batch: 400, loss: 0.17967400068357212\n",
      "Epoch: 158 Batch: 500, loss: 0.007552623992023517\n",
      "Epoch: 159 Batch: 0, loss: 0.06908043073970414\n",
      "Epoch: 159 Batch: 100, loss: 0.293240665983016\n",
      "Epoch: 159 Batch: 200, loss: 0.3606488245003375\n",
      "Epoch: 159 Batch: 300, loss: 0.5275253750372532\n",
      "Epoch: 159 Batch: 400, loss: 0.06691395533654519\n",
      "Epoch: 159 Batch: 500, loss: 0.4671402578231865\n",
      "Epoch: 160 Batch: 0, loss: 0.013882190943517676\n",
      "Epoch: 160 Batch: 100, loss: 0.07169387097443103\n",
      "Epoch: 160 Batch: 200, loss: 0.043221431064295206\n",
      "Epoch: 160 Batch: 300, loss: 0.06105148334766224\n",
      "Epoch: 160 Batch: 400, loss: 0.4669655346433366\n",
      "Epoch: 160 Batch: 500, loss: 0.007863241168342496\n",
      "Epoch: 161 Batch: 0, loss: 0.0033155561165191983\n",
      "Epoch: 161 Batch: 100, loss: 1.203832013124828\n",
      "Epoch: 161 Batch: 200, loss: 1.6776363094230435\n",
      "Epoch: 161 Batch: 300, loss: 0.35171453595828495\n",
      "Epoch: 161 Batch: 400, loss: 0.08932739380377672\n",
      "Epoch: 161 Batch: 500, loss: 0.007596487256516762\n",
      "Epoch: 162 Batch: 0, loss: 0.3049242319843856\n",
      "Epoch: 162 Batch: 100, loss: 0.5134519691594556\n",
      "Epoch: 162 Batch: 200, loss: 0.2328935608099854\n",
      "Epoch: 162 Batch: 300, loss: 0.02176709647460333\n",
      "Epoch: 162 Batch: 400, loss: 0.16184167674951028\n",
      "Epoch: 162 Batch: 500, loss: 0.016897063209133905\n",
      "Epoch: 163 Batch: 0, loss: 0.30362052425350405\n",
      "Epoch: 163 Batch: 100, loss: 0.0005769038026073968\n",
      "Epoch: 163 Batch: 200, loss: 0.09439515325111578\n",
      "Epoch: 163 Batch: 300, loss: 0.8720922813721534\n",
      "Epoch: 163 Batch: 400, loss: 0.29262059802397655\n",
      "Epoch: 163 Batch: 500, loss: 0.4010853750438645\n",
      "Epoch: 164 Batch: 0, loss: 0.00011687794988058396\n",
      "Epoch: 164 Batch: 100, loss: 2.6840629201479844\n",
      "Epoch: 164 Batch: 200, loss: 0.3853449200244554\n",
      "Epoch: 164 Batch: 300, loss: 0.5250000693723768\n",
      "Epoch: 164 Batch: 400, loss: 0.2996952957659075\n",
      "Epoch: 164 Batch: 500, loss: 0.2964971800863612\n",
      "Epoch: 165 Batch: 0, loss: 0.13213269170490882\n",
      "Epoch: 165 Batch: 100, loss: 0.8368931092747894\n",
      "Epoch: 165 Batch: 200, loss: 0.28472047526909566\n",
      "Epoch: 165 Batch: 300, loss: 0.0004031593928972894\n",
      "Epoch: 165 Batch: 400, loss: 0.1396403283302858\n",
      "Epoch: 165 Batch: 500, loss: 0.00037185473595285174\n",
      "Epoch: 166 Batch: 0, loss: 4.2354865862159246\n",
      "Epoch: 166 Batch: 100, loss: 0.7941596852849665\n",
      "Epoch: 166 Batch: 200, loss: 0.4545573990239524\n",
      "Epoch: 166 Batch: 300, loss: 1.2100070938204597\n",
      "Epoch: 166 Batch: 400, loss: 0.15443750944578918\n",
      "Epoch: 166 Batch: 500, loss: 0.06316089769005265\n",
      "Epoch: 167 Batch: 0, loss: 0.8624173197970677\n",
      "Epoch: 167 Batch: 100, loss: 0.12902585097392236\n",
      "Epoch: 167 Batch: 200, loss: 0.35529909602352827\n",
      "Epoch: 167 Batch: 300, loss: 0.12269578894851363\n",
      "Epoch: 167 Batch: 400, loss: 0.004861585608516383\n",
      "Epoch: 167 Batch: 500, loss: 0.45814812857863474\n",
      "Epoch: 168 Batch: 0, loss: 0.06649258042817233\n",
      "Epoch: 168 Batch: 100, loss: 0.2895633063476687\n",
      "Epoch: 168 Batch: 200, loss: 0.47198239881586274\n",
      "Epoch: 168 Batch: 300, loss: 0.02404019918103845\n",
      "Epoch: 168 Batch: 400, loss: 0.36922052863424415\n",
      "Epoch: 168 Batch: 500, loss: 0.185121524894645\n",
      "Epoch: 169 Batch: 0, loss: 0.0005377994855283931\n",
      "Epoch: 169 Batch: 100, loss: 1.0592084366874839\n",
      "Epoch: 169 Batch: 200, loss: 0.0907527940550018\n",
      "Epoch: 169 Batch: 300, loss: 0.02605496134073001\n",
      "Epoch: 169 Batch: 400, loss: 0.0726688573666377\n",
      "Epoch: 169 Batch: 500, loss: 0.19873439800149495\n",
      "Epoch: 170 Batch: 0, loss: 0.35148739204240276\n",
      "Epoch: 170 Batch: 100, loss: 1.3498730456971333\n",
      "Epoch: 170 Batch: 200, loss: 0.00040114777775435774\n",
      "Epoch: 170 Batch: 300, loss: 1.2181864741938842\n",
      "Epoch: 170 Batch: 400, loss: 0.1489034239333926\n",
      "Epoch: 170 Batch: 500, loss: 0.3268052097922824\n",
      "Epoch: 171 Batch: 0, loss: 0.3021742974532865\n",
      "Epoch: 171 Batch: 100, loss: 0.1532187427009747\n",
      "Epoch: 171 Batch: 200, loss: 0.07892884151350497\n",
      "Epoch: 171 Batch: 300, loss: 0.636157190070248\n",
      "Epoch: 171 Batch: 400, loss: 0.9827496049188457\n",
      "Epoch: 171 Batch: 500, loss: 0.5203462517528762\n",
      "Epoch: 172 Batch: 0, loss: 0.003225849739376265\n",
      "Epoch: 172 Batch: 100, loss: 0.10501777501087735\n",
      "Epoch: 172 Batch: 200, loss: 0.0702834212051515\n",
      "Epoch: 172 Batch: 300, loss: 0.130784635820877\n",
      "Epoch: 172 Batch: 400, loss: 5.244713697546744e-05\n",
      "Epoch: 172 Batch: 500, loss: 0.014799652925656912\n",
      "Epoch: 173 Batch: 0, loss: 1.6831782891431284\n",
      "Epoch: 173 Batch: 100, loss: 0.5631680157674106\n",
      "Epoch: 173 Batch: 200, loss: 0.09238191123008155\n",
      "Epoch: 173 Batch: 300, loss: 1.0493615895432726\n",
      "Epoch: 173 Batch: 400, loss: 0.04620714199353189\n",
      "Epoch: 173 Batch: 500, loss: 0.06718106063301127\n",
      "Epoch: 174 Batch: 0, loss: 0.6417063841610882\n",
      "Epoch: 174 Batch: 100, loss: 0.3829073177253032\n",
      "Epoch: 174 Batch: 200, loss: 0.46736752336263554\n",
      "Epoch: 174 Batch: 300, loss: 0.29302248659364977\n",
      "Epoch: 174 Batch: 400, loss: 0.03372557559271302\n",
      "Epoch: 174 Batch: 500, loss: 0.002658032804175216\n",
      "Epoch: 175 Batch: 0, loss: 0.36434623664141286\n",
      "Epoch: 175 Batch: 100, loss: 0.5314425300115737\n",
      "Epoch: 175 Batch: 200, loss: 0.04966593138209137\n",
      "Epoch: 175 Batch: 300, loss: 0.06658167494482534\n",
      "Epoch: 175 Batch: 400, loss: 0.0024938031794294775\n",
      "Epoch: 175 Batch: 500, loss: 0.4795351462361701\n",
      "Epoch: 176 Batch: 0, loss: 0.2313063981306591\n",
      "Epoch: 176 Batch: 100, loss: 0.21373283733884063\n",
      "Epoch: 176 Batch: 200, loss: 0.015420194118198394\n",
      "Epoch: 176 Batch: 300, loss: 0.12965155203558418\n",
      "Epoch: 176 Batch: 400, loss: 2.282768900277292\n",
      "Epoch: 176 Batch: 500, loss: 1.6808055570669336\n",
      "Epoch: 177 Batch: 0, loss: 0.3440255569102683\n",
      "Epoch: 177 Batch: 100, loss: 0.47446542683308135\n",
      "Epoch: 177 Batch: 200, loss: 0.618878453997636\n",
      "Epoch: 177 Batch: 300, loss: 1.5028908776070283e-05\n",
      "Epoch: 177 Batch: 400, loss: 0.367593076147293\n",
      "Epoch: 177 Batch: 500, loss: 0.20800357640585054\n",
      "Epoch: 178 Batch: 0, loss: 0.10737220206409265\n",
      "Epoch: 178 Batch: 100, loss: 0.36374005491348316\n",
      "Epoch: 178 Batch: 200, loss: 2.5932346405179545\n",
      "Epoch: 178 Batch: 300, loss: 0.6571560483062614\n",
      "Epoch: 178 Batch: 400, loss: 0.00044898518388386153\n",
      "Epoch: 178 Batch: 500, loss: 1.8477825112136157\n",
      "Epoch: 179 Batch: 0, loss: 0.03644193871798306\n",
      "Epoch: 179 Batch: 100, loss: 1.956231215535908\n",
      "Epoch: 179 Batch: 200, loss: 0.24707244623946348\n",
      "Epoch: 179 Batch: 300, loss: 0.297929624127732\n",
      "Epoch: 179 Batch: 400, loss: 0.05776590657451804\n",
      "Epoch: 179 Batch: 500, loss: 0.020254457782048783\n",
      "Epoch: 180 Batch: 0, loss: 0.23138159002323605\n",
      "Epoch: 180 Batch: 100, loss: 0.3705635663992015\n",
      "Epoch: 180 Batch: 200, loss: 0.07879302279851591\n",
      "Epoch: 180 Batch: 300, loss: 0.136962489321773\n",
      "Epoch: 180 Batch: 400, loss: 0.0838841032715358\n",
      "Epoch: 180 Batch: 500, loss: 0.7732172461685957\n",
      "Epoch: 181 Batch: 0, loss: 0.014657614109682133\n",
      "Epoch: 181 Batch: 100, loss: 0.016565474541170556\n",
      "Epoch: 181 Batch: 200, loss: 0.6480506678867848\n",
      "Epoch: 181 Batch: 300, loss: 0.27453586012340014\n",
      "Epoch: 181 Batch: 400, loss: 1.2220328354150474\n",
      "Epoch: 181 Batch: 500, loss: 0.8862573116847033\n",
      "Epoch: 182 Batch: 0, loss: 0.5933476697491213\n",
      "Epoch: 182 Batch: 100, loss: 0.27717751298908644\n",
      "Epoch: 182 Batch: 200, loss: 0.15325381771649232\n",
      "Epoch: 182 Batch: 300, loss: 0.013986582024593753\n",
      "Epoch: 182 Batch: 400, loss: 0.041271732014746404\n",
      "Epoch: 182 Batch: 500, loss: 0.10120189890638331\n",
      "Epoch: 183 Batch: 0, loss: 0.022108675789575104\n",
      "Epoch: 183 Batch: 100, loss: 0.437169659059772\n",
      "Epoch: 183 Batch: 200, loss: 0.015713883049172508\n",
      "Epoch: 183 Batch: 300, loss: 0.06650130951464839\n",
      "Epoch: 183 Batch: 400, loss: 0.0004764993579444076\n",
      "Epoch: 183 Batch: 500, loss: 0.11846364488929342\n",
      "Epoch: 184 Batch: 0, loss: 0.000966220715826776\n",
      "Epoch: 184 Batch: 100, loss: 1.9379984337704874\n",
      "Epoch: 184 Batch: 200, loss: 0.4642692204490837\n",
      "Epoch: 184 Batch: 300, loss: 0.4054708257265768\n",
      "Epoch: 184 Batch: 400, loss: 0.17376439355942855\n",
      "Epoch: 184 Batch: 500, loss: 0.02717148618312914\n",
      "Epoch: 185 Batch: 0, loss: 0.6044521571508602\n",
      "Epoch: 185 Batch: 100, loss: 0.0005912195602191904\n",
      "Epoch: 185 Batch: 200, loss: 1.1476392938451223\n",
      "Epoch: 185 Batch: 300, loss: 0.00046225583259190895\n",
      "Epoch: 185 Batch: 400, loss: 0.48854846061744966\n",
      "Epoch: 185 Batch: 500, loss: 0.14422623359323697\n",
      "Epoch: 186 Batch: 0, loss: 0.0009402816775157558\n",
      "Epoch: 186 Batch: 100, loss: 0.0977547435926332\n",
      "Epoch: 186 Batch: 200, loss: 2.3096021480124835\n",
      "Epoch: 186 Batch: 300, loss: 0.02072619878253282\n",
      "Epoch: 186 Batch: 400, loss: 0.06141241513853916\n",
      "Epoch: 186 Batch: 500, loss: 0.3663550686619387\n",
      "Epoch: 187 Batch: 0, loss: 0.01926482816178499\n",
      "Epoch: 187 Batch: 100, loss: 0.5393727119449526\n",
      "Epoch: 187 Batch: 200, loss: 0.00012081565282887482\n",
      "Epoch: 187 Batch: 300, loss: 0.23016686484696455\n",
      "Epoch: 187 Batch: 400, loss: 0.0023177902118656428\n",
      "Epoch: 187 Batch: 500, loss: 0.10768798554796469\n",
      "Epoch: 188 Batch: 0, loss: 0.007937538880677818\n",
      "Epoch: 188 Batch: 100, loss: 0.2568190342734747\n",
      "Epoch: 188 Batch: 200, loss: 0.0643997212723862\n",
      "Epoch: 188 Batch: 300, loss: 0.027481945176152687\n",
      "Epoch: 188 Batch: 400, loss: 0.0009786985276747364\n",
      "Epoch: 188 Batch: 500, loss: 0.021038240208213547\n",
      "Epoch: 189 Batch: 0, loss: 0.07904867777960398\n",
      "Epoch: 189 Batch: 100, loss: 0.4214516719628986\n",
      "Epoch: 189 Batch: 200, loss: 0.3643504331318851\n",
      "Epoch: 189 Batch: 300, loss: 0.07042473350998273\n",
      "Epoch: 189 Batch: 400, loss: 0.029937654928198113\n",
      "Epoch: 189 Batch: 500, loss: 0.002698974771344629\n",
      "Epoch: 190 Batch: 0, loss: 0.013962785683281038\n",
      "Epoch: 190 Batch: 100, loss: 0.5710472037138015\n",
      "Epoch: 190 Batch: 200, loss: 0.20950211177067996\n",
      "Epoch: 190 Batch: 300, loss: 0.4430773757388383\n",
      "Epoch: 190 Batch: 400, loss: 0.36573645058159243\n",
      "Epoch: 190 Batch: 500, loss: 9.624151936186539e-05\n",
      "Epoch: 191 Batch: 0, loss: 0.013268075975546755\n",
      "Epoch: 191 Batch: 100, loss: 0.030986748036852925\n",
      "Epoch: 191 Batch: 200, loss: 0.005250195534589484\n",
      "Epoch: 191 Batch: 300, loss: 0.28928071549412426\n",
      "Epoch: 191 Batch: 400, loss: 0.10517185748741882\n",
      "Epoch: 191 Batch: 500, loss: 0.07537099598129231\n",
      "Epoch: 192 Batch: 0, loss: 0.00015762498035132942\n",
      "Epoch: 192 Batch: 100, loss: 0.03774322801366179\n",
      "Epoch: 192 Batch: 200, loss: 0.004077085121525191\n",
      "Epoch: 192 Batch: 300, loss: 0.8493830888611522\n",
      "Epoch: 192 Batch: 400, loss: 0.926566691308962\n",
      "Epoch: 192 Batch: 500, loss: 7.343241056601724e-05\n",
      "Epoch: 193 Batch: 0, loss: 0.2183277071759518\n",
      "Epoch: 193 Batch: 100, loss: 0.3274525266264916\n",
      "Epoch: 193 Batch: 200, loss: 1.3134395587637193\n",
      "Epoch: 193 Batch: 300, loss: 0.3248642782393823\n",
      "Epoch: 193 Batch: 400, loss: 2.5838889915262144\n",
      "Epoch: 193 Batch: 500, loss: 0.06373543472307631\n",
      "Epoch: 194 Batch: 0, loss: 1.011604313766588\n",
      "Epoch: 194 Batch: 100, loss: 1.074537283616177\n",
      "Epoch: 194 Batch: 200, loss: 0.16817502017183164\n",
      "Epoch: 194 Batch: 300, loss: 0.1337890259958213\n",
      "Epoch: 194 Batch: 400, loss: 0.027439140502682053\n",
      "Epoch: 194 Batch: 500, loss: 0.36738510849673217\n",
      "Epoch: 195 Batch: 0, loss: 0.0681251665596198\n",
      "Epoch: 195 Batch: 100, loss: 0.004665563527336179\n",
      "Epoch: 195 Batch: 200, loss: 0.5561684662377233\n",
      "Epoch: 195 Batch: 300, loss: 0.39379529369399885\n",
      "Epoch: 195 Batch: 400, loss: 0.005197657396753666\n",
      "Epoch: 195 Batch: 500, loss: 0.00041943655718037706\n",
      "Epoch: 196 Batch: 0, loss: 0.0572935430914842\n",
      "Epoch: 196 Batch: 100, loss: 4.777791351419303e-06\n",
      "Epoch: 196 Batch: 200, loss: 0.001788187978226258\n",
      "Epoch: 196 Batch: 300, loss: 0.6434329628113393\n",
      "Epoch: 196 Batch: 400, loss: 0.009022989191981199\n",
      "Epoch: 196 Batch: 500, loss: 0.12826084128326543\n",
      "Epoch: 197 Batch: 0, loss: 0.06277714919357869\n",
      "Epoch: 197 Batch: 100, loss: 0.09251881884492219\n",
      "Epoch: 197 Batch: 200, loss: 0.32607473572779655\n",
      "Epoch: 197 Batch: 300, loss: 0.034793703357479215\n",
      "Epoch: 197 Batch: 400, loss: 0.2686125502949058\n",
      "Epoch: 197 Batch: 500, loss: 0.16617609901009828\n",
      "Epoch: 198 Batch: 0, loss: 0.07501853946772162\n",
      "Epoch: 198 Batch: 100, loss: 0.01822186633528549\n",
      "Epoch: 198 Batch: 200, loss: 0.6158756368317604\n",
      "Epoch: 198 Batch: 300, loss: 1.685899209181735\n",
      "Epoch: 198 Batch: 400, loss: 0.00013585555068298719\n",
      "Epoch: 198 Batch: 500, loss: 0.06839926992634596\n",
      "Epoch: 199 Batch: 0, loss: 1.67094984318951\n",
      "Epoch: 199 Batch: 100, loss: 0.09267167934626748\n",
      "Epoch: 199 Batch: 200, loss: 0.03456286893300513\n",
      "Epoch: 199 Batch: 300, loss: 0.03696490047460627\n",
      "Epoch: 199 Batch: 400, loss: 0.02036457073800259\n",
      "Epoch: 199 Batch: 500, loss: 0.052809537616594626\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "for i in random_test_indices:\n",
    "    x1, x2, y = rm[i], lstat[i], target[i]\n",
    "    predicate = model(np.array([x1, x2]), w, b)\n",
    "    predicate_label = int(predicate > decision_boundary)\n",
    "\n",
    "    print('RM: {}, LSTAT: {}, EXPENSIVE: {}, Predicated: {}'.format(x1, x2, y, predicate_label))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RM: 5.701, LSTAT: 18.35, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 4.973, LSTAT: 12.64, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.79, LSTAT: 15.84, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.416, LSTAT: 9.04, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 4.963, LSTAT: 14.0, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.619, LSTAT: 7.22, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.987, LSTAT: 26.77, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.065, LSTAT: 5.52, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.642, LSTAT: 9.69, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 7.489, LSTAT: 1.73, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.416, LSTAT: 6.19, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.393, LSTAT: 5.19, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.565, LSTAT: 17.16, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.024, LSTAT: 1.98, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.88, LSTAT: 12.03, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.404, LSTAT: 20.31, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.003, LSTAT: 21.32, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.709, LSTAT: 15.79, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.957, LSTAT: 3.53, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.416, LSTAT: 6.19, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.875, LSTAT: 2.97, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.241, LSTAT: 5.49, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.602, LSTAT: 16.2, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.579, LSTAT: 5.49, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.453, LSTAT: 8.23, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.343, LSTAT: 20.32, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.348, LSTAT: 17.64, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 4.138, LSTAT: 23.34, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.101, LSTAT: 9.81, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.004, LSTAT: 17.1, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.251, LSTAT: 16.44, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.818, LSTAT: 22.11, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.007, LSTAT: 5.5, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.852, LSTAT: 19.78, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.826, LSTAT: 4.16, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.211, LSTAT: 7.44, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.868, LSTAT: 9.97, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.425, LSTAT: 12.03, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.023, LSTAT: 11.72, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.459, LSTAT: 23.98, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.416, LSTAT: 6.19, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 8.704, LSTAT: 5.12, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.63, LSTAT: 6.53, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.421, LSTAT: 9.14, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.437, LSTAT: 14.36, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.316, LSTAT: 5.68, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.635, LSTAT: 4.54, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 5.594, LSTAT: 13.09, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.575, LSTAT: 4.98, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.145, LSTAT: 6.86, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.03, LSTAT: 18.8, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.826, LSTAT: 4.16, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.556, LSTAT: 4.56, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.708, LSTAT: 11.74, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.822, LSTAT: 15.03, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.727, LSTAT: 5.29, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.145, LSTAT: 6.86, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 6.484, LSTAT: 18.68, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.913, LSTAT: 16.21, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.417, LSTAT: 19.31, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.786, LSTAT: 14.15, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.431, LSTAT: 15.39, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.985, LSTAT: 9.74, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.701, LSTAT: 16.42, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.936, LSTAT: 16.94, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.884, LSTAT: 7.79, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 7.267, LSTAT: 6.05, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.223, LSTAT: 21.78, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.144, LSTAT: 9.45, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 6.372, LSTAT: 11.12, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.787, LSTAT: 10.24, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.249, LSTAT: 4.81, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.203, LSTAT: 9.59, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 5.39, LSTAT: 21.14, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.405, LSTAT: 8.2, EXPENSIVE: 0, Predicated: 1\n",
      "RM: 5.597, LSTAT: 21.45, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.856, LSTAT: 13.0, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.657, LSTAT: 21.22, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.349, LSTAT: 19.77, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.402, LSTAT: 11.32, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.594, LSTAT: 13.09, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.572, LSTAT: 14.69, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.693, LSTAT: 17.19, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.593, LSTAT: 12.5, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 8.259, LSTAT: 3.54, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.212, LSTAT: 17.6, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 7.82, LSTAT: 3.57, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 8.337, LSTAT: 2.47, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 7.107, LSTAT: 8.61, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.762, LSTAT: 9.5, EXPENSIVE: 1, Predicated: 0\n",
      "RM: 5.875, LSTAT: 14.43, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.957, LSTAT: 3.53, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 6.193, LSTAT: 15.17, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.399, LSTAT: 30.81, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 5.727, LSTAT: 11.28, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.113, LSTAT: 12.73, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.98, LSTAT: 5.04, EXPENSIVE: 1, Predicated: 1\n",
      "RM: 5.834, LSTAT: 8.47, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.229, LSTAT: 13.11, EXPENSIVE: 0, Predicated: 0\n",
      "RM: 6.678, LSTAT: 6.27, EXPENSIVE: 1, Predicated: 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\n",
    "# 剩下一件事情，就是要检查我们这个模型的准确度到底如何！！\n",
    "\"\"\"\n",
    "如何衡量模型的好坏：\n",
    "1. accuracy 准确度\n",
    "2. precision 精确度\n",
    "3. recall 召回率\n",
    "4. f1, f2 score\n",
    "5. AUC-ROC 曲线\n",
    "引出一个非常非常重要的概念： =》 过拟合 和 欠拟合 （over-fitting and under-fitting）\n",
    "整个机器学习的过程，就是在不断的进行过拟合和欠拟合的调整！\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n如何衡量模型的好坏：\\n1. accuracy 准确度\\n2. precision 精确度\\n3. recall 召回率\\n4. f1, f2 score\\n5. AUC-ROC 曲线\\n引出一个非常非常重要的概念： =》 过拟合 和 欠拟合 （over-fitting and under-fitting）\\n整个机器学习的过程，就是在不断的进行过拟合和欠拟合的调整！\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "32732e49ddba1da8b293d0354da9484fcc377d4ba69e79a82935691a68d0ecf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}