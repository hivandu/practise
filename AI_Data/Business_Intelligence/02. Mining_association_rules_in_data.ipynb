{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 挖掘数据中的关联规则"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from efficient_apriori import apriori\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "path = os.path.expanduser('~/data/')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# 设置数据集\n",
    "transactions = [('牛奶','面包','尿布'),\n",
    "\t\t('可乐','面包', '尿布', '啤酒'),\n",
    "\t\t('牛奶','尿布', '啤酒', '鸡蛋'),\n",
    "\t\t('面包', '牛奶', '尿布', '啤酒'),\n",
    "\t\t('面包', '牛奶', '尿布', '可乐')]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# 挖掘频繁项集和频繁规则\n",
    "itemsets, rules = apriori(transactions, min_support=0.5,  min_confidence=1)\n",
    "print(\"频繁项集：\", itemsets)\n",
    "print(\"关联规则：\", rules)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "频繁项集： {1: {('尿布',): 5, ('面包',): 4, ('牛奶',): 4, ('啤酒',): 3}, 2: {('尿布', '牛奶'): 4, ('尿布', '面包'): 4, ('牛奶', '面包'): 3, ('啤酒', '尿布'): 3}, 3: {('尿布', '牛奶', '面包'): 3}}\n",
      "关联规则： [{牛奶} -> {尿布}, {面包} -> {尿布}, {啤酒} -> {尿布}, {牛奶, 面包} -> {尿布}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## BreadBasket"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# 数据加载\n",
    "data = pd.read_csv(path +'/BI/BreadBasket_DMS.csv')\n",
    "# 统一小写\n",
    "data['Item'] = data['Item'].str.lower()\n",
    "# 去掉none项\n",
    "data = data.drop(data[data.Item == 'none'].index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 采用efficient_apriori工具包\n",
    "def rule1():\n",
    "\tfrom efficient_apriori import apriori\n",
    "\tstart = time.time()\n",
    "\t# 得到一维数组orders_series，并且将Transaction作为index, value为Item取值\n",
    "\torders_series = data.set_index('Transaction')['Item']\n",
    "\t# 将数据集进行格式转换\n",
    "\ttransactions = []\n",
    "\ttemp_index = 0\n",
    "\tfor i, v in orders_series.items():\n",
    "\t\tif i != temp_index:\n",
    "\t\t\ttemp_set = set()\n",
    "\t\t\ttemp_index = i\n",
    "\t\t\ttemp_set.add(v)\n",
    "\t\t\ttransactions.append(temp_set)\n",
    "\t\telse:\n",
    "\t\t\ttemp_set.add(v)\n",
    "\t\n",
    "\t# 挖掘频繁项集和频繁规则\n",
    "\titemsets, rules = apriori(transactions, min_support=0.02,  min_confidence=0.5)\n",
    "\tprint('频繁项集：', itemsets)\n",
    "\tprint('关联规则：', rules)\n",
    "\tend = time.time()\n",
    "\tprint(\"用时：\", end-start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# 采用mlxtend.frequent_patterns工具包\n",
    "def rule2():\n",
    "\tfrom mlxtend.frequent_patterns import apriori\n",
    "\tfrom mlxtend.frequent_patterns import association_rules\n",
    "\tpd.options.display.max_columns=100\n",
    "\tstart = time.time()\n",
    "\thot_encoded_df=data.groupby(['Transaction','Item'])['Item'].count().unstack().reset_index().fillna(0).set_index('Transaction')\n",
    "\thot_encoded_df = hot_encoded_df.applymap(encode_units)\n",
    "\tfrequent_itemsets = apriori(hot_encoded_df, min_support=0.02, use_colnames=True)\n",
    "\trules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.5)\n",
    "\tprint(\"频繁项集：\", frequent_itemsets)\n",
    "\tprint(\"关联规则：\", rules[ (rules['lift'] >= 1) & (rules['confidence'] >= 0.5) ])\n",
    "\t#print(rules['confidence'])\n",
    "\tend = time.time()\n",
    "\tprint(\"用时：\", end-start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "rule1()\n",
    "print('-'*100)\n",
    "rule2()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "频繁项集： {1: {('scandinavian',): 275, ('cookies',): 515, ('hot chocolate',): 552, ('muffin',): 364, ('coffee',): 4528, ('pastry',): 815, ('bread',): 3096, ('medialuna',): 585, ('tea',): 1350, ('farm house',): 371, ('juice',): 365, ('soup',): 326, ('cake',): 983, ('sandwich',): 680, ('alfajores',): 344, ('brownie',): 379, ('truffles',): 192, ('toast',): 318, ('scone',): 327}, 2: {('bread', 'coffee'): 852, ('bread', 'pastry'): 276, ('coffee', 'pastry'): 450, ('coffee', 'medialuna'): 333, ('coffee', 'tea'): 472, ('bread', 'tea'): 266, ('coffee', 'juice'): 195, ('coffee', 'hot chocolate'): 280, ('coffee', 'cookies'): 267, ('cake', 'coffee'): 518, ('cake', 'tea'): 225, ('bread', 'cake'): 221, ('coffee', 'sandwich'): 362, ('coffee', 'toast'): 224}}\n",
      "关联规则： [{pastry} -> {coffee}, {medialuna} -> {coffee}, {juice} -> {coffee}, {hot chocolate} -> {coffee}, {cookies} -> {coffee}, {cake} -> {coffee}, {sandwich} -> {coffee}, {toast} -> {coffee}]\n",
      "用时： 0.12102985382080078\n",
      "----------------------------------------------------------------------------------------------------\n",
      "频繁项集：      support                 itemsets\n",
      "0   0.036348              (alfajores)\n",
      "1   0.327134                  (bread)\n",
      "2   0.040046                (brownie)\n",
      "3   0.103867                   (cake)\n",
      "4   0.478445                 (coffee)\n",
      "5   0.054417                (cookies)\n",
      "6   0.039201             (farm house)\n",
      "7   0.058326          (hot chocolate)\n",
      "8   0.038567                  (juice)\n",
      "9   0.061813              (medialuna)\n",
      "10  0.038462                 (muffin)\n",
      "11  0.086116                 (pastry)\n",
      "12  0.071851               (sandwich)\n",
      "13  0.029057           (scandinavian)\n",
      "14  0.034552                  (scone)\n",
      "15  0.034446                   (soup)\n",
      "16  0.142646                    (tea)\n",
      "17  0.033601                  (toast)\n",
      "18  0.020287               (truffles)\n",
      "19  0.023352            (bread, cake)\n",
      "20  0.090025          (coffee, bread)\n",
      "21  0.029163          (pastry, bread)\n",
      "22  0.028107             (tea, bread)\n",
      "23  0.054734           (coffee, cake)\n",
      "24  0.023774              (tea, cake)\n",
      "25  0.028212        (coffee, cookies)\n",
      "26  0.029586  (coffee, hot chocolate)\n",
      "27  0.020604          (coffee, juice)\n",
      "28  0.035186      (coffee, medialuna)\n",
      "29  0.047549         (coffee, pastry)\n",
      "30  0.038250       (coffee, sandwich)\n",
      "31  0.049873            (coffee, tea)\n",
      "32  0.023669          (coffee, toast)\n",
      "关联规则：         antecedents consequents  antecedent support  consequent support  \\\n",
      "9            (cake)    (coffee)            0.103867            0.478445   \n",
      "13        (cookies)    (coffee)            0.054417            0.478445   \n",
      "15  (hot chocolate)    (coffee)            0.058326            0.478445   \n",
      "17          (juice)    (coffee)            0.038567            0.478445   \n",
      "19      (medialuna)    (coffee)            0.061813            0.478445   \n",
      "21         (pastry)    (coffee)            0.086116            0.478445   \n",
      "23       (sandwich)    (coffee)            0.071851            0.478445   \n",
      "27          (toast)    (coffee)            0.033601            0.478445   \n",
      "\n",
      "     support  confidence      lift  leverage  conviction  \n",
      "9   0.054734    0.526958  1.101399  0.005039    1.102557  \n",
      "13  0.028212    0.518447  1.083608  0.002177    1.083069  \n",
      "15  0.029586    0.507246  1.060199  0.001680    1.058451  \n",
      "17  0.020604    0.534247  1.116632  0.002152    1.119810  \n",
      "19  0.035186    0.569231  1.189753  0.005612    1.210754  \n",
      "21  0.047549    0.552147  1.154046  0.006347    1.164569  \n",
      "23  0.038250    0.532353  1.112674  0.003873    1.115276  \n",
      "27  0.023669    0.704403  1.472276  0.007592    1.764411  \n",
      "用时： 0.2929859161376953\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "## MovieActors"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "### 分析MovieLens 电影分类中的频繁项集和关联规则"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# 数据加载\n",
    "movies = pd.read_csv(path+'/BI/movie_actors.csv')\n",
    "#print(movies.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 将genres进行one-hot编码（离散特征有多少取值，就用多少维来表示这个特征）\n",
    "movies_hot_encoded = movies.drop('actors',1).join(movies.actors.str.get_dummies('/'))\n",
    "pd.options.display.max_columns=100\n",
    "print(movies_hot_encoded.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            title  GangZhao  LukeZhiGangLiu  PengZhenZhong  YuanFang  一纳  丁嘉丽  \\\n",
      "0      囧妈‎ (2020)         0               0              0         0   0    0   \n",
      "1  我和我的祖国‎ (2019)         0               0              0         0   0    0   \n",
      "2   我不是药神‎ (2018)         0               0              0         0   0    0   \n",
      "3  疯狂的外星人‎ (2019)         0               0              0         0   0    0   \n",
      "4   疯狂的石头‎ (2006)         0               0              0         0   0    0   \n",
      "\n",
      "   丁志城  丁志诚  丁黑  万弘杰  严敏  严晓频  中孝介  丹尼尔·海尼  乔任梁  九孔  于和伟  于波  于荣光  于谦  仁龙  \\\n",
      "0    0    0   0    0   0    0    0       0    0   0    0   0    0   0   0   \n",
      "1    0    0   0    0   0    0    0       0    0   0    0   0    0   0   0   \n",
      "2    0    0   0    0   0    0    0       0    0   0    0   0    0   0   0   \n",
      "3    0    0   0    0   0    0    0       0    0   0    1   0    0   0   0   \n",
      "4    0    0   0    0   0    0    0       0    0   0    0   0    0   0   0   \n",
      "\n",
      "   付连智  任达华  任静  任鹏远  伊一  伊春德  伊能静  伊莎贝尔·于佩尔  优恵  何念  何炅  何琳  余彬  余文乐  余男  \\\n",
      "0    0    0   0    0   0    0    0         0   0   0   0   0   0    0   0   \n",
      "1    0    0   0    0   0    0    0         0   0   0   0   0   0    0   0   \n",
      "2    0    0   0    0   0    0    0         0   0   0   0   0   0    0   0   \n",
      "3    0    0   0    0   0    0    0         0   0   0   0   0   0    0   0   \n",
      "4    0    0   0    0   0    0    0         0   1   0   0   0   0    0   0   \n",
      "\n",
      "   佟丽娅  佟大为  佟瑞欣  侯勇  侯梦莎  保剑锋  俞杭英  倪虹洁  傅东育  傅彪  傅浤鸣  傅艺伟  克里斯·帕拉特  ...  \\\n",
      "0    0    0    0   0    0    0    0    0    0   0    0    0        0  ...   \n",
      "1    0    0    0   0    0    0    0    0    0   0    0    0        0  ...   \n",
      "2    0    0    0   0    0    0    0    0    0   0    0    0        0  ...   \n",
      "3    0    0    0   0    0    0    0    0    0   0    0    0        0  ...   \n",
      "4    0    0    0   0    0    0    0    0    0   0    0    0        0  ...   \n",
      "\n",
      "   陈正道  陈红  陈继铭  陈逸宁  陶慧  陶晶莹  陶白莉  陶虹  隋兰  雷佳音  雷恪生  雷蒙德·雷德  霍建起  鞠觉亮  韩三平  \\\n",
      "0    0   0    0    0   0    0    0   0   0    0    0       0    0    0    0   \n",
      "1    0   0    0    0   0    0    0   0   0    0    0       0    0    0    0   \n",
      "2    0   0    0    0   0    0    0   0   0    0    0       0    0    0    0   \n",
      "3    0   0    0    0   0    0    0   0   0    1    0       0    0    0    0   \n",
      "4    0   0    0    0   0    0    0   0   0    0    0       0    0    0    0   \n",
      "\n",
      "   韩东君  韩庚  韩昊霖  颜丙燕  马东  马修·莫里森  马健  马少骅  马思纯  马晓伟  马特·弗里沃  马苏  高一功  高圆圆  \\\n",
      "0    0   0    0    0   0       0   0    0    0    0       0   0    0    0   \n",
      "1    0   0    1    0   0       0   0    0    0    0       0   0    0    0   \n",
      "2    0   0    0    0   0       0   0    0    0    0       0   0    0    0   \n",
      "3    0   0    0    0   0       1   0    0    0    0       0   0    0    0   \n",
      "4    0   0    0    0   0       0   0    0    0    0       0   0    0    0   \n",
      "\n",
      "   高宝宝  高捷  魏宗万  魏积安  鲍国安  麦斯·米科尔森  黄奕  黄宏  黄小蕾  黄尧  黄建新  黄晓明  黄梅莹  黄渤  黄磊  \\\n",
      "0    0   0    0    0    0        0   0   0    0   0    0    0    1   0   0   \n",
      "1    0   0    0    0    0        0   0   0    0   0    0    0    0   1   0   \n",
      "2    0   0    0    0    0        0   0   0    0   0    0    0    0   0   0   \n",
      "3    0   0    0    0    0        0   0   0    0   0    0    0    0   1   0   \n",
      "4    0   0    0    0    0        0   0   0    0   0    0    0    0   1   0   \n",
      "\n",
      "   黄蜀芹  黄轩  黄达亮  黄龄  黎明  黑泽清  \n",
      "0    0   0    0   0   0    0  \n",
      "1    0   0    0   0   0    0  \n",
      "2    0   0    0   0   0    0  \n",
      "3    0   0    0   0   0    0  \n",
      "4    0   0    0   0   0    0  \n",
      "\n",
      "[5 rows x 483 columns]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 将movieId, title设置为index\n",
    "movies_hot_encoded.set_index(['title'],inplace=True)\n",
    "#print(movies_hot_encoded.head())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 挖掘频繁项集，最小支持度为0.02\n",
    "itemsets = apriori(movies_hot_encoded,use_colnames=True, min_support=0.05)\n",
    "# 按照支持度从大到小进行时候粗\n",
    "itemsets = itemsets.sort_values(by=\"support\" , ascending=False) \n",
    "print('-'*20, '频繁项集', '-'*20)\n",
    "print(itemsets)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 频繁项集 --------------------\n",
      "     support      itemsets\n",
      "2   0.768421          (徐峥)\n",
      "7   0.157895          (黄渤)\n",
      "11  0.094737      (黄渤, 徐峥)\n",
      "1   0.073684          (宁浩)\n",
      "0   0.063158         (于和伟)\n",
      "6   0.063158          (陶虹)\n",
      "8   0.063158      (宁浩, 徐峥)\n",
      "9   0.063158      (黄渤, 宁浩)\n",
      "13  0.063158  (宁浩, 黄渤, 徐峥)\n",
      "3   0.052632         (王宝强)\n",
      "4   0.052632          (王迅)\n",
      "5   0.052632         (陈凯歌)\n",
      "10  0.052632      (徐峥, 陶虹)\n",
      "12  0.052632      (黄渤, 王迅)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# 根据频繁项集计算关联规则，设置最小提升度为2\n",
    "rules =  association_rules(itemsets, metric='lift', min_threshold=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# 按照提升度从大到小进行排序\n",
    "rules = rules.sort_values(by=\"lift\" , ascending=False) \n",
    "#rules.to_csv('./rules.csv')\n",
    "print('-'*20, '关联规则', '-'*20)\n",
    "print(rules)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 关联规则 --------------------\n",
      "  antecedents consequents  antecedent support  consequent support   support  \\\n",
      "3    (黄渤, 徐峥)        (宁浩)            0.094737            0.073684  0.063158   \n",
      "4        (宁浩)    (黄渤, 徐峥)            0.073684            0.094737  0.063158   \n",
      "2    (徐峥, 宁浩)        (黄渤)            0.063158            0.157895  0.063158   \n",
      "7        (王迅)        (黄渤)            0.052632            0.157895  0.052632   \n",
      "5        (黄渤)    (徐峥, 宁浩)            0.157895            0.063158  0.063158   \n",
      "6        (黄渤)        (王迅)            0.157895            0.052632  0.052632   \n",
      "0        (黄渤)        (宁浩)            0.157895            0.073684  0.063158   \n",
      "1        (宁浩)        (黄渤)            0.073684            0.157895  0.063158   \n",
      "\n",
      "   confidence      lift  leverage  conviction  \n",
      "3    0.666667  9.047619  0.056177    2.778947  \n",
      "4    0.857143  9.047619  0.056177    6.336842  \n",
      "2    1.000000  6.333333  0.053186         inf  \n",
      "7    1.000000  6.333333  0.044321         inf  \n",
      "5    0.400000  6.333333  0.053186    1.561404  \n",
      "6    0.333333  6.333333  0.044321    1.421053  \n",
      "0    0.400000  5.428571  0.051524    1.543860  \n",
      "1    0.857143  5.428571  0.051524    5.894737  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "### 分析MovieLens 电影分类中的频繁项集和关联规则"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 数据加载\n",
    "movies = pd.read_csv(path+'/BI/movies.csv')\n",
    "#print(movies.head())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# 将genres进行one-hot编码（离散特征有多少取值，就用多少维来表示这个特征）\n",
    "print(movies['genres'])\n",
    "movies_hot_encoded = movies.drop('genres',1).join(movies.genres.str.get_dummies(sep='|'))\n",
    "print(movies_hot_encoded)\n",
    "\n",
    "pd.options.display.max_columns=100\n",
    "print(movies_hot_encoded.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        Adventure|Animation|Children|Comedy|Fantasy\n",
      "1                         Adventure|Children|Fantasy\n",
      "2                                     Comedy|Romance\n",
      "3                               Comedy|Drama|Romance\n",
      "4                                             Comedy\n",
      "                            ...                     \n",
      "27273                                         Comedy\n",
      "27274                                         Comedy\n",
      "27275                                      Adventure\n",
      "27276                             (no genres listed)\n",
      "27277                       Adventure|Fantasy|Horror\n",
      "Name: genres, Length: 27278, dtype: object\n",
      "       movieId                               title  (no genres listed)  \\\n",
      "0            1                    Toy Story (1995)                   0   \n",
      "1            2                      Jumanji (1995)                   0   \n",
      "2            3             Grumpier Old Men (1995)                   0   \n",
      "3            4            Waiting to Exhale (1995)                   0   \n",
      "4            5  Father of the Bride Part II (1995)                   0   \n",
      "...        ...                                 ...                 ...   \n",
      "27273   131254        Kein Bund für's Leben (2007)                   0   \n",
      "27274   131256       Feuer, Eis & Dosenbier (2002)                   0   \n",
      "27275   131258                  The Pirates (2014)                   0   \n",
      "27276   131260                 Rentun Ruusu (2001)                   1   \n",
      "27277   131262                    Innocence (2014)                   0   \n",
      "\n",
      "       Action  Adventure  Animation  Children  Comedy  Crime  Documentary  \\\n",
      "0           0          1          1         1       1      0            0   \n",
      "1           0          1          0         1       0      0            0   \n",
      "2           0          0          0         0       1      0            0   \n",
      "3           0          0          0         0       1      0            0   \n",
      "4           0          0          0         0       1      0            0   \n",
      "...       ...        ...        ...       ...     ...    ...          ...   \n",
      "27273       0          0          0         0       1      0            0   \n",
      "27274       0          0          0         0       1      0            0   \n",
      "27275       0          1          0         0       0      0            0   \n",
      "27276       0          0          0         0       0      0            0   \n",
      "27277       0          1          0         0       0      0            0   \n",
      "\n",
      "       Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  Romance  \\\n",
      "0          0        1          0       0     0        0        0        0   \n",
      "1          0        1          0       0     0        0        0        0   \n",
      "2          0        0          0       0     0        0        0        1   \n",
      "3          1        0          0       0     0        0        0        1   \n",
      "4          0        0          0       0     0        0        0        0   \n",
      "...      ...      ...        ...     ...   ...      ...      ...      ...   \n",
      "27273      0        0          0       0     0        0        0        0   \n",
      "27274      0        0          0       0     0        0        0        0   \n",
      "27275      0        0          0       0     0        0        0        0   \n",
      "27276      0        0          0       0     0        0        0        0   \n",
      "27277      0        1          0       1     0        0        0        0   \n",
      "\n",
      "       Sci-Fi  Thriller  War  Western  \n",
      "0           0         0    0        0  \n",
      "1           0         0    0        0  \n",
      "2           0         0    0        0  \n",
      "3           0         0    0        0  \n",
      "4           0         0    0        0  \n",
      "...       ...       ...  ...      ...  \n",
      "27273       0         0    0        0  \n",
      "27274       0         0    0        0  \n",
      "27275       0         0    0        0  \n",
      "27276       0         0    0        0  \n",
      "27277       0         0    0        0  \n",
      "\n",
      "[27278 rows x 22 columns]\n",
      "   movieId                               title  (no genres listed)  Action  \\\n",
      "0        1                    Toy Story (1995)                   0       0   \n",
      "1        2                      Jumanji (1995)                   0       0   \n",
      "2        3             Grumpier Old Men (1995)                   0       0   \n",
      "3        4            Waiting to Exhale (1995)                   0       0   \n",
      "4        5  Father of the Bride Part II (1995)                   0       0   \n",
      "\n",
      "   Adventure  Animation  Children  Comedy  Crime  Documentary  Drama  Fantasy  \\\n",
      "0          1          1         1       1      0            0      0        1   \n",
      "1          1          0         1       0      0            0      0        1   \n",
      "2          0          0         0       1      0            0      0        0   \n",
      "3          0          0         0       1      0            0      1        0   \n",
      "4          0          0         0       1      0            0      0        0   \n",
      "\n",
      "   Film-Noir  Horror  IMAX  Musical  Mystery  Romance  Sci-Fi  Thriller  War  \\\n",
      "0          0       0     0        0        0        0       0         0    0   \n",
      "1          0       0     0        0        0        0       0         0    0   \n",
      "2          0       0     0        0        0        1       0         0    0   \n",
      "3          0       0     0        0        0        1       0         0    0   \n",
      "4          0       0     0        0        0        0       0         0    0   \n",
      "\n",
      "   Western  \n",
      "0        0  \n",
      "1        0  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# 将movieId, title设置为index\n",
    "movies_hot_encoded.set_index(['movieId','title'],inplace=True)\n",
    "#print(movies_hot_encoded.head())\n",
    "# 挖掘频繁项集，最小支持度为0.02\n",
    "itemsets = apriori(movies_hot_encoded,use_colnames=True, min_support=0.02)\n",
    "# 按照支持度从大到小进行时候粗\n",
    "itemsets = itemsets.sort_values(by=\"support\" , ascending=False) \n",
    "print('-'*20, '频繁项集', '-'*20)\n",
    "print(itemsets)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 频繁项集 --------------------\n",
      "     support                  itemsets\n",
      "7   0.489185                   (Drama)\n",
      "4   0.306987                  (Comedy)\n",
      "14  0.153164                (Thriller)\n",
      "12  0.151294                 (Romance)\n",
      "0   0.129042                  (Action)\n",
      "5   0.107743                   (Crime)\n",
      "9   0.095718                  (Horror)\n",
      "31  0.094325          (Romance, Drama)\n",
      "26  0.093335           (Comedy, Drama)\n",
      "6   0.090586             (Documentary)\n",
      "1   0.085380               (Adventure)\n",
      "27  0.069470         (Romance, Comedy)\n",
      "32  0.068480         (Drama, Thriller)\n",
      "13  0.063898                  (Sci-Fi)\n",
      "28  0.062761            (Crime, Drama)\n",
      "11  0.055503                 (Mystery)\n",
      "8   0.051763                 (Fantasy)\n",
      "29  0.045165         (Crime, Thriller)\n",
      "20  0.044101           (Action, Drama)\n",
      "15  0.043772                     (War)\n",
      "3   0.041755                (Children)\n",
      "22  0.040655        (Action, Thriller)\n",
      "34  0.039336        (Thriller, Horror)\n",
      "10  0.037979                 (Musical)\n",
      "2   0.037649               (Animation)\n",
      "17  0.035633       (Action, Adventure)\n",
      "33  0.032774              (War, Drama)\n",
      "35  0.029144       (Thriller, Mystery)\n",
      "19  0.028118           (Action, Crime)\n",
      "36  0.027458  (Romance, Comedy, Drama)\n",
      "30  0.026432          (Drama, Mystery)\n",
      "18  0.026358          (Action, Comedy)\n",
      "25  0.025368           (Comedy, Crime)\n",
      "24  0.025295        (Drama, Adventure)\n",
      "37  0.024965  (Crime, Drama, Thriller)\n",
      "16  0.024782                 (Western)\n",
      "21  0.023499          (Action, Sci-Fi)\n",
      "23  0.022032       (Comedy, Adventure)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 根据频繁项集计算关联规则，设置最小提升度为2\n",
    "rules =  association_rules(itemsets, metric='lift', min_threshold=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 按照提升度从大到小进行排序\n",
    "rules = rules.sort_values(by=\"lift\" , ascending=False) \n",
    "#rules.to_csv('./rules.csv')\n",
    "print('-'*20, '关联规则', '-'*20)\n",
    "print(rules)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------- 关联规则 --------------------\n",
      "          antecedents        consequents  antecedent support  \\\n",
      "9           (Mystery)         (Thriller)            0.055503   \n",
      "8          (Thriller)          (Mystery)            0.153164   \n",
      "14            (Crime)  (Drama, Thriller)            0.107743   \n",
      "13  (Drama, Thriller)            (Crime)            0.068480   \n",
      "7         (Adventure)           (Action)            0.085380   \n",
      "6            (Action)        (Adventure)            0.129042   \n",
      "16           (Action)           (Sci-Fi)            0.129042   \n",
      "17           (Sci-Fi)           (Action)            0.063898   \n",
      "1          (Thriller)            (Crime)            0.153164   \n",
      "0             (Crime)         (Thriller)            0.107743   \n",
      "5            (Horror)         (Thriller)            0.095718   \n",
      "4          (Thriller)           (Horror)            0.153164   \n",
      "12     (Crime, Drama)         (Thriller)            0.062761   \n",
      "15         (Thriller)     (Crime, Drama)            0.153164   \n",
      "2            (Action)         (Thriller)            0.129042   \n",
      "3          (Thriller)           (Action)            0.153164   \n",
      "10           (Action)            (Crime)            0.129042   \n",
      "11            (Crime)           (Action)            0.107743   \n",
      "\n",
      "    consequent support   support  confidence      lift  leverage  conviction  \n",
      "9             0.153164  0.029144    0.525099  3.428352  0.020643    1.783185  \n",
      "8             0.055503  0.029144    0.190282  3.428352  0.020643    1.166453  \n",
      "14            0.068480  0.024965    0.231711  3.383632  0.017587    1.212461  \n",
      "13            0.107743  0.024965    0.364561  3.383632  0.017587    1.404159  \n",
      "7             0.129042  0.035633    0.417347  3.234198  0.024616    1.494813  \n",
      "6             0.085380  0.035633    0.276136  3.234198  0.024616    1.263525  \n",
      "16            0.063898  0.023499    0.182102  2.849906  0.015253    1.144523  \n",
      "17            0.129042  0.023499    0.367757  2.849906  0.015253    1.377568  \n",
      "1             0.107743  0.045165    0.294878  2.736877  0.028662    1.265394  \n",
      "0             0.153164  0.045165    0.419190  2.736877  0.028662    1.458027  \n",
      "5             0.153164  0.039336    0.410954  2.683100  0.024675    1.437639  \n",
      "4             0.095718  0.039336    0.256821  2.683100  0.024675    1.216776  \n",
      "12            0.153164  0.024965    0.397780  2.597093  0.015352    1.406192  \n",
      "15            0.062761  0.024965    0.162997  2.597093  0.015352    1.119755  \n",
      "2             0.153164  0.040655    0.315057  2.056994  0.020891    1.236360  \n",
      "3             0.129042  0.040655    0.265438  2.056994  0.020891    1.185684  \n",
      "10            0.107743  0.028118    0.217898  2.022393  0.014215    1.140845  \n",
      "11            0.129042  0.028118    0.260973  2.022393  0.014215    1.178520  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "## regression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "\"\"\"\n",
    "\t使用sklearn自带的糖尿病数据集，进行回归分析\n",
    "\tDiabetes：包含442个患者的10个生理特征（年龄，性别、体重、血压）和一年以后疾病级数指标\n",
    "\"\"\"\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import mean_squared_error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# 加载数据\n",
    "diabetes = datasets.load_diabetes()\n",
    "data = diabetes.data\n",
    "#import numpy as np\n",
    "#print(np.max(data))\n",
    "#data.to_csv('diabetes.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# 数据探索\n",
    "print(data.shape)\n",
    "print(data[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(442, 10)\n",
      "[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
      " -0.04340085 -0.00259226  0.01990842 -0.01764613]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# 训练集 70%，测试集30%\n",
    "train_x, test_x, train_y, test_y = train_test_split(diabetes.data, diabetes.target, test_size=0.3, random_state=14)\n",
    "print(len(train_x))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "309\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#回归训练及预测\n",
    "clf = linear_model.LinearRegression()\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "print(clf.coef_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[  32.03000032 -228.38626681  492.80665731  313.61844116 -991.31389923\n",
      "  551.99413533  190.16297006  278.51146815  781.03825662   72.08348977]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "#print(train_x.shape)\n",
    "#print(clf.score(test_x, test_y))\n",
    "pred_y = clf.predict(test_x)\n",
    "print(mean_squared_error(test_y, pred_y))\n",
    "r_sq = clf.score(train_x, train_y) #确定系数\n",
    "print('r_sq:', r_sq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3180.3670319563726\n",
      "r_sq: 0.5194074106259234\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "### Pearson"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def compute(x):\n",
    "    return 2*x*x+1\n",
    "x=[i for i in range(100)]\n",
    "y=[compute(i) for i in x]\n",
    "data = pd.DataFrame({'x':x,'y':y})\n",
    "# 查看pearson系数\n",
    "print(data.corr())\n",
    "print(data.corr(method='spearman'))\n",
    "print(data.corr(method='kendall'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          x         y\n",
      "x  1.000000  0.967644\n",
      "y  0.967644  1.000000\n",
      "     x    y\n",
      "x  1.0  1.0\n",
      "y  1.0  1.0\n",
      "     x    y\n",
      "x  1.0  1.0\n",
      "y  1.0  1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "### 回归分析\n",
    "import random\n",
    "from sklearn import linear_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "reg = linear_model.LinearRegression()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def generate(x):\n",
    "\ty = 2*x+10+random.random()\n",
    "\treturn y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for x in range(1000):\n",
    "\ttrain_x.append([x])\n",
    "\ty = generate(x)\n",
    "\ttrain_y.append([y])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "reg.fit (train_x, train_y)\n",
    "# coef_ 保存线性模型的系数w\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.99995684]]\n",
      "[10.52414906]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "## Market Basket"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from efficient_apriori import apriori\n",
    "trade_list=[]\n",
    "with open(path + \"/BI/Market_Basket_Optimisation.csv\") as ff:\n",
    "\tfor line in ff:\n",
    "\t\tline=line.strip()\n",
    "\t\ttrade=line.split(',')\n",
    "\t\ttrade_list.append(trade)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "#使用Apriori算法\n",
    "itemsets, rules = apriori(trade_list, min_support=0.05,  min_confidence=0.3)\n",
    "print(\"频繁项集：\", itemsets)\n",
    "print(\"关联规则：\", rules)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "频繁项集： {1: {('frozen smoothie',): 475, ('low fat yogurt',): 574, ('shrimp',): 536, ('olive oil',): 494, ('mineral water',): 1788, ('green tea',): 991, ('eggs',): 1348, ('burgers',): 654, ('turkey',): 469, ('whole wheat rice',): 439, ('milk',): 972, ('french fries',): 1282, ('soup',): 379, ('frozen vegetables',): 715, ('spaghetti',): 1306, ('cookies',): 603, ('cooking oil',): 383, ('chicken',): 450, ('chocolate',): 1229, ('tomatoes',): 513, ('pancakes',): 713, ('grated cheese',): 393, ('escalope',): 595, ('ground beef',): 737, ('cake',): 608}, 2: {('eggs', 'mineral water'): 382, ('mineral water', 'spaghetti'): 448, ('chocolate', 'mineral water'): 395}}\n",
      "关联规则： [{spaghetti} -> {mineral water}, {chocolate} -> {mineral water}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "32732e49ddba1da8b293d0354da9484fcc377d4ba69e79a82935691a68d0ecf6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}