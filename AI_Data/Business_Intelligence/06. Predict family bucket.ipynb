{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 预测全家桶与机器学习神器"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## Attrition"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### Attrition Catboost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "trainset=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "testset=pd.read_csv('../../resource/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "trainset['Attrition']=trainset['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = trainset.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = testset.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import catboost as cb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "model = cb.CatBoostClassifier(iterations=1000, \n",
    "                              depth=7, \n",
    "                              learning_rate=0.01, \n",
    "                              loss_function='Logloss', \n",
    "                              eval_metric='AUC',\n",
    "                              logging_level='Verbose', \n",
    "                              metric_period=50\n",
    "                             )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# 得到分类特征的列号\n",
    "categorical_features_indices = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    if X_train.columns.values[i] in attr:\n",
    "        categorical_features_indices.append(i)\n",
    "print(categorical_features_indices)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 3, 5, 6, 9, 13, 15, 19, 20]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=categorical_features_indices)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0:\ttest: 0.6390374\tbest: 0.6390374 (0)\ttotal: 2.7ms\tremaining: 2.69s\n",
      "50:\ttest: 0.7893703\tbest: 0.7893703 (50)\ttotal: 159ms\tremaining: 2.95s\n",
      "100:\ttest: 0.7950453\tbest: 0.7950453 (100)\ttotal: 329ms\tremaining: 2.93s\n",
      "150:\ttest: 0.8011568\tbest: 0.8011568 (150)\ttotal: 502ms\tremaining: 2.82s\n",
      "200:\ttest: 0.7958092\tbest: 0.8011568 (150)\ttotal: 695ms\tremaining: 2.76s\n",
      "250:\ttest: 0.8023573\tbest: 0.8023573 (250)\ttotal: 889ms\tremaining: 2.65s\n",
      "300:\ttest: 0.8034487\tbest: 0.8034487 (300)\ttotal: 1.06s\tremaining: 2.45s\n",
      "350:\ttest: 0.8046491\tbest: 0.8046491 (350)\ttotal: 1.24s\tremaining: 2.29s\n",
      "400:\ttest: 0.8030121\tbest: 0.8046491 (350)\ttotal: 1.43s\tremaining: 2.13s\n",
      "450:\ttest: 0.8054131\tbest: 0.8054131 (450)\ttotal: 1.64s\tremaining: 1.99s\n",
      "500:\ttest: 0.8067227\tbest: 0.8067227 (500)\ttotal: 1.86s\tremaining: 1.85s\n",
      "550:\ttest: 0.8062862\tbest: 0.8067227 (500)\ttotal: 2.04s\tremaining: 1.66s\n",
      "600:\ttest: 0.8056313\tbest: 0.8067227 (500)\ttotal: 2.23s\tremaining: 1.48s\n",
      "650:\ttest: 0.8053039\tbest: 0.8067227 (500)\ttotal: 2.42s\tremaining: 1.29s\n",
      "700:\ttest: 0.8061770\tbest: 0.8067227 (500)\ttotal: 2.61s\tremaining: 1.11s\n",
      "750:\ttest: 0.8082506\tbest: 0.8082506 (750)\ttotal: 2.78s\tremaining: 923ms\n",
      "800:\ttest: 0.8072684\tbest: 0.8082506 (750)\ttotal: 3.04s\tremaining: 756ms\n",
      "850:\ttest: 0.8073775\tbest: 0.8082506 (750)\ttotal: 3.23s\tremaining: 566ms\n",
      "900:\ttest: 0.8084688\tbest: 0.8084688 (900)\ttotal: 3.43s\tremaining: 377ms\n",
      "950:\ttest: 0.8092328\tbest: 0.8092328 (950)\ttotal: 3.62s\tremaining: 187ms\n",
      "999:\ttest: 0.8105424\tbest: 0.8105424 (999)\ttotal: 3.84s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8105423988\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fdc916a2090>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#model = cb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test)\n",
    "#predict = model.predict_proba(test)\n",
    "#print(predict)\n",
    "test['Attrition']=predict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "## 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "# test[['Attrition']].to_csv('submit_cb.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "## Attrition GBDT"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=trainset['Attrition'].map(lambda x:1 if x=='Yes' else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = trainset.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = testset.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# 采用回归算法，可以得到更好的AUC结果\n",
    "model = GradientBoostingRegressor(random_state=10)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(test)\n",
    "print(predict)\n",
    "test['Attrition']=predict\n",
    "#print(predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1.01678366e-01  4.47445681e-02  1.42121556e-01  7.57204880e-02\n",
      "  7.03200210e-01  3.70055651e-01  3.74376235e-01  4.37242139e-02\n",
      " -1.15634448e-01  2.97987772e-01  1.20779518e-01  1.09366950e-01\n",
      "  1.07679394e-01  7.66600582e-01  7.51844882e-02 -4.76111832e-02\n",
      "  4.28285053e-02 -1.09673242e-02  1.59486732e-01  9.62417811e-02\n",
      "  6.47325348e-01  1.10040397e-01 -9.94554567e-03 -4.55439809e-02\n",
      "  2.68815031e-01  3.37430996e-01  7.35105859e-02  1.06048931e-01\n",
      "  5.50770434e-01  4.15464265e-02  1.79826162e-01  1.01207422e-03\n",
      "  1.58722155e-01  1.58671176e-01  8.62998751e-02  2.67636183e-02\n",
      "  1.24005756e-01  9.94003577e-02  8.73177129e-02  1.59141438e-03\n",
      "  3.02853331e-02 -5.02317582e-03 -2.69498786e-03  8.75329962e-03\n",
      "  3.69313030e-02  5.03418977e-01  2.62794122e-01 -1.16559089e-02\n",
      "  8.28838190e-01  4.78927949e-01  2.30745577e-01  3.61855221e-01\n",
      "  1.97193403e-01  2.08480315e-01  4.27257886e-01  7.31510619e-02\n",
      " -4.10414290e-02  1.41280282e-01 -5.16541193e-02  4.63709471e-01\n",
      "  8.91047041e-03  1.57167715e-01  1.84855334e-01  1.13116428e-01\n",
      "  4.46265354e-01  1.00820826e-01  7.08375330e-02  6.37916953e-02\n",
      "  7.90271693e-02  3.50858142e-01  8.43984002e-02  2.85213179e-01\n",
      "  1.04485698e-01  1.20758657e-02  3.51095480e-02  8.00985610e-02\n",
      "  6.84449166e-02  1.13112977e-01  1.77433366e-01 -2.05739435e-02\n",
      " -4.76577275e-02  1.29302613e-02  3.32325238e-02  1.18673501e-01\n",
      "  5.91157913e-02  7.93768217e-02  6.01967826e-02  1.57592456e-01\n",
      "  6.66959752e-02  6.90960977e-02  4.96217528e-01  3.57899272e-02\n",
      "  1.39515858e-01  2.40791672e-01 -7.51708010e-02  6.94081026e-02\n",
      "  9.39873785e-02  3.21196083e-01 -4.76763552e-02  1.34821474e-02\n",
      "  2.19062667e-01  3.66039069e-01  3.44431854e-01  3.26254249e-02\n",
      " -1.90729947e-02  2.26095477e-02  1.04759230e-01  3.21919749e-01\n",
      "  5.20608898e-01  5.92291999e-02  2.76918434e-01  1.50335871e-01\n",
      " -2.32225872e-02  1.37745337e-01  7.02121029e-02  2.40504156e-02\n",
      " -1.83350362e-02  1.10830730e-01  4.37648859e-02 -6.21781805e-02\n",
      "  3.02702114e-02 -4.43218432e-03  1.99606416e-02  7.92852082e-01\n",
      "  3.00599518e-01  1.11339129e-01  6.41440161e-02  7.71254026e-02\n",
      "  8.88823641e-02  4.38784724e-02  7.20951064e-02  6.81299346e-01\n",
      "  4.45871282e-01  2.86304938e-01  3.35873763e-01  2.66461924e-01\n",
      "  3.68630236e-01  1.15704982e-01  8.92148111e-02  2.77847112e-01\n",
      "  2.01300768e-02  1.14969206e-01  1.57500157e-01  6.80522005e-02\n",
      "  2.32527064e-01  1.00925834e-02  6.68175914e-02  1.01203833e-01\n",
      "  1.53286650e-01 -4.04768746e-02 -1.66495630e-02  1.67942188e-01\n",
      "  6.05068896e-02  1.47024077e-01  4.82134726e-02  1.82307956e-02\n",
      "  2.78127362e-01  1.95225871e-01  8.52037177e-02 -4.86623546e-02\n",
      "  2.53996999e-01 -4.15455092e-02  3.25779791e-01  5.73075378e-01\n",
      "  2.07987130e-02  1.49099988e-01  3.15818350e-01 -2.40181674e-05\n",
      " -3.90114920e-02  9.46526743e-03  7.89657435e-02  8.87631693e-02\n",
      "  3.21649488e-02  1.93424518e-01  1.95749300e-01  3.31933538e-01\n",
      "  6.92359788e-02  3.06183063e-01  3.14928530e-01  1.55234252e-01\n",
      " -1.51408728e-02  1.88543423e-03  1.98220305e-02  6.86230677e-01\n",
      " -1.13091623e-02  1.57242051e-02  1.97955143e-01  2.36289404e-02\n",
      "  2.60205033e-01  1.32609768e-01  2.51464113e-01  7.41649588e-01\n",
      "  6.43095075e-02 -5.44132338e-02  1.32196173e-01  2.02623984e-01\n",
      "  8.47459908e-02  4.08807947e-02  5.58523111e-01  2.46524114e-02\n",
      "  2.43820956e-01  1.24861506e-01  1.58939457e-01  7.54770988e-03\n",
      "  7.92706304e-02  1.81286089e-01  4.30835527e-01 -3.80002905e-02\n",
      "  8.28918966e-02  1.47852343e-02  9.80401111e-02  1.94043180e-02\n",
      "  1.76909921e-02  9.43626951e-02  5.23583141e-02 -1.54912709e-02\n",
      "  4.83923119e-02  2.76540997e-01  5.03204846e-02  9.20246367e-01\n",
      "  8.07185777e-02  4.12035468e-01  5.09187992e-01  1.68638791e-01\n",
      "  2.80326779e-01 -1.08722422e-02  5.28288273e-02  3.70142537e-01\n",
      "  7.63654128e-01  2.13252369e-01 -7.84403781e-03  4.43898956e-01\n",
      " -1.39441774e-02  2.56857775e-02  7.14615543e-03  2.85003120e-01\n",
      "  4.64692435e-01 -9.25899031e-02  9.78737627e-02  8.90592044e-02\n",
      "  1.11027278e-01  1.05783790e-01  1.43637917e-02  9.55080031e-02\n",
      "  7.20672477e-02  4.54912103e-02  3.96397638e-02  4.13056135e-01\n",
      "  1.83594979e-02  1.28774900e-01  1.99024506e-01  1.38500037e-01\n",
      "  2.21309385e-01  1.65110705e-01  2.83837078e-01  2.80273587e-02\n",
      " -4.59208213e-02  6.94518598e-01  2.93032445e-01  3.64194473e-01\n",
      "  2.71657966e-01  7.24382244e-02  2.14046525e-01  1.35579809e-02\n",
      "  1.88356257e-01  2.93602451e-01 -5.80784811e-04  2.04865374e-01\n",
      "  1.28818792e-01  8.59591941e-02  1.00198600e-01 -2.14552034e-02\n",
      "  8.08882224e-02  4.95489702e-02  3.51382579e-03  3.90933827e-02\n",
      "  1.94128900e-01  3.30237759e-01  1.40952972e-01  1.91272969e-01\n",
      "  2.12574509e-01  1.84276049e-01  9.16673787e-02 -3.22161443e-02\n",
      "  1.19657691e-01  2.07738446e-01 -1.47083162e-01  9.64869527e-02\n",
      "  6.49368915e-02  3.51400437e-02  5.75395894e-02  5.23520231e-01\n",
      "  1.88642571e-02  1.34401530e-01]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "# test[['Attrition']].to_csv('submit_gbdt.csv')\n",
    "print('submit_gbdt.csv saved')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "submit_gbdt.csv saved\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "### Attrition LGB Onehot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "train=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('../../resource/BI/test.csv',index_col=0)\n",
    "#print(train['Attrition'].value_counts())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary:logistic', #\n",
    "                         'eval_metric' : 'auc',\n",
    "                         'eta' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'colsample_bytree':0.8,\n",
    "                         'subsample': 0.9,\n",
    "                         'subsample_freq': 8,\n",
    "                         'alpha': 0.6,\n",
    "                         'lambda': 0,\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# 使用DictVectorizer对离散值进行编码\n",
    "dvec = DictVectorizer(sparse=False)\n",
    "X_train = dvec.fit_transform(X_train.to_dict(orient='record'))\n",
    "X_valid = dvec.transform(X_valid.to_dict(orient='record'))\n",
    "temp_test = dvec.transform(test.to_dict(orient='record'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# 进行DMatrix转换\n",
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "valid_data = xgb.DMatrix(X_valid, label=y_valid)\n",
    "test_data = xgb.DMatrix(temp_test)\n",
    "\n",
    "model = xgb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test_data)\n",
    "test['Attrition']=predict\n",
    "print(predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[00:18:55] WARNING: /private/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/pip-req-build-nxocilc1/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"subsample_freq\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.83432\tvalid-auc:0.66839\n",
      "[25]\ttrain-auc:0.96482\tvalid-auc:0.74855\n",
      "[50]\ttrain-auc:0.97567\tvalid-auc:0.76416\n",
      "[75]\ttrain-auc:0.98638\tvalid-auc:0.77900\n",
      "[100]\ttrain-auc:0.98983\tvalid-auc:0.77715\n",
      "[125]\ttrain-auc:0.99280\tvalid-auc:0.78326\n",
      "[150]\ttrain-auc:0.99485\tvalid-auc:0.79395\n",
      "[175]\ttrain-auc:0.99713\tvalid-auc:0.79810\n",
      "[200]\ttrain-auc:0.99832\tvalid-auc:0.79996\n",
      "[225]\ttrain-auc:0.99893\tvalid-auc:0.80367\n",
      "[250]\ttrain-auc:0.99942\tvalid-auc:0.80541\n",
      "[275]\ttrain-auc:0.99969\tvalid-auc:0.80661\n",
      "[300]\ttrain-auc:0.99982\tvalid-auc:0.80683\n",
      "[325]\ttrain-auc:0.99991\tvalid-auc:0.81087\n",
      "[350]\ttrain-auc:0.99993\tvalid-auc:0.81251\n",
      "[375]\ttrain-auc:0.99996\tvalid-auc:0.81371\n",
      "[400]\ttrain-auc:0.99997\tvalid-auc:0.81665\n",
      "[425]\ttrain-auc:0.99999\tvalid-auc:0.81764\n",
      "[450]\ttrain-auc:1.00000\tvalid-auc:0.82058\n",
      "[475]\ttrain-auc:1.00000\tvalid-auc:0.82047\n",
      "[500]\ttrain-auc:1.00000\tvalid-auc:0.82102\n",
      "[525]\ttrain-auc:1.00000\tvalid-auc:0.82080\n",
      "[550]\ttrain-auc:1.00000\tvalid-auc:0.82047\n",
      "[575]\ttrain-auc:1.00000\tvalid-auc:0.82037\n",
      "[600]\ttrain-auc:1.00000\tvalid-auc:0.82135\n",
      "[625]\ttrain-auc:1.00000\tvalid-auc:0.82124\n",
      "[650]\ttrain-auc:1.00000\tvalid-auc:0.82037\n",
      "[675]\ttrain-auc:1.00000\tvalid-auc:0.81960\n",
      "[700]\ttrain-auc:1.00000\tvalid-auc:0.82080\n",
      "[725]\ttrain-auc:1.00000\tvalid-auc:0.82080\n",
      "[750]\ttrain-auc:1.00000\tvalid-auc:0.82015\n",
      "[775]\ttrain-auc:1.00000\tvalid-auc:0.82102\n",
      "[800]\ttrain-auc:1.00000\tvalid-auc:0.82167\n",
      "[825]\ttrain-auc:1.00000\tvalid-auc:0.82178\n",
      "[850]\ttrain-auc:1.00000\tvalid-auc:0.82222\n",
      "[875]\ttrain-auc:1.00000\tvalid-auc:0.82288\n",
      "[900]\ttrain-auc:1.00000\tvalid-auc:0.82255\n",
      "[925]\ttrain-auc:1.00000\tvalid-auc:0.82135\n",
      "[950]\ttrain-auc:1.00000\tvalid-auc:0.82178\n",
      "[975]\ttrain-auc:1.00000\tvalid-auc:0.82244\n",
      "[1000]\ttrain-auc:1.00000\tvalid-auc:0.82233\n",
      "[1025]\ttrain-auc:1.00000\tvalid-auc:0.82309\n",
      "[1050]\ttrain-auc:1.00000\tvalid-auc:0.82298\n",
      "[1075]\ttrain-auc:1.00000\tvalid-auc:0.82342\n",
      "[1100]\ttrain-auc:1.00000\tvalid-auc:0.82331\n",
      "[1125]\ttrain-auc:1.00000\tvalid-auc:0.82244\n",
      "[1150]\ttrain-auc:1.00000\tvalid-auc:0.82255\n",
      "[1175]\ttrain-auc:1.00000\tvalid-auc:0.82244\n",
      "[1200]\ttrain-auc:1.00000\tvalid-auc:0.82244\n",
      "[1225]\ttrain-auc:1.00000\tvalid-auc:0.82222\n",
      "[1250]\ttrain-auc:1.00000\tvalid-auc:0.82167\n",
      "[1275]\ttrain-auc:1.00000\tvalid-auc:0.82156\n",
      "[1288]\ttrain-auc:1.00000\tvalid-auc:0.82211\n",
      "[6.76429495e-02 4.01110062e-03 2.66334880e-02 3.59864347e-02\n",
      " 9.44155693e-01 9.75453630e-02 2.80261815e-01 2.23731082e-02\n",
      " 5.39018866e-03 2.55808622e-01 5.63223334e-03 5.92584945e-02\n",
      " 1.42322034e-02 9.18446362e-01 1.01263439e-02 6.45388674e-04\n",
      " 2.32080240e-02 1.03707742e-02 9.31843836e-03 1.04023024e-01\n",
      " 6.29730940e-01 1.09966621e-02 3.50746256e-03 2.56938883e-03\n",
      " 4.88870442e-01 3.08080882e-01 2.05488671e-02 5.22501068e-03\n",
      " 6.94125712e-01 6.10084878e-03 6.10272307e-03 9.14271921e-03\n",
      " 7.90145695e-02 5.76324128e-02 5.89376967e-03 5.90685336e-03\n",
      " 4.36512604e-02 1.35510284e-02 5.30924983e-02 3.43076177e-02\n",
      " 2.71688774e-02 8.13570246e-03 9.04591940e-03 1.47543075e-02\n",
      " 2.35710125e-02 5.66191375e-01 1.27863675e-01 1.78457494e-03\n",
      " 8.88712406e-01 5.89396834e-01 6.73072562e-02 5.55844903e-01\n",
      " 3.64756621e-02 3.35250199e-02 5.08734405e-01 6.95699966e-03\n",
      " 3.10283992e-03 1.82964038e-02 1.29797345e-03 2.46341184e-01\n",
      " 3.87218012e-03 3.65561135e-02 6.93682488e-03 5.61502902e-03\n",
      " 2.47387812e-01 1.80630684e-02 2.57866308e-02 1.29718827e-02\n",
      " 6.03612438e-02 2.35771853e-02 4.06959876e-02 1.20629340e-01\n",
      " 1.40492339e-02 4.06458043e-03 5.75215509e-03 3.27900350e-02\n",
      " 2.04440169e-02 1.04806516e-02 1.03175052e-01 2.37631449e-03\n",
      " 4.64742118e-03 3.57432663e-03 5.76118892e-03 9.58358776e-03\n",
      " 2.09054332e-02 1.03127863e-02 1.51583599e-02 6.70129135e-02\n",
      " 2.72240341e-02 3.88344303e-02 7.24764884e-01 5.72340982e-03\n",
      " 2.74497624e-02 4.07253683e-01 7.68308388e-03 6.31543016e-03\n",
      " 3.92758735e-02 1.72666982e-01 1.93244487e-03 2.82590464e-02\n",
      " 2.94720028e-02 1.76239207e-01 2.43631542e-01 1.51282493e-02\n",
      " 5.73875895e-03 4.46491083e-03 4.26261388e-02 5.48965991e-01\n",
      " 3.16387005e-02 1.41626028e-02 5.37521727e-02 3.90966050e-02\n",
      " 1.02879228e-02 9.10273194e-03 3.75438668e-02 1.87218990e-02\n",
      " 4.22240747e-03 2.48480607e-02 6.03173254e-03 6.85939624e-04\n",
      " 2.85953265e-02 3.80214187e-03 4.90126200e-03 8.84422362e-01\n",
      " 2.39874467e-01 1.44194113e-02 1.88569620e-03 2.24275589e-02\n",
      " 4.17369939e-02 6.96616340e-03 4.42835689e-03 3.91989648e-01\n",
      " 5.98220706e-01 1.23750605e-01 4.87225540e-02 3.75197604e-02\n",
      " 2.64022917e-01 2.00930107e-02 3.11678946e-02 9.55386553e-03\n",
      " 1.05934991e-02 2.44052541e-02 5.76123446e-02 7.20600858e-02\n",
      " 8.20308477e-02 6.96256896e-03 1.65238287e-02 1.11645777e-02\n",
      " 2.26042289e-02 9.16523952e-03 1.01184212e-02 6.94866478e-02\n",
      " 9.92663763e-03 6.33575246e-02 3.17790769e-02 1.56819131e-02\n",
      " 1.27787357e-02 6.80136010e-02 4.00722586e-02 7.94721022e-03\n",
      " 3.31515849e-01 4.44991514e-03 9.87472311e-02 8.15559745e-01\n",
      " 9.19122715e-03 7.34356344e-02 5.32856584e-01 3.15332436e-03\n",
      " 1.64396956e-03 7.07288506e-03 2.23737191e-02 1.83483250e-02\n",
      " 7.43345823e-03 7.45878741e-02 7.29693519e-03 5.26013151e-02\n",
      " 8.87047872e-03 3.79824825e-02 6.49774522e-02 1.01212658e-01\n",
      " 1.76855025e-03 8.06533638e-03 1.49846089e-03 7.80889153e-01\n",
      " 1.01765674e-02 3.62545415e-03 1.35573193e-01 7.96103477e-03\n",
      " 7.23590329e-02 3.67182009e-02 3.28822285e-01 8.47285986e-01\n",
      " 8.14886857e-03 1.60854915e-03 1.76208578e-02 2.83748191e-02\n",
      " 3.15778353e-03 7.99394399e-03 6.39628351e-01 2.30943244e-02\n",
      " 5.27547039e-02 8.64879601e-03 4.98356186e-02 4.37274761e-03\n",
      " 3.34769636e-02 3.06347664e-02 3.12551379e-01 5.49989240e-03\n",
      " 3.56262028e-02 1.56474821e-02 3.04304473e-02 9.26679187e-03\n",
      " 3.79501982e-03 1.02395415e-02 1.57671832e-02 4.54425858e-03\n",
      " 5.45748370e-03 1.23888776e-01 1.37338378e-02 2.67289340e-01\n",
      " 2.72608493e-02 1.75604150e-01 7.52256811e-01 5.45543246e-02\n",
      " 9.90229845e-02 7.40265334e-03 1.54791325e-02 4.64608967e-01\n",
      " 7.69294500e-01 3.37706581e-02 3.92593071e-03 9.50426012e-02\n",
      " 3.70784313e-03 1.53056141e-02 4.94588492e-03 8.70079622e-02\n",
      " 1.65182695e-01 1.53770193e-03 1.03495419e-02 1.02074109e-02\n",
      " 2.47621853e-02 1.85770635e-02 8.34676344e-03 1.58135816e-02\n",
      " 2.86089405e-02 5.40839788e-03 2.19341889e-02 2.19395220e-01\n",
      " 1.21189542e-02 1.80162434e-02 3.60318422e-02 2.74985582e-02\n",
      " 9.42697302e-02 1.41109787e-02 1.47727609e-01 1.69515852e-02\n",
      " 5.40760765e-03 9.12416041e-01 4.19841073e-02 4.97739226e-01\n",
      " 4.89705689e-02 1.67608131e-02 5.35255149e-02 2.30217557e-02\n",
      " 2.43908502e-02 1.98667541e-01 3.50254471e-03 4.99726832e-02\n",
      " 8.27085376e-02 2.54726061e-03 8.48796405e-03 4.37576929e-03\n",
      " 1.22514209e-02 1.02835000e-02 2.33529694e-03 3.21507230e-02\n",
      " 9.52470154e-02 8.16883445e-02 7.59432167e-02 4.16824333e-02\n",
      " 1.49552658e-01 2.57408153e-02 8.47490318e-03 8.54545739e-03\n",
      " 4.68360037e-02 1.06919818e-01 5.30153397e-04 4.34162393e-02\n",
      " 8.27982835e-03 8.65093060e-03 7.60132493e-03 4.58381504e-01\n",
      " 3.27736884e-03 1.81487612e-02]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "# test[['Attrition']].to_csv('submit_xgb.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "### Attrition LGB"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "train=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('../../resource/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "OSError",
     "evalue": "dlopen(/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f33d3cd1130d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# param = {\n",
    "#     'num_leaves':41,\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective':'binary',\n",
    "#     'max_depth':15,\n",
    "#     'learning_rate':0.001,\n",
    "#     'metric':'binary_logloss'}\n",
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary', #\n",
    "                         #'metric' : 'binary_logloss',\n",
    "                         'metric' : 'auc',\n",
    "#                          'metric' : 'self_metric',\n",
    "                         'learning_rate' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'feature_fraction':0.8,\n",
    "                         'bagging_fraction': 0.9,\n",
    "                         'bagging_freq': 8,\n",
    "                         'lambda_l1': 0.6,\n",
    "                         'lambda_l2': 0,\n",
    "#                          'scale_pos_weight':k,\n",
    "#                         'is_unbalance':True\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-03e76ad80875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "model = lgb.train(param,train_data,valid_sets=[train_data,valid_data],num_boost_round = 10000 ,early_stopping_rounds=200,verbose_eval=25, categorical_feature=attr)\n",
    "predict=model.predict(test)\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "#test['Attrition']=predict\n",
    "# test[['Attrition']].to_csv('submit_lgb.csv')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'lgb' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-008f602b15c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(predict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Attrition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lgb' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "### Attrition LR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "train=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('../../resource/BI/test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)\n",
    "# train.to_csv('train_label_encoder.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "model = LogisticRegression(max_iter=100, \n",
    "                           verbose=True, \n",
    "                           random_state=33,\n",
    "                           tol=1e-4\n",
    "                          )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "model.fit(X_train, y_train)\n",
    "predict = model.predict_proba(test)[:, 1]\n",
    "test['Attrition']=predict\n",
    "\n",
    "print(test['Attrition'])\n",
    "# test[['Attrition']].to_csv('submit_lr.csv')\n",
    "print('submit_lr.csv saved')\n",
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "#test[['Attrition']].to_csv('submit_lr.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "user_id\n",
      "442     0.107272\n",
      "1091    0.328287\n",
      "981     0.240421\n",
      "785     0.072643\n",
      "1332    0.350858\n",
      "          ...   \n",
      "1439    0.059847\n",
      "481     0.152947\n",
      "124     0.139410\n",
      "198     0.172930\n",
      "1229    0.221405\n",
      "Name: Attrition, Length: 294, dtype: float64\n",
      "submit_lr.csv saved\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/du/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "## Attrition NGBoost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "train=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('../../resource/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "import ngboost as ng\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "model = ng.NGBClassifier(n_estimators=1000, \n",
    "                              learning_rate=0.01, \n",
    "                              verbose=True, \n",
    "                              verbose_eval=50\n",
    "                             )\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[iter 0] loss=0.4190 val_loss=0.0000 scale=1.0000 norm=2.0000\n",
      "[iter 50] loss=0.3427 val_loss=0.0000 scale=1.0000 norm=1.7212\n",
      "[iter 100] loss=0.3005 val_loss=0.0000 scale=1.0000 norm=1.6308\n",
      "[iter 150] loss=0.2782 val_loss=0.0000 scale=1.0000 norm=1.5989\n",
      "[iter 200] loss=0.2683 val_loss=0.0000 scale=1.0000 norm=1.5975\n",
      "[iter 250] loss=0.2606 val_loss=0.0000 scale=1.0000 norm=1.5968\n",
      "[iter 300] loss=0.2531 val_loss=0.0000 scale=1.0000 norm=1.5853\n",
      "[iter 350] loss=0.2493 val_loss=0.0000 scale=1.0000 norm=1.5803\n",
      "[iter 400] loss=0.2465 val_loss=0.0000 scale=0.5000 norm=0.7870\n",
      "[iter 450] loss=0.2442 val_loss=0.0000 scale=0.1250 norm=0.1966\n",
      "[iter 500] loss=0.2421 val_loss=0.0000 scale=1.0000 norm=1.5711\n",
      "[iter 550] loss=0.2407 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 600] loss=0.2407 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 650] loss=0.2407 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 700] loss=0.2407 val_loss=0.0000 scale=0.0010 norm=0.0015\n",
      "[iter 750] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 800] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 850] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 900] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 950] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "NGBClassifier(n_estimators=1000,\n",
       "              random_state=RandomState(MT19937) at 0x7FDC80BCEE20,\n",
       "              verbose_eval=50)"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "#predict = model.predict(test)\n",
    "predict = model.predict_proba(test)[:, 1]\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "## 转化为二分类输出\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "# test[['Attrition']].to_csv('submit_ngb.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "### Attrition SVC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "train=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "test=test1=pd.read_csv('../../resource/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_valid = mms.fit_transform(X_valid)\n",
    "test = mms.fit_transform(test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "model = SVC(kernel='rbf', \n",
    "\t\t\tgamma=\"auto\",\n",
    "\t\t\tmax_iter=1000,\n",
    "\t\t\trandom_state=33,\n",
    "\t\t\tverbose=True,\n",
    "\t\t\ttol=1e-5,\n",
    "\t\t\tcache_size=50000\n",
    "\t\t   )\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(sum(y_train))\n",
    "\n",
    "model = LinearSVC(\n",
    "\t\t\tmax_iter=1000,\n",
    "\t\t\trandom_state=33,\n",
    "\t\t\tverbose=True,\n",
    "\t\t   )\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(test)\n",
    "print(predict)\n",
    "#print(test)\n",
    "#predict = model.predict_proba(test)[:, 1]\n",
    "test1['Attrition']=predict"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LibLinear][0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "# test1[['Attrition']].to_csv('submit_svc.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "### Attrition XGBoost"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "train=pd.read_csv('../../resource/BI/train.csv',index_col=0)\n",
    "test=pd.read_csv('../../resource/BI/test.csv',index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary:logistic', #\n",
    "                         'eval_metric' : 'auc',\n",
    "                         'eta' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'colsample_bytree':0.8,\n",
    "                         'subsample': 0.9,\n",
    "                         'subsample_freq': 8,\n",
    "                         'alpha': 0.6,\n",
    "                         'lambda': 0,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "valid_data = xgb.DMatrix(X_valid, label=y_valid)\n",
    "test_data = xgb.DMatrix(test)\n",
    "\n",
    "model = xgb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test_data)\n",
    "test['Attrition']=predict\n",
    "print(predict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[00:26:30] WARNING: /private/var/folders/h4/7cr1cmpn7v5b3x20_9wz8m740000gn/T/pip-req-build-nxocilc1/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"subsample_freq\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84716\tvalid-auc:0.68455\n",
      "[25]\ttrain-auc:0.96263\tvalid-auc:0.76094\n",
      "[50]\ttrain-auc:0.97222\tvalid-auc:0.77431\n",
      "[75]\ttrain-auc:0.98666\tvalid-auc:0.77769\n",
      "[100]\ttrain-auc:0.99135\tvalid-auc:0.77606\n",
      "[125]\ttrain-auc:0.99367\tvalid-auc:0.78097\n",
      "[150]\ttrain-auc:0.99584\tvalid-auc:0.78555\n",
      "[175]\ttrain-auc:0.99762\tvalid-auc:0.78937\n",
      "[200]\ttrain-auc:0.99852\tvalid-auc:0.79515\n",
      "[225]\ttrain-auc:0.99900\tvalid-auc:0.80007\n",
      "[250]\ttrain-auc:0.99930\tvalid-auc:0.80214\n",
      "[275]\ttrain-auc:0.99968\tvalid-auc:0.80127\n",
      "[300]\ttrain-auc:0.99983\tvalid-auc:0.80399\n",
      "[325]\ttrain-auc:0.99992\tvalid-auc:0.80399\n",
      "[350]\ttrain-auc:0.99995\tvalid-auc:0.80279\n",
      "[375]\ttrain-auc:0.99997\tvalid-auc:0.80530\n",
      "[400]\ttrain-auc:0.99998\tvalid-auc:0.80760\n",
      "[425]\ttrain-auc:1.00000\tvalid-auc:0.80781\n",
      "[450]\ttrain-auc:1.00000\tvalid-auc:0.81022\n",
      "[475]\ttrain-auc:1.00000\tvalid-auc:0.81131\n",
      "[500]\ttrain-auc:1.00000\tvalid-auc:0.81076\n",
      "[525]\ttrain-auc:1.00000\tvalid-auc:0.81131\n",
      "[550]\ttrain-auc:1.00000\tvalid-auc:0.81196\n",
      "[575]\ttrain-auc:1.00000\tvalid-auc:0.81141\n",
      "[600]\ttrain-auc:1.00000\tvalid-auc:0.81076\n",
      "[625]\ttrain-auc:1.00000\tvalid-auc:0.81163\n",
      "[650]\ttrain-auc:1.00000\tvalid-auc:0.81174\n",
      "[675]\ttrain-auc:1.00000\tvalid-auc:0.81185\n",
      "[700]\ttrain-auc:1.00000\tvalid-auc:0.81131\n",
      "[725]\ttrain-auc:1.00000\tvalid-auc:0.81251\n",
      "[750]\ttrain-auc:1.00000\tvalid-auc:0.81273\n",
      "[775]\ttrain-auc:1.00000\tvalid-auc:0.81458\n",
      "[800]\ttrain-auc:1.00000\tvalid-auc:0.81545\n",
      "[825]\ttrain-auc:1.00000\tvalid-auc:0.81600\n",
      "[850]\ttrain-auc:1.00000\tvalid-auc:0.81502\n",
      "[875]\ttrain-auc:1.00000\tvalid-auc:0.81600\n",
      "[900]\ttrain-auc:1.00000\tvalid-auc:0.81556\n",
      "[925]\ttrain-auc:1.00000\tvalid-auc:0.81513\n",
      "[950]\ttrain-auc:1.00000\tvalid-auc:0.81578\n",
      "[975]\ttrain-auc:1.00000\tvalid-auc:0.81698\n",
      "[1000]\ttrain-auc:1.00000\tvalid-auc:0.81676\n",
      "[1025]\ttrain-auc:1.00000\tvalid-auc:0.81698\n",
      "[1050]\ttrain-auc:1.00000\tvalid-auc:0.81709\n",
      "[1075]\ttrain-auc:1.00000\tvalid-auc:0.81687\n",
      "[1100]\ttrain-auc:1.00000\tvalid-auc:0.81676\n",
      "[1125]\ttrain-auc:1.00000\tvalid-auc:0.81676\n",
      "[1150]\ttrain-auc:1.00000\tvalid-auc:0.81665\n",
      "[1175]\ttrain-auc:1.00000\tvalid-auc:0.81709\n",
      "[1200]\ttrain-auc:1.00000\tvalid-auc:0.81676\n",
      "[1225]\ttrain-auc:1.00000\tvalid-auc:0.81665\n",
      "[1247]\ttrain-auc:1.00000\tvalid-auc:0.81665\n",
      "[8.75645056e-02 5.55810519e-03 2.38260329e-02 3.95015925e-02\n",
      " 9.16398466e-01 7.28884935e-02 3.67762238e-01 1.71045233e-02\n",
      " 5.68654062e-03 2.43635073e-01 5.98938158e-03 4.30202894e-02\n",
      " 2.60120034e-02 8.85016799e-01 1.10692158e-02 8.10798258e-04\n",
      " 2.42553465e-02 1.74575523e-02 1.62008964e-02 7.12528378e-02\n",
      " 6.79670691e-01 1.33510083e-02 3.56135634e-03 3.55942780e-03\n",
      " 4.94043708e-01 2.60168642e-01 2.44028512e-02 6.75430847e-03\n",
      " 6.73452973e-01 4.01564315e-03 1.22773461e-02 1.04120132e-02\n",
      " 1.15470774e-01 5.93645237e-02 6.05636789e-03 6.37468509e-03\n",
      " 4.59974781e-02 1.81645453e-02 9.68391001e-02 1.33369323e-02\n",
      " 3.31642628e-02 1.60623696e-02 9.47122183e-03 3.37651186e-02\n",
      " 2.16269288e-02 5.44342875e-01 1.21861182e-01 1.66394957e-03\n",
      " 9.03824270e-01 6.11919820e-01 8.49214941e-02 5.06523609e-01\n",
      " 5.77784628e-02 3.70067209e-02 5.26506305e-01 8.91713426e-03\n",
      " 2.97790673e-03 2.03948636e-02 2.30464828e-03 2.21850693e-01\n",
      " 6.07268512e-03 2.73109376e-02 1.28236162e-02 5.96423959e-03\n",
      " 2.42231041e-01 1.86271016e-02 2.07118411e-02 9.05169267e-03\n",
      " 7.24208355e-02 3.42075825e-02 6.49048015e-02 1.56399593e-01\n",
      " 2.87115183e-02 4.88726981e-03 3.60124954e-03 4.16693799e-02\n",
      " 2.19936911e-02 9.30505805e-03 1.02870502e-01 2.76159844e-03\n",
      " 3.23056313e-03 3.97223793e-03 7.51345698e-03 1.24556050e-02\n",
      " 1.95753928e-02 1.39180236e-02 1.68261062e-02 7.96042830e-02\n",
      " 3.02882940e-02 3.86400297e-02 7.38436937e-01 7.06413947e-03\n",
      " 2.44238842e-02 4.04458016e-01 5.98545419e-03 9.10441764e-03\n",
      " 2.59479731e-02 3.11524719e-01 1.46433734e-03 2.13899091e-02\n",
      " 3.71953025e-02 1.68107614e-01 3.05831522e-01 1.50440279e-02\n",
      " 4.32284269e-03 4.13600821e-03 4.32741530e-02 4.67090011e-01\n",
      " 5.02058789e-02 1.61698777e-02 8.71271044e-02 2.50747818e-02\n",
      " 1.02587305e-02 1.53473727e-02 5.11374064e-02 1.37745030e-02\n",
      " 4.74829506e-03 1.12885684e-02 6.06085313e-03 9.48780915e-04\n",
      " 2.83205640e-02 3.72294639e-03 6.12537609e-03 8.07152510e-01\n",
      " 2.72252083e-01 1.12641398e-02 1.58809812e-03 2.16721799e-02\n",
      " 4.08097394e-02 7.80361053e-03 4.32882318e-03 2.45986670e-01\n",
      " 4.31647658e-01 1.60858318e-01 3.88116911e-02 7.21299499e-02\n",
      " 2.68746674e-01 2.12037507e-02 1.62008647e-02 1.22241462e-02\n",
      " 9.94450413e-03 1.66444778e-02 6.07114844e-02 4.21055332e-02\n",
      " 7.05186725e-02 7.67887197e-03 1.66759528e-02 1.10568674e-02\n",
      " 2.72174552e-02 8.08719359e-03 1.01871686e-02 6.09516501e-02\n",
      " 1.09060770e-02 5.47301695e-02 4.61454429e-02 1.29976775e-02\n",
      " 1.44731868e-02 2.83906385e-02 4.66110483e-02 9.30048712e-03\n",
      " 3.76417369e-01 4.14223131e-03 1.10269852e-01 7.18887210e-01\n",
      " 1.07584465e-02 8.31649452e-02 4.95917439e-01 3.72731034e-03\n",
      " 2.03520060e-03 7.02588633e-03 1.79836582e-02 1.52869122e-02\n",
      " 1.05638178e-02 7.51118958e-02 6.04562741e-03 4.20156568e-02\n",
      " 7.14482507e-03 5.03720045e-02 7.19283372e-02 5.68569079e-02\n",
      " 1.50983466e-03 5.17370878e-03 1.56558468e-03 8.01290989e-01\n",
      " 9.29386355e-03 7.81155564e-03 1.53901801e-01 1.04507999e-02\n",
      " 6.00401238e-02 4.19182964e-02 3.02474499e-01 8.21880102e-01\n",
      " 1.64461397e-02 1.86255330e-03 1.58772189e-02 2.29864176e-02\n",
      " 5.75189060e-03 6.52994402e-03 5.94728053e-01 3.38583104e-02\n",
      " 4.27370109e-02 9.26744845e-03 9.51938778e-02 4.08506952e-03\n",
      " 9.90745425e-02 3.22654024e-02 3.87713253e-01 3.61106358e-03\n",
      " 3.57654132e-02 1.16823902e-02 2.48342734e-02 9.60877631e-03\n",
      " 3.84610472e-03 1.34891672e-02 2.04113647e-02 6.85609784e-03\n",
      " 4.07525711e-03 1.27736896e-01 1.96546186e-02 3.08871031e-01\n",
      " 2.01924313e-02 1.65774912e-01 7.31202245e-01 6.79448918e-02\n",
      " 9.01734084e-02 4.31668386e-03 1.81083549e-02 3.77139211e-01\n",
      " 6.37915850e-01 2.77713835e-02 3.21664009e-03 1.08523376e-01\n",
      " 3.74487066e-03 1.09792864e-02 4.25562775e-03 1.01915225e-01\n",
      " 1.41107708e-01 1.61231740e-03 1.34496037e-02 1.52694648e-02\n",
      " 2.02339068e-02 2.06658505e-02 7.60275358e-03 2.22794637e-02\n",
      " 3.09726391e-02 4.72538546e-03 2.69095581e-02 2.25356042e-01\n",
      " 1.00401053e-02 2.44082157e-02 3.39231044e-02 3.14030200e-02\n",
      " 1.15510292e-01 1.29057029e-02 1.27553463e-01 1.83539186e-02\n",
      " 5.59399789e-03 9.13509011e-01 4.58553545e-02 5.64379632e-01\n",
      " 6.29298985e-02 1.89157669e-02 7.29646608e-02 1.67028941e-02\n",
      " 3.08089070e-02 2.33513579e-01 4.68740752e-03 5.67401126e-02\n",
      " 8.43151361e-02 2.64176331e-03 1.57845244e-02 3.67205893e-03\n",
      " 6.93766866e-03 8.75851419e-03 2.58543016e-03 4.97082248e-02\n",
      " 7.85639659e-02 9.08537582e-02 5.07364646e-02 4.63187397e-02\n",
      " 9.17820632e-02 2.19892394e-02 1.21005392e-02 6.68789772e-03\n",
      " 3.85819152e-02 1.60983995e-01 5.84883732e-04 5.75074814e-02\n",
      " 9.16451123e-03 1.07924296e-02 1.04706073e-02 4.62771654e-01\n",
      " 2.89386231e-03 1.96503494e-02]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "# test[['Attrition']].to_csv('submit_xgb.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "## Manage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "e149da774136999aaf00d4dc0a73ad671f5415143dd98642849dddd1d0bac9b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}